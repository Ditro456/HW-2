{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "40ea6e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import pickle\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from common.layers import *\n",
    "from common.gradient import numerical_gradient\n",
    "\n",
    "\n",
    "class SimpleConvNet:\n",
    "    \n",
    "    def __init__(self, input_dim=(1, 28, 28), \n",
    "                 conv_param={'filter_num':30, 'filter_size':5, 'pad':0, 'stride':1},\n",
    "                 hidden_size=100, output_size=10, weight_init_std=0.01):\n",
    "        filter_num = conv_param['filter_num']\n",
    "        filter_size = conv_param['filter_size']\n",
    "        filter_pad = conv_param['pad']\n",
    "        filter_stride = conv_param['stride']\n",
    "        input_size = input_dim[1]\n",
    "        conv_output_size = (input_size - filter_size + 2*filter_pad) / filter_stride + 1\n",
    "        pool_output_size = int(filter_num * (conv_output_size/2) * (conv_output_size/2))\n",
    "\n",
    "        # 가중치 초기화\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * \\\n",
    "                            np.random.randn(filter_num, input_dim[0], filter_size, filter_size)\n",
    "        self.params['b1'] = np.zeros(filter_num)\n",
    "        self.params['W2'] = weight_init_std * \\\n",
    "                            np.random.randn(pool_output_size, hidden_size)\n",
    "        self.params['b2'] = np.zeros(hidden_size)\n",
    "        self.params['W3'] = weight_init_std * \\\n",
    "                            np.random.randn(hidden_size, output_size)\n",
    "        self.params['b3'] = np.zeros(output_size)\n",
    "\n",
    "        # 계층 생성\n",
    "        self.layers = OrderedDict()\n",
    "        self.layers['Conv1'] = Convolution(self.params['W1'], self.params['b1'],\n",
    "                                           conv_param['stride'], conv_param['pad'])\n",
    "        self.layers['Relu1'] = Relu()\n",
    "        self.layers['Pool1'] = Pooling(pool_h=2, pool_w=2, stride=2)\n",
    "        self.layers['Affine1'] = Affine(self.params['W2'], self.params['b2'])\n",
    "        self.layers['Relu2'] = Relu()\n",
    "        self.layers['Affine2'] = Affine(self.params['W3'], self.params['b3'])\n",
    "\n",
    "        self.last_layer = SoftmaxWithLoss()\n",
    "\n",
    "    def predict(self, x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def loss(self, x, t):\n",
    "         \n",
    "         \n",
    "        y = self.predict(x)\n",
    "        return self.last_layer.forward(y, t)\n",
    "\n",
    "    def accuracy(self, x, t, batch_size=100):\n",
    "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
    "        \n",
    "        acc = 0.0\n",
    "        \n",
    "        for i in range(int(x.shape[0] / batch_size)):\n",
    "            tx = x[i*batch_size:(i+1)*batch_size]\n",
    "            tt = t[i*batch_size:(i+1)*batch_size]\n",
    "            y = self.predict(tx)\n",
    "            y = np.argmax(y, axis=1)\n",
    "            acc += np.sum(y == tt) \n",
    "        \n",
    "        return acc / x.shape[0]\n",
    "\n",
    "    def numerical_gradient(self, x, t):\n",
    "         \n",
    "        loss_w = lambda w: self.loss(x, t)\n",
    "\n",
    "        grads = {}\n",
    "        for idx in (1, 2, 3):\n",
    "            grads['W' + str(idx)] = numerical_gradient(loss_w, self.params['W' + str(idx)])\n",
    "            grads['b' + str(idx)] = numerical_gradient(loss_w, self.params['b' + str(idx)])\n",
    "\n",
    "        return grads\n",
    "\n",
    "    def gradient(self, x, t):\n",
    "        \n",
    "        # forward\n",
    "        self.loss(x, t)\n",
    "\n",
    "        # backward\n",
    "        dout = 1\n",
    "        dout = self.last_layer.backward(dout)\n",
    "\n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "\n",
    "        # 결과 저장\n",
    "        grads = {}\n",
    "        grads['W1'], grads['b1'] = self.layers['Conv1'].dW, self.layers['Conv1'].db\n",
    "        grads['W2'], grads['b2'] = self.layers['Affine1'].dW, self.layers['Affine1'].db\n",
    "        grads['W3'], grads['b3'] = self.layers['Affine2'].dW, self.layers['Affine2'].db\n",
    "\n",
    "        return grads\n",
    "        \n",
    "    def save_params(self, file_name=\"params.pkl\"):\n",
    "        params = {}\n",
    "        for key, val in self.params.items():\n",
    "            params[key] = val\n",
    "        with open(file_name, 'wb') as f:\n",
    "            pickle.dump(params, f)\n",
    "\n",
    "    def load_params(self, file_name=\"params.pkl\"):\n",
    "        with open(file_name, 'rb') as f:\n",
    "            params = pickle.load(f)\n",
    "        for key, val in params.items():\n",
    "            self.params[key] = val\n",
    "\n",
    "        for i, key in enumerate(['Conv1', 'Affine1', 'Affine2']):\n",
    "            self.layers[key].W = self.params['W' + str(i+1)]\n",
    "            self.layers[key].b = self.params['b' + str(i+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "45d98e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting train-images-idx3-ubyte.gz to NumPy Array ...\n",
      "Done\n",
      "Converting train-labels-idx1-ubyte.gz to NumPy Array ...\n",
      "Done\n",
      "Converting t10k-images-idx3-ubyte.gz to NumPy Array ...\n",
      "Done\n",
      "Converting t10k-labels-idx1-ubyte.gz to NumPy Array ...\n",
      "Done\n",
      "Creating pickle file ...\n",
      "Done!\n",
      "train loss:2.299777060685799\n",
      "=== epoch:1, train acc:0.363, test acc:0.351 ===\n",
      "train loss:2.2961129181657585\n",
      "train loss:2.2875772965483416\n",
      "train loss:2.2772668600609\n",
      "train loss:2.2652208892557524\n",
      "train loss:2.2388828748333425\n",
      "train loss:2.2163686805977267\n",
      "train loss:2.1631177337168026\n",
      "train loss:2.1390987592574073\n",
      "train loss:2.1282910867731566\n",
      "train loss:2.045648345496055\n",
      "train loss:2.0255809734272634\n",
      "train loss:1.9457624849957187\n",
      "train loss:1.8520768432250634\n",
      "train loss:1.7855974152246912\n",
      "train loss:1.7363285358566756\n",
      "train loss:1.6152142791401576\n",
      "train loss:1.5011397760525025\n",
      "train loss:1.4312847903293402\n",
      "train loss:1.4933393500812138\n",
      "train loss:1.3842976547794814\n",
      "train loss:1.2948732040910844\n",
      "train loss:1.2274457622035486\n",
      "train loss:1.2207636627290392\n",
      "train loss:1.1457121104662709\n",
      "train loss:1.2286136965423125\n",
      "train loss:1.0796211062242436\n",
      "train loss:1.105609111085734\n",
      "train loss:0.980397582585312\n",
      "train loss:0.9997028104575282\n",
      "train loss:0.9514443718512636\n",
      "train loss:1.1047984819187842\n",
      "train loss:0.8732205985152345\n",
      "train loss:1.0382990097670828\n",
      "train loss:0.8818775458748942\n",
      "train loss:0.9818318200248464\n",
      "train loss:0.9106305776330557\n",
      "train loss:0.9044709487056077\n",
      "train loss:1.0737264593636633\n",
      "train loss:0.9289887220099413\n",
      "train loss:0.8858427728223199\n",
      "train loss:1.0263348605823486\n",
      "train loss:0.9615398982238426\n",
      "train loss:0.9199045579049987\n",
      "train loss:0.8836691902461523\n",
      "train loss:1.1041425443431196\n",
      "train loss:0.7939082899017654\n",
      "train loss:0.7547755231176575\n",
      "train loss:1.0811489382777026\n",
      "train loss:0.8258763806642996\n",
      "train loss:0.8844877989452999\n",
      "train loss:1.0633287515162564\n",
      "train loss:0.6448647932586227\n",
      "train loss:0.8579855679937753\n",
      "train loss:0.8261461231096929\n",
      "train loss:0.6546731229294316\n",
      "train loss:0.6864023052747311\n",
      "train loss:0.762859737879739\n",
      "train loss:0.7809674547557931\n",
      "train loss:0.7533391553099144\n",
      "train loss:0.6990076141962801\n",
      "train loss:0.5593721377439947\n",
      "train loss:0.7252993935240536\n",
      "train loss:0.8055122257856755\n",
      "train loss:0.7475940661781811\n",
      "train loss:0.6775382208758236\n",
      "train loss:0.629443423254076\n",
      "train loss:0.950914062135256\n",
      "train loss:0.7946111075123916\n",
      "train loss:0.5862954443482885\n",
      "train loss:0.7286062473666313\n",
      "train loss:0.8158956007694242\n",
      "train loss:1.0324956787056323\n",
      "train loss:0.8667342415270076\n",
      "train loss:0.6640468998002871\n",
      "train loss:0.7564253984365061\n",
      "train loss:0.6765444275059567\n",
      "train loss:0.6617016912389451\n",
      "train loss:0.965033433751485\n",
      "train loss:0.6544306813888123\n",
      "train loss:0.8108167845795851\n",
      "train loss:0.9164554078594397\n",
      "train loss:0.715483758785216\n",
      "train loss:0.800582810884631\n",
      "train loss:0.8471607534553784\n",
      "train loss:0.9718175224997582\n",
      "train loss:0.7221018711553054\n",
      "train loss:0.5582247774373618\n",
      "train loss:0.8287551560255575\n",
      "train loss:0.7737268249408118\n",
      "train loss:0.76428208722501\n",
      "train loss:0.5815158431799725\n",
      "train loss:0.6458172989472728\n",
      "train loss:0.6505998047124305\n",
      "train loss:0.5168519227943571\n",
      "train loss:0.6757946753223346\n",
      "train loss:0.8195378879272509\n",
      "train loss:0.6141200687164905\n",
      "train loss:0.44214777310473435\n",
      "train loss:0.7886694047870259\n",
      "train loss:0.6002605998044035\n",
      "train loss:0.6945907984160812\n",
      "train loss:0.6593987321942492\n",
      "train loss:0.8460355630155496\n",
      "train loss:0.5020122792481562\n",
      "train loss:0.6596070785617678\n",
      "train loss:0.579012844126323\n",
      "train loss:0.677015383572527\n",
      "train loss:0.6085569021127674\n",
      "train loss:0.6862896614783582\n",
      "train loss:0.6404928541541921\n",
      "train loss:0.5697691937821456\n",
      "train loss:0.5936614572169974\n",
      "train loss:0.5638225907819288\n",
      "train loss:0.5098154229711022\n",
      "train loss:0.6958574024042616\n",
      "train loss:0.8218706911102127\n",
      "train loss:0.522280989996046\n",
      "train loss:0.536350663164196\n",
      "train loss:0.6136643664415642\n",
      "train loss:0.5915165289204928\n",
      "train loss:0.6400113672575461\n",
      "train loss:0.5922591877037258\n",
      "train loss:0.6466876497584617\n",
      "train loss:0.42945702657451273\n",
      "train loss:0.6461135742187115\n",
      "train loss:0.6545813942214003\n",
      "train loss:0.7323678405795101\n",
      "train loss:0.6017433078818774\n",
      "train loss:0.5082173083379414\n",
      "train loss:0.6532221941838159\n",
      "train loss:0.6440324013932366\n",
      "train loss:0.6702445936317005\n",
      "train loss:0.6457456056030968\n",
      "train loss:0.6396459365169423\n",
      "train loss:0.6128168211762486\n",
      "train loss:0.5691713180583781\n",
      "train loss:0.4907625940216695\n",
      "train loss:0.6112022533320166\n",
      "train loss:0.6526015121787039\n",
      "train loss:0.5601822447591119\n",
      "train loss:0.5828616110798012\n",
      "train loss:0.5213182493915244\n",
      "train loss:0.6129488129870276\n",
      "train loss:0.5863280833872518\n",
      "train loss:0.7811454453325255\n",
      "train loss:0.5043602845884216\n",
      "train loss:0.5040249157345066\n",
      "train loss:0.6115396723099377\n",
      "train loss:0.7425119613453124\n",
      "train loss:0.5692271291063501\n",
      "train loss:0.6243462266312102\n",
      "train loss:0.5457655315034284\n",
      "train loss:0.6173727808302806\n",
      "train loss:0.6779226124255625\n",
      "train loss:0.49069702553053846\n",
      "train loss:0.5856573999940752\n",
      "train loss:0.7052333442806561\n",
      "train loss:0.6230603914735016\n",
      "train loss:0.5937194857851867\n",
      "train loss:0.6480931786173716\n",
      "train loss:0.8202048772877426\n",
      "train loss:0.4681051587911684\n",
      "train loss:0.5034285687373518\n",
      "train loss:0.735958788807135\n",
      "train loss:0.532438380606673\n",
      "train loss:0.39411965438981533\n",
      "train loss:0.49476654088024274\n",
      "train loss:0.580130767995183\n",
      "train loss:0.588327380618004\n",
      "train loss:0.5926096613444964\n",
      "train loss:0.4666529153502738\n",
      "train loss:0.752502520149125\n",
      "train loss:0.7553241988882877\n",
      "train loss:0.6655378907212328\n",
      "train loss:0.581595801748823\n",
      "train loss:0.6001737276998097\n",
      "train loss:0.5594466390823383\n",
      "train loss:0.604325951570718\n",
      "train loss:0.44916400155344016\n",
      "train loss:0.5486949791038963\n",
      "train loss:0.6765748568036761\n",
      "train loss:0.6255352175633194\n",
      "train loss:0.6870051192465322\n",
      "train loss:0.5286618197319659\n",
      "train loss:0.6154207336180743\n",
      "train loss:0.6170904657527833\n",
      "train loss:0.4924236779124631\n",
      "train loss:0.5559872572393185\n",
      "train loss:0.6209749547068716\n",
      "train loss:0.4487879731143274\n",
      "train loss:0.5351784425219374\n",
      "train loss:0.6365464461238172\n",
      "train loss:0.6540432427739646\n",
      "train loss:0.602613246493733\n",
      "train loss:0.5417683191546767\n",
      "train loss:0.4685545814675093\n",
      "train loss:0.4439828662398719\n",
      "train loss:0.4878576104309726\n",
      "train loss:0.6470747677012264\n",
      "train loss:0.4922216399122186\n",
      "train loss:0.46604763536630317\n",
      "train loss:0.5070710376202936\n",
      "train loss:0.49028754253650036\n",
      "train loss:0.5140135274111064\n",
      "train loss:0.5969974463283324\n",
      "train loss:0.6115591660966276\n",
      "train loss:0.5942602293022036\n",
      "train loss:0.4955418034383431\n",
      "train loss:0.7297593472436904\n",
      "train loss:0.7128928891687499\n",
      "train loss:0.5286289449424647\n",
      "train loss:0.5331483237023105\n",
      "train loss:0.6126905521635668\n",
      "train loss:0.6508473359008962\n",
      "train loss:0.5217441126966276\n",
      "train loss:0.5380131004488433\n",
      "train loss:0.5735445429241289\n",
      "train loss:0.44037387608202516\n",
      "train loss:0.5402072836962134\n",
      "train loss:0.6426222681582484\n",
      "train loss:0.6330266600191892\n",
      "train loss:0.7153395990365459\n",
      "train loss:0.5239452371874596\n",
      "train loss:0.5957654019258016\n",
      "train loss:0.4900571408394173\n",
      "train loss:0.6248800126085707\n",
      "train loss:0.5537792654718399\n",
      "train loss:0.5335288118275617\n",
      "train loss:0.5830197149953799\n",
      "train loss:0.47790476472131316\n",
      "train loss:0.537449029284658\n",
      "train loss:0.450589827438652\n",
      "train loss:0.5274633939289337\n",
      "train loss:0.6802120794088813\n",
      "train loss:0.54454044789163\n",
      "train loss:0.6563467818403015\n",
      "train loss:0.504822994529439\n",
      "train loss:0.4745160381031468\n",
      "train loss:0.5814658540787304\n",
      "train loss:0.40547208252005873\n",
      "train loss:0.6873798928214033\n",
      "train loss:0.4435630400337518\n",
      "train loss:0.5824695458630609\n",
      "train loss:0.4424548843320041\n",
      "train loss:0.5821422405900261\n",
      "train loss:0.517317160680928\n",
      "train loss:0.432946387706465\n",
      "train loss:0.5590556833269925\n",
      "train loss:0.7829831002696457\n",
      "train loss:0.5339269329732601\n",
      "train loss:0.4322529075014455\n",
      "train loss:0.40852096910264923\n",
      "train loss:0.6324285239234044\n",
      "train loss:0.6073075840521527\n",
      "train loss:0.6062571308794337\n",
      "train loss:0.5145089446196299\n",
      "train loss:0.5220510535053269\n",
      "train loss:0.6206446517657699\n",
      "train loss:0.4230422018199229\n",
      "train loss:0.4951379114054696\n",
      "train loss:0.5209756365098134\n",
      "train loss:0.505141195996891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.5177567510810669\n",
      "train loss:0.5625158204196401\n",
      "train loss:0.5336637201571847\n",
      "train loss:0.7182675504605112\n",
      "train loss:0.5683646726368798\n",
      "train loss:0.4102421701271625\n",
      "train loss:0.6123527435402542\n",
      "train loss:0.4604141460122224\n",
      "train loss:0.5635116218141647\n",
      "train loss:0.5224618409901044\n",
      "train loss:0.4692708889916808\n",
      "train loss:0.7009281629311619\n",
      "train loss:0.4323314905469563\n",
      "train loss:0.5810940099363247\n",
      "train loss:0.45892917970264124\n",
      "train loss:0.48075049268038633\n",
      "train loss:0.5357238335901395\n",
      "train loss:0.5754192223921653\n",
      "train loss:0.41854775402534455\n",
      "train loss:0.5127467527453807\n",
      "train loss:0.671361243112595\n",
      "train loss:0.4621525078601596\n",
      "train loss:0.5974871248791829\n",
      "train loss:0.6053477672204809\n",
      "train loss:0.6352668351056896\n",
      "train loss:0.5251836240775996\n",
      "train loss:0.574505126500913\n",
      "train loss:0.49925823239093814\n",
      "train loss:0.6374468848038214\n",
      "train loss:0.5679720320760934\n",
      "train loss:0.5573902010930969\n",
      "train loss:0.5324138222680478\n",
      "train loss:0.6419997234633954\n",
      "train loss:0.5322108226704464\n",
      "train loss:0.5095369757373883\n",
      "train loss:0.6310273736159071\n",
      "train loss:0.512834669978145\n",
      "train loss:0.5694420265048281\n",
      "train loss:0.4953341976601301\n",
      "train loss:0.668074972058879\n",
      "train loss:0.6804307553253766\n",
      "train loss:0.5465470836396463\n",
      "train loss:0.5770398544141707\n",
      "train loss:0.50356261525339\n",
      "train loss:0.5384621333587074\n",
      "train loss:0.6368130774504864\n",
      "train loss:0.5848332935250159\n",
      "train loss:0.5466333244788044\n",
      "train loss:0.5733089561526602\n",
      "train loss:0.4978341766769702\n",
      "train loss:0.5312765040708163\n",
      "train loss:0.5478099335141244\n",
      "train loss:0.4545560715967952\n",
      "train loss:0.5018460464078184\n",
      "train loss:0.5284656951095932\n",
      "train loss:0.5806073344004642\n",
      "train loss:0.3872123432978399\n",
      "train loss:0.5854548973708096\n",
      "train loss:0.4574799954054531\n",
      "train loss:0.4023086840268115\n",
      "train loss:0.6349576882589422\n",
      "train loss:0.598718493190068\n",
      "train loss:0.5434759896342067\n",
      "train loss:0.5451531036197161\n",
      "train loss:0.5241268046709401\n",
      "train loss:0.6465024417681292\n",
      "train loss:0.5439144874650667\n",
      "train loss:0.44536932609514546\n",
      "train loss:0.405242094568074\n",
      "train loss:0.4943959902021728\n",
      "train loss:0.5116765365726383\n",
      "train loss:0.5122870285716885\n",
      "train loss:0.47050859620588037\n",
      "train loss:0.3708317202263447\n",
      "train loss:0.46440549707395445\n",
      "train loss:0.4749342920024606\n",
      "train loss:0.5455768709352232\n",
      "train loss:0.6280934698561144\n",
      "train loss:0.5589357808737718\n",
      "train loss:0.3711627048884358\n",
      "train loss:0.4202617083478041\n",
      "train loss:0.5019906834111572\n",
      "train loss:0.4082621702189683\n",
      "train loss:0.5711690094545823\n",
      "train loss:0.5958140276374028\n",
      "train loss:0.47014606529871883\n",
      "train loss:0.5882139014690952\n",
      "train loss:0.570417570499035\n",
      "train loss:0.6493146024973617\n",
      "train loss:0.5664900881490681\n",
      "train loss:0.6490908862451299\n",
      "train loss:0.5415053399695943\n",
      "train loss:0.5613491782803086\n",
      "train loss:0.5102210287484248\n",
      "train loss:0.43260926576102604\n",
      "train loss:0.49357202855652665\n",
      "train loss:0.41880699376059477\n",
      "train loss:0.4317510832591124\n",
      "train loss:0.6524259177027413\n",
      "train loss:0.5252093158456748\n",
      "train loss:0.5021242040907373\n",
      "train loss:0.4901511755215935\n",
      "train loss:0.5141247257743723\n",
      "train loss:0.45646957065561616\n",
      "train loss:0.46456802174400763\n",
      "train loss:0.4982230053318519\n",
      "train loss:0.3489588695972504\n",
      "train loss:0.43165698123250335\n",
      "train loss:0.5891592934416601\n",
      "train loss:0.6725689811145661\n",
      "train loss:0.40669767320621486\n",
      "train loss:0.4408300486696967\n",
      "train loss:0.49958639616032857\n",
      "train loss:0.6293915716542122\n",
      "train loss:0.5058047030099627\n",
      "train loss:0.41608038604802755\n",
      "train loss:0.385441510470973\n",
      "train loss:0.6241345884397653\n",
      "train loss:0.3819100806693021\n",
      "train loss:0.6166963295591271\n",
      "train loss:0.3350669073295208\n",
      "train loss:0.5158487062704853\n",
      "train loss:0.5461613495817094\n",
      "train loss:0.4977383843440085\n",
      "train loss:0.4945506665818058\n",
      "train loss:0.4662451243091924\n",
      "train loss:0.4626779561982378\n",
      "train loss:0.3231526238543719\n",
      "train loss:0.4926361434633473\n",
      "train loss:0.5535173994707054\n",
      "train loss:0.5146964506991444\n",
      "train loss:0.5620864970528386\n",
      "train loss:0.4577558777514439\n",
      "train loss:0.5457864213912328\n",
      "train loss:0.46687804139729605\n",
      "train loss:0.3913023134441994\n",
      "train loss:0.42074473803135715\n",
      "train loss:0.458088727060396\n",
      "train loss:0.4396772244985938\n",
      "train loss:0.5613439366399819\n",
      "train loss:0.5420989031229614\n",
      "train loss:0.4512145240253737\n",
      "train loss:0.4506291808336891\n",
      "train loss:0.4728440924867367\n",
      "train loss:0.6442819759241794\n",
      "train loss:0.6365051510407153\n",
      "train loss:0.4544304692238165\n",
      "train loss:0.42993561510666245\n",
      "train loss:0.3875247611673363\n",
      "train loss:0.40883997105369846\n",
      "train loss:0.5860230823504667\n",
      "train loss:0.4310026534684371\n",
      "train loss:0.34955585853142457\n",
      "train loss:0.5120541698345403\n",
      "train loss:0.5370472029739252\n",
      "train loss:0.4026129333728711\n",
      "train loss:0.41061201306404205\n",
      "train loss:0.4365968601949096\n",
      "train loss:0.6057747052649307\n",
      "train loss:0.36311897135936183\n",
      "train loss:0.3871346403624908\n",
      "train loss:0.5436904118896186\n",
      "train loss:0.37880098556005704\n",
      "train loss:0.4663362796878214\n",
      "train loss:0.4148850696957919\n",
      "train loss:0.3864563270346916\n",
      "train loss:0.4600806572885696\n",
      "train loss:0.5585376610684964\n",
      "train loss:0.36244169633819434\n",
      "train loss:0.5089508510216101\n",
      "train loss:0.43081426976034665\n",
      "train loss:0.37691329210794755\n",
      "train loss:0.3453570101252037\n",
      "train loss:0.494678967605415\n",
      "train loss:0.3768216698904903\n",
      "train loss:0.3312226079174399\n",
      "train loss:0.3777793157315534\n",
      "train loss:0.34889200514324903\n",
      "train loss:0.4484881322494496\n",
      "train loss:0.4482953233854143\n",
      "train loss:0.4515622058665081\n",
      "train loss:0.5072784614459218\n",
      "train loss:0.4575731055312876\n",
      "train loss:0.5132512207481699\n",
      "train loss:0.5860536560589786\n",
      "train loss:0.28722621005105065\n",
      "train loss:0.36677563334324126\n",
      "train loss:0.4959018953305603\n",
      "train loss:0.42228374992023576\n",
      "train loss:0.43690687772076026\n",
      "train loss:0.49923239347098547\n",
      "train loss:0.4199273322976487\n",
      "train loss:0.43184044581151526\n",
      "train loss:0.4779122994234941\n",
      "train loss:0.3816260944756614\n",
      "train loss:0.34949330149297536\n",
      "train loss:0.4032809357636703\n",
      "train loss:0.4278460440444684\n",
      "train loss:0.5769029285403956\n",
      "train loss:0.30277973662517516\n",
      "train loss:0.4481328376379058\n",
      "train loss:0.43546583590880755\n",
      "train loss:0.381502317218773\n",
      "train loss:0.5563735851448662\n",
      "train loss:0.5942017328233308\n",
      "train loss:0.5750625245130095\n",
      "train loss:0.5215005612729864\n",
      "train loss:0.44069899046389394\n",
      "train loss:0.5781352146452675\n",
      "train loss:0.37113317431244897\n",
      "train loss:0.46190463666692666\n",
      "train loss:0.5565480008944692\n",
      "train loss:0.48436345212128395\n",
      "train loss:0.47176921176553727\n",
      "train loss:0.3620411779173692\n",
      "train loss:0.4342982555196942\n",
      "train loss:0.4408632749980964\n",
      "train loss:0.47823285021654927\n",
      "train loss:0.5028567258953354\n",
      "train loss:0.41241877173628977\n",
      "train loss:0.5107530575222119\n",
      "train loss:0.4892949557599572\n",
      "train loss:0.361078294111415\n",
      "train loss:0.39583205504997127\n",
      "train loss:0.5611343037582579\n",
      "train loss:0.44422302500045113\n",
      "train loss:0.5329940085272963\n",
      "train loss:0.42310397531860255\n",
      "train loss:0.5516241982006518\n",
      "train loss:0.32059853789845305\n",
      "train loss:0.5016199067752267\n",
      "train loss:0.40688740777863075\n",
      "train loss:0.4399371613610699\n",
      "train loss:0.4169057189780831\n",
      "train loss:0.5988399449696636\n",
      "train loss:0.3951111754070179\n",
      "train loss:0.457417706330574\n",
      "train loss:0.48836184173343755\n",
      "train loss:0.46490337196245485\n",
      "train loss:0.41920579776528766\n",
      "train loss:0.499825876933979\n",
      "train loss:0.37736781402335806\n",
      "train loss:0.30710511349511693\n",
      "train loss:0.4804719446457673\n",
      "train loss:0.6026704837606903\n",
      "train loss:0.4452439132673714\n",
      "train loss:0.47590851578111015\n",
      "train loss:0.5059040829053597\n",
      "train loss:0.5414689500176789\n",
      "train loss:0.7054659324847223\n",
      "train loss:0.3823717729983461\n",
      "train loss:0.4330178382080305\n",
      "train loss:0.5138946847752939\n",
      "train loss:0.3118174641137639\n",
      "train loss:0.5441166948094672\n",
      "train loss:0.4695338912110477\n",
      "train loss:0.3507726016789674\n",
      "train loss:0.54099241671637\n",
      "train loss:0.499260297061933\n",
      "train loss:0.43676351173584366\n",
      "train loss:0.4041585454300801\n",
      "train loss:0.5324550865249053\n",
      "train loss:0.465300219367058\n",
      "train loss:0.5383722960520626\n",
      "train loss:0.4918824010273908\n",
      "train loss:0.3455277506508617\n",
      "train loss:0.40054665503356973\n",
      "train loss:0.40817145241893754\n",
      "train loss:0.45275841738249506\n",
      "train loss:0.4093240468738073\n",
      "train loss:0.4459599930212075\n",
      "train loss:0.48530636600678967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.3664650038106021\n",
      "train loss:0.311077055719451\n",
      "train loss:0.3896287997761539\n",
      "train loss:0.4496724490707129\n",
      "train loss:0.4191704285936553\n",
      "train loss:0.5605802832754534\n",
      "train loss:0.5415784797214627\n",
      "train loss:0.4118318569603337\n",
      "train loss:0.5227371455242035\n",
      "train loss:0.4065244311753258\n",
      "train loss:0.3157192979303285\n",
      "train loss:0.34719007308370003\n",
      "train loss:0.26073205518973047\n",
      "train loss:0.3179136003997159\n",
      "train loss:0.3345430578124444\n",
      "train loss:0.5244079310947358\n",
      "train loss:0.4424209284904844\n",
      "train loss:0.4100572878390289\n",
      "train loss:0.43793923081237357\n",
      "train loss:0.29464301662919196\n",
      "train loss:0.3393857835731415\n",
      "train loss:0.5510915905344684\n",
      "train loss:0.6264205052913376\n",
      "train loss:0.5349415080012793\n",
      "train loss:0.3648927588343978\n",
      "train loss:0.45450628743027865\n",
      "train loss:0.4331386175238087\n",
      "train loss:0.3928623681397089\n",
      "train loss:0.3868978783884413\n",
      "train loss:0.4329099091086502\n",
      "train loss:0.4886125143225026\n",
      "train loss:0.4169132897897462\n",
      "train loss:0.4086023447853934\n",
      "train loss:0.37046850476920584\n",
      "train loss:0.42011645703619804\n",
      "train loss:0.38979140603437623\n",
      "train loss:0.4785569514609858\n",
      "train loss:0.3336847811420857\n",
      "train loss:0.4202606205290615\n",
      "train loss:0.38718672442632124\n",
      "train loss:0.418265035289812\n",
      "train loss:0.5183092763358755\n",
      "train loss:0.2616966222108344\n",
      "train loss:0.49113271514942985\n",
      "train loss:0.4272177888458713\n",
      "train loss:0.41723146309378284\n",
      "train loss:0.44721421890716456\n",
      "train loss:0.4336695208584214\n",
      "train loss:0.4105975591703311\n",
      "train loss:0.5496798741401888\n",
      "train loss:0.3874604345348133\n",
      "train loss:0.5118530623160148\n",
      "train loss:0.480148375242454\n",
      "train loss:0.33085668416837277\n",
      "train loss:0.5891954849671155\n",
      "train loss:0.39562887873220487\n",
      "train loss:0.44491532599418077\n",
      "train loss:0.4132827995407134\n",
      "train loss:0.4239813598592886\n",
      "train loss:0.5654138540174511\n",
      "train loss:0.5040172901929607\n",
      "train loss:0.4004268414135901\n",
      "train loss:0.42876617041255893\n",
      "train loss:0.42538902125797806\n",
      "train loss:0.40970486585879967\n",
      "train loss:0.5962972362323041\n",
      "=== epoch:2, train acc:0.874, test acc:0.826 ===\n",
      "train loss:0.7015558096211233\n",
      "train loss:0.4100261985094493\n",
      "train loss:0.2961990040750108\n",
      "train loss:0.5866217671283569\n",
      "train loss:0.4549069164269396\n",
      "train loss:0.5267505353275069\n",
      "train loss:0.47268668108648976\n",
      "train loss:0.40578499183569194\n",
      "train loss:0.5011138683955337\n",
      "train loss:0.3949426722016596\n",
      "train loss:0.4671630405630872\n",
      "train loss:0.43273499813241884\n",
      "train loss:0.47114104625647363\n",
      "train loss:0.4764339110822201\n",
      "train loss:0.5222723237235769\n",
      "train loss:0.43569395299186425\n",
      "train loss:0.4133650128352722\n",
      "train loss:0.32664460483279517\n",
      "train loss:0.3743511752693279\n",
      "train loss:0.5732813185937045\n",
      "train loss:0.34989782088021637\n",
      "train loss:0.39060002943628297\n",
      "train loss:0.41623294259332416\n",
      "train loss:0.6623096733443998\n",
      "train loss:0.5918175094693846\n",
      "train loss:0.5277215515517062\n",
      "train loss:0.42894787415961116\n",
      "train loss:0.38313791833678884\n",
      "train loss:0.3836433603280063\n",
      "train loss:0.4016485168105299\n",
      "train loss:0.3405748766049728\n",
      "train loss:0.5275530789992472\n",
      "train loss:0.4187525573439692\n",
      "train loss:0.4889823382081683\n",
      "train loss:0.515785327272306\n",
      "train loss:0.29845422675828936\n",
      "train loss:0.35563721747258936\n",
      "train loss:0.396173285457507\n",
      "train loss:0.393383225648511\n",
      "train loss:0.26673581691671633\n",
      "train loss:0.46741836471803055\n",
      "train loss:0.2945541103470546\n",
      "train loss:0.4614861584249413\n",
      "train loss:0.38589236162264023\n",
      "train loss:0.423300557164686\n",
      "train loss:0.404644656989138\n",
      "train loss:0.4884860890522862\n",
      "train loss:0.5230826815579505\n",
      "train loss:0.2884356033448142\n",
      "train loss:0.39260025484485017\n",
      "train loss:0.43650699720178165\n",
      "train loss:0.42302174483171917\n",
      "train loss:0.3019513128138069\n",
      "train loss:0.33867316144644555\n",
      "train loss:0.3798265401047327\n",
      "train loss:0.3970360175715061\n",
      "train loss:0.33788210869658153\n",
      "train loss:0.4169209679643051\n",
      "train loss:0.33867198292289674\n",
      "train loss:0.44938333968639393\n",
      "train loss:0.37327141867741204\n",
      "train loss:0.4155157998311174\n",
      "train loss:0.42244520559620713\n",
      "train loss:0.34493568921310064\n",
      "train loss:0.3578970305701592\n",
      "train loss:0.435735298089152\n",
      "train loss:0.6031996683600491\n",
      "train loss:0.3842669365590816\n",
      "train loss:0.4828843716858296\n",
      "train loss:0.3438345710903321\n",
      "train loss:0.3926178271729621\n",
      "train loss:0.41167063093816025\n",
      "train loss:0.5632042553144173\n",
      "train loss:0.37801066551471607\n",
      "train loss:0.4968242770241197\n",
      "train loss:0.3479663300353066\n",
      "train loss:0.3346196819336191\n",
      "train loss:0.5386706857088904\n",
      "train loss:0.32639186692271077\n",
      "train loss:0.4415003634592831\n",
      "train loss:0.39185127509864287\n",
      "train loss:0.3813767669803142\n",
      "train loss:0.43633612020195917\n",
      "train loss:0.4145603746000072\n",
      "train loss:0.42797369844532157\n",
      "train loss:0.3518341546532212\n",
      "train loss:0.3962272562905107\n",
      "train loss:0.4505174602363093\n",
      "train loss:0.2786948785283401\n",
      "train loss:0.42091696668913336\n",
      "train loss:0.35660531284318253\n",
      "train loss:0.5860161005415117\n",
      "train loss:0.2975693032967011\n",
      "train loss:0.3868058756775246\n",
      "train loss:0.5558918460649437\n",
      "train loss:0.39556665818315584\n",
      "train loss:0.46844222414197956\n",
      "train loss:0.38866467013893546\n",
      "train loss:0.3553225054084739\n",
      "train loss:0.4784199244948399\n",
      "train loss:0.3954417365054692\n",
      "train loss:0.5223254673443666\n",
      "train loss:0.41693635644873916\n",
      "train loss:0.3574018233166816\n",
      "train loss:0.3972331531797559\n",
      "train loss:0.3969182987161296\n",
      "train loss:0.3494435080241784\n",
      "train loss:0.30675288333491296\n",
      "train loss:0.44587553589685036\n",
      "train loss:0.4180501591945809\n",
      "train loss:0.4806211248202106\n",
      "train loss:0.35017451231199415\n",
      "train loss:0.44076104326357446\n",
      "train loss:0.37081927371778234\n",
      "train loss:0.33888822125036255\n",
      "train loss:0.3432533670823414\n",
      "train loss:0.4247377230451923\n",
      "train loss:0.5094304413868965\n",
      "train loss:0.5168601570626646\n",
      "train loss:0.3489904086191931\n",
      "train loss:0.3132986461624985\n",
      "train loss:0.4112285955805972\n",
      "train loss:0.38774847457025\n",
      "train loss:0.43747956690961187\n",
      "train loss:0.3624498939768679\n",
      "train loss:0.3726065490099323\n",
      "train loss:0.48873837165861117\n",
      "train loss:0.4087102654219813\n",
      "train loss:0.3395544405302246\n",
      "train loss:0.34484393209858843\n",
      "train loss:0.39311404921328297\n",
      "train loss:0.2588125751571785\n",
      "train loss:0.29598487596675177\n",
      "train loss:0.4026484126555919\n",
      "train loss:0.426976217587783\n",
      "train loss:0.3835048886272765\n",
      "train loss:0.3913796918259539\n",
      "train loss:0.3113759408774968\n",
      "train loss:0.37029594974779\n",
      "train loss:0.5280441098791796\n",
      "train loss:0.42191420000437363\n",
      "train loss:0.33888869468272154\n",
      "train loss:0.3998041739300723\n",
      "train loss:0.43323639016936527\n",
      "train loss:0.47278813319910173\n",
      "train loss:0.3830910515122216\n",
      "train loss:0.32673298602354117\n",
      "train loss:0.4015032404175646\n",
      "train loss:0.3837752107510998\n",
      "train loss:0.5760178941552906\n",
      "train loss:0.4570976171083998\n",
      "train loss:0.36654026242208465\n",
      "train loss:0.4194919372700792\n",
      "train loss:0.3855761576960263\n",
      "train loss:0.5426467677809148\n",
      "train loss:0.311288831674165\n",
      "train loss:0.3743911734817597\n",
      "train loss:0.4169784558007408\n",
      "train loss:0.38729764007790574\n",
      "train loss:0.4203661659155346\n",
      "train loss:0.4547867259351496\n",
      "train loss:0.35103574957985606\n",
      "train loss:0.4349045273876446\n",
      "train loss:0.3797604420308007\n",
      "train loss:0.355139604669813\n",
      "train loss:0.3160412464034062\n",
      "train loss:0.38898963005569087\n",
      "train loss:0.5401814696909024\n",
      "train loss:0.40249768656935425\n",
      "train loss:0.39651733819980756\n",
      "train loss:0.41879676472286403\n",
      "train loss:0.3753746978698732\n",
      "train loss:0.28077867974665566\n",
      "train loss:0.4121716798129396\n",
      "train loss:0.39549658552150924\n",
      "train loss:0.34022333572623414\n",
      "train loss:0.45265041538735096\n",
      "train loss:0.36012685308477066\n",
      "train loss:0.40515117827093133\n",
      "train loss:0.3398778153996587\n",
      "train loss:0.4771359195005926\n",
      "train loss:0.4472970251147994\n",
      "train loss:0.5705364521230406\n",
      "train loss:0.39066359933464206\n",
      "train loss:0.4564065068635053\n",
      "train loss:0.2574662809593048\n",
      "train loss:0.4254060853078755\n",
      "train loss:0.39406913309498665\n",
      "train loss:0.41739182359390203\n",
      "train loss:0.32783621002694596\n",
      "train loss:0.3756757131314017\n",
      "train loss:0.356574941166396\n",
      "train loss:0.40582668758105006\n",
      "train loss:0.4580675067184209\n",
      "train loss:0.2449949263771466\n",
      "train loss:0.45364190032299734\n",
      "train loss:0.3523023121561198\n",
      "train loss:0.34826628458386094\n",
      "train loss:0.3494603644548942\n",
      "train loss:0.34126055527814936\n",
      "train loss:0.45286962181341606\n",
      "train loss:0.43278890976101636\n",
      "train loss:0.4782895453551429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.3004703584316305\n",
      "train loss:0.3122729495849948\n",
      "train loss:0.44199052074301415\n",
      "train loss:0.31224180995845857\n",
      "train loss:0.45288748714625676\n",
      "train loss:0.2906747699751445\n",
      "train loss:0.41447381959006224\n",
      "train loss:0.3592392189043799\n",
      "train loss:0.4676961367987845\n",
      "train loss:0.4822724932027812\n",
      "train loss:0.44541710190729716\n",
      "train loss:0.4230330275129568\n",
      "train loss:0.4654703039386877\n",
      "train loss:0.43581214705985366\n",
      "train loss:0.5148197100896259\n",
      "train loss:0.34425102789952855\n",
      "train loss:0.2858330886828261\n",
      "train loss:0.22621951083827285\n",
      "train loss:0.4355302901619875\n",
      "train loss:0.45900534067129395\n",
      "train loss:0.3151422425514677\n",
      "train loss:0.3515536543240411\n",
      "train loss:0.2128945045455119\n",
      "train loss:0.3378806400853351\n",
      "train loss:0.31067819755179144\n",
      "train loss:0.4837092716263243\n",
      "train loss:0.5388362978264855\n",
      "train loss:0.3719902480532499\n",
      "train loss:0.2708640394900646\n",
      "train loss:0.30380191961176023\n",
      "train loss:0.3290741711062969\n",
      "train loss:0.38043499531267705\n",
      "train loss:0.5064379106703173\n",
      "train loss:0.478244468588141\n",
      "train loss:0.3060571676217476\n",
      "train loss:0.371590584451993\n",
      "train loss:0.3350766450227387\n",
      "train loss:0.21956412408816955\n",
      "train loss:0.3184270445862194\n",
      "train loss:0.32896924606385425\n",
      "train loss:0.2803789663151818\n",
      "train loss:0.44663801120416763\n",
      "train loss:0.33353508053703584\n",
      "train loss:0.2990171374933975\n",
      "train loss:0.3943154491525871\n",
      "train loss:0.2460910565031732\n",
      "train loss:0.3710566420575077\n",
      "train loss:0.5492277644951888\n",
      "train loss:0.2944559098257556\n",
      "train loss:0.3301730492686258\n",
      "train loss:0.30365798724267046\n",
      "train loss:0.2931825966282596\n",
      "train loss:0.3040090618809351\n",
      "train loss:0.42583539670926235\n",
      "train loss:0.24582521695218618\n",
      "train loss:0.26462552043324983\n",
      "train loss:0.38933393767376684\n",
      "train loss:0.32338555608223357\n",
      "train loss:0.34556003170801963\n",
      "train loss:0.3362146485923573\n",
      "train loss:0.37391901449344717\n",
      "train loss:0.3506244459119346\n",
      "train loss:0.31426977159107106\n",
      "train loss:0.35614747409188646\n",
      "train loss:0.257526765383971\n",
      "train loss:0.3168978823201067\n",
      "train loss:0.37282129521474205\n",
      "train loss:0.2761536520578735\n",
      "train loss:0.2291164884640278\n",
      "train loss:0.28124262013462276\n",
      "train loss:0.5908311813270083\n",
      "train loss:0.40350441482192606\n",
      "train loss:0.4231215637690217\n",
      "train loss:0.4368815890419191\n",
      "train loss:0.25675738067583076\n",
      "train loss:0.38501433375406274\n",
      "train loss:0.3776402673280298\n",
      "train loss:0.40222076906315296\n",
      "train loss:0.31483424588105263\n",
      "train loss:0.30624873745955516\n",
      "train loss:0.3742869413196378\n",
      "train loss:0.30235494105103117\n",
      "train loss:0.3271158283506154\n",
      "train loss:0.27913131067303915\n",
      "train loss:0.3532260183706575\n",
      "train loss:0.29154660926504805\n",
      "train loss:0.3315739987855493\n",
      "train loss:0.3666894990458199\n",
      "train loss:0.44404774783498163\n",
      "train loss:0.36354303097482465\n",
      "train loss:0.41318037314432066\n",
      "train loss:0.4206182543554331\n",
      "train loss:0.3112142513991548\n",
      "train loss:0.3204560500902568\n",
      "train loss:0.21541110605700642\n",
      "train loss:0.3556600570705574\n",
      "train loss:0.33104689346775956\n",
      "train loss:0.44001190237023563\n",
      "train loss:0.44052088030303355\n",
      "train loss:0.3484347665586637\n",
      "train loss:0.3589194087990012\n",
      "train loss:0.5047079584816602\n",
      "train loss:0.4642686379504728\n",
      "train loss:0.29689062231600355\n",
      "train loss:0.3869520464611388\n",
      "train loss:0.42955250485679264\n",
      "train loss:0.36178775266525404\n",
      "train loss:0.4304096574253218\n",
      "train loss:0.44086016428860253\n",
      "train loss:0.37039027969956095\n",
      "train loss:0.5174521504306759\n",
      "train loss:0.31149775599790364\n",
      "train loss:0.3176477850124487\n",
      "train loss:0.6327534768985139\n",
      "train loss:0.22621542465455005\n",
      "train loss:0.39561587800826964\n",
      "train loss:0.37823446634617774\n",
      "train loss:0.4232467030791194\n",
      "train loss:0.3447980740756772\n",
      "train loss:0.5784718899856967\n",
      "train loss:0.49180027434892964\n",
      "train loss:0.3222817800684373\n",
      "train loss:0.3615463149746534\n",
      "train loss:0.26513330373528654\n",
      "train loss:0.35505350448412615\n",
      "train loss:0.37497566855023146\n",
      "train loss:0.257775190725747\n",
      "train loss:0.23497674565425675\n",
      "train loss:0.321701174382215\n",
      "train loss:0.4318517039341348\n",
      "train loss:0.3082769436916138\n",
      "train loss:0.40898484283651276\n",
      "train loss:0.3014081697999019\n",
      "train loss:0.34270428321775326\n",
      "train loss:0.3370903541913259\n",
      "train loss:0.37644522173742523\n",
      "train loss:0.32124615242194215\n",
      "train loss:0.38908352654281475\n",
      "train loss:0.4357432986882561\n",
      "train loss:0.3332770933536453\n",
      "train loss:0.33035911154301156\n",
      "train loss:0.2665077466435584\n",
      "train loss:0.3879356051292849\n",
      "train loss:0.3939880499637263\n",
      "train loss:0.29466727133900145\n",
      "train loss:0.41136984485023764\n",
      "train loss:0.35528583739993974\n",
      "train loss:0.3076563647807919\n",
      "train loss:0.3551888564389173\n",
      "train loss:0.5382683525237668\n",
      "train loss:0.4205673183444135\n",
      "train loss:0.3764567624841182\n",
      "train loss:0.32360037374345585\n",
      "train loss:0.48405647075394803\n",
      "train loss:0.28290946203108563\n",
      "train loss:0.45933159110061506\n",
      "train loss:0.38818312598091614\n",
      "train loss:0.3656197924978365\n",
      "train loss:0.2279381807201997\n",
      "train loss:0.4331351109683135\n",
      "train loss:0.2793877442731969\n",
      "train loss:0.26325521015028536\n",
      "train loss:0.27438306430234083\n",
      "train loss:0.30563200606785507\n",
      "train loss:0.48799591605115245\n",
      "train loss:0.3999328965918588\n",
      "train loss:0.2529347394454036\n",
      "train loss:0.2651477738122697\n",
      "train loss:0.35902927931294004\n",
      "train loss:0.3393855737439029\n",
      "train loss:0.2882691725875626\n",
      "train loss:0.2500474139486154\n",
      "train loss:0.33883697011780883\n",
      "train loss:0.42286603018359625\n",
      "train loss:0.2995122492358717\n",
      "train loss:0.38765673831806935\n",
      "train loss:0.36611854157636564\n",
      "train loss:0.4034820708559275\n",
      "train loss:0.3528493416538368\n",
      "train loss:0.3571579834299169\n",
      "train loss:0.42866356378679166\n",
      "train loss:0.3874913649047596\n",
      "train loss:0.3764813546977265\n",
      "train loss:0.3339504234186464\n",
      "train loss:0.3408874182940446\n",
      "train loss:0.47001495671725735\n",
      "train loss:0.28562591302204515\n",
      "train loss:0.4156829084012264\n",
      "train loss:0.5225128299250175\n",
      "train loss:0.24107132289655164\n",
      "train loss:0.3379238229328347\n",
      "train loss:0.26325004367275523\n",
      "train loss:0.3437708432979511\n",
      "train loss:0.219433880357803\n",
      "train loss:0.31878377867770175\n",
      "train loss:0.47044713878755523\n",
      "train loss:0.3656738721571877\n",
      "train loss:0.49361618785982336\n",
      "train loss:0.32201762869847367\n",
      "train loss:0.3404353640365798\n",
      "train loss:0.40113039387882893\n",
      "train loss:0.31996930717014627\n",
      "train loss:0.3275319524323973\n",
      "train loss:0.39306184735932725\n",
      "train loss:0.2950607424270607\n",
      "train loss:0.42767338127796906\n",
      "train loss:0.32404002076963356\n",
      "train loss:0.3901734628872157\n",
      "train loss:0.5170997264073421\n",
      "train loss:0.39607261639028374\n",
      "train loss:0.3755888533993834\n",
      "train loss:0.4052128416836249\n",
      "train loss:0.5331788187085948\n",
      "train loss:0.35724402717315246\n",
      "train loss:0.39661928571376104\n",
      "train loss:0.3024398354109703\n",
      "train loss:0.28213869603052943\n",
      "train loss:0.41980688419316303\n",
      "train loss:0.3082808319688355\n",
      "train loss:0.2885805087796675\n",
      "train loss:0.3673403037113486\n",
      "train loss:0.3264482448200785\n",
      "train loss:0.2482814425422075\n",
      "train loss:0.32472771471681944\n",
      "train loss:0.2222347819561049\n",
      "train loss:0.3896549127467145\n",
      "train loss:0.5135241724098001\n",
      "train loss:0.3507987020376628\n",
      "train loss:0.3028103610245044\n",
      "train loss:0.19243827548225118\n",
      "train loss:0.34608785977582096\n",
      "train loss:0.24961251294867354\n",
      "train loss:0.4291249348929117\n",
      "train loss:0.3396895155836549\n",
      "train loss:0.3637408106943154\n",
      "train loss:0.437597136617875\n",
      "train loss:0.3730612053108226\n",
      "train loss:0.5843815119706304\n",
      "train loss:0.29079445258872527\n",
      "train loss:0.28830173690698185\n",
      "train loss:0.4385035044440858\n",
      "train loss:0.3391503572808778\n",
      "train loss:0.4766240724923271\n",
      "train loss:0.406683954303519\n",
      "train loss:0.2724209020572628\n",
      "train loss:0.4203566393719852\n",
      "train loss:0.3753327521968445\n",
      "train loss:0.2389836680319764\n",
      "train loss:0.2893061210942487\n",
      "train loss:0.32031423329234926\n",
      "train loss:0.3432511594536234\n",
      "train loss:0.41037480645561814\n",
      "train loss:0.32388185870621067\n",
      "train loss:0.23679732152979058\n",
      "train loss:0.3725381334228268\n",
      "train loss:0.54194840001637\n",
      "train loss:0.3826571430551756\n",
      "train loss:0.35398968876286363\n",
      "train loss:0.4108013323976115\n",
      "train loss:0.3738942302040121\n",
      "train loss:0.43830497567738574\n",
      "train loss:0.3893141478488096\n",
      "train loss:0.3414599482378783\n",
      "train loss:0.3479376589614779\n",
      "train loss:0.3458688573354791\n",
      "train loss:0.5273491596473342\n",
      "train loss:0.3301206751493997\n",
      "train loss:0.48030654401195927\n",
      "train loss:0.37075711092556385\n",
      "train loss:0.44817420472829794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.3198995631000343\n",
      "train loss:0.28815972213870056\n",
      "train loss:0.2351008052118308\n",
      "train loss:0.27039945959685197\n",
      "train loss:0.44765103043824\n",
      "train loss:0.3068197505027339\n",
      "train loss:0.3170533665277701\n",
      "train loss:0.37658011311943795\n",
      "train loss:0.38280305072195936\n",
      "train loss:0.3103350708200181\n",
      "train loss:0.29694139006639597\n",
      "train loss:0.26977756606264114\n",
      "train loss:0.326647831085963\n",
      "train loss:0.35208839797566815\n",
      "train loss:0.28331669749447314\n",
      "train loss:0.3495310812177721\n",
      "train loss:0.3190550996243898\n",
      "train loss:0.39953475992802956\n",
      "train loss:0.3433044718037188\n",
      "train loss:0.4367039748147264\n",
      "train loss:0.29106044694718525\n",
      "train loss:0.3693735783000986\n",
      "train loss:0.3474006694407145\n",
      "train loss:0.426494067379734\n",
      "train loss:0.2906838223828501\n",
      "train loss:0.4736605392656763\n",
      "train loss:0.3915042763595259\n",
      "train loss:0.3531941270632236\n",
      "train loss:0.3787157272815707\n",
      "train loss:0.28822336754889455\n",
      "train loss:0.2763599740924035\n",
      "train loss:0.32305304952051905\n",
      "train loss:0.2794208764399924\n",
      "train loss:0.3318034850727926\n",
      "train loss:0.36748017196472416\n",
      "train loss:0.3832582289573338\n",
      "train loss:0.27073130491167463\n",
      "train loss:0.3223310571864632\n",
      "train loss:0.33053005107037137\n",
      "train loss:0.3315115951928221\n",
      "train loss:0.3557936212651247\n",
      "train loss:0.2755348820897989\n",
      "train loss:0.22806192373261233\n",
      "train loss:0.37901866079031044\n",
      "train loss:0.42434427986302403\n",
      "train loss:0.3359453730353435\n",
      "train loss:0.2546929616208788\n",
      "train loss:0.34962828894554027\n",
      "train loss:0.3952556217510963\n",
      "train loss:0.41578399959438905\n",
      "train loss:0.372120875311018\n",
      "train loss:0.39985049987486576\n",
      "train loss:0.38096901199281447\n",
      "train loss:0.348252491068627\n",
      "train loss:0.4425710546909134\n",
      "train loss:0.34175961958204126\n",
      "train loss:0.3877047203286722\n",
      "train loss:0.33851657434124205\n",
      "train loss:0.24159061540880444\n",
      "train loss:0.31028332327854374\n",
      "train loss:0.3115528115701398\n",
      "train loss:0.380809840619721\n",
      "train loss:0.2872544223867706\n",
      "train loss:0.318904527800126\n",
      "train loss:0.3590318518239009\n",
      "train loss:0.35396961838559676\n",
      "train loss:0.39467696775172995\n",
      "train loss:0.37446259895978234\n",
      "train loss:0.31950426015309835\n",
      "train loss:0.2673689612996344\n",
      "train loss:0.3355305847200821\n",
      "train loss:0.3560776431387484\n",
      "train loss:0.338459814487589\n",
      "train loss:0.4177640241635796\n",
      "train loss:0.3082483559543233\n",
      "train loss:0.4227845233051603\n",
      "train loss:0.6302316589141017\n",
      "train loss:0.2537989166576893\n",
      "train loss:0.3763976180540649\n",
      "train loss:0.27703410694121877\n",
      "train loss:0.30779196246803503\n",
      "train loss:0.3881171021922226\n",
      "train loss:0.29582473043008056\n",
      "train loss:0.4015482075967185\n",
      "train loss:0.2372290108090894\n",
      "train loss:0.3288667968354085\n",
      "train loss:0.29757125419752856\n",
      "train loss:0.3194605010123639\n",
      "train loss:0.4653014383041637\n",
      "train loss:0.3442119022644256\n",
      "train loss:0.4281249493690629\n",
      "train loss:0.2611391137824698\n",
      "train loss:0.40320710768296025\n",
      "train loss:0.3646679349568575\n",
      "train loss:0.3017515143907761\n",
      "train loss:0.35559738638646843\n",
      "train loss:0.5364864363974806\n",
      "train loss:0.4230556762046234\n",
      "train loss:0.36573417882447673\n",
      "train loss:0.3219210733039656\n",
      "train loss:0.29234203330390607\n",
      "train loss:0.5067843970273885\n",
      "train loss:0.27104017639972555\n",
      "train loss:0.41472041381572033\n",
      "train loss:0.39397538634421286\n",
      "train loss:0.3862989497838878\n",
      "train loss:0.43002295068444385\n",
      "train loss:0.32655825832983704\n",
      "train loss:0.3358027027551337\n",
      "train loss:0.46767720839179594\n",
      "train loss:0.25518966763360057\n",
      "train loss:0.3596519352748727\n",
      "train loss:0.22308653167590084\n",
      "train loss:0.4206788840223954\n",
      "train loss:0.3560046143632608\n",
      "train loss:0.42250614280852267\n",
      "train loss:0.24782556322733373\n",
      "train loss:0.4129543806809335\n",
      "train loss:0.33229613986404943\n",
      "train loss:0.18883555756270962\n",
      "train loss:0.2946046942400915\n",
      "train loss:0.33635790152687006\n",
      "train loss:0.24646174110871907\n",
      "train loss:0.34988497209521924\n",
      "train loss:0.243385848048003\n",
      "train loss:0.4610193495139204\n",
      "train loss:0.36628478461537733\n",
      "=== epoch:3, train acc:0.892, test acc:0.875 ===\n",
      "train loss:0.35609820512843837\n",
      "train loss:0.39311983680585577\n",
      "train loss:0.2976516098214048\n",
      "train loss:0.3717630617338186\n",
      "train loss:0.3005518439946456\n",
      "train loss:0.34909017585853985\n",
      "train loss:0.4352055270237821\n",
      "train loss:0.30308292877548354\n",
      "train loss:0.4237509762659122\n",
      "train loss:0.2838108407160911\n",
      "train loss:0.4164329705700289\n",
      "train loss:0.3177969725331434\n",
      "train loss:0.21667353856834443\n",
      "train loss:0.317897954768161\n",
      "train loss:0.450159591889549\n",
      "train loss:0.37933429154593645\n",
      "train loss:0.32836643042644276\n",
      "train loss:0.313783591630433\n",
      "train loss:0.3924408534736721\n",
      "train loss:0.28736002718861553\n",
      "train loss:0.42774657176925646\n",
      "train loss:0.3566527602241223\n",
      "train loss:0.425221757146993\n",
      "train loss:0.46836380828337565\n",
      "train loss:0.37418591155280156\n",
      "train loss:0.33927596843176794\n",
      "train loss:0.49837751466216623\n",
      "train loss:0.45870329773069535\n",
      "train loss:0.32976251980183846\n",
      "train loss:0.42856928073326783\n",
      "train loss:0.5498267572087048\n",
      "train loss:0.36368826348506716\n",
      "train loss:0.33337889160214773\n",
      "train loss:0.4251412432519991\n",
      "train loss:0.46301024542846236\n",
      "train loss:0.29280205381413604\n",
      "train loss:0.3247300044969901\n",
      "train loss:0.28810922596238825\n",
      "train loss:0.39881275126332083\n",
      "train loss:0.2789178285317744\n",
      "train loss:0.2566625271301715\n",
      "train loss:0.35982231835080986\n",
      "train loss:0.3125728954905119\n",
      "train loss:0.3669370102438518\n",
      "train loss:0.35115297944269785\n",
      "train loss:0.31367740731670607\n",
      "train loss:0.4143747718772249\n",
      "train loss:0.24957672554906105\n",
      "train loss:0.33828699480587654\n",
      "train loss:0.24223902153443658\n",
      "train loss:0.3317495158171157\n",
      "train loss:0.4032884859338622\n",
      "train loss:0.26364556114487664\n",
      "train loss:0.4097792757344767\n",
      "train loss:0.30815385896575004\n",
      "train loss:0.47582420241678064\n",
      "train loss:0.2191958215828584\n",
      "train loss:0.31472270549580955\n",
      "train loss:0.24768216424873415\n",
      "train loss:0.40295167252223146\n",
      "train loss:0.3389396087233038\n",
      "train loss:0.2922722138795406\n",
      "train loss:0.3947908053007352\n",
      "train loss:0.29064902491250083\n",
      "train loss:0.32113326801659\n",
      "train loss:0.3824618606784347\n",
      "train loss:0.3046559670047974\n",
      "train loss:0.3543537693329739\n",
      "train loss:0.4191514964443901\n",
      "train loss:0.31956684662447\n",
      "train loss:0.29928892962538556\n",
      "train loss:0.29633966427616387\n",
      "train loss:0.4798197362045526\n",
      "train loss:0.36369939871295076\n",
      "train loss:0.3751772001880631\n",
      "train loss:0.3271998208600936\n",
      "train loss:0.3056836170606763\n",
      "train loss:0.36546073269452073\n",
      "train loss:0.24649127698309134\n",
      "train loss:0.40615744189418684\n",
      "train loss:0.24736967311790012\n",
      "train loss:0.3502580611879577\n",
      "train loss:0.3046480011101149\n",
      "train loss:0.3124460803926355\n",
      "train loss:0.34164702053362506\n",
      "train loss:0.3390694747911207\n",
      "train loss:0.35549838835611275\n",
      "train loss:0.34162106168247375\n",
      "train loss:0.3695452860683293\n",
      "train loss:0.3661998985796423\n",
      "train loss:0.43006634212599315\n",
      "train loss:0.2897264720051968\n",
      "train loss:0.2934112531064565\n",
      "train loss:0.27628398561498546\n",
      "train loss:0.35900287758947613\n",
      "train loss:0.24260644155421357\n",
      "train loss:0.4103139120991394\n",
      "train loss:0.2861398283239887\n",
      "train loss:0.3104651272840233\n",
      "train loss:0.37125806427346925\n",
      "train loss:0.38771342739989784\n",
      "train loss:0.42605251018278084\n",
      "train loss:0.2635898496643934\n",
      "train loss:0.2949600614909554\n",
      "train loss:0.2837324589297875\n",
      "train loss:0.2638945250312933\n",
      "train loss:0.4352517036661264\n",
      "train loss:0.36446110254082986\n",
      "train loss:0.25770655824409955\n",
      "train loss:0.4673162455004819\n",
      "train loss:0.2367796885534992\n",
      "train loss:0.24688315366420216\n",
      "train loss:0.31811412745315215\n",
      "train loss:0.32123825702662884\n",
      "train loss:0.22980160792245244\n",
      "train loss:0.37107589332785923\n",
      "train loss:0.42482666661245666\n",
      "train loss:0.2754025518331911\n",
      "train loss:0.36994992733628834\n",
      "train loss:0.4639478154763865\n",
      "train loss:0.26950120555409446\n",
      "train loss:0.35057547995484717\n",
      "train loss:0.17277935314373935\n",
      "train loss:0.37200239277580244\n",
      "train loss:0.24385794818751427\n",
      "train loss:0.24174636990100315\n",
      "train loss:0.31509255683511905\n",
      "train loss:0.2563895072354278\n",
      "train loss:0.31025846224769843\n",
      "train loss:0.33219363298760185\n",
      "train loss:0.2682149606949843\n",
      "train loss:0.2767902285590062\n",
      "train loss:0.236029254295674\n",
      "train loss:0.31705580218834156\n",
      "train loss:0.30835616244850483\n",
      "train loss:0.30748265699635774\n",
      "train loss:0.24516824721265593\n",
      "train loss:0.3674135860792485\n",
      "train loss:0.4347245640694725\n",
      "train loss:0.2735939870464626\n",
      "train loss:0.27299837117809367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.34259385979934676\n",
      "train loss:0.3873905031417572\n",
      "train loss:0.3170107285967325\n",
      "train loss:0.3361037726166181\n",
      "train loss:0.21776769347738395\n",
      "train loss:0.445365399350611\n",
      "train loss:0.22096796964583432\n",
      "train loss:0.2898776958809764\n",
      "train loss:0.30112201484451484\n",
      "train loss:0.3085555151653893\n",
      "train loss:0.3225160099358159\n",
      "train loss:0.3619557623271597\n",
      "train loss:0.2361322049188317\n",
      "train loss:0.5116538305900127\n",
      "train loss:0.23762751610929023\n",
      "train loss:0.2992845080443151\n",
      "train loss:0.4075512389405172\n",
      "train loss:0.4828475891475135\n",
      "train loss:0.3052018055208961\n",
      "train loss:0.3774607617015111\n",
      "train loss:0.26470351314985213\n",
      "train loss:0.4194468143602297\n",
      "train loss:0.358661693629167\n",
      "train loss:0.35472148010985727\n",
      "train loss:0.3472492879076415\n",
      "train loss:0.32200159222041813\n",
      "train loss:0.32178999876998854\n",
      "train loss:0.29010405942733963\n",
      "train loss:0.2797930556484411\n",
      "train loss:0.3221031449034647\n",
      "train loss:0.3546537564058593\n",
      "train loss:0.34273053403776543\n",
      "train loss:0.316815013869737\n",
      "train loss:0.29296727519958965\n",
      "train loss:0.27279913529333494\n",
      "train loss:0.23018602055457932\n",
      "train loss:0.25264753943864393\n",
      "train loss:0.3403230912400242\n",
      "train loss:0.24537563850841745\n",
      "train loss:0.2981773992463234\n",
      "train loss:0.40134871457600263\n",
      "train loss:0.28856362688957254\n",
      "train loss:0.35424612198121613\n",
      "train loss:0.28695308414878296\n",
      "train loss:0.27834298895570336\n",
      "train loss:0.3127317518238539\n",
      "train loss:0.3351650106712538\n",
      "train loss:0.3701359196237566\n",
      "train loss:0.34248078782625996\n",
      "train loss:0.32955585800874787\n",
      "train loss:0.3188505235600916\n",
      "train loss:0.45062387472590026\n",
      "train loss:0.24673491701103029\n",
      "train loss:0.34316023872037626\n",
      "train loss:0.3532591512279986\n",
      "train loss:0.3241824259047782\n",
      "train loss:0.3213359765523368\n",
      "train loss:0.38577447781461116\n",
      "train loss:0.38849567198897367\n",
      "train loss:0.26496143695193325\n",
      "train loss:0.24901967144299658\n",
      "train loss:0.26056142273946853\n",
      "train loss:0.17194791469958998\n",
      "train loss:0.37655941582180824\n",
      "train loss:0.38073322714743507\n",
      "train loss:0.2950042084216709\n",
      "train loss:0.38834929614443814\n",
      "train loss:0.2869859964962613\n",
      "train loss:0.2851942062440435\n",
      "train loss:0.33467251215669785\n",
      "train loss:0.25985578844356527\n",
      "train loss:0.2884898220041205\n",
      "train loss:0.3656727857189627\n",
      "train loss:0.24025728592873904\n",
      "train loss:0.26981242378206055\n",
      "train loss:0.2766352518381263\n",
      "train loss:0.39738067498484725\n",
      "train loss:0.24941954758833249\n",
      "train loss:0.23206265233533016\n",
      "train loss:0.25586997351300883\n",
      "train loss:0.3181173703926898\n",
      "train loss:0.19181157513550764\n",
      "train loss:0.3249180991532382\n",
      "train loss:0.5029109264234133\n",
      "train loss:0.49724995594170585\n",
      "train loss:0.3737292325896244\n",
      "train loss:0.33775007534221113\n",
      "train loss:0.4684602986045316\n",
      "train loss:0.34576375752260896\n",
      "train loss:0.17635372155290036\n",
      "train loss:0.29091884799950546\n",
      "train loss:0.29622399587653575\n",
      "train loss:0.25804453580641445\n",
      "train loss:0.4093188029299024\n",
      "train loss:0.23395869259100405\n",
      "train loss:0.27235908954580057\n",
      "train loss:0.28046778198727834\n",
      "train loss:0.4064342069964655\n",
      "train loss:0.2610350958366317\n",
      "train loss:0.2911981263315078\n",
      "train loss:0.3340164344827531\n",
      "train loss:0.1912716413529203\n",
      "train loss:0.2542416508450032\n",
      "train loss:0.29836842049710144\n",
      "train loss:0.2997696679599262\n",
      "train loss:0.29100999648524667\n",
      "train loss:0.2738489761883695\n",
      "train loss:0.2955917048636824\n",
      "train loss:0.30752726631465044\n",
      "train loss:0.2617357622077155\n",
      "train loss:0.2904794904840072\n",
      "train loss:0.3333884443494486\n",
      "train loss:0.35039878075735986\n",
      "train loss:0.25676495831098384\n",
      "train loss:0.21531130890075573\n",
      "train loss:0.2500643066615675\n",
      "train loss:0.25903218075945156\n",
      "train loss:0.43535650153461175\n",
      "train loss:0.3596831294099434\n",
      "train loss:0.2663121952533617\n",
      "train loss:0.1927410736516767\n",
      "train loss:0.40807010515571657\n",
      "train loss:0.29886330372680675\n",
      "train loss:0.2519133836731513\n",
      "train loss:0.382690457107733\n",
      "train loss:0.3116570434124931\n",
      "train loss:0.27573595276807256\n",
      "train loss:0.2815578780812009\n",
      "train loss:0.17884534803755636\n",
      "train loss:0.25380844919948486\n",
      "train loss:0.33408239862988637\n",
      "train loss:0.3753060947927516\n",
      "train loss:0.22321275353442155\n",
      "train loss:0.33611323011495015\n",
      "train loss:0.38868569256047836\n",
      "train loss:0.3014012520639728\n",
      "train loss:0.33466413298388425\n",
      "train loss:0.24113206240859178\n",
      "train loss:0.19056695503123042\n",
      "train loss:0.4822887790718616\n",
      "train loss:0.25052246673458106\n",
      "train loss:0.21041343940785484\n",
      "train loss:0.337553134161567\n",
      "train loss:0.3589973267997973\n",
      "train loss:0.4274086069930935\n",
      "train loss:0.2427925541790308\n",
      "train loss:0.3288078499106173\n",
      "train loss:0.45942716684212526\n",
      "train loss:0.27945847421143716\n",
      "train loss:0.4477147853559982\n",
      "train loss:0.40604646775491077\n",
      "train loss:0.27075579229340446\n",
      "train loss:0.2784372905071396\n",
      "train loss:0.43652075505175697\n",
      "train loss:0.332326876616048\n",
      "train loss:0.4336614227873003\n",
      "train loss:0.382149414998429\n",
      "train loss:0.37863376751025385\n",
      "train loss:0.3510718874910742\n",
      "train loss:0.29526765740501043\n",
      "train loss:0.2360130367198795\n",
      "train loss:0.37594156871169376\n",
      "train loss:0.31791558937609865\n",
      "train loss:0.3342392090617137\n",
      "train loss:0.42373624003670474\n",
      "train loss:0.39205628138290616\n",
      "train loss:0.2613947633488924\n",
      "train loss:0.3308089312289841\n",
      "train loss:0.35834942651373713\n",
      "train loss:0.23732276044904282\n",
      "train loss:0.29821931352864217\n",
      "train loss:0.2813571088180424\n",
      "train loss:0.2831947070571712\n",
      "train loss:0.27156669476491474\n",
      "train loss:0.31292557073042954\n",
      "train loss:0.2719212578759887\n",
      "train loss:0.298930365088959\n",
      "train loss:0.29239031376426694\n",
      "train loss:0.3106620155297109\n",
      "train loss:0.32763376103664804\n",
      "train loss:0.3106354970817732\n",
      "train loss:0.2689382628438622\n",
      "train loss:0.30245947269220436\n",
      "train loss:0.29822998963732933\n",
      "train loss:0.3141722066500083\n",
      "train loss:0.28321085959942155\n",
      "train loss:0.45634568142704984\n",
      "train loss:0.3940186412560529\n",
      "train loss:0.467787183988502\n",
      "train loss:0.3355488785764809\n",
      "train loss:0.2179397998053963\n",
      "train loss:0.35440212344599586\n",
      "train loss:0.36389549164815377\n",
      "train loss:0.3296053229661209\n",
      "train loss:0.35595895197981064\n",
      "train loss:0.2447430801140833\n",
      "train loss:0.2969561931092283\n",
      "train loss:0.21783680957919235\n",
      "train loss:0.2660555756964025\n",
      "train loss:0.2821808158094087\n",
      "train loss:0.3151737820437316\n",
      "train loss:0.3025581933026336\n",
      "train loss:0.25760267332164594\n",
      "train loss:0.425855411029369\n",
      "train loss:0.2419849063387501\n",
      "train loss:0.14725048187970535\n",
      "train loss:0.3302537141149907\n",
      "train loss:0.36461167258809274\n",
      "train loss:0.24460376888810287\n",
      "train loss:0.42902925218423277\n",
      "train loss:0.3030589748227593\n",
      "train loss:0.3063374806373986\n",
      "train loss:0.37752492085832856\n",
      "train loss:0.2689509919489595\n",
      "train loss:0.2966129417145402\n",
      "train loss:0.25754891806623537\n",
      "train loss:0.23728188811674297\n",
      "train loss:0.2898458243082439\n",
      "train loss:0.45484137209623554\n",
      "train loss:0.2533037059629067\n",
      "train loss:0.2036473136232885\n",
      "train loss:0.3577148745940265\n",
      "train loss:0.35987123221784095\n",
      "train loss:0.31185160340919243\n",
      "train loss:0.3662719081690042\n",
      "train loss:0.36483835636320205\n",
      "train loss:0.36314488273462386\n",
      "train loss:0.31058294150124666\n",
      "train loss:0.3206638028552242\n",
      "train loss:0.23232792665521887\n",
      "train loss:0.2347234994964095\n",
      "train loss:0.2742324469187556\n",
      "train loss:0.26545445421378494\n",
      "train loss:0.17033098639871277\n",
      "train loss:0.3143020967977246\n",
      "train loss:0.216965731883635\n",
      "train loss:0.3543728865033878\n",
      "train loss:0.32936719434371503\n",
      "train loss:0.2375300805362812\n",
      "train loss:0.28302350782089297\n",
      "train loss:0.3282187891577318\n",
      "train loss:0.3446938784680175\n",
      "train loss:0.2156821973981834\n",
      "train loss:0.29920158377870815\n",
      "train loss:0.4071951148957005\n",
      "train loss:0.25920138367394274\n",
      "train loss:0.3338780691150863\n",
      "train loss:0.350648082105084\n",
      "train loss:0.28323882897308295\n",
      "train loss:0.33486472666976136\n",
      "train loss:0.3350037303368311\n",
      "train loss:0.2018925061794462\n",
      "train loss:0.37087632864201453\n",
      "train loss:0.47076437236774443\n",
      "train loss:0.33404000371270226\n",
      "train loss:0.380858549952988\n",
      "train loss:0.38242060820159934\n",
      "train loss:0.30980997979206937\n",
      "train loss:0.249356541877689\n",
      "train loss:0.3266089193584327\n",
      "train loss:0.27739801250356655\n",
      "train loss:0.2477430428128969\n",
      "train loss:0.3274042837753234\n",
      "train loss:0.2572822004832508\n",
      "train loss:0.4024144759228017\n",
      "train loss:0.35388307275185055\n",
      "train loss:0.3221122839186903\n",
      "train loss:0.3518321367146372\n",
      "train loss:0.23295070859467468\n",
      "train loss:0.2585170860107997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.2873472913580447\n",
      "train loss:0.2778953342716805\n",
      "train loss:0.23732400341539542\n",
      "train loss:0.3320221414649997\n",
      "train loss:0.3170074242244081\n",
      "train loss:0.28512281070326895\n",
      "train loss:0.19737475563866536\n",
      "train loss:0.31067413499368657\n",
      "train loss:0.235994860521568\n",
      "train loss:0.3289867218377191\n",
      "train loss:0.3337552191521482\n",
      "train loss:0.28615651994918606\n",
      "train loss:0.34739861300418157\n",
      "train loss:0.15145266391848147\n",
      "train loss:0.20659103555720978\n",
      "train loss:0.2545643449276179\n",
      "train loss:0.29471696429508404\n",
      "train loss:0.2338260883381472\n",
      "train loss:0.3039308179714506\n",
      "train loss:0.2057119574602887\n",
      "train loss:0.39910614810557976\n",
      "train loss:0.2920118738131468\n",
      "train loss:0.37991803055185974\n",
      "train loss:0.24709425966141865\n",
      "train loss:0.48002566495413695\n",
      "train loss:0.2200884983180866\n",
      "train loss:0.28806254441976153\n",
      "train loss:0.21860780280643557\n",
      "train loss:0.2812045855834313\n",
      "train loss:0.418038752414295\n",
      "train loss:0.3439148367434716\n",
      "train loss:0.3697904909900632\n",
      "train loss:0.28472590839279793\n",
      "train loss:0.33865940518997933\n",
      "train loss:0.2948921850994719\n",
      "train loss:0.34113587442622645\n",
      "train loss:0.26451598758624084\n",
      "train loss:0.3382525855930698\n",
      "train loss:0.3438009117150049\n",
      "train loss:0.31264440594591236\n",
      "train loss:0.27574309712111555\n",
      "train loss:0.39532359616102414\n",
      "train loss:0.5808422900155494\n",
      "train loss:0.26324257925651834\n",
      "train loss:0.3118781343242074\n",
      "train loss:0.30596683576322764\n",
      "train loss:0.28140013848872597\n",
      "train loss:0.3185216671259185\n",
      "train loss:0.2911934132264689\n",
      "train loss:0.19746175977248168\n",
      "train loss:0.3240484027633165\n",
      "train loss:0.36859744488158774\n",
      "train loss:0.2513158708295067\n",
      "train loss:0.29568429365963544\n",
      "train loss:0.29428542696873455\n",
      "train loss:0.3357270059047506\n",
      "train loss:0.23271139981341954\n",
      "train loss:0.28773194467689467\n",
      "train loss:0.2844200356788307\n",
      "train loss:0.3321058149590105\n",
      "train loss:0.2820726278098679\n",
      "train loss:0.4245797644320202\n",
      "train loss:0.34361145374721813\n",
      "train loss:0.14743493621805154\n",
      "train loss:0.16711491509274332\n",
      "train loss:0.29683738218945516\n",
      "train loss:0.36161524409111506\n",
      "train loss:0.2951110231687466\n",
      "train loss:0.3295253401172843\n",
      "train loss:0.32247006519693827\n",
      "train loss:0.1482563215896583\n",
      "train loss:0.20741725926698276\n",
      "train loss:0.2604436625959693\n",
      "train loss:0.4426825177091982\n",
      "train loss:0.20399759919305166\n",
      "train loss:0.2855908157833539\n",
      "train loss:0.3241625999893922\n",
      "train loss:0.42712268304671186\n",
      "train loss:0.2080655734080647\n",
      "train loss:0.25845417939528503\n",
      "train loss:0.33162380801116176\n",
      "train loss:0.2533789217727386\n",
      "train loss:0.33103441562154307\n",
      "train loss:0.2388256521540265\n",
      "train loss:0.2516702114830272\n",
      "train loss:0.2878764621840402\n",
      "train loss:0.36981172076190894\n",
      "train loss:0.18605777870121534\n",
      "train loss:0.23956709511912982\n",
      "train loss:0.21432899807231123\n",
      "train loss:0.4149595511606188\n",
      "train loss:0.33538312327885506\n",
      "train loss:0.2292829361299119\n",
      "train loss:0.3342183635067633\n",
      "train loss:0.24748937954365227\n",
      "train loss:0.3601567190433786\n",
      "train loss:0.2827274876227668\n",
      "train loss:0.26371982715408143\n",
      "train loss:0.1514964829790405\n",
      "train loss:0.3053749346132918\n",
      "train loss:0.28531220273744784\n",
      "train loss:0.20564225912202036\n",
      "train loss:0.3893423390599215\n",
      "train loss:0.4488533800728954\n",
      "train loss:0.24676610977575283\n",
      "train loss:0.2868710157626056\n",
      "train loss:0.3386161675345775\n",
      "train loss:0.28058702669701135\n",
      "train loss:0.18438203539481932\n",
      "train loss:0.23784729704846255\n",
      "train loss:0.17061592014632077\n",
      "train loss:0.31074083361460064\n",
      "train loss:0.23068791909643277\n",
      "train loss:0.19684485349601777\n",
      "train loss:0.24971739364169315\n",
      "train loss:0.24573842899638274\n",
      "train loss:0.24654409166640603\n",
      "train loss:0.3285303843156529\n",
      "train loss:0.4369970663443802\n",
      "train loss:0.41379457355601557\n",
      "train loss:0.40098528141483314\n",
      "train loss:0.26419523746907103\n",
      "train loss:0.16632686832499186\n",
      "train loss:0.322032735870144\n",
      "train loss:0.2910485485544751\n",
      "train loss:0.37009256191890183\n",
      "train loss:0.2922298338193306\n",
      "train loss:0.2498821703357794\n",
      "train loss:0.23136640223384244\n",
      "train loss:0.26701951924360057\n",
      "train loss:0.19424117688935727\n",
      "train loss:0.26438162377233226\n",
      "train loss:0.40868785106633054\n",
      "train loss:0.2359979818917235\n",
      "train loss:0.22923536787820112\n",
      "train loss:0.32524175807194317\n",
      "train loss:0.31324711712769276\n",
      "train loss:0.4164058349097337\n",
      "train loss:0.46708233624115403\n",
      "train loss:0.3300496882422784\n",
      "train loss:0.32071249109650213\n",
      "train loss:0.23296254902137503\n",
      "train loss:0.20556401138715605\n",
      "train loss:0.3572532592086503\n",
      "train loss:0.2598789681765485\n",
      "train loss:0.19185516210529083\n",
      "train loss:0.3256234649398256\n",
      "train loss:0.4172242700946851\n",
      "train loss:0.2620961589736865\n",
      "train loss:0.1777208908333582\n",
      "train loss:0.360161323748596\n",
      "train loss:0.397825932868305\n",
      "train loss:0.18912230218337092\n",
      "train loss:0.45709525931121897\n",
      "train loss:0.3754557854288847\n",
      "train loss:0.2294824740895588\n",
      "train loss:0.3261553401887086\n",
      "train loss:0.25549604758282646\n",
      "train loss:0.2447459153048758\n",
      "train loss:0.3673781277585255\n",
      "train loss:0.25648197092921776\n",
      "train loss:0.33977301365258183\n",
      "train loss:0.4210972686580075\n",
      "train loss:0.17714813832717907\n",
      "train loss:0.37255338845321195\n",
      "train loss:0.35593209004185355\n",
      "train loss:0.289137591796101\n",
      "train loss:0.32176865428660323\n",
      "train loss:0.2890542869498237\n",
      "train loss:0.2953707167025799\n",
      "train loss:0.2031736563072979\n",
      "train loss:0.23526248177772813\n",
      "train loss:0.3445875374221541\n",
      "train loss:0.28401045942325687\n",
      "train loss:0.24820944925024194\n",
      "train loss:0.2098498915090311\n",
      "train loss:0.35753900483155776\n",
      "train loss:0.3513590923789237\n",
      "train loss:0.3168383997220148\n",
      "train loss:0.21626183714263575\n",
      "train loss:0.31128938937513145\n",
      "train loss:0.23750270821425165\n",
      "train loss:0.3074041618573968\n",
      "train loss:0.2532673157037247\n",
      "train loss:0.36508860755680084\n",
      "train loss:0.4102541080798019\n",
      "train loss:0.32111051855421807\n",
      "train loss:0.3232153563918181\n",
      "train loss:0.3831204203625458\n",
      "=== epoch:4, train acc:0.903, test acc:0.88 ===\n",
      "train loss:0.25365713485474606\n",
      "train loss:0.18014143104932046\n",
      "train loss:0.27708008247021587\n",
      "train loss:0.30123475331788935\n",
      "train loss:0.5247766298609524\n",
      "train loss:0.28277709358995334\n",
      "train loss:0.3552294847173195\n",
      "train loss:0.3371810448366251\n",
      "train loss:0.3329654080742905\n",
      "train loss:0.32838130712671465\n",
      "train loss:0.3828235666350559\n",
      "train loss:0.26028078430252394\n",
      "train loss:0.22156191722631344\n",
      "train loss:0.2816722465269211\n",
      "train loss:0.4876357928547587\n",
      "train loss:0.357233226498382\n",
      "train loss:0.22796273757197968\n",
      "train loss:0.3014857430936053\n",
      "train loss:0.4317220220336142\n",
      "train loss:0.32612176934509784\n",
      "train loss:0.2794673170503888\n",
      "train loss:0.46326444184058907\n",
      "train loss:0.30866863287821356\n",
      "train loss:0.24874684358885055\n",
      "train loss:0.29920053958836423\n",
      "train loss:0.2247038977906826\n",
      "train loss:0.3579006617136622\n",
      "train loss:0.2572114035198766\n",
      "train loss:0.23516913093989486\n",
      "train loss:0.26574977149293166\n",
      "train loss:0.25479944182748343\n",
      "train loss:0.25769427092031116\n",
      "train loss:0.38794458942751014\n",
      "train loss:0.31993383098191647\n",
      "train loss:0.46369623156757533\n",
      "train loss:0.2565869764416852\n",
      "train loss:0.28432763124659677\n",
      "train loss:0.29711865615544303\n",
      "train loss:0.2249055275957349\n",
      "train loss:0.3321539713738945\n",
      "train loss:0.35179930334976156\n",
      "train loss:0.31053421851310753\n",
      "train loss:0.27809025443051955\n",
      "train loss:0.4278366569055027\n",
      "train loss:0.33606979430728967\n",
      "train loss:0.32595493477937754\n",
      "train loss:0.2648342872135898\n",
      "train loss:0.3234906633735097\n",
      "train loss:0.35605988018064755\n",
      "train loss:0.3155455054290436\n",
      "train loss:0.2732860826466632\n",
      "train loss:0.2488022997498429\n",
      "train loss:0.3208772140392614\n",
      "train loss:0.4173757328864857\n",
      "train loss:0.3032477124832649\n",
      "train loss:0.35606164225436165\n",
      "train loss:0.24054275167365177\n",
      "train loss:0.26509679314031803\n",
      "train loss:0.3147055672799624\n",
      "train loss:0.2667489602751157\n",
      "train loss:0.30212841318636374\n",
      "train loss:0.2835062681608777\n",
      "train loss:0.3092852836086512\n",
      "train loss:0.3782348610615048\n",
      "train loss:0.3072913000005712\n",
      "train loss:0.32873427331145977\n",
      "train loss:0.24348786621751323\n",
      "train loss:0.28346534958342856\n",
      "train loss:0.34191595009112064\n",
      "train loss:0.3540331713729956\n",
      "train loss:0.2831078670722341\n",
      "train loss:0.2279446380794404\n",
      "train loss:0.3173106620085179\n",
      "train loss:0.22909652452570306\n",
      "train loss:0.39317079195134963\n",
      "train loss:0.3096128124640826\n",
      "train loss:0.2436650659271839\n",
      "train loss:0.29936584553341006\n",
      "train loss:0.21189715292847494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.2041960063959415\n",
      "train loss:0.19467052584982472\n",
      "train loss:0.33017451982244816\n",
      "train loss:0.3028572264347896\n",
      "train loss:0.36727773555789545\n",
      "train loss:0.33343065614974654\n",
      "train loss:0.3087267182468232\n",
      "train loss:0.2662323128038967\n",
      "train loss:0.35593329134052765\n",
      "train loss:0.5262352532463838\n",
      "train loss:0.29536243771659554\n",
      "train loss:0.3216786142120505\n",
      "train loss:0.3061007269315547\n",
      "train loss:0.23474875644825566\n",
      "train loss:0.2614731374907043\n",
      "train loss:0.32586820017128615\n",
      "train loss:0.26806437621443646\n",
      "train loss:0.34287728151785385\n",
      "train loss:0.2126206023649424\n",
      "train loss:0.2231277752029187\n",
      "train loss:0.4271664236783036\n",
      "train loss:0.21470659760343958\n",
      "train loss:0.259357540950201\n",
      "train loss:0.2706457003011003\n",
      "train loss:0.3241552544389517\n",
      "train loss:0.22700360550348972\n",
      "train loss:0.3166518306391623\n",
      "train loss:0.28177662282395227\n",
      "train loss:0.3243431460624655\n",
      "train loss:0.2040132044086393\n",
      "train loss:0.38916400113304883\n",
      "train loss:0.23550858779840148\n",
      "train loss:0.3554213415293579\n",
      "train loss:0.24677816520432969\n",
      "train loss:0.22531330746711487\n",
      "train loss:0.29434633453901743\n",
      "train loss:0.35764526689998144\n",
      "train loss:0.18942478256245604\n",
      "train loss:0.3720453334373348\n",
      "train loss:0.3865430116656325\n",
      "train loss:0.30891918343700775\n",
      "train loss:0.28363026906729494\n",
      "train loss:0.4022967937133962\n",
      "train loss:0.24724649112150499\n",
      "train loss:0.3843449641693444\n",
      "train loss:0.2683947601419911\n",
      "train loss:0.2763448685987906\n",
      "train loss:0.22059826716442202\n",
      "train loss:0.3014835416452853\n",
      "train loss:0.2675613236406072\n",
      "train loss:0.25739039503891603\n",
      "train loss:0.24212466688705545\n",
      "train loss:0.24555763088418125\n",
      "train loss:0.2715197447479404\n",
      "train loss:0.24874911186197\n",
      "train loss:0.2665984049219747\n",
      "train loss:0.23183266488412616\n",
      "train loss:0.24906618345996218\n",
      "train loss:0.2415823427189012\n",
      "train loss:0.4310416335026971\n",
      "train loss:0.3157022559258186\n",
      "train loss:0.34556747969540125\n",
      "train loss:0.276271008136286\n",
      "train loss:0.272200371442927\n",
      "train loss:0.2346745589851967\n",
      "train loss:0.3497867156121906\n",
      "train loss:0.32210965868208274\n",
      "train loss:0.24934879298504697\n",
      "train loss:0.46370159678034717\n",
      "train loss:0.30338015729753937\n",
      "train loss:0.24677834198597487\n",
      "train loss:0.28021122466407894\n",
      "train loss:0.19180107310829606\n",
      "train loss:0.20544132829224793\n",
      "train loss:0.2719617830371941\n",
      "train loss:0.18982462957318752\n",
      "train loss:0.3792157247198114\n",
      "train loss:0.2222675432811134\n",
      "train loss:0.2935546072967248\n",
      "train loss:0.4508196817269403\n",
      "train loss:0.2028840610652441\n",
      "train loss:0.2291022317389211\n",
      "train loss:0.3511567291731925\n",
      "train loss:0.3165477499636214\n",
      "train loss:0.27950546682536204\n",
      "train loss:0.4211450540164238\n",
      "train loss:0.23447596065983606\n",
      "train loss:0.26953037033773397\n",
      "train loss:0.3115030566662449\n",
      "train loss:0.36892861262851523\n",
      "train loss:0.2139474017710569\n",
      "train loss:0.3160863349824018\n",
      "train loss:0.36283799211250056\n",
      "train loss:0.3023786450926584\n",
      "train loss:0.2540703673232251\n",
      "train loss:0.3067918187328008\n",
      "train loss:0.21821789964087693\n",
      "train loss:0.3180799949693463\n",
      "train loss:0.1835063794810527\n",
      "train loss:0.2782286203245944\n",
      "train loss:0.2882284268611713\n",
      "train loss:0.37023946888169834\n",
      "train loss:0.301928819386746\n",
      "train loss:0.19786467368369984\n",
      "train loss:0.35832425156497727\n",
      "train loss:0.27149526844389266\n",
      "train loss:0.2600211389009173\n",
      "train loss:0.40716814873170654\n",
      "train loss:0.20564718642837307\n",
      "train loss:0.25758643960502037\n",
      "train loss:0.41610919371652627\n",
      "train loss:0.270843433379599\n",
      "train loss:0.29189146768489865\n",
      "train loss:0.3418809550140675\n",
      "train loss:0.22495714664076977\n",
      "train loss:0.22152589561736008\n",
      "train loss:0.39252021253399133\n",
      "train loss:0.3451753113270367\n",
      "train loss:0.3203300979114781\n",
      "train loss:0.23311857320133175\n",
      "train loss:0.24179493568020521\n",
      "train loss:0.27204831865631696\n",
      "train loss:0.32467257119899373\n",
      "train loss:0.3428298597552146\n",
      "train loss:0.2011785968868645\n",
      "train loss:0.30313464193661227\n",
      "train loss:0.3334567169178768\n",
      "train loss:0.24875756508425886\n",
      "train loss:0.3284235190928992\n",
      "train loss:0.312277455379457\n",
      "train loss:0.35647820999110436\n",
      "train loss:0.3312278595466341\n",
      "train loss:0.35304447186138566\n",
      "train loss:0.12875915897651313\n",
      "train loss:0.28481069760786576\n",
      "train loss:0.22461834190263366\n",
      "train loss:0.29307019813484575\n",
      "train loss:0.31660768816158064\n",
      "train loss:0.29210243534845526\n",
      "train loss:0.18018727682134572\n",
      "train loss:0.43079617990681013\n",
      "train loss:0.2799339627942925\n",
      "train loss:0.3073151625037191\n",
      "train loss:0.23135920854974112\n",
      "train loss:0.4746117886132711\n",
      "train loss:0.37688877427184997\n",
      "train loss:0.25447420876765847\n",
      "train loss:0.25054079038160615\n",
      "train loss:0.329199263911744\n",
      "train loss:0.4093653316858773\n",
      "train loss:0.35833430102688785\n",
      "train loss:0.31831104199529403\n",
      "train loss:0.19632723750686346\n",
      "train loss:0.23889053729033904\n",
      "train loss:0.1876299895234892\n",
      "train loss:0.21879368719712786\n",
      "train loss:0.2808506908559813\n",
      "train loss:0.2453131258933008\n",
      "train loss:0.32152225781850474\n",
      "train loss:0.23096655465879443\n",
      "train loss:0.16478976965499414\n",
      "train loss:0.37328363719704954\n",
      "train loss:0.3240029272653578\n",
      "train loss:0.21088372418826232\n",
      "train loss:0.3573554252473818\n",
      "train loss:0.2952038806564386\n",
      "train loss:0.4114455681878283\n",
      "train loss:0.28278612917113904\n",
      "train loss:0.36431570484841813\n",
      "train loss:0.3819340864824388\n",
      "train loss:0.4306812438565857\n",
      "train loss:0.3300908971309831\n",
      "train loss:0.17630652722660722\n",
      "train loss:0.2668700804831272\n",
      "train loss:0.4437370354595891\n",
      "train loss:0.3688883023087613\n",
      "train loss:0.21423649383125473\n",
      "train loss:0.20167500917104977\n",
      "train loss:0.2646443311170949\n",
      "train loss:0.3454151409257684\n",
      "train loss:0.23706128131155363\n",
      "train loss:0.17001709598040557\n",
      "train loss:0.29588842576180724\n",
      "train loss:0.25838746127565104\n",
      "train loss:0.35193410469908754\n",
      "train loss:0.19160763777686005\n",
      "train loss:0.25995728246064453\n",
      "train loss:0.29761241834681895\n",
      "train loss:0.298953281634842\n",
      "train loss:0.2238448645170259\n",
      "train loss:0.3133197018029599\n",
      "train loss:0.3664522621206803\n",
      "train loss:0.2143663618262295\n",
      "train loss:0.2630900500934653\n",
      "train loss:0.27706013914210087\n",
      "train loss:0.4278412060082839\n",
      "train loss:0.2634218816450041\n",
      "train loss:0.2328714384685094\n",
      "train loss:0.2211486915661237\n",
      "train loss:0.34253713571340605\n",
      "train loss:0.2078153113339063\n",
      "train loss:0.27785616836621546\n",
      "train loss:0.22862383173754247\n",
      "train loss:0.3368898741430734\n",
      "train loss:0.11817013091689463\n",
      "train loss:0.22669773127463158\n",
      "train loss:0.19334327661875406\n",
      "train loss:0.23155051373245733\n",
      "train loss:0.2239545236793617\n",
      "train loss:0.30774448285496114\n",
      "train loss:0.19932799668126566\n",
      "train loss:0.2378057708354672\n",
      "train loss:0.38132808291215914\n",
      "train loss:0.28497759686041335\n",
      "train loss:0.20568313053251688\n",
      "train loss:0.3247953319446615\n",
      "train loss:0.32772474725035056\n",
      "train loss:0.15966680970820535\n",
      "train loss:0.30524069546842847\n",
      "train loss:0.29013625513338703\n",
      "train loss:0.12468795663232596\n",
      "train loss:0.2464662823954398\n",
      "train loss:0.2348976766036134\n",
      "train loss:0.2354492813723215\n",
      "train loss:0.36463591672919016\n",
      "train loss:0.3099430956866347\n",
      "train loss:0.1454783827968282\n",
      "train loss:0.24646398615031267\n",
      "train loss:0.3411375635530399\n",
      "train loss:0.18064931913919285\n",
      "train loss:0.21455629355679331\n",
      "train loss:0.2112633340995631\n",
      "train loss:0.2019706818054622\n",
      "train loss:0.35589011324219477\n",
      "train loss:0.3102378473108624\n",
      "train loss:0.2239117931847534\n",
      "train loss:0.2775132286660658\n",
      "train loss:0.26348698871125875\n",
      "train loss:0.28797172115817465\n",
      "train loss:0.20821027087454044\n",
      "train loss:0.1936866329874741\n",
      "train loss:0.3228018178886083\n",
      "train loss:0.226903027658132\n",
      "train loss:0.3775944498573854\n",
      "train loss:0.3154111321610782\n",
      "train loss:0.4255141897223169\n",
      "train loss:0.26639853179812456\n",
      "train loss:0.28579719188974534\n",
      "train loss:0.2522198119483928\n",
      "train loss:0.2584216322166258\n",
      "train loss:0.33402030359865703\n",
      "train loss:0.3114076754914349\n",
      "train loss:0.28183437933652333\n",
      "train loss:0.21560422547726113\n",
      "train loss:0.3401978563324578\n",
      "train loss:0.2169813005352839\n",
      "train loss:0.24828113931574214\n",
      "train loss:0.3661184778056129\n",
      "train loss:0.3389637061655422\n",
      "train loss:0.21489870029833724\n",
      "train loss:0.2860032417322035\n",
      "train loss:0.30568812046889776\n",
      "train loss:0.23794616133925595\n",
      "train loss:0.28512306435780266\n",
      "train loss:0.30354559618396576\n",
      "train loss:0.23321925473640007\n",
      "train loss:0.30142733814186284\n",
      "train loss:0.27035757584689274\n",
      "train loss:0.2420534276772158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.21176324851117875\n",
      "train loss:0.3005131292373795\n",
      "train loss:0.28263619186957206\n",
      "train loss:0.254207785205373\n",
      "train loss:0.30057856031199526\n",
      "train loss:0.27375523323944095\n",
      "train loss:0.2557779406037941\n",
      "train loss:0.2729785805830421\n",
      "train loss:0.17823427017280438\n",
      "train loss:0.35375260733213487\n",
      "train loss:0.3037367003318925\n",
      "train loss:0.23811200781149128\n",
      "train loss:0.4695148425368628\n",
      "train loss:0.19792430172717626\n",
      "train loss:0.21648406781930818\n",
      "train loss:0.28805138151876136\n",
      "train loss:0.32442328462540937\n",
      "train loss:0.2873779771664637\n",
      "train loss:0.29495788183862376\n",
      "train loss:0.3153084396144425\n",
      "train loss:0.27481072445584176\n",
      "train loss:0.40811241973663215\n",
      "train loss:0.2926248274825199\n",
      "train loss:0.17554832775271412\n",
      "train loss:0.3278056643138632\n",
      "train loss:0.3054838867933942\n",
      "train loss:0.2335329141532404\n",
      "train loss:0.28089724966787516\n",
      "train loss:0.3420078254977627\n",
      "train loss:0.17865027558254665\n",
      "train loss:0.3681309343599657\n",
      "train loss:0.2680295049059154\n",
      "train loss:0.25459802778953916\n",
      "train loss:0.23320953137054057\n",
      "train loss:0.2937977927314789\n",
      "train loss:0.295731206234057\n",
      "train loss:0.3698974910636314\n",
      "train loss:0.16008219076199925\n",
      "train loss:0.32574881298641906\n",
      "train loss:0.315478150101141\n",
      "train loss:0.17219668772337765\n",
      "train loss:0.26207413975204824\n",
      "train loss:0.22018913266815524\n",
      "train loss:0.14871174279076818\n",
      "train loss:0.3014529622421415\n",
      "train loss:0.2511809549265571\n",
      "train loss:0.4617395385464049\n",
      "train loss:0.2505023013817995\n",
      "train loss:0.1708146347723052\n",
      "train loss:0.18763190853381648\n",
      "train loss:0.2191749165923789\n",
      "train loss:0.24630881282798836\n",
      "train loss:0.5225661046968497\n",
      "train loss:0.24928537789463737\n",
      "train loss:0.2373093656855204\n",
      "train loss:0.36437817966495845\n",
      "train loss:0.2888444580869767\n",
      "train loss:0.2912557509420541\n",
      "train loss:0.2928933877461359\n",
      "train loss:0.2836025997476495\n",
      "train loss:0.21588747599801614\n",
      "train loss:0.2884972750865703\n",
      "train loss:0.35078645464017977\n",
      "train loss:0.2880667248760678\n",
      "train loss:0.4263026955702927\n",
      "train loss:0.24376988898870722\n",
      "train loss:0.2817291460105376\n",
      "train loss:0.3098187306626994\n",
      "train loss:0.2347690722335597\n",
      "train loss:0.29468469546936854\n",
      "train loss:0.36437393910824994\n",
      "train loss:0.24373805345015134\n",
      "train loss:0.2527531926092269\n",
      "train loss:0.15802449765603538\n",
      "train loss:0.3034959312021009\n",
      "train loss:0.3075689389827421\n",
      "train loss:0.4132686869743559\n",
      "train loss:0.1610020815752616\n",
      "train loss:0.3172502289482259\n",
      "train loss:0.2791073593252165\n",
      "train loss:0.25002308026500963\n",
      "train loss:0.271582322818674\n",
      "train loss:0.21392205814979562\n",
      "train loss:0.3198374835523808\n",
      "train loss:0.4954942314614494\n",
      "train loss:0.2727842291737864\n",
      "train loss:0.3589350639395915\n",
      "train loss:0.32796481476984035\n",
      "train loss:0.3223982075662887\n",
      "train loss:0.25393909662256026\n",
      "train loss:0.22843609048978777\n",
      "train loss:0.3699043191833381\n",
      "train loss:0.2786309593000749\n",
      "train loss:0.3216383523816244\n",
      "train loss:0.2414802897387205\n",
      "train loss:0.4112743999364848\n",
      "train loss:0.17184229914488092\n",
      "train loss:0.38121290499703275\n",
      "train loss:0.3313333990828164\n",
      "train loss:0.1954089558858537\n",
      "train loss:0.27191034413121257\n",
      "train loss:0.3048990358203438\n",
      "train loss:0.3427134881450125\n",
      "train loss:0.20089601081193123\n",
      "train loss:0.22081312703547648\n",
      "train loss:0.35518440054616235\n",
      "train loss:0.3704497703208131\n",
      "train loss:0.3453994721903365\n",
      "train loss:0.2908301096352906\n",
      "train loss:0.29017851233641073\n",
      "train loss:0.20435882951772888\n",
      "train loss:0.28647879500951035\n",
      "train loss:0.38876047991854756\n",
      "train loss:0.30053007893704414\n",
      "train loss:0.14485473548580874\n",
      "train loss:0.3135470770316441\n",
      "train loss:0.3856015633720275\n",
      "train loss:0.32219993960457943\n",
      "train loss:0.2673454240149675\n",
      "train loss:0.21169602815138147\n",
      "train loss:0.20518189982212373\n",
      "train loss:0.2467545956407633\n",
      "train loss:0.29854995258582206\n",
      "train loss:0.18660745059389602\n",
      "train loss:0.22424515281973437\n",
      "train loss:0.3072869479905009\n",
      "train loss:0.28115002114775595\n",
      "train loss:0.4500695033071382\n",
      "train loss:0.32652811678534965\n",
      "train loss:0.32492614071560516\n",
      "train loss:0.2481917925302025\n",
      "train loss:0.21061916766573316\n",
      "train loss:0.381812206272222\n",
      "train loss:0.2801965144880375\n",
      "train loss:0.3709335393777109\n",
      "train loss:0.27057120316167577\n",
      "train loss:0.19674625732566295\n",
      "train loss:0.30543921462037077\n",
      "train loss:0.312714463457887\n",
      "train loss:0.2794877962039795\n",
      "train loss:0.1911230733388668\n",
      "train loss:0.17788442950584407\n",
      "train loss:0.38511089323536934\n",
      "train loss:0.2168080144834396\n",
      "train loss:0.33591933291486437\n",
      "train loss:0.30233878749983867\n",
      "train loss:0.19923018072755266\n",
      "train loss:0.23966657398843863\n",
      "train loss:0.2522005812994983\n",
      "train loss:0.23904584538107806\n",
      "train loss:0.3306552764193041\n",
      "train loss:0.24089361644581492\n",
      "train loss:0.3812103981301581\n",
      "train loss:0.26886737681472567\n",
      "train loss:0.24766060772100254\n",
      "train loss:0.18860111048193443\n",
      "train loss:0.38387819822833613\n",
      "train loss:0.24535421955464248\n",
      "train loss:0.13495703315158594\n",
      "train loss:0.3157816012374278\n",
      "train loss:0.16042012633413394\n",
      "train loss:0.41154889633956154\n",
      "train loss:0.2777487404644103\n",
      "train loss:0.21702648556019022\n",
      "train loss:0.1340321356898731\n",
      "train loss:0.1737583008992881\n",
      "train loss:0.236959730992018\n",
      "train loss:0.31114948162322775\n",
      "train loss:0.19722490183008592\n",
      "train loss:0.27665399190829093\n",
      "train loss:0.24928477713988023\n",
      "train loss:0.24943231340023175\n",
      "train loss:0.22707137059934063\n",
      "train loss:0.22108535402968346\n",
      "train loss:0.28724281257626183\n",
      "train loss:0.30704254866164055\n",
      "train loss:0.2703577964997111\n",
      "train loss:0.23243677393409304\n",
      "train loss:0.34160933755608935\n",
      "train loss:0.21683531804344944\n",
      "train loss:0.17115453059563623\n",
      "train loss:0.15777319028322714\n",
      "train loss:0.30206817350028026\n",
      "train loss:0.43591590181235246\n",
      "train loss:0.2974013437586976\n",
      "train loss:0.18951062242210334\n",
      "train loss:0.2241718806529558\n",
      "train loss:0.3170127110087509\n",
      "train loss:0.3244894352444206\n",
      "train loss:0.3060512162947994\n",
      "train loss:0.3150371935236676\n",
      "train loss:0.27577165742371046\n",
      "train loss:0.17788664449908909\n",
      "train loss:0.27381389029590425\n",
      "train loss:0.17779234112977174\n",
      "train loss:0.3629283939301616\n",
      "train loss:0.39359051720720173\n",
      "train loss:0.4096877440468777\n",
      "train loss:0.20990051407950416\n",
      "train loss:0.3133779770091242\n",
      "train loss:0.24357762277676043\n",
      "train loss:0.17908987361228898\n",
      "train loss:0.2967829152439241\n",
      "train loss:0.3186702080298649\n",
      "train loss:0.24323498168586208\n",
      "train loss:0.3707102567352634\n",
      "train loss:0.35714033283198854\n",
      "train loss:0.2690187651200367\n",
      "train loss:0.2055605016698929\n",
      "train loss:0.33127935346099696\n",
      "train loss:0.23853401074640534\n",
      "train loss:0.2676689753417035\n",
      "train loss:0.2533701669063726\n",
      "train loss:0.225109303527438\n",
      "train loss:0.26321504462050493\n",
      "train loss:0.3677728483835549\n",
      "train loss:0.3180237297266556\n",
      "train loss:0.3293068549340676\n",
      "train loss:0.1977409622929696\n",
      "train loss:0.30672748483602147\n",
      "train loss:0.27584835260267543\n",
      "train loss:0.27450574027019964\n",
      "train loss:0.2578227733228518\n",
      "train loss:0.2212953279130771\n",
      "train loss:0.28910678173444804\n",
      "train loss:0.2682039562813694\n",
      "train loss:0.34414570378153386\n",
      "train loss:0.2683108662118254\n",
      "train loss:0.2369568176072466\n",
      "train loss:0.260202289381491\n",
      "train loss:0.21152996884732603\n",
      "train loss:0.2507896785238311\n",
      "train loss:0.18749026180122186\n",
      "train loss:0.2523312221509949\n",
      "train loss:0.2826826925708199\n",
      "train loss:0.28401573958339815\n",
      "train loss:0.219113851974823\n",
      "train loss:0.23807534547194964\n",
      "train loss:0.24609996633798917\n",
      "train loss:0.19548248742524968\n",
      "train loss:0.2145838457700399\n",
      "train loss:0.2692920259870479\n",
      "train loss:0.2746711203973959\n",
      "train loss:0.211932560022437\n",
      "train loss:0.27564073054149796\n",
      "train loss:0.22509018857873578\n",
      "train loss:0.31160696763217166\n",
      "train loss:0.3859793654996934\n",
      "train loss:0.26692604612693577\n",
      "train loss:0.1999203479291286\n",
      "train loss:0.25771595552901\n",
      "train loss:0.2102852704046936\n",
      "=== epoch:5, train acc:0.904, test acc:0.886 ===\n",
      "train loss:0.26395206025830237\n",
      "train loss:0.20969972826100583\n",
      "train loss:0.2980346092434388\n",
      "train loss:0.2361616091936551\n",
      "train loss:0.36470420541811843\n",
      "train loss:0.2654864996292197\n",
      "train loss:0.20584243299271254\n",
      "train loss:0.3395875504830555\n",
      "train loss:0.17764968962165892\n",
      "train loss:0.2933976011749888\n",
      "train loss:0.3123950472827096\n",
      "train loss:0.3105851748178784\n",
      "train loss:0.258564915321636\n",
      "train loss:0.244268096723701\n",
      "train loss:0.315808880036093\n",
      "train loss:0.3130721798671881\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.33778060450918984\n",
      "train loss:0.30034331054725205\n",
      "train loss:0.3369718742073426\n",
      "train loss:0.2563120616252718\n",
      "train loss:0.21256562749699942\n",
      "train loss:0.2053577064875228\n",
      "train loss:0.41997745965784106\n",
      "train loss:0.27484677746051717\n",
      "train loss:0.22493093693289748\n",
      "train loss:0.25410263727180976\n",
      "train loss:0.4590293711918716\n",
      "train loss:0.3002599038428237\n",
      "train loss:0.24831534894118618\n",
      "train loss:0.29491155945381636\n",
      "train loss:0.2103273362835571\n",
      "train loss:0.28726813251393074\n",
      "train loss:0.37178253688156915\n",
      "train loss:0.1984366133689963\n",
      "train loss:0.3807616586171821\n",
      "train loss:0.2435592009104951\n",
      "train loss:0.3275949425773937\n",
      "train loss:0.19692181306746231\n",
      "train loss:0.3035194372115835\n",
      "train loss:0.29421041019772654\n",
      "train loss:0.3006266034323607\n",
      "train loss:0.24609502559843688\n",
      "train loss:0.2679342278001097\n",
      "train loss:0.2196167953499918\n",
      "train loss:0.18118358551135155\n",
      "train loss:0.27295834668280944\n",
      "train loss:0.3321170764295778\n",
      "train loss:0.2602250198576872\n",
      "train loss:0.2540372844253418\n",
      "train loss:0.33426919411669836\n",
      "train loss:0.3163419234573286\n",
      "train loss:0.26567627965706236\n",
      "train loss:0.3778217004614845\n",
      "train loss:0.18485499013004789\n",
      "train loss:0.19715372500683168\n",
      "train loss:0.2527571715257296\n",
      "train loss:0.28602778074059065\n",
      "train loss:0.20672349049495967\n",
      "train loss:0.21836899854998568\n",
      "train loss:0.23226790955593693\n",
      "train loss:0.2662086722833184\n",
      "train loss:0.34654312477319416\n",
      "train loss:0.335552631014417\n",
      "train loss:0.22998985502245844\n",
      "train loss:0.19897843961157163\n",
      "train loss:0.2822067030806974\n",
      "train loss:0.33460310224039097\n",
      "train loss:0.22357578893872976\n",
      "train loss:0.3365965441471429\n",
      "train loss:0.258883266593778\n",
      "train loss:0.29173724573910786\n",
      "train loss:0.24936536286526312\n",
      "train loss:0.2912241043805984\n",
      "train loss:0.2260976799136435\n",
      "train loss:0.3035006763076653\n",
      "train loss:0.21154676665144997\n",
      "train loss:0.40378721611877594\n",
      "train loss:0.24187876443142972\n",
      "train loss:0.2985097442909082\n",
      "train loss:0.3674062609052607\n",
      "train loss:0.38786542750305847\n",
      "train loss:0.33067771143791946\n",
      "train loss:0.1874126887076282\n",
      "train loss:0.24051318673362443\n",
      "train loss:0.2447866977986259\n",
      "train loss:0.20782302134883282\n",
      "train loss:0.27347190823282\n",
      "train loss:0.3444693242065118\n",
      "train loss:0.35064539698453406\n",
      "train loss:0.3018037663638207\n",
      "train loss:0.23971487329656196\n",
      "train loss:0.18495607465978992\n",
      "train loss:0.1867529539565935\n",
      "train loss:0.20627889167807162\n",
      "train loss:0.1663693588984197\n",
      "train loss:0.22309600844160282\n",
      "train loss:0.3050687235311624\n",
      "train loss:0.19461030944447774\n",
      "train loss:0.2019278253011623\n",
      "train loss:0.2352037767909663\n",
      "train loss:0.32163887353459214\n",
      "train loss:0.4664601527300069\n",
      "train loss:0.4443194634555189\n",
      "train loss:0.27399360309258947\n",
      "train loss:0.289625164539751\n",
      "train loss:0.3250624591667977\n",
      "train loss:0.20970818521629245\n",
      "train loss:0.22834718995597503\n",
      "train loss:0.20281790744936734\n",
      "train loss:0.2619384362217757\n",
      "train loss:0.2612511162463336\n",
      "train loss:0.4620803294969278\n",
      "train loss:0.2795906090646778\n",
      "train loss:0.30284607564550003\n",
      "train loss:0.2657836974959977\n",
      "train loss:0.31763018727004194\n",
      "train loss:0.21360104602074168\n",
      "train loss:0.32283149908084596\n",
      "train loss:0.3514815822795559\n",
      "train loss:0.3093946987486227\n",
      "train loss:0.23777879080317293\n",
      "train loss:0.28149500060020927\n",
      "train loss:0.21446655540372317\n",
      "train loss:0.32077980070452833\n",
      "train loss:0.3762417257209581\n",
      "train loss:0.25241898898371007\n",
      "train loss:0.12935460368257248\n",
      "train loss:0.23463355269164787\n",
      "train loss:0.2408606689036317\n",
      "train loss:0.2715545784566839\n",
      "train loss:0.3936395119771943\n",
      "train loss:0.2120732489165996\n",
      "train loss:0.3030655787750003\n",
      "train loss:0.36526170999221186\n",
      "train loss:0.2503700007751871\n",
      "train loss:0.40661844320707735\n",
      "train loss:0.26641518971382755\n",
      "train loss:0.39714198746234003\n",
      "train loss:0.18226072309614053\n",
      "train loss:0.23962417247732368\n",
      "train loss:0.2908104127226337\n",
      "train loss:0.1737703793190995\n",
      "train loss:0.11847416966501938\n",
      "train loss:0.22541099586446947\n",
      "train loss:0.2850701010201714\n",
      "train loss:0.2109776348619587\n",
      "train loss:0.2592802661093732\n",
      "train loss:0.2305843531583378\n",
      "train loss:0.21218418745513604\n",
      "train loss:0.3306504594749753\n",
      "train loss:0.1411710979395061\n",
      "train loss:0.30431995361935266\n",
      "train loss:0.23275925437007236\n",
      "train loss:0.40477221861764645\n",
      "train loss:0.24787505037542132\n",
      "train loss:0.23970397666185037\n",
      "train loss:0.23007975651608192\n",
      "train loss:0.20702288884923484\n",
      "train loss:0.2120975660299684\n",
      "train loss:0.272426003313172\n",
      "train loss:0.20285594060528603\n",
      "train loss:0.2801833689257228\n",
      "train loss:0.24153380540904915\n",
      "train loss:0.23238284126286873\n",
      "train loss:0.2960722424842297\n",
      "train loss:0.19353747242123837\n",
      "train loss:0.30049234094723215\n",
      "train loss:0.20014692345717616\n",
      "train loss:0.2872929928670008\n",
      "train loss:0.2939925293923728\n",
      "train loss:0.17703941126669961\n",
      "train loss:0.17699041707384772\n",
      "train loss:0.2595715209971164\n",
      "train loss:0.3481322052455135\n",
      "train loss:0.29341328534560557\n",
      "train loss:0.1224084118732154\n",
      "train loss:0.2426181310002879\n",
      "train loss:0.31646322760272205\n",
      "train loss:0.3318321859682736\n",
      "train loss:0.1886568749804309\n",
      "train loss:0.2695562535055772\n",
      "train loss:0.26052975520512783\n",
      "train loss:0.18444589695600622\n",
      "train loss:0.2256896316078802\n",
      "train loss:0.1900474373124688\n",
      "train loss:0.2759165310472122\n",
      "train loss:0.31469291378844777\n",
      "train loss:0.11974356248586511\n",
      "train loss:0.21759072870036938\n",
      "train loss:0.18255414821067323\n",
      "train loss:0.26892913836742965\n",
      "train loss:0.29863298240514996\n",
      "train loss:0.24192107967153453\n",
      "train loss:0.20281660963345716\n",
      "train loss:0.19424469898008825\n",
      "train loss:0.2615930405477458\n",
      "train loss:0.2946156929566779\n",
      "train loss:0.19616042364726907\n",
      "train loss:0.1918031616888178\n",
      "train loss:0.17994130193963098\n",
      "train loss:0.4073139524414555\n",
      "train loss:0.3414966948290564\n",
      "train loss:0.2246858304310343\n",
      "train loss:0.1697507641043666\n",
      "train loss:0.3853811357180378\n",
      "train loss:0.21310495491904516\n",
      "train loss:0.2926796794792291\n",
      "train loss:0.3747921456657846\n",
      "train loss:0.29099980401907544\n",
      "train loss:0.30315778179962644\n",
      "train loss:0.2902350804279285\n",
      "train loss:0.31579738376242283\n",
      "train loss:0.33641931755573296\n",
      "train loss:0.35908771590013927\n",
      "train loss:0.32405870324764907\n",
      "train loss:0.27319893552188795\n",
      "train loss:0.22611352123521086\n",
      "train loss:0.29578488252578583\n",
      "train loss:0.18838886611958802\n",
      "train loss:0.26408416027326387\n",
      "train loss:0.39069332681779967\n",
      "train loss:0.34715777216421584\n",
      "train loss:0.26959833826341184\n",
      "train loss:0.2432761057046186\n",
      "train loss:0.21873867013512935\n",
      "train loss:0.26456204607303824\n",
      "train loss:0.26929280117714155\n",
      "train loss:0.3832738216184616\n",
      "train loss:0.20240651190527173\n",
      "train loss:0.3014924463372648\n",
      "train loss:0.3098730921426829\n",
      "train loss:0.25218335210528303\n",
      "train loss:0.23119138233000755\n",
      "train loss:0.32464530382759876\n",
      "train loss:0.22023381292792746\n",
      "train loss:0.12389776921041822\n",
      "train loss:0.3768636948794051\n",
      "train loss:0.25942815824783716\n",
      "train loss:0.27470530631046425\n",
      "train loss:0.23880560368995443\n",
      "train loss:0.19074755924264436\n",
      "train loss:0.2318166211348094\n",
      "train loss:0.18935637394403249\n",
      "train loss:0.26811443874084195\n",
      "train loss:0.2491765020897269\n",
      "train loss:0.2361747490480118\n",
      "train loss:0.2316022428798732\n",
      "train loss:0.3094467528224614\n",
      "train loss:0.3589105268244884\n",
      "train loss:0.25463178338783626\n",
      "train loss:0.23142239656137725\n",
      "train loss:0.20623285576278383\n",
      "train loss:0.18143827518921035\n",
      "train loss:0.20350933458384796\n",
      "train loss:0.23869484532823115\n",
      "train loss:0.30843120819484643\n",
      "train loss:0.13246348016875442\n",
      "train loss:0.18796877341953003\n",
      "train loss:0.3007291487898161\n",
      "train loss:0.30206044362483636\n",
      "train loss:0.25294293163080933\n",
      "train loss:0.35322638319685196\n",
      "train loss:0.23288614044870554\n",
      "train loss:0.22686588509691252\n",
      "train loss:0.23438929033283715\n",
      "train loss:0.2427211894050192\n",
      "train loss:0.31191864162578126\n",
      "train loss:0.1737626346625952\n",
      "train loss:0.32954643316220567\n",
      "train loss:0.3352928165322135\n",
      "train loss:0.202026696926028\n",
      "train loss:0.3249559386927715\n",
      "train loss:0.33175255796225983\n",
      "train loss:0.26993852699196325\n",
      "train loss:0.3297958270502964\n",
      "train loss:0.22287921362660693\n",
      "train loss:0.23667711249329582\n",
      "train loss:0.1834206477203006\n",
      "train loss:0.23526818475847905\n",
      "train loss:0.26669051247601294\n",
      "train loss:0.23557223113110762\n",
      "train loss:0.23827335096881583\n",
      "train loss:0.2461233065947124\n",
      "train loss:0.3764610680159457\n",
      "train loss:0.2566918086575063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.2429263454690431\n",
      "train loss:0.26325892416339386\n",
      "train loss:0.13587576489034883\n",
      "train loss:0.4037845901756333\n",
      "train loss:0.30106371111878344\n",
      "train loss:0.28219950978388897\n",
      "train loss:0.20570370551038844\n",
      "train loss:0.33133736355255883\n",
      "train loss:0.24385642778265043\n",
      "train loss:0.23659267528419942\n",
      "train loss:0.260480833038931\n",
      "train loss:0.3639663596850764\n",
      "train loss:0.13472614019120238\n",
      "train loss:0.2679144900612301\n",
      "train loss:0.23276712868315821\n",
      "train loss:0.2513474501437183\n",
      "train loss:0.24323489060426862\n",
      "train loss:0.30647653265661257\n",
      "train loss:0.1968976204361547\n",
      "train loss:0.2316745909558112\n",
      "train loss:0.3449544110198257\n",
      "train loss:0.27818425458960083\n",
      "train loss:0.26190331534558176\n",
      "train loss:0.22598247997384266\n",
      "train loss:0.2481715393440927\n",
      "train loss:0.4444737502940337\n",
      "train loss:0.18412475966726288\n",
      "train loss:0.271738567702315\n",
      "train loss:0.18536882789144626\n",
      "train loss:0.3148258580603631\n",
      "train loss:0.16995125715062642\n",
      "train loss:0.2477641472308055\n",
      "train loss:0.321046607375634\n",
      "train loss:0.35501577177744587\n",
      "train loss:0.22409044155307645\n",
      "train loss:0.3164215108269909\n",
      "train loss:0.19362560826912176\n",
      "train loss:0.24875138818492096\n",
      "train loss:0.20600580055513035\n",
      "train loss:0.32648996434107147\n",
      "train loss:0.26175738163984286\n",
      "train loss:0.2847741942389781\n",
      "train loss:0.22186719313139847\n",
      "train loss:0.2751487267440418\n",
      "train loss:0.26425283129777183\n",
      "train loss:0.3620245214851422\n",
      "train loss:0.2736046297681854\n",
      "train loss:0.16384116787056083\n",
      "train loss:0.2682864852866826\n",
      "train loss:0.2080309196735289\n",
      "train loss:0.1675593532578236\n",
      "train loss:0.23030907764994052\n",
      "train loss:0.26170182397569947\n",
      "train loss:0.24594106563766768\n",
      "train loss:0.1843343076914498\n",
      "train loss:0.22085796412593325\n",
      "train loss:0.2443137568098359\n",
      "train loss:0.2758598007340039\n",
      "train loss:0.3053774350431792\n",
      "train loss:0.2915229685413107\n",
      "train loss:0.253684119964932\n",
      "train loss:0.33258789987599263\n",
      "train loss:0.2755902291050395\n",
      "train loss:0.25566820485963926\n",
      "train loss:0.21146048503420978\n",
      "train loss:0.4020254578856883\n",
      "train loss:0.2019920972607077\n",
      "train loss:0.3864929748605482\n",
      "train loss:0.3178872435263383\n",
      "train loss:0.2727704833680669\n",
      "train loss:0.19561243560671254\n",
      "train loss:0.30562781383782567\n",
      "train loss:0.27366606803803206\n",
      "train loss:0.2550467052001046\n",
      "train loss:0.3018012700024139\n",
      "train loss:0.29178287487182236\n",
      "train loss:0.3251256836655415\n",
      "train loss:0.26243280554133314\n",
      "train loss:0.34461371923843354\n",
      "train loss:0.3269586537942034\n",
      "train loss:0.27226742123438047\n",
      "train loss:0.15338804622246288\n",
      "train loss:0.21820987967839967\n",
      "train loss:0.238509943996034\n",
      "train loss:0.34736113989743933\n",
      "train loss:0.24990152665800777\n",
      "train loss:0.2198532391166077\n",
      "train loss:0.18951203759708246\n",
      "train loss:0.2817560714363363\n",
      "train loss:0.16299575141307568\n",
      "train loss:0.23978087526034053\n",
      "train loss:0.26251716909297934\n",
      "train loss:0.17517573502174802\n",
      "train loss:0.2489396449922433\n",
      "train loss:0.2174296029668567\n",
      "train loss:0.3267844212704681\n",
      "train loss:0.2439145336391487\n",
      "train loss:0.22773416810002056\n",
      "train loss:0.18750285388097454\n",
      "train loss:0.3101603985826744\n",
      "train loss:0.23174090879024578\n",
      "train loss:0.2580134856156256\n",
      "train loss:0.2905546107961598\n",
      "train loss:0.24369739020158834\n",
      "train loss:0.39232823563114316\n",
      "train loss:0.289908886640143\n",
      "train loss:0.21266118198725714\n",
      "train loss:0.18954430233756484\n",
      "train loss:0.22089318358319773\n",
      "train loss:0.37669276121311723\n",
      "train loss:0.279577626317969\n",
      "train loss:0.25582596101352295\n",
      "train loss:0.14944718447667296\n",
      "train loss:0.32649314004445024\n",
      "train loss:0.3128154104853144\n",
      "train loss:0.1541123539432905\n",
      "train loss:0.3772476146366703\n",
      "train loss:0.3590289887663023\n",
      "train loss:0.2978948282259996\n",
      "train loss:0.15939927826003422\n",
      "train loss:0.2735684088689477\n",
      "train loss:0.26876536739372103\n",
      "train loss:0.3578863654950748\n",
      "train loss:0.19532949545872788\n",
      "train loss:0.32098653525184906\n",
      "train loss:0.19648032935067342\n",
      "train loss:0.2605271803276519\n",
      "train loss:0.24950208947984254\n",
      "train loss:0.2308485801759597\n",
      "train loss:0.33266229359782934\n",
      "train loss:0.3471407939088427\n",
      "train loss:0.2288694850098063\n",
      "train loss:0.3157548894936275\n",
      "train loss:0.23865372775038846\n",
      "train loss:0.13538325983466987\n",
      "train loss:0.3255683743769005\n",
      "train loss:0.294235890055884\n",
      "train loss:0.19015362361307697\n",
      "train loss:0.27517815944046853\n",
      "train loss:0.2826244680790522\n",
      "train loss:0.28484679548100256\n",
      "train loss:0.2516634789795036\n",
      "train loss:0.29131428727049924\n",
      "train loss:0.28840499452304064\n",
      "train loss:0.3133756297225114\n",
      "train loss:0.2793403752753721\n",
      "train loss:0.45896223154841387\n",
      "train loss:0.27822854656372514\n",
      "train loss:0.3151721249240608\n",
      "train loss:0.1179470717099033\n",
      "train loss:0.28524270220454784\n",
      "train loss:0.3532520665950392\n",
      "train loss:0.2860180552532774\n",
      "train loss:0.23349255390305337\n",
      "train loss:0.26619416503371285\n",
      "train loss:0.19765913650039277\n",
      "train loss:0.3778993171776145\n",
      "train loss:0.25186544780833675\n",
      "train loss:0.2237103815796303\n",
      "train loss:0.21262527735095507\n",
      "train loss:0.216284352122774\n",
      "train loss:0.15201273222819803\n",
      "train loss:0.2062097749539072\n",
      "train loss:0.2819041731265481\n",
      "train loss:0.1625115481504778\n",
      "train loss:0.2648997555623016\n",
      "train loss:0.0989762967920186\n",
      "train loss:0.2774564781525035\n",
      "train loss:0.3196343972128927\n",
      "train loss:0.2502961624838672\n",
      "train loss:0.22049117906529403\n",
      "train loss:0.31531576316215243\n",
      "train loss:0.32208713910686754\n",
      "train loss:0.19081729774082248\n",
      "train loss:0.2099395403992141\n",
      "train loss:0.3095246259796095\n",
      "train loss:0.2841068388690427\n",
      "train loss:0.32180276067117203\n",
      "train loss:0.2539904752503103\n",
      "train loss:0.26492142875988256\n",
      "train loss:0.18518884819038295\n",
      "train loss:0.2859832608568096\n",
      "train loss:0.3051043018676322\n",
      "train loss:0.3060009423626287\n",
      "train loss:0.16673562700141417\n",
      "train loss:0.3814534552788221\n",
      "train loss:0.18972601430772612\n",
      "train loss:0.2545827741995489\n",
      "train loss:0.3452064835035448\n",
      "train loss:0.2337148357734542\n",
      "train loss:0.26771643992139604\n",
      "train loss:0.14527590839916146\n",
      "train loss:0.2984339792037658\n",
      "train loss:0.1824320621440013\n",
      "train loss:0.23844605368909522\n",
      "train loss:0.30279009743475926\n",
      "train loss:0.258937076419735\n",
      "train loss:0.2633136035619588\n",
      "train loss:0.2836902036015446\n",
      "train loss:0.2591871983296178\n",
      "train loss:0.27626098404096244\n",
      "train loss:0.25549265760259954\n",
      "train loss:0.22376201267572818\n",
      "train loss:0.20992167708222528\n",
      "train loss:0.3377187446182702\n",
      "train loss:0.230148649654861\n",
      "train loss:0.2024787627414986\n",
      "train loss:0.28833878453330136\n",
      "train loss:0.21128684318467922\n",
      "train loss:0.22589784775573274\n",
      "train loss:0.2177708804292427\n",
      "train loss:0.18619680537976777\n",
      "train loss:0.16979637374829942\n",
      "train loss:0.2076971731612321\n",
      "train loss:0.2639732925230237\n",
      "train loss:0.1860826002635649\n",
      "train loss:0.2938615316103177\n",
      "train loss:0.22336031503522805\n",
      "train loss:0.295685648632288\n",
      "train loss:0.28941511441683615\n",
      "train loss:0.21344004058355387\n",
      "train loss:0.23928402771296525\n",
      "train loss:0.22809777495249392\n",
      "train loss:0.20879521515778698\n",
      "train loss:0.1543636398975678\n",
      "train loss:0.3173478374040538\n",
      "train loss:0.15248446378560163\n",
      "train loss:0.24397047242056805\n",
      "train loss:0.345110371275208\n",
      "train loss:0.25552926121350544\n",
      "train loss:0.18468585040454177\n",
      "train loss:0.19156755220825708\n",
      "train loss:0.1662847795448259\n",
      "train loss:0.13055200900102032\n",
      "train loss:0.1693242126814573\n",
      "train loss:0.1979638415824069\n",
      "train loss:0.20923419082457045\n",
      "train loss:0.2571370292086798\n",
      "train loss:0.2867006437986222\n",
      "train loss:0.2747820969545675\n",
      "train loss:0.1375334134099063\n",
      "train loss:0.25949823625032115\n",
      "train loss:0.20483977330038733\n",
      "train loss:0.22194213367461707\n",
      "train loss:0.21362543952754945\n",
      "train loss:0.29988131933256784\n",
      "train loss:0.21156247941930303\n",
      "train loss:0.3514476920235405\n",
      "train loss:0.12456904599035684\n",
      "train loss:0.2780369689105152\n",
      "train loss:0.2168409842444787\n",
      "train loss:0.3472261178222009\n",
      "train loss:0.334970532879109\n",
      "train loss:0.1623961202157046\n",
      "train loss:0.29403287707392706\n",
      "train loss:0.10587566377551406\n",
      "train loss:0.28887590642832484\n",
      "train loss:0.1554664232356096\n",
      "train loss:0.2625070918801563\n",
      "train loss:0.21395624306768965\n",
      "train loss:0.1799648049708458\n",
      "train loss:0.24234169673407546\n",
      "train loss:0.19911727456064646\n",
      "train loss:0.13436796886677843\n",
      "train loss:0.12706227165946316\n",
      "train loss:0.18080197561666114\n",
      "train loss:0.16520341180257006\n",
      "train loss:0.26191402261432223\n",
      "train loss:0.1803063149474637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.19177221959328858\n",
      "train loss:0.3391016481487755\n",
      "train loss:0.28416708178505967\n",
      "train loss:0.24462886744501308\n",
      "train loss:0.2665158237735168\n",
      "train loss:0.23671911175401014\n",
      "train loss:0.23591880337793278\n",
      "train loss:0.23249744399045205\n",
      "train loss:0.27281920154587574\n",
      "train loss:0.17060650403685712\n",
      "train loss:0.3616639338062421\n",
      "train loss:0.104139634153981\n",
      "train loss:0.25636900268714324\n",
      "train loss:0.2901547619150106\n",
      "train loss:0.2690900826342691\n",
      "train loss:0.26757940824268794\n",
      "train loss:0.28892704104576294\n",
      "train loss:0.3468065810808197\n",
      "train loss:0.2517054813013538\n",
      "train loss:0.3114377681263427\n",
      "train loss:0.28615544802894094\n",
      "train loss:0.22398383149854628\n",
      "train loss:0.1723908502766092\n",
      "train loss:0.26403509626821675\n",
      "train loss:0.14186347319215747\n",
      "train loss:0.3369389211410811\n",
      "train loss:0.2219487079051291\n",
      "train loss:0.20703751214087307\n",
      "train loss:0.2704911302632731\n",
      "train loss:0.25307957876945947\n",
      "train loss:0.3590358459949865\n",
      "train loss:0.2465152698984448\n",
      "train loss:0.27669178434554914\n",
      "train loss:0.18484316025875028\n",
      "train loss:0.3322684729408655\n",
      "train loss:0.2607775156057398\n",
      "train loss:0.3829115146290749\n",
      "train loss:0.46654477833608504\n",
      "train loss:0.2043708208014968\n",
      "train loss:0.1773205499052154\n",
      "train loss:0.2671753890636269\n",
      "train loss:0.21577897809983287\n",
      "train loss:0.24104361853001888\n",
      "train loss:0.2122534114121235\n",
      "train loss:0.27005499080491174\n",
      "train loss:0.24711691104636363\n",
      "=== epoch:6, train acc:0.916, test acc:0.9 ===\n",
      "train loss:0.31733420834103654\n",
      "train loss:0.32340509626716624\n",
      "train loss:0.2849610899738867\n",
      "train loss:0.2639634558431888\n",
      "train loss:0.13010425493966787\n",
      "train loss:0.27591786765885506\n",
      "train loss:0.18740066368896902\n",
      "train loss:0.29401373228007116\n",
      "train loss:0.24847355184939285\n",
      "train loss:0.21385160585432106\n",
      "train loss:0.24394569804472765\n",
      "train loss:0.25763573510003085\n",
      "train loss:0.28969268127220743\n",
      "train loss:0.42090164730046714\n",
      "train loss:0.27285347642658353\n",
      "train loss:0.24844847957745636\n",
      "train loss:0.1863281472470063\n",
      "train loss:0.1561593696427833\n",
      "train loss:0.24513959711913885\n",
      "train loss:0.2640206757181713\n",
      "train loss:0.32956687775904164\n",
      "train loss:0.27786104604285444\n",
      "train loss:0.1892492683119108\n",
      "train loss:0.29967087032753026\n",
      "train loss:0.40385846921739366\n",
      "train loss:0.25369043771917504\n",
      "train loss:0.18266483643062847\n",
      "train loss:0.312734859351071\n",
      "train loss:0.2788919299099432\n",
      "train loss:0.20591146224428303\n",
      "train loss:0.21603539750298026\n",
      "train loss:0.24364481174937555\n",
      "train loss:0.14830913880963617\n",
      "train loss:0.24826404118247963\n",
      "train loss:0.17418767369919969\n",
      "train loss:0.2427271142131821\n",
      "train loss:0.13057652776631845\n",
      "train loss:0.2931636275463906\n",
      "train loss:0.34367695733381676\n",
      "train loss:0.11879604429197974\n",
      "train loss:0.1850841246581422\n",
      "train loss:0.2185490654837686\n",
      "train loss:0.25237105421928385\n",
      "train loss:0.2218130191868047\n",
      "train loss:0.20842933757513737\n",
      "train loss:0.25161597532950464\n",
      "train loss:0.24153150702396858\n",
      "train loss:0.2599118954904112\n",
      "train loss:0.24095394734202838\n",
      "train loss:0.1911542052070279\n",
      "train loss:0.2327122150985467\n",
      "train loss:0.31838240964472136\n",
      "train loss:0.3235971233888059\n",
      "train loss:0.28425839546238496\n",
      "train loss:0.26052539101670097\n",
      "train loss:0.36462939484217544\n",
      "train loss:0.16675002410175865\n",
      "train loss:0.2146983838651863\n",
      "train loss:0.300528126822112\n",
      "train loss:0.256260955837157\n",
      "train loss:0.17560132304461396\n",
      "train loss:0.2869955854574717\n",
      "train loss:0.280812858247021\n",
      "train loss:0.30223956450409073\n",
      "train loss:0.43490951580262716\n",
      "train loss:0.310326445435012\n",
      "train loss:0.16732746038346413\n",
      "train loss:0.18077750795278047\n",
      "train loss:0.33298796984580703\n",
      "train loss:0.31402338105169225\n",
      "train loss:0.15326006410301188\n",
      "train loss:0.42034313063501083\n",
      "train loss:0.19017357173267285\n",
      "train loss:0.2077862896745972\n",
      "train loss:0.17248482844700444\n",
      "train loss:0.2062070899106183\n",
      "train loss:0.15968312544070615\n",
      "train loss:0.2678658207936313\n",
      "train loss:0.21136368827446603\n",
      "train loss:0.25076881742543183\n",
      "train loss:0.26970498029170925\n",
      "train loss:0.27600561070002927\n",
      "train loss:0.23667080842405505\n",
      "train loss:0.2602892159063242\n",
      "train loss:0.22231113878236286\n",
      "train loss:0.17954323669105046\n",
      "train loss:0.3137207715818214\n",
      "train loss:0.22300383707137109\n",
      "train loss:0.30826995301502824\n",
      "train loss:0.21871939773138827\n",
      "train loss:0.28338758310820933\n",
      "train loss:0.19425143977310036\n",
      "train loss:0.2901282241489995\n",
      "train loss:0.21229521269360815\n",
      "train loss:0.1938765507278429\n",
      "train loss:0.2589324556798838\n",
      "train loss:0.2633459222832887\n",
      "train loss:0.26711205005750127\n",
      "train loss:0.21052326464702065\n",
      "train loss:0.21219405579924125\n",
      "train loss:0.12346314144966154\n",
      "train loss:0.3233809298725997\n",
      "train loss:0.21497450472909357\n",
      "train loss:0.3108021730498609\n",
      "train loss:0.22322898048052328\n",
      "train loss:0.1390422745458061\n",
      "train loss:0.16423378750749482\n",
      "train loss:0.14580505674313216\n",
      "train loss:0.36643149876917824\n",
      "train loss:0.22031730969844787\n",
      "train loss:0.2743398147202955\n",
      "train loss:0.22881060823656646\n",
      "train loss:0.17628831581135518\n",
      "train loss:0.2955806305897475\n",
      "train loss:0.23384991547467274\n",
      "train loss:0.19315946667381534\n",
      "train loss:0.1863580868026855\n",
      "train loss:0.32970365195599227\n",
      "train loss:0.26981395342019454\n",
      "train loss:0.1789412462305145\n",
      "train loss:0.14804635799822236\n",
      "train loss:0.23189726634608449\n",
      "train loss:0.23606984279415305\n",
      "train loss:0.2905269173011912\n",
      "train loss:0.20430515022209533\n",
      "train loss:0.20843389306155832\n",
      "train loss:0.22012305483434233\n",
      "train loss:0.17732100101564136\n",
      "train loss:0.2632228031434548\n",
      "train loss:0.25480692123540316\n",
      "train loss:0.25628601666839357\n",
      "train loss:0.28676457686926066\n",
      "train loss:0.2670499165683367\n",
      "train loss:0.13728542788905426\n",
      "train loss:0.22015173083515033\n",
      "train loss:0.22244062285599867\n",
      "train loss:0.24949818617299535\n",
      "train loss:0.3326325512052186\n",
      "train loss:0.26731894612712703\n",
      "train loss:0.13049303599469422\n",
      "train loss:0.3010241987493031\n",
      "train loss:0.27955572408761403\n",
      "train loss:0.23493984377897953\n",
      "train loss:0.3218800933960676\n",
      "train loss:0.2573197917543093\n",
      "train loss:0.2535014509193011\n",
      "train loss:0.38463551218394576\n",
      "train loss:0.14672438828566198\n",
      "train loss:0.2720232585704887\n",
      "train loss:0.23155658594276637\n",
      "train loss:0.21103313655203937\n",
      "train loss:0.17438380428879705\n",
      "train loss:0.24887777637467554\n",
      "train loss:0.26459919241634267\n",
      "train loss:0.2851768111385125\n",
      "train loss:0.23532686405766395\n",
      "train loss:0.2200950565313016\n",
      "train loss:0.3132611665007197\n",
      "train loss:0.13851598766791404\n",
      "train loss:0.2684297707312555\n",
      "train loss:0.2197920162569816\n",
      "train loss:0.1107246622694714\n",
      "train loss:0.2259346069702743\n",
      "train loss:0.21815328463390546\n",
      "train loss:0.25253123032743363\n",
      "train loss:0.1568701026644107\n",
      "train loss:0.22801962596946923\n",
      "train loss:0.3549329316718174\n",
      "train loss:0.43377250567006553\n",
      "train loss:0.11202589958778304\n",
      "train loss:0.20118012409028527\n",
      "train loss:0.2115021848729172\n",
      "train loss:0.24254237381739613\n",
      "train loss:0.25400465698117214\n",
      "train loss:0.22594513005090422\n",
      "train loss:0.27647685358776863\n",
      "train loss:0.15807258185779077\n",
      "train loss:0.1705324791470162\n",
      "train loss:0.471494187550331\n",
      "train loss:0.23577151042627956\n",
      "train loss:0.19496985411274106\n",
      "train loss:0.15218562007512193\n",
      "train loss:0.2753430610372206\n",
      "train loss:0.3235757874278533\n",
      "train loss:0.21866438529340804\n",
      "train loss:0.23988700689369413\n",
      "train loss:0.1959109584003664\n",
      "train loss:0.22335959235032596\n",
      "train loss:0.27939938481105436\n",
      "train loss:0.18591319161705386\n",
      "train loss:0.2521209403746596\n",
      "train loss:0.22574633609579606\n",
      "train loss:0.19008993988332087\n",
      "train loss:0.26711131936789495\n",
      "train loss:0.17017913522010628\n",
      "train loss:0.16028069377001242\n",
      "train loss:0.24758671838431898\n",
      "train loss:0.27070190284617845\n",
      "train loss:0.19778234066104936\n",
      "train loss:0.31919992862340413\n",
      "train loss:0.19990250551469343\n",
      "train loss:0.2399561581466619\n",
      "train loss:0.21481267327732947\n",
      "train loss:0.24930993028409426\n",
      "train loss:0.22403244477241516\n",
      "train loss:0.21125000898030155\n",
      "train loss:0.16762361653699603\n",
      "train loss:0.24489702872122648\n",
      "train loss:0.1597368763485165\n",
      "train loss:0.09242207770176421\n",
      "train loss:0.16711060819782703\n",
      "train loss:0.29442416198463456\n",
      "train loss:0.2010730149388361\n",
      "train loss:0.2148685398311289\n",
      "train loss:0.1887252143294494\n",
      "train loss:0.2184363764348765\n",
      "train loss:0.2850684366780179\n",
      "train loss:0.159855124103856\n",
      "train loss:0.24165091330190652\n",
      "train loss:0.2281533386093881\n",
      "train loss:0.25154983461487906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.16734489467164793\n",
      "train loss:0.26356504468948866\n",
      "train loss:0.2985611710049651\n",
      "train loss:0.28008740982174507\n",
      "train loss:0.20065186267821922\n",
      "train loss:0.2599554431114428\n",
      "train loss:0.17207220980836915\n",
      "train loss:0.21932423780856422\n",
      "train loss:0.26626510914197365\n",
      "train loss:0.2578405804634021\n",
      "train loss:0.21453697224748464\n",
      "train loss:0.33971358857877026\n",
      "train loss:0.2571764547749242\n",
      "train loss:0.18491137072444283\n",
      "train loss:0.3417406034486642\n",
      "train loss:0.21172160645035404\n",
      "train loss:0.2146615838010861\n",
      "train loss:0.21930280427237311\n",
      "train loss:0.3008192767626626\n",
      "train loss:0.31966201138252875\n",
      "train loss:0.15290027207871634\n",
      "train loss:0.267884959477533\n",
      "train loss:0.221038879700528\n",
      "train loss:0.3692221975346284\n",
      "train loss:0.18247729641187024\n",
      "train loss:0.3274163149764939\n",
      "train loss:0.19136689127990983\n",
      "train loss:0.16075350555141796\n",
      "train loss:0.3277362478180569\n",
      "train loss:0.11996776726123953\n",
      "train loss:0.2407352278600265\n",
      "train loss:0.3168298901857506\n",
      "train loss:0.15902860544478659\n",
      "train loss:0.22621431200946965\n",
      "train loss:0.2937729019699862\n",
      "train loss:0.42290895572750165\n",
      "train loss:0.16030044793608345\n",
      "train loss:0.2322932657201813\n",
      "train loss:0.19961088989156278\n",
      "train loss:0.19506376486811675\n",
      "train loss:0.22360831956582164\n",
      "train loss:0.2439970608139835\n",
      "train loss:0.24171997135422515\n",
      "train loss:0.20099229660221402\n",
      "train loss:0.23575895101276623\n",
      "train loss:0.2283165862961874\n",
      "train loss:0.2626422087580205\n",
      "train loss:0.24318557102633975\n",
      "train loss:0.26590546195090353\n",
      "train loss:0.20275827236897737\n",
      "train loss:0.14191755324766986\n",
      "train loss:0.2718591457124955\n",
      "train loss:0.16269181233915192\n",
      "train loss:0.13118973840965575\n",
      "train loss:0.22224024762331251\n",
      "train loss:0.1968803747797\n",
      "train loss:0.21187563082338784\n",
      "train loss:0.24066162084532725\n",
      "train loss:0.13548960145417122\n",
      "train loss:0.2123489850067096\n",
      "train loss:0.20346510527163272\n",
      "train loss:0.21212131205614163\n",
      "train loss:0.21690239913133053\n",
      "train loss:0.18503198930554687\n",
      "train loss:0.2985479314913858\n",
      "train loss:0.321145591019969\n",
      "train loss:0.11208394028400892\n",
      "train loss:0.2409942201190842\n",
      "train loss:0.2198266338771553\n",
      "train loss:0.21881442845998675\n",
      "train loss:0.21968170386733965\n",
      "train loss:0.20504273675325535\n",
      "train loss:0.21030652641273473\n",
      "train loss:0.2352653344949706\n",
      "train loss:0.21702425697610334\n",
      "train loss:0.2102087042823031\n",
      "train loss:0.3462969939779868\n",
      "train loss:0.17653726545266046\n",
      "train loss:0.26434674239688916\n",
      "train loss:0.3625954993879709\n",
      "train loss:0.2884795955969526\n",
      "train loss:0.3999944635550271\n",
      "train loss:0.18248978175807526\n",
      "train loss:0.30459863645999863\n",
      "train loss:0.1863885397715581\n",
      "train loss:0.1799683547064073\n",
      "train loss:0.25195236191882764\n",
      "train loss:0.24319378360420033\n",
      "train loss:0.1495219823535482\n",
      "train loss:0.12645817345628083\n",
      "train loss:0.22111264548130463\n",
      "train loss:0.20984962935655754\n",
      "train loss:0.2609659914020537\n",
      "train loss:0.2171001413544981\n",
      "train loss:0.24079865158146274\n",
      "train loss:0.15261442613797757\n",
      "train loss:0.22503886746476653\n",
      "train loss:0.1799478942658919\n",
      "train loss:0.19936635093057048\n",
      "train loss:0.2879145879037578\n",
      "train loss:0.1626321698535772\n",
      "train loss:0.29244332779119303\n",
      "train loss:0.24211823117779618\n",
      "train loss:0.22612419493356764\n",
      "train loss:0.2622932548578403\n",
      "train loss:0.1667239145017022\n",
      "train loss:0.261286289737486\n",
      "train loss:0.21941761102318683\n",
      "train loss:0.2473893891284606\n",
      "train loss:0.3300624623624205\n",
      "train loss:0.22448299304743835\n",
      "train loss:0.2842099090132608\n",
      "train loss:0.2123747583490812\n",
      "train loss:0.2673492938948085\n",
      "train loss:0.1733822623921149\n",
      "train loss:0.15351682993075655\n",
      "train loss:0.28861568221050055\n",
      "train loss:0.200376756912183\n",
      "train loss:0.33626719141317435\n",
      "train loss:0.1965779906257195\n",
      "train loss:0.3238141158541503\n",
      "train loss:0.33691609296194863\n",
      "train loss:0.211923010804877\n",
      "train loss:0.32584694894006694\n",
      "train loss:0.24296819222860924\n",
      "train loss:0.1613184678780035\n",
      "train loss:0.21002810828800286\n",
      "train loss:0.2425223776598635\n",
      "train loss:0.3307877154364479\n",
      "train loss:0.231666551460039\n",
      "train loss:0.1507173435078984\n",
      "train loss:0.20506157522306637\n",
      "train loss:0.30535536079143116\n",
      "train loss:0.23584725682554197\n",
      "train loss:0.1783569734041864\n",
      "train loss:0.3303343294849702\n",
      "train loss:0.20784500876336506\n",
      "train loss:0.18290918674602946\n",
      "train loss:0.23001652127370556\n",
      "train loss:0.2007167253218057\n",
      "train loss:0.21110918182036467\n",
      "train loss:0.22068850556343966\n",
      "train loss:0.3149035175439821\n",
      "train loss:0.38427316986587323\n",
      "train loss:0.29313638010500764\n",
      "train loss:0.21445247706196624\n",
      "train loss:0.3265753609885361\n",
      "train loss:0.17895308276198368\n",
      "train loss:0.25776873397488353\n",
      "train loss:0.3087011980500719\n",
      "train loss:0.31414502619296625\n",
      "train loss:0.24887293205451222\n",
      "train loss:0.1725614756530491\n",
      "train loss:0.32388631154720826\n",
      "train loss:0.12182440338504284\n",
      "train loss:0.20098699911212425\n",
      "train loss:0.2905268644762416\n",
      "train loss:0.22624933419857246\n",
      "train loss:0.2536006312023623\n",
      "train loss:0.27137742892975636\n",
      "train loss:0.3393637838278555\n",
      "train loss:0.2736123511428152\n",
      "train loss:0.33376514312953715\n",
      "train loss:0.12556956271392014\n",
      "train loss:0.2886822293376615\n",
      "train loss:0.27515493556223575\n",
      "train loss:0.1054118068723471\n",
      "train loss:0.36180846317730847\n",
      "train loss:0.1900381670806458\n",
      "train loss:0.31623408614016474\n",
      "train loss:0.2971756264907516\n",
      "train loss:0.2676553750708628\n",
      "train loss:0.21704961136401535\n",
      "train loss:0.16391705002021162\n",
      "train loss:0.25879053483046977\n",
      "train loss:0.18953803163886948\n",
      "train loss:0.24013071198577485\n",
      "train loss:0.23261488266134342\n",
      "train loss:0.20676497113705192\n",
      "train loss:0.21971411975702979\n",
      "train loss:0.20253208244298693\n",
      "train loss:0.15102807933520654\n",
      "train loss:0.1667354453555054\n",
      "train loss:0.2521635855829178\n",
      "train loss:0.15186260839788185\n",
      "train loss:0.16234313205523235\n",
      "train loss:0.2550794031772749\n",
      "train loss:0.17433413881914955\n",
      "train loss:0.23033975637245807\n",
      "train loss:0.30634969481483426\n",
      "train loss:0.22012975532412657\n",
      "train loss:0.27165622560824576\n",
      "train loss:0.22427302822983627\n",
      "train loss:0.20198973011650442\n",
      "train loss:0.19040432263597828\n",
      "train loss:0.09472187452094742\n",
      "train loss:0.2721931959693147\n",
      "train loss:0.12703596963232708\n",
      "train loss:0.13509348285158285\n",
      "train loss:0.20400689279923917\n",
      "train loss:0.2739503140112331\n",
      "train loss:0.3570049678594485\n",
      "train loss:0.3649293592352937\n",
      "train loss:0.28555347925180785\n",
      "train loss:0.22555344051829743\n",
      "train loss:0.3518300495500445\n",
      "train loss:0.277611468270624\n",
      "train loss:0.21523705557370018\n",
      "train loss:0.2362129828724285\n",
      "train loss:0.2628846707157672\n",
      "train loss:0.17090604176043567\n",
      "train loss:0.14444840341863419\n",
      "train loss:0.21270302181591888\n",
      "train loss:0.24190279850257848\n",
      "train loss:0.209279550634925\n",
      "train loss:0.26417859722213977\n",
      "train loss:0.27163848792285317\n",
      "train loss:0.2670220520649979\n",
      "train loss:0.29980395074565586\n",
      "train loss:0.2661422244162209\n",
      "train loss:0.2661019692607447\n",
      "train loss:0.20221042813843687\n",
      "train loss:0.2144633585858612\n",
      "train loss:0.3208454309414467\n",
      "train loss:0.1683209453795341\n",
      "train loss:0.37409330670587465\n",
      "train loss:0.26717932864163896\n",
      "train loss:0.19914864369756255\n",
      "train loss:0.16181210446605868\n",
      "train loss:0.1778817473530316\n",
      "train loss:0.31230732640673964\n",
      "train loss:0.24815703524945856\n",
      "train loss:0.20741069246314797\n",
      "train loss:0.25872402879615536\n",
      "train loss:0.2019934088097871\n",
      "train loss:0.16357588891618607\n",
      "train loss:0.25816683254527256\n",
      "train loss:0.17918194229163423\n",
      "train loss:0.19544497879872175\n",
      "train loss:0.29403463240277655\n",
      "train loss:0.26041625817246916\n",
      "train loss:0.2717892292131516\n",
      "train loss:0.24961866584757744\n",
      "train loss:0.22831951537970774\n",
      "train loss:0.35230323785052886\n",
      "train loss:0.19847136931884726\n",
      "train loss:0.2631647384698015\n",
      "train loss:0.21973510090458045\n",
      "train loss:0.31361702392433805\n",
      "train loss:0.2146268035931872\n",
      "train loss:0.2904127598621841\n",
      "train loss:0.25692701400301393\n",
      "train loss:0.2633930028983696\n",
      "train loss:0.1535674228899892\n",
      "train loss:0.22782584556853927\n",
      "train loss:0.19429523557879247\n",
      "train loss:0.23332670487060508\n",
      "train loss:0.2919509557144803\n",
      "train loss:0.28325618434836203\n",
      "train loss:0.2691309149614276\n",
      "train loss:0.16970589944841358\n",
      "train loss:0.25309522596317435\n",
      "train loss:0.23438760786579302\n",
      "train loss:0.19510798007243263\n",
      "train loss:0.1855386098182295\n",
      "train loss:0.18161260953623198\n",
      "train loss:0.25063933909880687\n",
      "train loss:0.2714201899483384\n",
      "train loss:0.19337666449253846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.2277006485541369\n",
      "train loss:0.20765717549718282\n",
      "train loss:0.24514950684610398\n",
      "train loss:0.224464739008522\n",
      "train loss:0.19634967406107187\n",
      "train loss:0.22109853683825698\n",
      "train loss:0.192269984101115\n",
      "train loss:0.2096294370413321\n",
      "train loss:0.19703117708592494\n",
      "train loss:0.3095220398355333\n",
      "train loss:0.18301370312094647\n",
      "train loss:0.15003377206083407\n",
      "train loss:0.20212581364897517\n",
      "train loss:0.13101467710607187\n",
      "train loss:0.3136334206288127\n",
      "train loss:0.2386519884764245\n",
      "train loss:0.31441174407843797\n",
      "train loss:0.3270222452723948\n",
      "train loss:0.20023496764916116\n",
      "train loss:0.21428322049592835\n",
      "train loss:0.15588905325066685\n",
      "train loss:0.16538441491831052\n",
      "train loss:0.13246751127562084\n",
      "train loss:0.3433342257077413\n",
      "train loss:0.2624598100613593\n",
      "train loss:0.1478095912788892\n",
      "train loss:0.2353483496355964\n",
      "train loss:0.18159265666709104\n",
      "train loss:0.17097165055888333\n",
      "train loss:0.2312791540182604\n",
      "train loss:0.18017827056694027\n",
      "train loss:0.22816903855967507\n",
      "train loss:0.18540624108326045\n",
      "train loss:0.2796733088799691\n",
      "train loss:0.3126000172152112\n",
      "train loss:0.26741372082510906\n",
      "train loss:0.198435717950731\n",
      "train loss:0.11372575124894382\n",
      "train loss:0.20974081861583715\n",
      "train loss:0.17686328781083355\n",
      "train loss:0.20200848700003196\n",
      "train loss:0.18177080507144125\n",
      "train loss:0.28940479026110383\n",
      "train loss:0.17823232924511856\n",
      "train loss:0.26589724788733676\n",
      "train loss:0.1979892257614669\n",
      "train loss:0.38256635926332755\n",
      "train loss:0.2052966141065099\n",
      "train loss:0.12569327117934231\n",
      "train loss:0.25686137432573447\n",
      "train loss:0.15608682719226408\n",
      "train loss:0.29119839027680916\n",
      "train loss:0.34426224881995393\n",
      "train loss:0.26217016560480905\n",
      "train loss:0.17956650263038315\n",
      "train loss:0.22808665964581076\n",
      "train loss:0.2669928036908239\n",
      "train loss:0.2644132193371783\n",
      "train loss:0.24170589190601557\n",
      "train loss:0.16815596779725756\n",
      "train loss:0.29395670915831407\n",
      "train loss:0.19796662292056585\n",
      "train loss:0.2583408402923033\n",
      "train loss:0.14148823893360019\n",
      "train loss:0.2625228213562502\n",
      "train loss:0.16498641567402447\n",
      "train loss:0.24948103350742673\n",
      "train loss:0.16457095152898182\n",
      "train loss:0.24104389264506537\n",
      "train loss:0.2796142871641136\n",
      "train loss:0.1616265542278819\n",
      "train loss:0.1228480983703629\n",
      "train loss:0.24635161099186495\n",
      "train loss:0.2067604711520011\n",
      "train loss:0.30173493232954696\n",
      "train loss:0.3384058709334314\n",
      "train loss:0.2870030465469572\n",
      "train loss:0.2860740115864444\n",
      "train loss:0.35059264666797335\n",
      "train loss:0.19843202978127722\n",
      "train loss:0.14752218214859356\n",
      "train loss:0.21226108922708462\n",
      "train loss:0.2738015918985525\n",
      "train loss:0.23265326630418756\n",
      "train loss:0.2183265834475888\n",
      "train loss:0.24845883813075872\n",
      "train loss:0.25566165021426046\n",
      "train loss:0.23884111064584637\n",
      "train loss:0.2536319391182589\n",
      "train loss:0.30499142946668895\n",
      "train loss:0.2745970372816384\n",
      "train loss:0.21953087762072238\n",
      "train loss:0.31081779610028765\n",
      "train loss:0.19120318290095575\n",
      "train loss:0.2404343360177025\n",
      "train loss:0.19778463632290846\n",
      "train loss:0.214766909267877\n",
      "train loss:0.24601557279520445\n",
      "train loss:0.2183906580595784\n",
      "train loss:0.2692639694394236\n",
      "train loss:0.19299778778698268\n",
      "train loss:0.14460071534702984\n",
      "train loss:0.30209114806088505\n",
      "train loss:0.1803102818700221\n",
      "train loss:0.20016113159215249\n",
      "train loss:0.2437936518581462\n",
      "train loss:0.16157342857405355\n",
      "train loss:0.2811828108109731\n",
      "train loss:0.2995585571093375\n",
      "train loss:0.1055829016424555\n",
      "=== epoch:7, train acc:0.911, test acc:0.893 ===\n",
      "train loss:0.201910405346297\n",
      "train loss:0.16562518458089914\n",
      "train loss:0.18543988686118612\n",
      "train loss:0.18150936083131528\n",
      "train loss:0.304116354529732\n",
      "train loss:0.2184826003475993\n",
      "train loss:0.1841315634941697\n",
      "train loss:0.18806913689793717\n",
      "train loss:0.1569034321008781\n",
      "train loss:0.18568817693576295\n",
      "train loss:0.21265808504897585\n",
      "train loss:0.4046767325441985\n",
      "train loss:0.2806451452538751\n",
      "train loss:0.3268829034914436\n",
      "train loss:0.2265955055491185\n",
      "train loss:0.16009006107912863\n",
      "train loss:0.1673417721640034\n",
      "train loss:0.190872153006661\n",
      "train loss:0.2643151193030255\n",
      "train loss:0.16461090848150253\n",
      "train loss:0.4279244359523618\n",
      "train loss:0.08643359986170258\n",
      "train loss:0.22468129660603794\n",
      "train loss:0.3471166934566994\n",
      "train loss:0.20067323023570485\n",
      "train loss:0.18935488235571257\n",
      "train loss:0.19426137154345693\n",
      "train loss:0.3712096616703915\n",
      "train loss:0.2819429117680801\n",
      "train loss:0.21688914672353973\n",
      "train loss:0.2769089107235214\n",
      "train loss:0.4945763232987931\n",
      "train loss:0.22557486935388457\n",
      "train loss:0.23200332479318989\n",
      "train loss:0.18948479126107692\n",
      "train loss:0.3064491400466434\n",
      "train loss:0.21767364511877166\n",
      "train loss:0.2795547358162117\n",
      "train loss:0.2754568036028558\n",
      "train loss:0.2515883182052105\n",
      "train loss:0.1627793503926146\n",
      "train loss:0.2550074507344639\n",
      "train loss:0.229162250081911\n",
      "train loss:0.2567953646141021\n",
      "train loss:0.2215290760600535\n",
      "train loss:0.21827506505277827\n",
      "train loss:0.27616904156049\n",
      "train loss:0.24726268407341806\n",
      "train loss:0.2910675004555785\n",
      "train loss:0.20650456607837708\n",
      "train loss:0.3046614638835724\n",
      "train loss:0.21026490099193804\n",
      "train loss:0.22610186465075105\n",
      "train loss:0.24216559668747248\n",
      "train loss:0.22814052610061636\n",
      "train loss:0.2949230684448574\n",
      "train loss:0.2507271163096014\n",
      "train loss:0.27834740914640177\n",
      "train loss:0.21370368992286534\n",
      "train loss:0.3209659744427313\n",
      "train loss:0.21290363348690697\n",
      "train loss:0.1553748759914093\n",
      "train loss:0.18288733657434653\n",
      "train loss:0.193615143497615\n",
      "train loss:0.3234474018622949\n",
      "train loss:0.20310911055659742\n",
      "train loss:0.1576010458617053\n",
      "train loss:0.22675488372673702\n",
      "train loss:0.1681844379932514\n",
      "train loss:0.14383188940820324\n",
      "train loss:0.35977230054501386\n",
      "train loss:0.25128037871959596\n",
      "train loss:0.2205944853637158\n",
      "train loss:0.21254849630680375\n",
      "train loss:0.17190601552929796\n",
      "train loss:0.29116889545867836\n",
      "train loss:0.17702607733471798\n",
      "train loss:0.31009782252638\n",
      "train loss:0.18136627241905523\n",
      "train loss:0.13769032796962036\n",
      "train loss:0.20011418984598756\n",
      "train loss:0.25636068265252354\n",
      "train loss:0.1852430159773157\n",
      "train loss:0.2206395244734695\n",
      "train loss:0.14528508530612969\n",
      "train loss:0.14807701973023976\n",
      "train loss:0.28701080037075233\n",
      "train loss:0.15826387402596992\n",
      "train loss:0.15199674543968075\n",
      "train loss:0.1765841459364226\n",
      "train loss:0.27264773076228754\n",
      "train loss:0.20359146249827081\n",
      "train loss:0.2973312411020485\n",
      "train loss:0.35498677388303035\n",
      "train loss:0.17348237870154024\n",
      "train loss:0.2808699779427207\n",
      "train loss:0.15250058412795323\n",
      "train loss:0.27247091537202545\n",
      "train loss:0.2590454809813761\n",
      "train loss:0.22366894896065923\n",
      "train loss:0.191435853026802\n",
      "train loss:0.2046797996554796\n",
      "train loss:0.19312409186956148\n",
      "train loss:0.3305183949321524\n",
      "train loss:0.2443442867177124\n",
      "train loss:0.14430349647084686\n",
      "train loss:0.19615304005469045\n",
      "train loss:0.26680649715668453\n",
      "train loss:0.14749294015152117\n",
      "train loss:0.31484765335624243\n",
      "train loss:0.2023526582688291\n",
      "train loss:0.15203815797942238\n",
      "train loss:0.25645124141003606\n",
      "train loss:0.20795742479375826\n",
      "train loss:0.14547785411438896\n",
      "train loss:0.23186191495824338\n",
      "train loss:0.1873558574748067\n",
      "train loss:0.1987505997445066\n",
      "train loss:0.21862172773721394\n",
      "train loss:0.18768644389468875\n",
      "train loss:0.12602795115258825\n",
      "train loss:0.21303563391298477\n",
      "train loss:0.2594358068237329\n",
      "train loss:0.18129616031867596\n",
      "train loss:0.23158874420396175\n",
      "train loss:0.20629865324216065\n",
      "train loss:0.1896803721421073\n",
      "train loss:0.21317360171750674\n",
      "train loss:0.18866675251446063\n",
      "train loss:0.22602515375479879\n",
      "train loss:0.26409287016013744\n",
      "train loss:0.18734493035147964\n",
      "train loss:0.2307441220958933\n",
      "train loss:0.27672497703652343\n",
      "train loss:0.21119713321789818\n",
      "train loss:0.2930707767582082\n",
      "train loss:0.24525238185026388\n",
      "train loss:0.19178663298554124\n",
      "train loss:0.12799390012448764\n",
      "train loss:0.16292779726536322\n",
      "train loss:0.25277070689843245\n",
      "train loss:0.24889895198254955\n",
      "train loss:0.34204558158716536\n",
      "train loss:0.24477975473551186\n",
      "train loss:0.2588086957188346\n",
      "train loss:0.21524243161456924\n",
      "train loss:0.18947878401887575\n",
      "train loss:0.21481110444337534\n",
      "train loss:0.2662666271284565\n",
      "train loss:0.14221444187443796\n",
      "train loss:0.1763008666880073\n",
      "train loss:0.16318703469204324\n",
      "train loss:0.14075432280601474\n",
      "train loss:0.2002963909996929\n",
      "train loss:0.24883172264754133\n",
      "train loss:0.2292117250472328\n",
      "train loss:0.1424613009203476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.15405719245687036\n",
      "train loss:0.2727233655816009\n",
      "train loss:0.28674178368264785\n",
      "train loss:0.20711066065243572\n",
      "train loss:0.13861414369265573\n",
      "train loss:0.2227530169670262\n",
      "train loss:0.1743492674155258\n",
      "train loss:0.2714737872874427\n",
      "train loss:0.21566516114379508\n",
      "train loss:0.20294107883463713\n",
      "train loss:0.2646652659311618\n",
      "train loss:0.20197932637601787\n",
      "train loss:0.13034201581633365\n",
      "train loss:0.3421232987580376\n",
      "train loss:0.14330351661361\n",
      "train loss:0.26591791618431393\n",
      "train loss:0.16577360061976382\n",
      "train loss:0.2718580138334101\n",
      "train loss:0.15584018871132677\n",
      "train loss:0.18520523582307125\n",
      "train loss:0.2063177350231701\n",
      "train loss:0.18780758315274415\n",
      "train loss:0.1900635110541816\n",
      "train loss:0.3058604479531192\n",
      "train loss:0.19483805504382093\n",
      "train loss:0.12078049833768807\n",
      "train loss:0.16704922683864432\n",
      "train loss:0.14672274943740737\n",
      "train loss:0.14215225496575637\n",
      "train loss:0.32944380742124\n",
      "train loss:0.20393136008201423\n",
      "train loss:0.2458978952735655\n",
      "train loss:0.17782333289782548\n",
      "train loss:0.1644987387363757\n",
      "train loss:0.3490272603747072\n",
      "train loss:0.14827888887497861\n",
      "train loss:0.2325359677060819\n",
      "train loss:0.2937588670102685\n",
      "train loss:0.19789907591395484\n",
      "train loss:0.2509233964628783\n",
      "train loss:0.14533678288686244\n",
      "train loss:0.23731111036490357\n",
      "train loss:0.2701193412597715\n",
      "train loss:0.15005826655373938\n",
      "train loss:0.168584420113178\n",
      "train loss:0.22002928535292132\n",
      "train loss:0.12109402511255427\n",
      "train loss:0.18537832248600594\n",
      "train loss:0.2365832998696023\n",
      "train loss:0.24327338092604786\n",
      "train loss:0.13382135565051217\n",
      "train loss:0.20967585589104779\n",
      "train loss:0.2911291086614154\n",
      "train loss:0.2799629213694591\n",
      "train loss:0.1589379495170677\n",
      "train loss:0.21946898888963962\n",
      "train loss:0.12154395067403254\n",
      "train loss:0.20749336356649808\n",
      "train loss:0.21703672926311726\n",
      "train loss:0.1694133888490851\n",
      "train loss:0.14988556013751603\n",
      "train loss:0.23114553981685493\n",
      "train loss:0.21072029838427106\n",
      "train loss:0.1662690373616861\n",
      "train loss:0.21343174301530055\n",
      "train loss:0.20501946202846072\n",
      "train loss:0.16726056743088477\n",
      "train loss:0.1930844736519185\n",
      "train loss:0.2605588621341056\n",
      "train loss:0.2629745151478721\n",
      "train loss:0.21974570279715383\n",
      "train loss:0.22256485827428293\n",
      "train loss:0.30596799238600014\n",
      "train loss:0.12237499847684984\n",
      "train loss:0.23763640022572813\n",
      "train loss:0.195274502272709\n",
      "train loss:0.23203487133614956\n",
      "train loss:0.19612723995556322\n",
      "train loss:0.37668807380573255\n",
      "train loss:0.3071893868727255\n",
      "train loss:0.14839942155151903\n",
      "train loss:0.20250459189613285\n",
      "train loss:0.16213036335196832\n",
      "train loss:0.27633457297063707\n",
      "train loss:0.24754877573170325\n",
      "train loss:0.21722293745064275\n",
      "train loss:0.24222186218993266\n",
      "train loss:0.1991944725573773\n",
      "train loss:0.20083805682310174\n",
      "train loss:0.30867119556368616\n",
      "train loss:0.09946342379338442\n",
      "train loss:0.1228125539681158\n",
      "train loss:0.1427060583980744\n",
      "train loss:0.18082615646256742\n",
      "train loss:0.19731771001189102\n",
      "train loss:0.20464647353411303\n",
      "train loss:0.1873811762626332\n",
      "train loss:0.20949373376394453\n",
      "train loss:0.4495395108467593\n",
      "train loss:0.145562616313138\n",
      "train loss:0.21175451754741062\n",
      "train loss:0.23048879597077881\n",
      "train loss:0.2063398184101545\n",
      "train loss:0.19783360601361646\n",
      "train loss:0.1676327807475654\n",
      "train loss:0.15717262960926198\n",
      "train loss:0.37586999814013383\n",
      "train loss:0.2140935506639854\n",
      "train loss:0.25347895075554305\n",
      "train loss:0.2616074858793681\n",
      "train loss:0.17276017647008157\n",
      "train loss:0.13579058716032466\n",
      "train loss:0.1903321036523372\n",
      "train loss:0.196056799766442\n",
      "train loss:0.15818470568371068\n",
      "train loss:0.2164492372701034\n",
      "train loss:0.21752860243915403\n",
      "train loss:0.13805188917712588\n",
      "train loss:0.30595871663962737\n",
      "train loss:0.24598252097892032\n",
      "train loss:0.1342508962418108\n",
      "train loss:0.20524717905600695\n",
      "train loss:0.16338107175981936\n",
      "train loss:0.3086189115089119\n",
      "train loss:0.2099191659468208\n",
      "train loss:0.252292007604608\n",
      "train loss:0.3603662408840123\n",
      "train loss:0.3372589734765771\n",
      "train loss:0.11858616754939438\n",
      "train loss:0.24895451858022888\n",
      "train loss:0.17694308570086623\n",
      "train loss:0.22443848954117493\n",
      "train loss:0.1601283840653097\n",
      "train loss:0.22931973016325433\n",
      "train loss:0.15600926986207792\n",
      "train loss:0.35730559140311535\n",
      "train loss:0.19322965692296956\n",
      "train loss:0.119576070989018\n",
      "train loss:0.28159788197934743\n",
      "train loss:0.25185586834148976\n",
      "train loss:0.2286904830663702\n",
      "train loss:0.1838561927118335\n",
      "train loss:0.21335066440654493\n",
      "train loss:0.322501413143343\n",
      "train loss:0.0931905095341764\n",
      "train loss:0.21857035085191942\n",
      "train loss:0.29791036091673573\n",
      "train loss:0.21480130192929908\n",
      "train loss:0.19982128904103938\n",
      "train loss:0.2003754636220651\n",
      "train loss:0.2521310839463813\n",
      "train loss:0.18180684563138172\n",
      "train loss:0.22789534271013104\n",
      "train loss:0.1713045624590548\n",
      "train loss:0.3083214272394472\n",
      "train loss:0.22227218555076594\n",
      "train loss:0.24174887488572522\n",
      "train loss:0.20410679405107895\n",
      "train loss:0.2426278033215805\n",
      "train loss:0.22302922135984918\n",
      "train loss:0.25053683839610963\n",
      "train loss:0.21671817506128144\n",
      "train loss:0.17334865352696302\n",
      "train loss:0.1200383110615039\n",
      "train loss:0.17893184479303156\n",
      "train loss:0.15377493302889758\n",
      "train loss:0.20309646720930874\n",
      "train loss:0.1625011936692238\n",
      "train loss:0.2994616008160769\n",
      "train loss:0.19408593513125166\n",
      "train loss:0.2362263281951374\n",
      "train loss:0.18361331892523824\n",
      "train loss:0.09780132110790582\n",
      "train loss:0.2907408723908126\n",
      "train loss:0.1890478789334372\n",
      "train loss:0.2501090032295392\n",
      "train loss:0.1917212447422919\n",
      "train loss:0.2512201121878298\n",
      "train loss:0.19552659424134397\n",
      "train loss:0.23143390992756746\n",
      "train loss:0.23161728776510293\n",
      "train loss:0.2937675297582833\n",
      "train loss:0.21631436973186072\n",
      "train loss:0.18851561493192157\n",
      "train loss:0.21206256829720246\n",
      "train loss:0.17983813873441876\n",
      "train loss:0.1967183553927154\n",
      "train loss:0.22143339165306652\n",
      "train loss:0.28190675773540946\n",
      "train loss:0.16515459854623557\n",
      "train loss:0.14169777799714914\n",
      "train loss:0.3421268234288038\n",
      "train loss:0.18341529883125038\n",
      "train loss:0.20730372553011495\n",
      "train loss:0.14767858343732607\n",
      "train loss:0.1791728298816293\n",
      "train loss:0.16158148107015866\n",
      "train loss:0.15360610423721993\n",
      "train loss:0.26565035508058804\n",
      "train loss:0.330682401784252\n",
      "train loss:0.12050648453958514\n",
      "train loss:0.16913879169439103\n",
      "train loss:0.14594882296603107\n",
      "train loss:0.326352764262109\n",
      "train loss:0.25355209929590716\n",
      "train loss:0.3064456316720111\n",
      "train loss:0.1562363117839115\n",
      "train loss:0.2767700233562096\n",
      "train loss:0.13342698261377295\n",
      "train loss:0.18874725795082867\n",
      "train loss:0.19377801475893913\n",
      "train loss:0.19421046672939038\n",
      "train loss:0.20027861620477988\n",
      "train loss:0.23715971600816896\n",
      "train loss:0.19167064530937375\n",
      "train loss:0.20857290599969244\n",
      "train loss:0.24109670252512877\n",
      "train loss:0.09593771376985298\n",
      "train loss:0.08994944966686863\n",
      "train loss:0.3345376983618561\n",
      "train loss:0.2476438738153187\n",
      "train loss:0.18491779616560858\n",
      "train loss:0.127491399545004\n",
      "train loss:0.17257327052058166\n",
      "train loss:0.1859236877715847\n",
      "train loss:0.15582147097005092\n",
      "train loss:0.2252727928777665\n",
      "train loss:0.1506940321204859\n",
      "train loss:0.18172922375900963\n",
      "train loss:0.14495688791393213\n",
      "train loss:0.20786668171082037\n",
      "train loss:0.2037015357163842\n",
      "train loss:0.07931853069277497\n",
      "train loss:0.35415670420604917\n",
      "train loss:0.25872624734787136\n",
      "train loss:0.22701852635353884\n",
      "train loss:0.19939655706121628\n",
      "train loss:0.27228586935725163\n",
      "train loss:0.18899025139985587\n",
      "train loss:0.2899386745232864\n",
      "train loss:0.3923426182525283\n",
      "train loss:0.22665012631895554\n",
      "train loss:0.16182739788821748\n",
      "train loss:0.2060241393990865\n",
      "train loss:0.16666747004568758\n",
      "train loss:0.3514720309788158\n",
      "train loss:0.23996637304455803\n",
      "train loss:0.15722133639871144\n",
      "train loss:0.15868555417130295\n",
      "train loss:0.20245483961808866\n",
      "train loss:0.27401124632423485\n",
      "train loss:0.24746959408899674\n",
      "train loss:0.19200402420840718\n",
      "train loss:0.13008933706530929\n",
      "train loss:0.1887337931155465\n",
      "train loss:0.20444128105760462\n",
      "train loss:0.1519847947807311\n",
      "train loss:0.14159697925085346\n",
      "train loss:0.1820072502628943\n",
      "train loss:0.16640307749983616\n",
      "train loss:0.16719280009407053\n",
      "train loss:0.1846410949977974\n",
      "train loss:0.16219232677314438\n",
      "train loss:0.22039517314591286\n",
      "train loss:0.3193133736146042\n",
      "train loss:0.24134680355694735\n",
      "train loss:0.1810374289809399\n",
      "train loss:0.1223750155935513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.22445777199561712\n",
      "train loss:0.12553508119231133\n",
      "train loss:0.20768664892498495\n",
      "train loss:0.13429803660540462\n",
      "train loss:0.10775659687442321\n",
      "train loss:0.16197499507208796\n",
      "train loss:0.20748503035751623\n",
      "train loss:0.2048856536412041\n",
      "train loss:0.17758777819585134\n",
      "train loss:0.27306969442545026\n",
      "train loss:0.13339855150830415\n",
      "train loss:0.2281729741484642\n",
      "train loss:0.15227012756332944\n",
      "train loss:0.17527506011636845\n",
      "train loss:0.1871604111878196\n",
      "train loss:0.21180386078726518\n",
      "train loss:0.17012416153185939\n",
      "train loss:0.17105665398015457\n",
      "train loss:0.13774184391918673\n",
      "train loss:0.2947440413413039\n",
      "train loss:0.21215589620037595\n",
      "train loss:0.19095446152924014\n",
      "train loss:0.21447666370451002\n",
      "train loss:0.16518076449818453\n",
      "train loss:0.21191839230481224\n",
      "train loss:0.1600045188856163\n",
      "train loss:0.20846123494563035\n",
      "train loss:0.24755924876020186\n",
      "train loss:0.26571091910941297\n",
      "train loss:0.20658758572381763\n",
      "train loss:0.14366984038723168\n",
      "train loss:0.12016100177312389\n",
      "train loss:0.1899221377828783\n",
      "train loss:0.275516336622535\n",
      "train loss:0.17443999567382623\n",
      "train loss:0.18705339943222868\n",
      "train loss:0.16599391653801138\n",
      "train loss:0.2637647699141244\n",
      "train loss:0.200272915175692\n",
      "train loss:0.14647381088014264\n",
      "train loss:0.24641283001495812\n",
      "train loss:0.30787205766195025\n",
      "train loss:0.27393581495364405\n",
      "train loss:0.3003919031092805\n",
      "train loss:0.21863717008473707\n",
      "train loss:0.16933165331742672\n",
      "train loss:0.18659882676621897\n",
      "train loss:0.1830821079612015\n",
      "train loss:0.16828779023661744\n",
      "train loss:0.223010543787704\n",
      "train loss:0.2725240872279965\n",
      "train loss:0.26884791495222743\n",
      "train loss:0.23722041023313062\n",
      "train loss:0.32632062005180573\n",
      "train loss:0.24651460329517338\n",
      "train loss:0.18413340593539623\n",
      "train loss:0.1396793966640027\n",
      "train loss:0.3468697128800054\n",
      "train loss:0.14854890632770743\n",
      "train loss:0.19419919539454294\n",
      "train loss:0.29405700699983156\n",
      "train loss:0.2833666835622837\n",
      "train loss:0.2618994305661672\n",
      "train loss:0.1673682059978543\n",
      "train loss:0.2030837687164073\n",
      "train loss:0.21092474170471986\n",
      "train loss:0.18972585839508127\n",
      "train loss:0.12689152284302554\n",
      "train loss:0.22432748866805155\n",
      "train loss:0.24960859800986906\n",
      "train loss:0.18540309625406248\n",
      "train loss:0.23094536632190585\n",
      "train loss:0.17956844098653574\n",
      "train loss:0.18367544285067713\n",
      "train loss:0.24738435352279872\n",
      "train loss:0.22398891863236925\n",
      "train loss:0.14337001425021276\n",
      "train loss:0.13944739146394103\n",
      "train loss:0.19746044113869002\n",
      "train loss:0.20067305847674968\n",
      "train loss:0.21178853360361574\n",
      "train loss:0.1418736431231598\n",
      "train loss:0.22687138241339042\n",
      "train loss:0.11552547239494163\n",
      "train loss:0.15732853862217697\n",
      "train loss:0.2509227791341336\n",
      "train loss:0.14987953307170312\n",
      "train loss:0.27313113035188175\n",
      "train loss:0.12998674598336632\n",
      "train loss:0.1705115305823361\n",
      "train loss:0.32101631772840233\n",
      "train loss:0.19478111849969618\n",
      "train loss:0.18787595720111386\n",
      "train loss:0.30937757536531163\n",
      "train loss:0.17892714111636895\n",
      "train loss:0.1912687937077598\n",
      "train loss:0.1941753471897995\n",
      "train loss:0.1782373227563057\n",
      "train loss:0.1887814502848011\n",
      "train loss:0.2180036893808995\n",
      "train loss:0.2465555005613333\n",
      "train loss:0.10978952989125547\n",
      "train loss:0.19453533767778186\n",
      "train loss:0.19394631167084703\n",
      "train loss:0.2431511656476449\n",
      "train loss:0.2690846622574824\n",
      "train loss:0.20028305409490665\n",
      "train loss:0.2708822834181626\n",
      "train loss:0.2470570427216757\n",
      "train loss:0.158984403011446\n",
      "train loss:0.2225093417426148\n",
      "train loss:0.26866235339660466\n",
      "train loss:0.29010884313849833\n",
      "train loss:0.19089772990060916\n",
      "train loss:0.09571998426441378\n",
      "train loss:0.1941180075832785\n",
      "train loss:0.2203241526897804\n",
      "train loss:0.3097847935836032\n",
      "train loss:0.07208902889084584\n",
      "train loss:0.13229399025280256\n",
      "train loss:0.21912534343384313\n",
      "train loss:0.37174368188237217\n",
      "train loss:0.212333984896045\n",
      "train loss:0.189627757283061\n",
      "train loss:0.11900422880983014\n",
      "train loss:0.21822032912399195\n",
      "train loss:0.20119676590161226\n",
      "train loss:0.15780319346415192\n",
      "train loss:0.2195839782675558\n",
      "train loss:0.18649202548600638\n",
      "train loss:0.2045282434835332\n",
      "train loss:0.16130829979620764\n",
      "train loss:0.31293883151306756\n",
      "train loss:0.27555321309315434\n",
      "train loss:0.20704279039758863\n",
      "train loss:0.3714681143465727\n",
      "train loss:0.1467063237028035\n",
      "train loss:0.21396724275810924\n",
      "train loss:0.2683880825347941\n",
      "train loss:0.21404207282574547\n",
      "train loss:0.20557152482088345\n",
      "train loss:0.19234248426763798\n",
      "train loss:0.2569281502221304\n",
      "train loss:0.18589986820996918\n",
      "train loss:0.2434970615136036\n",
      "train loss:0.17458022919463645\n",
      "train loss:0.20995668690723868\n",
      "train loss:0.17479065696864424\n",
      "train loss:0.12226478237935226\n",
      "train loss:0.16351215789451906\n",
      "train loss:0.26455123191052926\n",
      "train loss:0.13004829799140932\n",
      "train loss:0.18983358974293377\n",
      "train loss:0.24935186381556884\n",
      "train loss:0.2346298710224626\n",
      "train loss:0.2798732427727218\n",
      "train loss:0.17666036035862626\n",
      "train loss:0.1358501954398632\n",
      "train loss:0.13530360148203274\n",
      "train loss:0.19766790645012022\n",
      "train loss:0.23688597526182775\n",
      "train loss:0.11475582807984384\n",
      "train loss:0.19492487352659893\n",
      "train loss:0.1524403936798357\n",
      "train loss:0.26487280294777454\n",
      "train loss:0.23438696336196457\n",
      "train loss:0.18393926756842355\n",
      "train loss:0.1625624845361473\n",
      "train loss:0.23274731815014074\n",
      "train loss:0.23626792266732846\n",
      "train loss:0.22082027773848\n",
      "train loss:0.21870711712977678\n",
      "train loss:0.14635089785913688\n",
      "train loss:0.1750932250931507\n",
      "train loss:0.23566021940839538\n",
      "=== epoch:8, train acc:0.93, test acc:0.899 ===\n",
      "train loss:0.1957200466991945\n",
      "train loss:0.2521289175257755\n",
      "train loss:0.20400395396532467\n",
      "train loss:0.10703045537079836\n",
      "train loss:0.1901632979816568\n",
      "train loss:0.1195590902505039\n",
      "train loss:0.14015842821667399\n",
      "train loss:0.22879505896536728\n",
      "train loss:0.18826076686377008\n",
      "train loss:0.19861180249994423\n",
      "train loss:0.1588637090817938\n",
      "train loss:0.29486553573130225\n",
      "train loss:0.23694688450550735\n",
      "train loss:0.19347024908270602\n",
      "train loss:0.22457367206525927\n",
      "train loss:0.23392028121775535\n",
      "train loss:0.15760867256986325\n",
      "train loss:0.2038514855997877\n",
      "train loss:0.22248628292780276\n",
      "train loss:0.12231947401519014\n",
      "train loss:0.26261748658954326\n",
      "train loss:0.2080506298503973\n",
      "train loss:0.12091078659869031\n",
      "train loss:0.16509157222883497\n",
      "train loss:0.23489824864584244\n",
      "train loss:0.2319121217222822\n",
      "train loss:0.16307249970966609\n",
      "train loss:0.236134297700277\n",
      "train loss:0.25398053888622796\n",
      "train loss:0.18648419805270858\n",
      "train loss:0.12050243564837895\n",
      "train loss:0.17357787949889036\n",
      "train loss:0.18773187242473224\n",
      "train loss:0.2435018608910567\n",
      "train loss:0.21756025779806054\n",
      "train loss:0.1387175823780359\n",
      "train loss:0.23262544348249087\n",
      "train loss:0.21583631970214884\n",
      "train loss:0.15356968664904386\n",
      "train loss:0.205340186376237\n",
      "train loss:0.12770145475267403\n",
      "train loss:0.21030662985612472\n",
      "train loss:0.11420681155569758\n",
      "train loss:0.1837020392964065\n",
      "train loss:0.2671603605229415\n",
      "train loss:0.12074628115400951\n",
      "train loss:0.18814701598551473\n",
      "train loss:0.16238787674652932\n",
      "train loss:0.1817271002965338\n",
      "train loss:0.2713240423692571\n",
      "train loss:0.14085144483375608\n",
      "train loss:0.32540217137467536\n",
      "train loss:0.20391955808166856\n",
      "train loss:0.2151631902894744\n",
      "train loss:0.2518463491170671\n",
      "train loss:0.1635969681810772\n",
      "train loss:0.2646683803155307\n",
      "train loss:0.1926081698938449\n",
      "train loss:0.2281636161373764\n",
      "train loss:0.16256202526030017\n",
      "train loss:0.12020592563536502\n",
      "train loss:0.2910912036447862\n",
      "train loss:0.23844171924975424\n",
      "train loss:0.14746550132454686\n",
      "train loss:0.07181385446870461\n",
      "train loss:0.21900740831809745\n",
      "train loss:0.27302579339853056\n",
      "train loss:0.12261935857148362\n",
      "train loss:0.27442345993121475\n",
      "train loss:0.2420198708407625\n",
      "train loss:0.1949500932173271\n",
      "train loss:0.18322010332761024\n",
      "train loss:0.17474254709190412\n",
      "train loss:0.16076015532663226\n",
      "train loss:0.22977242537111064\n",
      "train loss:0.3598102698506747\n",
      "train loss:0.25232354018272096\n",
      "train loss:0.14253677389679684\n",
      "train loss:0.17129839512535455\n",
      "train loss:0.30038984901156324\n",
      "train loss:0.15873748353608425\n",
      "train loss:0.16411192001250843\n",
      "train loss:0.29905838492155346\n",
      "train loss:0.1901652696948992\n",
      "train loss:0.28464769785640714\n",
      "train loss:0.3817516339846739\n",
      "train loss:0.2188739417576487\n",
      "train loss:0.2740940881244747\n",
      "train loss:0.20978958038019807\n",
      "train loss:0.1497971740359131\n",
      "train loss:0.26346521069199774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.2146041259877757\n",
      "train loss:0.2572827626278075\n",
      "train loss:0.3006844498470033\n",
      "train loss:0.20523615844958848\n",
      "train loss:0.3046966526582651\n",
      "train loss:0.19758252378474384\n",
      "train loss:0.230649719319734\n",
      "train loss:0.17701377682137728\n",
      "train loss:0.1949479281018852\n",
      "train loss:0.1492844454799594\n",
      "train loss:0.17154860016466209\n",
      "train loss:0.3835801791704182\n",
      "train loss:0.18310632162440965\n",
      "train loss:0.13884837155630614\n",
      "train loss:0.19347626074015828\n",
      "train loss:0.27145633796507057\n",
      "train loss:0.2497235562381396\n",
      "train loss:0.25900881588816427\n",
      "train loss:0.18627659378694086\n",
      "train loss:0.25973746498626565\n",
      "train loss:0.11991175309185988\n",
      "train loss:0.13457271499388485\n",
      "train loss:0.15992075654292065\n",
      "train loss:0.18151864315956526\n",
      "train loss:0.1936554601079694\n",
      "train loss:0.15014437205498488\n",
      "train loss:0.24118171410783518\n",
      "train loss:0.4191684928675221\n",
      "train loss:0.2407254421959636\n",
      "train loss:0.17256374894007276\n",
      "train loss:0.21898265588473342\n",
      "train loss:0.19082635680957097\n",
      "train loss:0.24796074982735866\n",
      "train loss:0.3412897116143837\n",
      "train loss:0.25882073546655815\n",
      "train loss:0.2047178617681009\n",
      "train loss:0.2388298390124964\n",
      "train loss:0.18141798908150317\n",
      "train loss:0.390271053879718\n",
      "train loss:0.18824393910933931\n",
      "train loss:0.31673000190254635\n",
      "train loss:0.20693387808710917\n",
      "train loss:0.30323845607344113\n",
      "train loss:0.15791526027356867\n",
      "train loss:0.2196364165912386\n",
      "train loss:0.18307013460025157\n",
      "train loss:0.19587634608646148\n",
      "train loss:0.23232065246703748\n",
      "train loss:0.15747967493764625\n",
      "train loss:0.17455797468985984\n",
      "train loss:0.22461968433497576\n",
      "train loss:0.19836396960134664\n",
      "train loss:0.27397937940515854\n",
      "train loss:0.2548157550381832\n",
      "train loss:0.24174647136104835\n",
      "train loss:0.2450548575066077\n",
      "train loss:0.21985821338753234\n",
      "train loss:0.17059217953702516\n",
      "train loss:0.22942170756722327\n",
      "train loss:0.17295604669816078\n",
      "train loss:0.23885584982524663\n",
      "train loss:0.2787049153278885\n",
      "train loss:0.23610646982514957\n",
      "train loss:0.1720226138549378\n",
      "train loss:0.1897196167497089\n",
      "train loss:0.17586620184364585\n",
      "train loss:0.19896910668058798\n",
      "train loss:0.24792423989008072\n",
      "train loss:0.19377667313232036\n",
      "train loss:0.2563743707584361\n",
      "train loss:0.22310867327767944\n",
      "train loss:0.19904726145851329\n",
      "train loss:0.15354093876334438\n",
      "train loss:0.1992147733251448\n",
      "train loss:0.16581560830933376\n",
      "train loss:0.19220429995773608\n",
      "train loss:0.21996214647076964\n",
      "train loss:0.30623847469380555\n",
      "train loss:0.15479678249847623\n",
      "train loss:0.1999313314735855\n",
      "train loss:0.1878353463481675\n",
      "train loss:0.19380894704308815\n",
      "train loss:0.062159487279625614\n",
      "train loss:0.2209184310604306\n",
      "train loss:0.18676523263349995\n",
      "train loss:0.3135748926384608\n",
      "train loss:0.1984166009128842\n",
      "train loss:0.2112710632853085\n",
      "train loss:0.06542443812221832\n",
      "train loss:0.17670317551278408\n",
      "train loss:0.18059731604942444\n",
      "train loss:0.1801436180556369\n",
      "train loss:0.17823733022321467\n",
      "train loss:0.2095859903239587\n",
      "train loss:0.1549295099775226\n",
      "train loss:0.2732204987240442\n",
      "train loss:0.3364296901458473\n",
      "train loss:0.13497455878091835\n",
      "train loss:0.2693173853799681\n",
      "train loss:0.18778238979415957\n",
      "train loss:0.12878454607154907\n",
      "train loss:0.191758517844872\n",
      "train loss:0.2509219836729225\n",
      "train loss:0.16993268669072617\n",
      "train loss:0.14074242073330506\n",
      "train loss:0.21753371303384525\n",
      "train loss:0.15161907297688468\n",
      "train loss:0.21283950422085327\n",
      "train loss:0.16074915588474506\n",
      "train loss:0.23474869790455483\n",
      "train loss:0.16830710533021306\n",
      "train loss:0.116821152132849\n",
      "train loss:0.16327915376014865\n",
      "train loss:0.15853333990545304\n",
      "train loss:0.23961690447291276\n",
      "train loss:0.1348858025080253\n",
      "train loss:0.22848037901526058\n",
      "train loss:0.09325200097120634\n",
      "train loss:0.2969803898440575\n",
      "train loss:0.2605974418840317\n",
      "train loss:0.20968169025321004\n",
      "train loss:0.24619096694660667\n",
      "train loss:0.29439875240158137\n",
      "train loss:0.16774130876491275\n",
      "train loss:0.17324791766166903\n",
      "train loss:0.21059336777798443\n",
      "train loss:0.17436490401114402\n",
      "train loss:0.2598091035496968\n",
      "train loss:0.21381900191210382\n",
      "train loss:0.1254135829699987\n",
      "train loss:0.15741834808410782\n",
      "train loss:0.19859513528034614\n",
      "train loss:0.2232194115316904\n",
      "train loss:0.252483053385938\n",
      "train loss:0.1668798511082747\n",
      "train loss:0.17215727645159473\n",
      "train loss:0.21885344107710256\n",
      "train loss:0.134181677173211\n",
      "train loss:0.2392206317416654\n",
      "train loss:0.27978747066458604\n",
      "train loss:0.13600789291605453\n",
      "train loss:0.15041962369895184\n",
      "train loss:0.231263583187751\n",
      "train loss:0.24202933234513963\n",
      "train loss:0.29615041855743496\n",
      "train loss:0.18443474828107786\n",
      "train loss:0.17901576028326363\n",
      "train loss:0.271923540565796\n",
      "train loss:0.16660549892354318\n",
      "train loss:0.1480427921975215\n",
      "train loss:0.1718147908897323\n",
      "train loss:0.09895711134098288\n",
      "train loss:0.1846145280602852\n",
      "train loss:0.12056606240947872\n",
      "train loss:0.1624681021575808\n",
      "train loss:0.14738340259023505\n",
      "train loss:0.21884738617407984\n",
      "train loss:0.14737658242808907\n",
      "train loss:0.2503602224894528\n",
      "train loss:0.24196751052287344\n",
      "train loss:0.1673875164273074\n",
      "train loss:0.3958186258531508\n",
      "train loss:0.08371181015641964\n",
      "train loss:0.22165706653512018\n",
      "train loss:0.183856683082182\n",
      "train loss:0.13839783942847986\n",
      "train loss:0.16385576661390774\n",
      "train loss:0.1870875797106683\n",
      "train loss:0.23318825987809805\n",
      "train loss:0.24021924063070035\n",
      "train loss:0.23111637720667208\n",
      "train loss:0.18056712039260772\n",
      "train loss:0.14928000472066316\n",
      "train loss:0.177733755694566\n",
      "train loss:0.1833285552167242\n",
      "train loss:0.18908004421297633\n",
      "train loss:0.15846222068307494\n",
      "train loss:0.1764910780663435\n",
      "train loss:0.2109243061239921\n",
      "train loss:0.1394857904574852\n",
      "train loss:0.1421130805592353\n",
      "train loss:0.06509738521957847\n",
      "train loss:0.16006247256195053\n",
      "train loss:0.18453771079904108\n",
      "train loss:0.23600469577393568\n",
      "train loss:0.16202627841629874\n",
      "train loss:0.17309312876621713\n",
      "train loss:0.11427474035623059\n",
      "train loss:0.21455387510289753\n",
      "train loss:0.17034532737011043\n",
      "train loss:0.23296114025248957\n",
      "train loss:0.3108931185162246\n",
      "train loss:0.18060425237071853\n",
      "train loss:0.18488653311757713\n",
      "train loss:0.2286228309740401\n",
      "train loss:0.23286620888330462\n",
      "train loss:0.2915837513539921\n",
      "train loss:0.2867918053226191\n",
      "train loss:0.2319629053869278\n",
      "train loss:0.2024614381849836\n",
      "train loss:0.158793026643332\n",
      "train loss:0.2486226923899133\n",
      "train loss:0.09953779848861533\n",
      "train loss:0.16010144929006953\n",
      "train loss:0.22935084586409446\n",
      "train loss:0.17024181429789728\n",
      "train loss:0.19207522212463668\n",
      "train loss:0.1994924517235732\n",
      "train loss:0.13817333790297393\n",
      "train loss:0.16834084846511405\n",
      "train loss:0.23082046131325945\n",
      "train loss:0.4214188993040796\n",
      "train loss:0.16774071261860116\n",
      "train loss:0.2682185020494043\n",
      "train loss:0.24965619693757005\n",
      "train loss:0.2518791769648489\n",
      "train loss:0.21943143277674668\n",
      "train loss:0.2416868737519937\n",
      "train loss:0.216314815011467\n",
      "train loss:0.16881537325235527\n",
      "train loss:0.24734012206446582\n",
      "train loss:0.22066857059968153\n",
      "train loss:0.16896406026798252\n",
      "train loss:0.21688719576494683\n",
      "train loss:0.23873897249710258\n",
      "train loss:0.16821031133914915\n",
      "train loss:0.1124518133468934\n",
      "train loss:0.289998799091116\n",
      "train loss:0.1601173553475822\n",
      "train loss:0.12486019914448962\n",
      "train loss:0.20097889583555897\n",
      "train loss:0.1770971239994151\n",
      "train loss:0.19759423029485707\n",
      "train loss:0.2077271395292649\n",
      "train loss:0.17097772549877038\n",
      "train loss:0.22880777796829388\n",
      "train loss:0.19036334588507448\n",
      "train loss:0.211016455980863\n",
      "train loss:0.12693303374008763\n",
      "train loss:0.19877939615467796\n",
      "train loss:0.22537417103661178\n",
      "train loss:0.23025921605837943\n",
      "train loss:0.23265548402922756\n",
      "train loss:0.2936402366913868\n",
      "train loss:0.1998938076573545\n",
      "train loss:0.1939166020221603\n",
      "train loss:0.23110257759493522\n",
      "train loss:0.13310314888795166\n",
      "train loss:0.22276695309965713\n",
      "train loss:0.25498962033492734\n",
      "train loss:0.26956518940870494\n",
      "train loss:0.26863874911119956\n",
      "train loss:0.2251876089547108\n",
      "train loss:0.1913938080062289\n",
      "train loss:0.137782929513357\n",
      "train loss:0.2433983818901056\n",
      "train loss:0.15486635520351658\n",
      "train loss:0.2459424660530432\n",
      "train loss:0.16665693529612544\n",
      "train loss:0.19211403848367697\n",
      "train loss:0.27104102409723174\n",
      "train loss:0.21709649614820217\n",
      "train loss:0.22484287345456422\n",
      "train loss:0.2543676917185029\n",
      "train loss:0.12308485247374293\n",
      "train loss:0.1949144335757117\n",
      "train loss:0.21395773424718803\n",
      "train loss:0.24619101710174257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.17326199855913246\n",
      "train loss:0.14834601617589296\n",
      "train loss:0.29032688698355047\n",
      "train loss:0.1791811686528913\n",
      "train loss:0.1858700274494501\n",
      "train loss:0.30726667524779905\n",
      "train loss:0.22705493413175282\n",
      "train loss:0.23203556719416693\n",
      "train loss:0.13891008356206175\n",
      "train loss:0.19735194745438975\n",
      "train loss:0.1220657794699271\n",
      "train loss:0.2341966461432379\n",
      "train loss:0.14443829278479728\n",
      "train loss:0.20179276643389854\n",
      "train loss:0.23738269933503864\n",
      "train loss:0.11447744472927314\n",
      "train loss:0.16351014042506926\n",
      "train loss:0.17128654680429858\n",
      "train loss:0.18672216390692925\n",
      "train loss:0.1555613725655676\n",
      "train loss:0.19434610659608922\n",
      "train loss:0.22522835490436408\n",
      "train loss:0.05948249825880505\n",
      "train loss:0.2637186303838775\n",
      "train loss:0.2337859463939492\n",
      "train loss:0.17880170490497108\n",
      "train loss:0.22465820847000217\n",
      "train loss:0.11943226016179682\n",
      "train loss:0.10231466885291693\n",
      "train loss:0.1427493866452748\n",
      "train loss:0.23667770109171918\n",
      "train loss:0.1366190606474267\n",
      "train loss:0.17422826769539765\n",
      "train loss:0.22498353863372725\n",
      "train loss:0.18728705237985285\n",
      "train loss:0.1957689923093787\n",
      "train loss:0.20697765050609526\n",
      "train loss:0.3810948625922858\n",
      "train loss:0.17645541451814079\n",
      "train loss:0.1161120593249413\n",
      "train loss:0.14540467692001482\n",
      "train loss:0.16641449978450665\n",
      "train loss:0.24076639092437818\n",
      "train loss:0.15261880911694725\n",
      "train loss:0.13260867691159808\n",
      "train loss:0.16833388100920688\n",
      "train loss:0.1442214195677617\n",
      "train loss:0.1382954254193532\n",
      "train loss:0.1724028757987429\n",
      "train loss:0.19423468571146074\n",
      "train loss:0.16220861923925292\n",
      "train loss:0.15218818856191652\n",
      "train loss:0.17080972674612538\n",
      "train loss:0.23969445796249123\n",
      "train loss:0.19195014702573576\n",
      "train loss:0.09552365125607315\n",
      "train loss:0.20308216667663337\n",
      "train loss:0.15798677313667342\n",
      "train loss:0.14033326076506702\n",
      "train loss:0.20750783943683362\n",
      "train loss:0.19746315300108172\n",
      "train loss:0.3279446285477816\n",
      "train loss:0.1477785558065473\n",
      "train loss:0.1398455550835942\n",
      "train loss:0.11555879420732504\n",
      "train loss:0.21673018862649182\n",
      "train loss:0.20910278270721996\n",
      "train loss:0.18185333281497237\n",
      "train loss:0.31474640109146607\n",
      "train loss:0.1181174074481434\n",
      "train loss:0.13126951893900565\n",
      "train loss:0.20506969066408487\n",
      "train loss:0.145361994356284\n",
      "train loss:0.1993279579045937\n",
      "train loss:0.16859372622644794\n",
      "train loss:0.14094116237044954\n",
      "train loss:0.1661024232933121\n",
      "train loss:0.161045486305188\n",
      "train loss:0.23793178629478054\n",
      "train loss:0.1508108721086883\n",
      "train loss:0.24544064403908922\n",
      "train loss:0.18347612348229028\n",
      "train loss:0.11070767381240873\n",
      "train loss:0.17081831554328575\n",
      "train loss:0.23792440022728112\n",
      "train loss:0.1565984262803926\n",
      "train loss:0.19069415692268094\n",
      "train loss:0.18516243898234264\n",
      "train loss:0.1780269143220628\n",
      "train loss:0.15792040555716927\n",
      "train loss:0.14073440526464265\n",
      "train loss:0.14739641434749726\n",
      "train loss:0.12090178308415578\n",
      "train loss:0.2023420156998987\n",
      "train loss:0.23502412739917644\n",
      "train loss:0.2606297873396436\n",
      "train loss:0.1486353588820388\n",
      "train loss:0.1404539254170097\n",
      "train loss:0.16003593974908906\n",
      "train loss:0.1597834655314809\n",
      "train loss:0.14319307556902475\n",
      "train loss:0.20102390023147163\n",
      "train loss:0.1026352828081307\n",
      "train loss:0.10607678479950042\n",
      "train loss:0.16585476335269927\n",
      "train loss:0.2541714965799155\n",
      "train loss:0.20793741665418689\n",
      "train loss:0.16800951353687407\n",
      "train loss:0.20298805367630612\n",
      "train loss:0.2511913106532379\n",
      "train loss:0.16893690757785954\n",
      "train loss:0.10094113275788402\n",
      "train loss:0.24813399797714417\n",
      "train loss:0.22855644338553435\n",
      "train loss:0.24069664264253826\n",
      "train loss:0.22424969743496814\n",
      "train loss:0.1614608210675649\n",
      "train loss:0.18081647802610928\n",
      "train loss:0.16341981033585962\n",
      "train loss:0.3459238322889523\n",
      "train loss:0.14892019580486002\n",
      "train loss:0.274185542744185\n",
      "train loss:0.21110632286793557\n",
      "train loss:0.22842421659299006\n",
      "train loss:0.15718813012569885\n",
      "train loss:0.19884828827664283\n",
      "train loss:0.17717136435380546\n",
      "train loss:0.2917996759969888\n",
      "train loss:0.1743570429309075\n",
      "train loss:0.21657056973349456\n",
      "train loss:0.16229886380440717\n",
      "train loss:0.06995345102901424\n",
      "train loss:0.13435188324097364\n",
      "train loss:0.1962150837005252\n",
      "train loss:0.29403158262297846\n",
      "train loss:0.22794260087331872\n",
      "train loss:0.21153025719424032\n",
      "train loss:0.1773734409641925\n",
      "train loss:0.19977619867673382\n",
      "train loss:0.2674989887829857\n",
      "train loss:0.22435721493608732\n",
      "train loss:0.26106910539848444\n",
      "train loss:0.13917068779889474\n",
      "train loss:0.11195209179544235\n",
      "train loss:0.20649983898494806\n",
      "train loss:0.22345814192788116\n",
      "train loss:0.3079891785687292\n",
      "train loss:0.21639090545903014\n",
      "train loss:0.1695053051428711\n",
      "train loss:0.17045871403412086\n",
      "train loss:0.13913239332715768\n",
      "train loss:0.2439996204160405\n",
      "train loss:0.15427934916822497\n",
      "train loss:0.19214659362588837\n",
      "train loss:0.09886424379253476\n",
      "train loss:0.23635535555858916\n",
      "train loss:0.16137398186167737\n",
      "train loss:0.2531220639825545\n",
      "train loss:0.15754817013632594\n",
      "train loss:0.10276637877397127\n",
      "train loss:0.3276395028800575\n",
      "train loss:0.21498893744058034\n",
      "train loss:0.2549640946323996\n",
      "train loss:0.2601365754568165\n",
      "train loss:0.17243795443937177\n",
      "train loss:0.17811005937973678\n",
      "train loss:0.15252847215785212\n",
      "train loss:0.2312398383760914\n",
      "train loss:0.3223698232776661\n",
      "train loss:0.2544728016438975\n",
      "train loss:0.21824738380462677\n",
      "train loss:0.13622584290667328\n",
      "train loss:0.19004812800335188\n",
      "train loss:0.14166289953490416\n",
      "train loss:0.16312327546050995\n",
      "train loss:0.15259923742561785\n",
      "train loss:0.11814850290342684\n",
      "train loss:0.13293574777284456\n",
      "train loss:0.1728673415363904\n",
      "train loss:0.1655852685160796\n",
      "train loss:0.2248357616568141\n",
      "train loss:0.1918667961886227\n",
      "train loss:0.37050736132123063\n",
      "train loss:0.11374991767185795\n",
      "train loss:0.2063981255542235\n",
      "train loss:0.20249372130881235\n",
      "train loss:0.20602972732605218\n",
      "train loss:0.1948610327488471\n",
      "train loss:0.12990265756400754\n",
      "train loss:0.248708030365145\n",
      "train loss:0.08455584300173959\n",
      "train loss:0.14093302960315368\n",
      "train loss:0.14913421161962892\n",
      "train loss:0.17147446353480084\n",
      "train loss:0.2137724291472757\n",
      "train loss:0.19265586612815938\n",
      "train loss:0.15470379963407904\n",
      "train loss:0.1246132687462671\n",
      "train loss:0.08279746053294926\n",
      "train loss:0.14389034431031658\n",
      "train loss:0.2803963642785516\n",
      "train loss:0.18308642177131249\n",
      "train loss:0.18260029215934867\n",
      "train loss:0.11610748624809043\n",
      "train loss:0.18634926374197544\n",
      "train loss:0.1364478944142297\n",
      "train loss:0.17469569809657537\n",
      "train loss:0.08616653678439308\n",
      "train loss:0.2745552300660471\n",
      "train loss:0.3731332523698956\n",
      "train loss:0.11887185147288495\n",
      "train loss:0.26824574243429194\n",
      "train loss:0.1720208629573826\n",
      "train loss:0.13643310417136287\n",
      "train loss:0.19421205929169352\n",
      "train loss:0.16997048180158114\n",
      "train loss:0.1800978414756112\n",
      "train loss:0.14349684880690047\n",
      "train loss:0.15498190172457071\n",
      "train loss:0.18109010526335606\n",
      "train loss:0.1648124210025041\n",
      "train loss:0.22902116964358124\n",
      "train loss:0.15388384143714273\n",
      "train loss:0.18340162240029073\n",
      "train loss:0.2261484061815002\n",
      "train loss:0.15684004623447495\n",
      "train loss:0.13546227034435424\n",
      "train loss:0.27169575733652374\n",
      "train loss:0.12236576678070653\n",
      "train loss:0.27919386441877725\n",
      "train loss:0.11504403635073052\n",
      "train loss:0.13919482852562592\n",
      "train loss:0.14678098297878062\n",
      "train loss:0.20355474682393818\n",
      "train loss:0.21519511811718728\n",
      "train loss:0.22752090503505357\n",
      "train loss:0.12426328748636185\n",
      "train loss:0.1386491582131807\n",
      "train loss:0.23117950608750348\n",
      "train loss:0.2031002681018974\n",
      "train loss:0.11746075079258737\n",
      "=== epoch:9, train acc:0.94, test acc:0.913 ===\n",
      "train loss:0.25183856999980403\n",
      "train loss:0.1936491508982843\n",
      "train loss:0.1718600920904622\n",
      "train loss:0.15395614117691778\n",
      "train loss:0.10270564874495626\n",
      "train loss:0.18109889487458397\n",
      "train loss:0.2348664621777014\n",
      "train loss:0.19494963691485792\n",
      "train loss:0.10743426302639376\n",
      "train loss:0.2563584505613555\n",
      "train loss:0.1933838650796858\n",
      "train loss:0.4356909353101242\n",
      "train loss:0.26560670234864303\n",
      "train loss:0.1162384364085857\n",
      "train loss:0.1460247055110873\n",
      "train loss:0.32321963071173243\n",
      "train loss:0.18635861760442077\n",
      "train loss:0.09942727532941084\n",
      "train loss:0.15384592557343596\n",
      "train loss:0.14384348748447343\n",
      "train loss:0.15200550998811807\n",
      "train loss:0.321393569846512\n",
      "train loss:0.2570647705734999\n",
      "train loss:0.28117748867838965\n",
      "train loss:0.24464044855310715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.2676122916808959\n",
      "train loss:0.2638803653214402\n",
      "train loss:0.19002912344859726\n",
      "train loss:0.12656514282826872\n",
      "train loss:0.09338797463530199\n",
      "train loss:0.23498777813854604\n",
      "train loss:0.13542715219159057\n",
      "train loss:0.17427137332701953\n",
      "train loss:0.173794749963445\n",
      "train loss:0.19463605947909757\n",
      "train loss:0.18248004513127708\n",
      "train loss:0.21815662093502108\n",
      "train loss:0.28632011358666865\n",
      "train loss:0.13393479678590603\n",
      "train loss:0.1262194042662985\n",
      "train loss:0.17787757796971504\n",
      "train loss:0.1835468888113929\n",
      "train loss:0.24361218752438718\n",
      "train loss:0.1915384515474635\n",
      "train loss:0.14816359940625104\n",
      "train loss:0.1462534721955985\n",
      "train loss:0.12639529559681859\n",
      "train loss:0.27481022998684307\n",
      "train loss:0.18580532766892438\n",
      "train loss:0.23911829042534813\n",
      "train loss:0.15862542569854537\n",
      "train loss:0.20765809364573912\n",
      "train loss:0.20397938437962168\n",
      "train loss:0.2215315725329767\n",
      "train loss:0.1419272057140051\n",
      "train loss:0.09854316616307822\n",
      "train loss:0.2515905573847996\n",
      "train loss:0.23319551633667246\n",
      "train loss:0.2076538006023055\n",
      "train loss:0.28735697216691014\n",
      "train loss:0.13490704261612377\n",
      "train loss:0.16286522083323698\n",
      "train loss:0.16104649567782137\n",
      "train loss:0.12823982709054937\n",
      "train loss:0.10468265649570124\n",
      "train loss:0.21113625941513164\n",
      "train loss:0.2514883549507941\n",
      "train loss:0.16984185047991754\n",
      "train loss:0.22059402574464873\n",
      "train loss:0.19424568093017006\n",
      "train loss:0.06789351283399737\n",
      "train loss:0.1392551653817067\n",
      "train loss:0.16775072575925784\n",
      "train loss:0.11822041301913114\n",
      "train loss:0.19731606173185706\n",
      "train loss:0.2091311467980024\n",
      "train loss:0.15506697737118524\n",
      "train loss:0.2074186870634731\n",
      "train loss:0.19630053810893883\n",
      "train loss:0.17745157738123385\n",
      "train loss:0.12115026613663286\n",
      "train loss:0.1439451867402525\n",
      "train loss:0.2130839145981024\n",
      "train loss:0.2154683036292461\n",
      "train loss:0.14805048924537162\n",
      "train loss:0.13823754773642147\n",
      "train loss:0.14692661702202023\n",
      "train loss:0.08780177767453246\n",
      "train loss:0.24324811157443693\n",
      "train loss:0.16078417575500453\n",
      "train loss:0.19920719342464618\n",
      "train loss:0.1110320545821876\n",
      "train loss:0.14585338671668321\n",
      "train loss:0.2528477227694019\n",
      "train loss:0.17307024129155646\n",
      "train loss:0.15826790941446425\n",
      "train loss:0.2972540274610696\n",
      "train loss:0.20327129272429253\n",
      "train loss:0.16173899315674434\n",
      "train loss:0.1525795312514064\n",
      "train loss:0.17180463703474189\n",
      "train loss:0.16175777516900852\n",
      "train loss:0.20394294960714646\n",
      "train loss:0.22761452873296117\n",
      "train loss:0.1773376820868197\n",
      "train loss:0.16038041675912462\n",
      "train loss:0.1329959960784597\n",
      "train loss:0.17561338918288677\n",
      "train loss:0.0963953431426999\n",
      "train loss:0.1281608454517859\n",
      "train loss:0.15101189776628923\n",
      "train loss:0.11213808182711527\n",
      "train loss:0.16047779517733868\n",
      "train loss:0.11502768953287192\n",
      "train loss:0.16761081770180045\n",
      "train loss:0.304161893278065\n",
      "train loss:0.1389644439013361\n",
      "train loss:0.176891853168818\n",
      "train loss:0.23878621642312337\n",
      "train loss:0.31573734067450754\n",
      "train loss:0.11733307157096176\n",
      "train loss:0.15945380151305505\n",
      "train loss:0.1599399655110359\n",
      "train loss:0.11862955870436448\n",
      "train loss:0.14005822599267753\n",
      "train loss:0.1809614400549662\n",
      "train loss:0.18656427974790135\n",
      "train loss:0.2761322350719328\n",
      "train loss:0.23424728508974776\n",
      "train loss:0.15082493050110093\n",
      "train loss:0.1741726696832721\n",
      "train loss:0.22546662173682155\n",
      "train loss:0.2401360428554839\n",
      "train loss:0.16187185039085605\n",
      "train loss:0.1947015563883704\n",
      "train loss:0.09277200380352639\n",
      "train loss:0.14717660494897292\n",
      "train loss:0.18594057615368076\n",
      "train loss:0.10331211663411176\n",
      "train loss:0.3276565044746742\n",
      "train loss:0.21154395056779685\n",
      "train loss:0.2074220765503391\n",
      "train loss:0.15022950711378338\n",
      "train loss:0.244349260957956\n",
      "train loss:0.16875149855430696\n",
      "train loss:0.12968468651522858\n",
      "train loss:0.13537445556233882\n",
      "train loss:0.2154125145052379\n",
      "train loss:0.1482437576375007\n",
      "train loss:0.18438263352542858\n",
      "train loss:0.16171045671154805\n",
      "train loss:0.20573339280498018\n",
      "train loss:0.3004432119416898\n",
      "train loss:0.13075631363879509\n",
      "train loss:0.19008180196083896\n",
      "train loss:0.12942328657499824\n",
      "train loss:0.18796938754432108\n",
      "train loss:0.21020725393682302\n",
      "train loss:0.184163984566077\n",
      "train loss:0.13642568098015523\n",
      "train loss:0.2383169592792936\n",
      "train loss:0.15894256645421945\n",
      "train loss:0.16902020316741395\n",
      "train loss:0.19540535759385264\n",
      "train loss:0.13692301729787926\n",
      "train loss:0.11840792420862382\n",
      "train loss:0.18897655208195527\n",
      "train loss:0.17483524042914184\n",
      "train loss:0.22396750017369635\n",
      "train loss:0.18390694194562443\n",
      "train loss:0.22761227694887945\n",
      "train loss:0.2021844848631304\n",
      "train loss:0.24139467696061023\n",
      "train loss:0.23900412161733456\n",
      "train loss:0.2027773672037125\n",
      "train loss:0.2300233285871129\n",
      "train loss:0.11914376360578156\n",
      "train loss:0.21261540251620212\n",
      "train loss:0.20927029313090362\n",
      "train loss:0.24026911432744277\n",
      "train loss:0.11235428315091879\n",
      "train loss:0.24276229456242826\n",
      "train loss:0.13537810107360548\n",
      "train loss:0.22137825563566985\n",
      "train loss:0.16367069664868414\n",
      "train loss:0.12142616515470786\n",
      "train loss:0.20064643408212576\n",
      "train loss:0.19925008096350902\n",
      "train loss:0.218989434013532\n",
      "train loss:0.260702243760598\n",
      "train loss:0.14822282512412602\n",
      "train loss:0.14957368861919795\n",
      "train loss:0.1515611350429809\n",
      "train loss:0.23265765634149896\n",
      "train loss:0.15955826969829578\n",
      "train loss:0.3067140776350479\n",
      "train loss:0.087702168551943\n",
      "train loss:0.23492951649703786\n",
      "train loss:0.18306024993779574\n",
      "train loss:0.12489035759896154\n",
      "train loss:0.17861242840533953\n",
      "train loss:0.22702766664137108\n",
      "train loss:0.15326177295625867\n",
      "train loss:0.21668659051203232\n",
      "train loss:0.18936521339931617\n",
      "train loss:0.23044073419577468\n",
      "train loss:0.11684598298931283\n",
      "train loss:0.19520725104760298\n",
      "train loss:0.1941873271871241\n",
      "train loss:0.19344594484210362\n",
      "train loss:0.17118544525409074\n",
      "train loss:0.1410260954585257\n",
      "train loss:0.23909970182135065\n",
      "train loss:0.2126904559664291\n",
      "train loss:0.2598651473431295\n",
      "train loss:0.23782107467464872\n",
      "train loss:0.22683433679595638\n",
      "train loss:0.1636697285144718\n",
      "train loss:0.2566639870253773\n",
      "train loss:0.15124823361585762\n",
      "train loss:0.17114098780744022\n",
      "train loss:0.37210484121237863\n",
      "train loss:0.24277379253294876\n",
      "train loss:0.2047577000870196\n",
      "train loss:0.22236975138018095\n",
      "train loss:0.1939120964125892\n",
      "train loss:0.17311934245990035\n",
      "train loss:0.1530368636024504\n",
      "train loss:0.13814698427467134\n",
      "train loss:0.1524727453693876\n",
      "train loss:0.1669952461899409\n",
      "train loss:0.18139603520647302\n",
      "train loss:0.13977209821636727\n",
      "train loss:0.17556731335054182\n",
      "train loss:0.20161025572955385\n",
      "train loss:0.12399238502277836\n",
      "train loss:0.20469573118022255\n",
      "train loss:0.18413641274089834\n",
      "train loss:0.22527209666129241\n",
      "train loss:0.10270027558762485\n",
      "train loss:0.22499957030677778\n",
      "train loss:0.19032202854696958\n",
      "train loss:0.1873929829447686\n",
      "train loss:0.2789565706642555\n",
      "train loss:0.12481538286395284\n",
      "train loss:0.2644779331262281\n",
      "train loss:0.15451390323332592\n",
      "train loss:0.16754997687394835\n",
      "train loss:0.21341899857627122\n",
      "train loss:0.1505458714933189\n",
      "train loss:0.11893621960711248\n",
      "train loss:0.11395475959701665\n",
      "train loss:0.11141647896578612\n",
      "train loss:0.15921800054890906\n",
      "train loss:0.14412987819173703\n",
      "train loss:0.18442597073676256\n",
      "train loss:0.22348766683846125\n",
      "train loss:0.173699216657323\n",
      "train loss:0.1716288483027272\n",
      "train loss:0.2535851894761432\n",
      "train loss:0.16374632447187795\n",
      "train loss:0.2636859374470842\n",
      "train loss:0.15346253976219665\n",
      "train loss:0.13974770069408227\n",
      "train loss:0.1887755043096998\n",
      "train loss:0.24108581257718747\n",
      "train loss:0.1494681835013852\n",
      "train loss:0.27092518614412403\n",
      "train loss:0.20258307933807201\n",
      "train loss:0.14153436280230353\n",
      "train loss:0.1303343854149146\n",
      "train loss:0.11086523213149109\n",
      "train loss:0.06839026812381292\n",
      "train loss:0.1339011367296776\n",
      "train loss:0.15427868933387348\n",
      "train loss:0.3771961010099932\n",
      "train loss:0.29795613612239846\n",
      "train loss:0.21317629243640274\n",
      "train loss:0.11706790418214329\n",
      "train loss:0.20454142084672952\n",
      "train loss:0.11976233519277674\n",
      "train loss:0.2673040569376884\n",
      "train loss:0.21944211703511157\n",
      "train loss:0.13672668045631986\n",
      "train loss:0.17601559797007918\n",
      "train loss:0.3329989426476376\n",
      "train loss:0.16631371115486346\n",
      "train loss:0.1669654707175189\n",
      "train loss:0.21917733925078292\n",
      "train loss:0.13039987116868176\n",
      "train loss:0.1406799806208859\n",
      "train loss:0.15739246518014954\n",
      "train loss:0.13996976178431292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.21589469596127095\n",
      "train loss:0.1478130747643645\n",
      "train loss:0.2006660284000215\n",
      "train loss:0.18900600190753788\n",
      "train loss:0.12155585671963574\n",
      "train loss:0.1890409085826672\n",
      "train loss:0.14955806567223767\n",
      "train loss:0.1999135809053952\n",
      "train loss:0.20823795872671663\n",
      "train loss:0.1992599208388654\n",
      "train loss:0.2152440006066243\n",
      "train loss:0.2303720675934679\n",
      "train loss:0.14578666667227796\n",
      "train loss:0.20199278233679097\n",
      "train loss:0.30507289101399915\n",
      "train loss:0.13653491056967956\n",
      "train loss:0.11720476436456778\n",
      "train loss:0.11132622058763757\n",
      "train loss:0.30291358089237613\n",
      "train loss:0.19618233457558895\n",
      "train loss:0.19601026917405937\n",
      "train loss:0.12047439521663902\n",
      "train loss:0.24698156651672842\n",
      "train loss:0.22797270748761267\n",
      "train loss:0.28337689494795826\n",
      "train loss:0.1811487928380565\n",
      "train loss:0.1768482448856327\n",
      "train loss:0.17008147375213517\n",
      "train loss:0.2867093687832976\n",
      "train loss:0.25196608255619063\n",
      "train loss:0.20293494703620601\n",
      "train loss:0.13794300347044514\n",
      "train loss:0.23461066900354566\n",
      "train loss:0.2859547550986948\n",
      "train loss:0.24739288850548888\n",
      "train loss:0.25417300599141296\n",
      "train loss:0.2082020490976306\n",
      "train loss:0.24746248118834405\n",
      "train loss:0.1910420877759753\n",
      "train loss:0.10139542917237948\n",
      "train loss:0.31360236966159205\n",
      "train loss:0.16008401259862434\n",
      "train loss:0.4417314925160712\n",
      "train loss:0.19081827814755287\n",
      "train loss:0.3280744728235667\n",
      "train loss:0.266871874165745\n",
      "train loss:0.184776225055546\n",
      "train loss:0.14637671961856635\n",
      "train loss:0.1903039091545989\n",
      "train loss:0.20142946468428177\n",
      "train loss:0.21102805552474466\n",
      "train loss:0.2756333684972789\n",
      "train loss:0.2221312507690144\n",
      "train loss:0.1941591293454359\n",
      "train loss:0.11486270835265121\n",
      "train loss:0.2091841909929496\n",
      "train loss:0.15209176454479778\n",
      "train loss:0.18686702861536314\n",
      "train loss:0.14785217280551038\n",
      "train loss:0.2227488932725281\n",
      "train loss:0.31644113298325743\n",
      "train loss:0.12129403661546928\n",
      "train loss:0.2203485215522913\n",
      "train loss:0.24306312645102562\n",
      "train loss:0.19593440762438713\n",
      "train loss:0.20768513217564258\n",
      "train loss:0.15160580498142362\n",
      "train loss:0.1440695233666782\n",
      "train loss:0.19241771070009062\n",
      "train loss:0.14305177251040985\n",
      "train loss:0.21896632811053518\n",
      "train loss:0.13561426472624072\n",
      "train loss:0.1915495479907539\n",
      "train loss:0.14247942505255676\n",
      "train loss:0.16795343202790008\n",
      "train loss:0.22694321090099956\n",
      "train loss:0.1594938689133642\n",
      "train loss:0.2862539546221266\n",
      "train loss:0.12684468589215495\n",
      "train loss:0.1616530900989639\n",
      "train loss:0.10838592734957096\n",
      "train loss:0.1464142224804146\n",
      "train loss:0.15477458530490557\n",
      "train loss:0.21211709255875197\n",
      "train loss:0.21405111525035048\n",
      "train loss:0.12731254695338784\n",
      "train loss:0.21798270213298848\n",
      "train loss:0.21106383293553616\n",
      "train loss:0.10869681872402037\n",
      "train loss:0.333933040329968\n",
      "train loss:0.10985799219147291\n",
      "train loss:0.1526452502433209\n",
      "train loss:0.19359705207053446\n",
      "train loss:0.26244046486825834\n",
      "train loss:0.17207678969817786\n",
      "train loss:0.1817925241249155\n",
      "train loss:0.08061016690178714\n",
      "train loss:0.15762125205317112\n",
      "train loss:0.2555535098194672\n",
      "train loss:0.2514368365406907\n",
      "train loss:0.14860871864815986\n",
      "train loss:0.24299512690443342\n",
      "train loss:0.16719198300564458\n",
      "train loss:0.19566282129521848\n",
      "train loss:0.18390756050675466\n",
      "train loss:0.132947857661612\n",
      "train loss:0.23245139300764134\n",
      "train loss:0.15360368089598317\n",
      "train loss:0.0712239861620092\n",
      "train loss:0.15965042554521852\n",
      "train loss:0.17023709892366082\n",
      "train loss:0.19445055640696662\n",
      "train loss:0.32154002227969947\n",
      "train loss:0.10757137893971613\n",
      "train loss:0.18421984956937185\n",
      "train loss:0.24581780032822692\n",
      "train loss:0.10452310647094915\n",
      "train loss:0.1413933861992257\n",
      "train loss:0.14861488089741556\n",
      "train loss:0.17100344559973507\n",
      "train loss:0.2131088579751134\n",
      "train loss:0.13415186309585528\n",
      "train loss:0.18739843573621062\n",
      "train loss:0.24101410232304668\n",
      "train loss:0.15184365749962336\n",
      "train loss:0.2017449848123841\n",
      "train loss:0.28305997488398577\n",
      "train loss:0.2707088430127693\n",
      "train loss:0.16083756450225928\n",
      "train loss:0.10586517209475614\n",
      "train loss:0.31609895873380106\n",
      "train loss:0.18223632155855515\n",
      "train loss:0.11687029914457887\n",
      "train loss:0.12189109017761085\n",
      "train loss:0.17665672971411783\n",
      "train loss:0.2823980934595269\n",
      "train loss:0.21418974031379764\n",
      "train loss:0.15146397479843274\n",
      "train loss:0.1691829990666271\n",
      "train loss:0.22728164478869825\n",
      "train loss:0.1683742976524886\n",
      "train loss:0.28602172107803747\n",
      "train loss:0.1775160870803761\n",
      "train loss:0.14035798596498683\n",
      "train loss:0.20042933949566433\n",
      "train loss:0.2542277997329146\n",
      "train loss:0.22795848359706528\n",
      "train loss:0.21906417954206917\n",
      "train loss:0.15706314541825517\n",
      "train loss:0.21511953001747763\n",
      "train loss:0.28636283553230496\n",
      "train loss:0.22706088090838034\n",
      "train loss:0.07360387003850798\n",
      "train loss:0.17087421641705697\n",
      "train loss:0.20769821708159913\n",
      "train loss:0.11781701887850338\n",
      "train loss:0.22229970529092047\n",
      "train loss:0.23912070051058237\n",
      "train loss:0.20094322396350411\n",
      "train loss:0.269149739142289\n",
      "train loss:0.1408265709041821\n",
      "train loss:0.2793094684868294\n",
      "train loss:0.20232222709252512\n",
      "train loss:0.25913707389995655\n",
      "train loss:0.27819090866946644\n",
      "train loss:0.1934549245788522\n",
      "train loss:0.1538575463945071\n",
      "train loss:0.1343574802463221\n",
      "train loss:0.18638944036287092\n",
      "train loss:0.21573134285477047\n",
      "train loss:0.2127836770346461\n",
      "train loss:0.19236773972093651\n",
      "train loss:0.22883247783882346\n",
      "train loss:0.07855714328438274\n",
      "train loss:0.13062233844993598\n",
      "train loss:0.19102051428125932\n",
      "train loss:0.2646439835503497\n",
      "train loss:0.18878643338915146\n",
      "train loss:0.24628106510391606\n",
      "train loss:0.22530322647872936\n",
      "train loss:0.14227328105142634\n",
      "train loss:0.2404466904889632\n",
      "train loss:0.2987203202049172\n",
      "train loss:0.1133560496123967\n",
      "train loss:0.1387963583135593\n",
      "train loss:0.1458367016728974\n",
      "train loss:0.22104692798089196\n",
      "train loss:0.14516045892954843\n",
      "train loss:0.15758874830816716\n",
      "train loss:0.2100291877919838\n",
      "train loss:0.17533292961609637\n",
      "train loss:0.23652146449013775\n",
      "train loss:0.14783399289384413\n",
      "train loss:0.16679690321191112\n",
      "train loss:0.18686706254336158\n",
      "train loss:0.2581858491968902\n",
      "train loss:0.17253343189421927\n",
      "train loss:0.15218440759319035\n",
      "train loss:0.3516162927068445\n",
      "train loss:0.09469414717928926\n",
      "train loss:0.17296815337234459\n",
      "train loss:0.19721421350852858\n",
      "train loss:0.167201217297629\n",
      "train loss:0.13022634133727753\n",
      "train loss:0.11374326787146874\n",
      "train loss:0.1941474141532653\n",
      "train loss:0.19023076918320733\n",
      "train loss:0.1450768348271308\n",
      "train loss:0.15845080937416628\n",
      "train loss:0.10452891154404736\n",
      "train loss:0.08203721297380134\n",
      "train loss:0.18251385944366433\n",
      "train loss:0.21277781888478964\n",
      "train loss:0.17543836176178287\n",
      "train loss:0.22316216691157148\n",
      "train loss:0.17929467013924885\n",
      "train loss:0.12363384461225502\n",
      "train loss:0.22020353536702855\n",
      "train loss:0.21896284415342834\n",
      "train loss:0.1788062311640098\n",
      "train loss:0.21794764971984343\n",
      "train loss:0.1984887464681431\n",
      "train loss:0.1196607658468142\n",
      "train loss:0.11679867859986202\n",
      "train loss:0.20297519451739873\n",
      "train loss:0.12128143515556462\n",
      "train loss:0.2605697120282951\n",
      "train loss:0.16430901227821879\n",
      "train loss:0.13081819429005118\n",
      "train loss:0.12218420939734143\n",
      "train loss:0.2191539415578142\n",
      "train loss:0.13977150851207698\n",
      "train loss:0.16163803880772418\n",
      "train loss:0.28370634382873017\n",
      "train loss:0.15732874899125665\n",
      "train loss:0.14742926660530586\n",
      "train loss:0.2702174908574158\n",
      "train loss:0.12045095402447448\n",
      "train loss:0.15987068714028388\n",
      "train loss:0.16721157815351223\n",
      "train loss:0.16746568003779042\n",
      "train loss:0.10124992761117561\n",
      "train loss:0.23245715118670596\n",
      "train loss:0.20777531662650092\n",
      "train loss:0.24305290557433243\n",
      "train loss:0.09911445610236587\n",
      "train loss:0.1804046632433151\n",
      "train loss:0.15281313361373003\n",
      "train loss:0.11181436552403966\n",
      "train loss:0.24337870844338852\n",
      "train loss:0.141226679727111\n",
      "train loss:0.16679675556549267\n",
      "train loss:0.13296139226646908\n",
      "train loss:0.23998095532534375\n",
      "train loss:0.13720983822049607\n",
      "train loss:0.17339550456018515\n",
      "train loss:0.22633670339852013\n",
      "train loss:0.1590743891311636\n",
      "train loss:0.16224913518867307\n",
      "train loss:0.16336720805265464\n",
      "train loss:0.2943475321148831\n",
      "train loss:0.12683881666888852\n",
      "train loss:0.08288926458899412\n",
      "train loss:0.26550945787743274\n",
      "train loss:0.14730288665980457\n",
      "train loss:0.11380843602278493\n",
      "train loss:0.11516257511585948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.14563821812892078\n",
      "train loss:0.055469024389396535\n",
      "train loss:0.1498583274947172\n",
      "train loss:0.14495046079423277\n",
      "train loss:0.2563467469420596\n",
      "train loss:0.21889791828043983\n",
      "train loss:0.2733027248960336\n",
      "train loss:0.33971108617723317\n",
      "train loss:0.22796440823373357\n",
      "train loss:0.19313951011976202\n",
      "train loss:0.14739553449728546\n",
      "train loss:0.24527931931915328\n",
      "train loss:0.12867797627209618\n",
      "train loss:0.11888879768102953\n",
      "train loss:0.27652628989330696\n",
      "train loss:0.23261204734057894\n",
      "train loss:0.2137594619443952\n",
      "train loss:0.11453217290104722\n",
      "train loss:0.15798203411629363\n",
      "train loss:0.0988059402754453\n",
      "train loss:0.18005985671977137\n",
      "train loss:0.2386935054484244\n",
      "train loss:0.1810031078346099\n",
      "train loss:0.19983434528999666\n",
      "train loss:0.15303263564870886\n",
      "train loss:0.24057517925187274\n",
      "train loss:0.10722943870752644\n",
      "train loss:0.2525491697162128\n",
      "train loss:0.2493390893732058\n",
      "train loss:0.2529464055892968\n",
      "train loss:0.15404419047467122\n",
      "train loss:0.2393755054540383\n",
      "train loss:0.3012320162017125\n",
      "train loss:0.28506218585030174\n",
      "train loss:0.19420242674693633\n",
      "train loss:0.169167727213798\n",
      "train loss:0.10943352103630033\n",
      "train loss:0.14362727669311634\n",
      "train loss:0.1401174098380522\n",
      "train loss:0.1445143625463964\n",
      "=== epoch:10, train acc:0.941, test acc:0.902 ===\n",
      "train loss:0.13527236158737277\n",
      "train loss:0.11005446803917364\n",
      "train loss:0.1974293975241358\n",
      "train loss:0.20253775802327773\n",
      "train loss:0.1419007055821885\n",
      "train loss:0.1890125637786841\n",
      "train loss:0.22104422154081174\n",
      "train loss:0.2524602941222403\n",
      "train loss:0.2911561486880928\n",
      "train loss:0.15058155348943672\n",
      "train loss:0.16589669317716108\n",
      "train loss:0.210841014374071\n",
      "train loss:0.22053639084160387\n",
      "train loss:0.18779920511019563\n",
      "train loss:0.17429041578214272\n",
      "train loss:0.15096508223941296\n",
      "train loss:0.13171462541367565\n",
      "train loss:0.15628863169052376\n",
      "train loss:0.14317024284384358\n",
      "train loss:0.22154991290473697\n",
      "train loss:0.1368349041580016\n",
      "train loss:0.10069197921420159\n",
      "train loss:0.12855305746668036\n",
      "train loss:0.2706124890402638\n",
      "train loss:0.14429455644385988\n",
      "train loss:0.15121868755349052\n",
      "train loss:0.19837236152721946\n",
      "train loss:0.21709209624836354\n",
      "train loss:0.19757888339004157\n",
      "train loss:0.09348476938277268\n",
      "train loss:0.2110523808715242\n",
      "train loss:0.16881158885554337\n",
      "train loss:0.1492223185469159\n",
      "train loss:0.19745201039487104\n",
      "train loss:0.1261997317262136\n",
      "train loss:0.17448880468147354\n",
      "train loss:0.1342594816584857\n",
      "train loss:0.18728659934882877\n",
      "train loss:0.13579789139290585\n",
      "train loss:0.13933581380043264\n",
      "train loss:0.18094862557445\n",
      "train loss:0.17224596471149442\n",
      "train loss:0.1715561102163376\n",
      "train loss:0.17538065086057114\n",
      "train loss:0.21858343033641214\n",
      "train loss:0.11307109522994602\n",
      "train loss:0.23207598244930983\n",
      "train loss:0.15285154413699611\n",
      "train loss:0.1868129470134441\n",
      "train loss:0.17236919586833838\n",
      "train loss:0.19368567436865672\n",
      "train loss:0.16850122342053203\n",
      "train loss:0.17437269721409698\n",
      "train loss:0.11700391337697079\n",
      "train loss:0.15490357812306785\n",
      "train loss:0.1268016810697226\n",
      "train loss:0.18094110917707695\n",
      "train loss:0.10547094783731088\n",
      "train loss:0.3466638666422764\n",
      "train loss:0.21075598000364493\n",
      "train loss:0.16169743809545495\n",
      "train loss:0.19427182590981654\n",
      "train loss:0.22459097440493772\n",
      "train loss:0.1793533049224394\n",
      "train loss:0.37224852269356473\n",
      "train loss:0.14183458610112126\n",
      "train loss:0.11007896275946774\n",
      "train loss:0.1957291305815189\n",
      "train loss:0.19472851600392324\n",
      "train loss:0.13399721297235692\n",
      "train loss:0.2001748165859122\n",
      "train loss:0.15487758779111516\n",
      "train loss:0.11803926703740732\n",
      "train loss:0.15274545339964088\n",
      "train loss:0.1352123358337484\n",
      "train loss:0.18517503676987207\n",
      "train loss:0.11568468351234211\n",
      "train loss:0.1377946773644684\n",
      "train loss:0.19272551888387085\n",
      "train loss:0.3010304011188081\n",
      "train loss:0.13943294631013406\n",
      "train loss:0.1846827167645359\n",
      "train loss:0.15718422446903538\n",
      "train loss:0.264744379340556\n",
      "train loss:0.18022664043450068\n",
      "train loss:0.23649957842105238\n",
      "train loss:0.15857236831420563\n",
      "train loss:0.13497496578970516\n",
      "train loss:0.24286764008618855\n",
      "train loss:0.330922643280105\n",
      "train loss:0.1868300025019415\n",
      "train loss:0.11493236995937771\n",
      "train loss:0.257156442642525\n",
      "train loss:0.18705362095655229\n",
      "train loss:0.16785667299619023\n",
      "train loss:0.17193446033261617\n",
      "train loss:0.22676685138587904\n",
      "train loss:0.1040689969691098\n",
      "train loss:0.2621159631299646\n",
      "train loss:0.1604680610913775\n",
      "train loss:0.1331636423196886\n",
      "train loss:0.14325951600970224\n",
      "train loss:0.10972450920525739\n",
      "train loss:0.25747471398838623\n",
      "train loss:0.20275264028246393\n",
      "train loss:0.19787100658118195\n",
      "train loss:0.16056313659220972\n",
      "train loss:0.2288610555056997\n",
      "train loss:0.18070834837805688\n",
      "train loss:0.13572287928146248\n",
      "train loss:0.10262583972018299\n",
      "train loss:0.24437307249892626\n",
      "train loss:0.1386716372732037\n",
      "train loss:0.19026348762687678\n",
      "train loss:0.1584726564543558\n",
      "train loss:0.1801572241711724\n",
      "train loss:0.1759118053235641\n",
      "train loss:0.19108405196823128\n",
      "train loss:0.18777521311816006\n",
      "train loss:0.17894132124604803\n",
      "train loss:0.13171832287064164\n",
      "train loss:0.11856289397775445\n",
      "train loss:0.1713981041724127\n",
      "train loss:0.1673539292406904\n",
      "train loss:0.17732211866266342\n",
      "train loss:0.2708813293127422\n",
      "train loss:0.26933688979320425\n",
      "train loss:0.22923249821236769\n",
      "train loss:0.15134336435858892\n",
      "train loss:0.19488842911522608\n",
      "train loss:0.2246113839205621\n",
      "train loss:0.19648012147988403\n",
      "train loss:0.16982741633274656\n",
      "train loss:0.17683859699872406\n",
      "train loss:0.16083732418426322\n",
      "train loss:0.2379936706562258\n",
      "train loss:0.18756044931825755\n",
      "train loss:0.22121602630786794\n",
      "train loss:0.2581487525585884\n",
      "train loss:0.1048091810131302\n",
      "train loss:0.13777852983640745\n",
      "train loss:0.16095265361663175\n",
      "train loss:0.18812536134713975\n",
      "train loss:0.16961780364499873\n",
      "train loss:0.1045589091962918\n",
      "train loss:0.15072341978688197\n",
      "train loss:0.2476449338709368\n",
      "train loss:0.15977432827170565\n",
      "train loss:0.15098087914354186\n",
      "train loss:0.3141357223883065\n",
      "train loss:0.1725983492830735\n",
      "train loss:0.1618391616904822\n",
      "train loss:0.175064742521685\n",
      "train loss:0.20863536797443585\n",
      "train loss:0.16485502123374715\n",
      "train loss:0.1393872441173044\n",
      "train loss:0.21699818256758455\n",
      "train loss:0.16886737646749306\n",
      "train loss:0.12288683640130145\n",
      "train loss:0.09185006071884366\n",
      "train loss:0.20058768954185047\n",
      "train loss:0.14225633236273028\n",
      "train loss:0.2628096370069239\n",
      "train loss:0.15122725788809052\n",
      "train loss:0.186553554403269\n",
      "train loss:0.1368203226009639\n",
      "train loss:0.15325822692209884\n",
      "train loss:0.26161385173240426\n",
      "train loss:0.1658230971530606\n",
      "train loss:0.13317610047404438\n",
      "train loss:0.1758871641212268\n",
      "train loss:0.19209459651225516\n",
      "train loss:0.11614395445229635\n",
      "train loss:0.2013690499730129\n",
      "train loss:0.14424989151098166\n",
      "train loss:0.15157598674807235\n",
      "train loss:0.21452122218454794\n",
      "train loss:0.12328782207588809\n",
      "train loss:0.21561902871659658\n",
      "train loss:0.1294123558538628\n",
      "train loss:0.19731570223781264\n",
      "train loss:0.11776447774129521\n",
      "train loss:0.16163605257451516\n",
      "train loss:0.20568150588311823\n",
      "train loss:0.13529678451285856\n",
      "train loss:0.18853177219779288\n",
      "train loss:0.1838530498018773\n",
      "train loss:0.12319786549217523\n",
      "train loss:0.16812247935092897\n",
      "train loss:0.08353137656069749\n",
      "train loss:0.22209963552218417\n",
      "train loss:0.1440869080278997\n",
      "train loss:0.19064593720987313\n",
      "train loss:0.18274340993768934\n",
      "train loss:0.16194062221245445\n",
      "train loss:0.13267312286373958\n",
      "train loss:0.143010216238221\n",
      "train loss:0.1415760378166191\n",
      "train loss:0.12430809108718968\n",
      "train loss:0.14672725399317302\n",
      "train loss:0.23296384604763265\n",
      "train loss:0.09027847420933899\n",
      "train loss:0.14457769835905052\n",
      "train loss:0.15921135207570264\n",
      "train loss:0.10065706449467209\n",
      "train loss:0.13948177874997164\n",
      "train loss:0.08306970816407437\n",
      "train loss:0.08129760084847716\n",
      "train loss:0.1749248643190927\n",
      "train loss:0.14157391863663998\n",
      "train loss:0.09081719559887148\n",
      "train loss:0.22647956797174676\n",
      "train loss:0.1853279610985922\n",
      "train loss:0.22401420267193012\n",
      "train loss:0.15409196418251472\n",
      "train loss:0.11192469063543534\n",
      "train loss:0.1295507666526919\n",
      "train loss:0.20116379837652293\n",
      "train loss:0.14296133508462242\n",
      "train loss:0.32663477560440335\n",
      "train loss:0.1622769000180438\n",
      "train loss:0.1778016753359356\n",
      "train loss:0.14707161816730854\n",
      "train loss:0.16538483315573746\n",
      "train loss:0.21361608772929166\n",
      "train loss:0.14685253192485903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.23576432391951235\n",
      "train loss:0.16745686947142294\n",
      "train loss:0.28915184063923843\n",
      "train loss:0.1070166785989502\n",
      "train loss:0.19534705129759847\n",
      "train loss:0.20055032079882654\n",
      "train loss:0.10797394380459957\n",
      "train loss:0.25767069402611636\n",
      "train loss:0.16931381341584928\n",
      "train loss:0.1123088681984844\n",
      "train loss:0.19257643634584645\n",
      "train loss:0.2581753076987263\n",
      "train loss:0.13406467240463257\n",
      "train loss:0.20332062448214316\n",
      "train loss:0.11325575850744599\n",
      "train loss:0.15602176575631804\n",
      "train loss:0.1135865538179442\n",
      "train loss:0.13175122634057623\n",
      "train loss:0.2416935756720461\n",
      "train loss:0.18341032233423127\n",
      "train loss:0.20599601203883444\n",
      "train loss:0.14396199005065097\n",
      "train loss:0.12688677364606737\n",
      "train loss:0.23342886196224152\n",
      "train loss:0.1951572495201099\n",
      "train loss:0.16703201867822642\n",
      "train loss:0.22172672865886725\n",
      "train loss:0.22881988417959362\n",
      "train loss:0.14785085173058685\n",
      "train loss:0.12874158023768084\n",
      "train loss:0.14315312703093494\n",
      "train loss:0.22184130364792665\n",
      "train loss:0.13277585563246055\n",
      "train loss:0.25898959044735376\n",
      "train loss:0.11919133284144025\n",
      "train loss:0.19993434550006353\n",
      "train loss:0.16443607877510188\n",
      "train loss:0.14993836376612737\n",
      "train loss:0.0635631430009746\n",
      "train loss:0.16970636649920828\n",
      "train loss:0.3330062260931384\n",
      "train loss:0.2022568454070073\n",
      "train loss:0.2289623227221997\n",
      "train loss:0.22538431681017687\n",
      "train loss:0.19636013957740142\n",
      "train loss:0.1676608093066733\n",
      "train loss:0.16590510464240527\n",
      "train loss:0.14684199676667478\n",
      "train loss:0.1575345688435662\n",
      "train loss:0.18407829107331586\n",
      "train loss:0.19321138546180372\n",
      "train loss:0.25627297568005425\n",
      "train loss:0.17461619201625314\n",
      "train loss:0.14616023658930338\n",
      "train loss:0.12768407114137942\n",
      "train loss:0.2585853869082526\n",
      "train loss:0.16962312230320475\n",
      "train loss:0.11661431017957252\n",
      "train loss:0.07109997805550426\n",
      "train loss:0.19192641446995143\n",
      "train loss:0.1419964829201475\n",
      "train loss:0.19974982141691136\n",
      "train loss:0.2895247519105293\n",
      "train loss:0.21675452346290563\n",
      "train loss:0.16894760691331434\n",
      "train loss:0.16030445030059123\n",
      "train loss:0.1803113823689852\n",
      "train loss:0.19171271945067794\n",
      "train loss:0.17903419537726037\n",
      "train loss:0.19593157686637425\n",
      "train loss:0.13724829583147796\n",
      "train loss:0.24955190306881372\n",
      "train loss:0.1441083832856614\n",
      "train loss:0.18243604228820076\n",
      "train loss:0.14460686957671187\n",
      "train loss:0.11904531108662915\n",
      "train loss:0.19037279542193397\n",
      "train loss:0.11701383028144179\n",
      "train loss:0.15016579922484097\n",
      "train loss:0.1324540237137076\n",
      "train loss:0.11645504308504247\n",
      "train loss:0.133379502688652\n",
      "train loss:0.172125469542305\n",
      "train loss:0.15692120881961658\n",
      "train loss:0.1870839564386377\n",
      "train loss:0.12219537165395503\n",
      "train loss:0.14502875497083728\n",
      "train loss:0.15455362074041268\n",
      "train loss:0.16450488147095915\n",
      "train loss:0.17642481274360614\n",
      "train loss:0.217618118554149\n",
      "train loss:0.17364156428169827\n",
      "train loss:0.1927398575732011\n",
      "train loss:0.08566078247397627\n",
      "train loss:0.06449314313144501\n",
      "train loss:0.10200484904045598\n",
      "train loss:0.16186178352160233\n",
      "train loss:0.16491666479495268\n",
      "train loss:0.15064426110413076\n",
      "train loss:0.18969805900124423\n",
      "train loss:0.12802087826430947\n",
      "train loss:0.17852961999000827\n",
      "train loss:0.10559463901094518\n",
      "train loss:0.14940934648361645\n",
      "train loss:0.06609766622089454\n",
      "train loss:0.1218907855934554\n",
      "train loss:0.12106128732019941\n",
      "train loss:0.15142005611264023\n",
      "train loss:0.1706614508045378\n",
      "train loss:0.1655048072098163\n",
      "train loss:0.17006192301153264\n",
      "train loss:0.15635187603029035\n",
      "train loss:0.14130573914705435\n",
      "train loss:0.15023143941465708\n",
      "train loss:0.20831940034950366\n",
      "train loss:0.27329724541087097\n",
      "train loss:0.23285621036780388\n",
      "train loss:0.13638740492836773\n",
      "train loss:0.12169576511863457\n",
      "train loss:0.17662835900341622\n",
      "train loss:0.24878834085534332\n",
      "train loss:0.21189831191803493\n",
      "train loss:0.12520810083243222\n",
      "train loss:0.1430382041395677\n",
      "train loss:0.22033228182031386\n",
      "train loss:0.098623414870843\n",
      "train loss:0.2290626792882304\n",
      "train loss:0.18800444475262335\n",
      "train loss:0.2192259250134484\n",
      "train loss:0.19347374680155402\n",
      "train loss:0.14342122855677608\n",
      "train loss:0.21670905945807703\n",
      "train loss:0.24182004234599408\n",
      "train loss:0.15464725922213515\n",
      "train loss:0.0729241102494187\n",
      "train loss:0.21699771056787898\n",
      "train loss:0.1973856235754851\n",
      "train loss:0.09837562101307393\n",
      "train loss:0.11545404801451335\n",
      "train loss:0.17790008916036723\n",
      "train loss:0.1738724365952894\n",
      "train loss:0.12087909489853484\n",
      "train loss:0.21609890704584755\n",
      "train loss:0.20919484586163356\n",
      "train loss:0.1876312366679387\n",
      "train loss:0.11316106916227806\n",
      "train loss:0.12389883954279708\n",
      "train loss:0.14058195706919943\n",
      "train loss:0.323267157943658\n",
      "train loss:0.17164393364585304\n",
      "train loss:0.1424135587386387\n",
      "train loss:0.3255867876395975\n",
      "train loss:0.20883952295621547\n",
      "train loss:0.13518379611554382\n",
      "train loss:0.14326599410205065\n",
      "train loss:0.1319698978007655\n",
      "train loss:0.13988584457931702\n",
      "train loss:0.1853359033873353\n",
      "train loss:0.11061276469034159\n",
      "train loss:0.15799685540209513\n",
      "train loss:0.10416366031364868\n",
      "train loss:0.2165326035219607\n",
      "train loss:0.10596874346259356\n",
      "train loss:0.16345309597386404\n",
      "train loss:0.17916706821624465\n",
      "train loss:0.22229441627427865\n",
      "train loss:0.17958438790126355\n",
      "train loss:0.14014286360749614\n",
      "train loss:0.15942502977573483\n",
      "train loss:0.11313557596535545\n",
      "train loss:0.09906308516721543\n",
      "train loss:0.20343529879737463\n",
      "train loss:0.11697128783932481\n",
      "train loss:0.17715500743247986\n",
      "train loss:0.11754059369847523\n",
      "train loss:0.17369344765859995\n",
      "train loss:0.1576845927745003\n",
      "train loss:0.20379711660347527\n",
      "train loss:0.20336012823602534\n",
      "train loss:0.1858806728104162\n",
      "train loss:0.3096650856301579\n",
      "train loss:0.20812134904814278\n",
      "train loss:0.11904421122706343\n",
      "train loss:0.1680861873045503\n",
      "train loss:0.16398057515745726\n",
      "train loss:0.1461370742497852\n",
      "train loss:0.15303521607404766\n",
      "train loss:0.1196019840858987\n",
      "train loss:0.12037397151729586\n",
      "train loss:0.13132762716041543\n",
      "train loss:0.0981502648247088\n",
      "train loss:0.1825495090411852\n",
      "train loss:0.21960352912212097\n",
      "train loss:0.09987714364667288\n",
      "train loss:0.13656323550209198\n",
      "train loss:0.18073004779934698\n",
      "train loss:0.16757869001018824\n",
      "train loss:0.10904421743422249\n",
      "train loss:0.17174704598528215\n",
      "train loss:0.11023183889253488\n",
      "train loss:0.10883266515313521\n",
      "train loss:0.154254715652142\n",
      "train loss:0.11788631427943595\n",
      "train loss:0.21202397391202218\n",
      "train loss:0.17859576349444548\n",
      "train loss:0.15099493714593162\n",
      "train loss:0.1770006462821837\n",
      "train loss:0.1112880399413668\n",
      "train loss:0.1897656675077306\n",
      "train loss:0.1897765409959168\n",
      "train loss:0.10458864462904828\n",
      "train loss:0.21445972952553624\n",
      "train loss:0.09748892487990245\n",
      "train loss:0.20207748001114242\n",
      "train loss:0.24583041642352074\n",
      "train loss:0.10005478709155356\n",
      "train loss:0.17344534393407474\n",
      "train loss:0.15483265041623992\n",
      "train loss:0.15850144704593697\n",
      "train loss:0.1215469055265689\n",
      "train loss:0.08450135998441616\n",
      "train loss:0.1981547003566516\n",
      "train loss:0.23554883708666638\n",
      "train loss:0.1356585088483472\n",
      "train loss:0.27272943912102393\n",
      "train loss:0.1697239577426651\n",
      "train loss:0.21024762140258244\n",
      "train loss:0.12087063108315131\n",
      "train loss:0.15114856076014097\n",
      "train loss:0.09986128204641263\n",
      "train loss:0.17598142424347032\n",
      "train loss:0.1049882587359402\n",
      "train loss:0.07543648631319508\n",
      "train loss:0.2002508076977711\n",
      "train loss:0.09447500596313298\n",
      "train loss:0.10888495660347736\n",
      "train loss:0.11689632323872164\n",
      "train loss:0.15470807946202653\n",
      "train loss:0.21359753600857392\n",
      "train loss:0.2270127678940528\n",
      "train loss:0.19815661258389675\n",
      "train loss:0.17619790442121697\n",
      "train loss:0.1528268574628633\n",
      "train loss:0.1487563646423687\n",
      "train loss:0.16993582492247417\n",
      "train loss:0.18347046829459235\n",
      "train loss:0.21326239031292973\n",
      "train loss:0.15603437828476935\n",
      "train loss:0.1976332210902912\n",
      "train loss:0.12400365239504897\n",
      "train loss:0.1385313251058296\n",
      "train loss:0.184431578881753\n",
      "train loss:0.302042891664902\n",
      "train loss:0.2367686031132684\n",
      "train loss:0.17091793145659218\n",
      "train loss:0.15248730940478425\n",
      "train loss:0.14926126471853063\n",
      "train loss:0.09317841720046799\n",
      "train loss:0.2074515115485438\n",
      "train loss:0.15896354814084848\n",
      "train loss:0.16052118167956164\n",
      "train loss:0.17297675728869433\n",
      "train loss:0.1655125825355792\n",
      "train loss:0.12433225986399002\n",
      "train loss:0.181694555267171\n",
      "train loss:0.1591238952812855\n",
      "train loss:0.15510821429295293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0844992137494307\n",
      "train loss:0.14196743854976085\n",
      "train loss:0.33558502745194796\n",
      "train loss:0.21806221219198946\n",
      "train loss:0.20585339633932165\n",
      "train loss:0.23779205396193492\n",
      "train loss:0.13098977883245352\n",
      "train loss:0.11960052290096806\n",
      "train loss:0.14872546386303218\n",
      "train loss:0.20100474555167835\n",
      "train loss:0.0960182092104711\n",
      "train loss:0.19268418794142148\n",
      "train loss:0.13871810754859903\n",
      "train loss:0.07954366593439803\n",
      "train loss:0.17954831269994334\n",
      "train loss:0.22850738214487404\n",
      "train loss:0.21371267923896833\n",
      "train loss:0.15941827393660124\n",
      "train loss:0.15984568701785412\n",
      "train loss:0.16177057880160903\n",
      "train loss:0.1537682938558248\n",
      "train loss:0.11888559067763108\n",
      "train loss:0.1347094532804016\n",
      "train loss:0.23188277043097863\n",
      "train loss:0.1923100395127836\n",
      "train loss:0.10866696701969827\n",
      "train loss:0.1255169209199345\n",
      "train loss:0.19020482884168716\n",
      "train loss:0.14292092124838945\n",
      "train loss:0.14165412144957643\n",
      "train loss:0.14334855748794528\n",
      "train loss:0.2185427867774755\n",
      "train loss:0.17070463470399816\n",
      "train loss:0.23595484961677082\n",
      "train loss:0.15782289570605204\n",
      "train loss:0.09061459479284198\n",
      "train loss:0.1681442101652091\n",
      "train loss:0.13229241629800056\n",
      "train loss:0.2048610884267863\n",
      "train loss:0.14851479612920349\n",
      "train loss:0.19777213338147348\n",
      "train loss:0.11425527478837044\n",
      "train loss:0.12246008062373365\n",
      "train loss:0.24031241382586427\n",
      "train loss:0.13150866865819585\n",
      "train loss:0.2844159945909572\n",
      "train loss:0.09840849394923631\n",
      "train loss:0.16005348338139463\n",
      "train loss:0.3138526084872866\n",
      "train loss:0.1386895980165206\n",
      "train loss:0.19318190509615632\n",
      "train loss:0.12173423404260593\n",
      "train loss:0.20103832434354285\n",
      "train loss:0.20529764745913487\n",
      "train loss:0.18747112657882922\n",
      "train loss:0.18121236086087703\n",
      "train loss:0.21380973033519005\n",
      "train loss:0.17444519419167268\n",
      "train loss:0.24935491101946547\n",
      "train loss:0.2112520430457375\n",
      "train loss:0.11260776596694588\n",
      "train loss:0.25879262000846065\n",
      "train loss:0.1140234991663455\n",
      "train loss:0.2546335571849452\n",
      "train loss:0.20068846082313851\n",
      "train loss:0.09483773202171009\n",
      "train loss:0.23101457560059557\n",
      "train loss:0.14031087800406386\n",
      "train loss:0.17295958442672427\n",
      "train loss:0.133666306061364\n",
      "train loss:0.25734366121023755\n",
      "train loss:0.12788431706470285\n",
      "train loss:0.09810259416049108\n",
      "train loss:0.2502877287304221\n",
      "train loss:0.07267398477811274\n",
      "train loss:0.11534519513403443\n",
      "train loss:0.18150993483878528\n",
      "train loss:0.24048331357830643\n",
      "train loss:0.14252514334046396\n",
      "train loss:0.11783125277681883\n",
      "train loss:0.14223922610182613\n",
      "train loss:0.13748342053352886\n",
      "train loss:0.16497157846173027\n",
      "train loss:0.11589168146856954\n",
      "train loss:0.1154511219518933\n",
      "train loss:0.18277912112869943\n",
      "train loss:0.13213918476660286\n",
      "train loss:0.149246706699908\n",
      "train loss:0.13192916879390093\n",
      "train loss:0.15685552605225073\n",
      "train loss:0.11982895604439404\n",
      "train loss:0.10871857560168868\n",
      "train loss:0.11867558777752557\n",
      "train loss:0.18170651404406007\n",
      "train loss:0.17404874818762864\n",
      "train loss:0.1650786135973478\n",
      "train loss:0.17244753816184313\n",
      "train loss:0.1708175865548184\n",
      "train loss:0.1842604570088684\n",
      "train loss:0.17484108509594937\n",
      "train loss:0.1581735365812194\n",
      "train loss:0.10334763094192927\n",
      "train loss:0.13590111364833127\n",
      "train loss:0.40020681957492393\n",
      "train loss:0.1612884007432246\n",
      "train loss:0.20260123541505107\n",
      "train loss:0.13962477714227747\n",
      "=== epoch:11, train acc:0.949, test acc:0.905 ===\n",
      "train loss:0.16250984362937848\n",
      "train loss:0.15269751491708772\n",
      "train loss:0.1552037662222091\n",
      "train loss:0.22987765443304514\n",
      "train loss:0.08154472233294585\n",
      "train loss:0.23889606727632187\n",
      "train loss:0.1658452934802409\n",
      "train loss:0.16526177179704427\n",
      "train loss:0.15237551048135184\n",
      "train loss:0.19165061854916815\n",
      "train loss:0.10899156480168924\n",
      "train loss:0.15600547731275072\n",
      "train loss:0.18074987524582065\n",
      "train loss:0.22686211891339805\n",
      "train loss:0.08674899947613585\n",
      "train loss:0.16281260865372207\n",
      "train loss:0.1651991135427952\n",
      "train loss:0.20882774909158108\n",
      "train loss:0.1771146197734651\n",
      "train loss:0.13576464819932293\n",
      "train loss:0.26050208995336344\n",
      "train loss:0.09809393209627247\n",
      "train loss:0.16373455911414297\n",
      "train loss:0.13737129224213426\n",
      "train loss:0.1390065708771494\n",
      "train loss:0.18585285762225584\n",
      "train loss:0.1989268830331152\n",
      "train loss:0.16342824947396117\n",
      "train loss:0.16132023835549725\n",
      "train loss:0.2590356546837953\n",
      "train loss:0.18837105086850067\n",
      "train loss:0.14844788870666548\n",
      "train loss:0.2181120007968587\n",
      "train loss:0.15372226430224745\n",
      "train loss:0.2367937789893162\n",
      "train loss:0.14100976797523976\n",
      "train loss:0.1630837312849348\n",
      "train loss:0.14802747181622947\n",
      "train loss:0.1718819471481143\n",
      "train loss:0.15939678206236965\n",
      "train loss:0.17293137071583406\n",
      "train loss:0.1810202390318119\n",
      "train loss:0.13263841600776693\n",
      "train loss:0.1626676477401103\n",
      "train loss:0.09369674346126726\n",
      "train loss:0.1296743479337329\n",
      "train loss:0.18680900256593153\n",
      "train loss:0.19855604461281826\n",
      "train loss:0.17824245527336607\n",
      "train loss:0.2475083408406099\n",
      "train loss:0.2046356128172812\n",
      "train loss:0.21677056702188177\n",
      "train loss:0.23113570947415593\n",
      "train loss:0.13803373130828434\n",
      "train loss:0.283391724202455\n",
      "train loss:0.2063605008844213\n",
      "train loss:0.14516683571412886\n",
      "train loss:0.14344989907828518\n",
      "train loss:0.2232034438361426\n",
      "train loss:0.19708311201478698\n",
      "train loss:0.13056761897211752\n",
      "train loss:0.13907052885355323\n",
      "train loss:0.12412543642527178\n",
      "train loss:0.09267412283300486\n",
      "train loss:0.16798504578539955\n",
      "train loss:0.3209220270106419\n",
      "train loss:0.19381056602712962\n",
      "train loss:0.2166633659732077\n",
      "train loss:0.10176155704867387\n",
      "train loss:0.12612749431066592\n",
      "train loss:0.21145240604360058\n",
      "train loss:0.08535987044451587\n",
      "train loss:0.21038920793462357\n",
      "train loss:0.17597121640726235\n",
      "train loss:0.16330273383274713\n",
      "train loss:0.08476659515528238\n",
      "train loss:0.16909040597344316\n",
      "train loss:0.10515513215787177\n",
      "train loss:0.11850301417025609\n",
      "train loss:0.1287500025259935\n",
      "train loss:0.13368915881817092\n",
      "train loss:0.09600927640633586\n",
      "train loss:0.11127872390650959\n",
      "train loss:0.16188466090996795\n",
      "train loss:0.15089096110817374\n",
      "train loss:0.06841345717177713\n",
      "train loss:0.12714680272808865\n",
      "train loss:0.1560057714159654\n",
      "train loss:0.16916989667287272\n",
      "train loss:0.11356525965127567\n",
      "train loss:0.14236483604243258\n",
      "train loss:0.14956853004363202\n",
      "train loss:0.15886466559841142\n",
      "train loss:0.1749191620049105\n",
      "train loss:0.12122180883339148\n",
      "train loss:0.14453934038632388\n",
      "train loss:0.10997333224934785\n",
      "train loss:0.15434576075069276\n",
      "train loss:0.07118525456770844\n",
      "train loss:0.19744294099347734\n",
      "train loss:0.09320050811554113\n",
      "train loss:0.2764966077173361\n",
      "train loss:0.21847539742249183\n",
      "train loss:0.06624640538143602\n",
      "train loss:0.08498357020787031\n",
      "train loss:0.14254514608994287\n",
      "train loss:0.16743657423471933\n",
      "train loss:0.1230504258395011\n",
      "train loss:0.23895591189545676\n",
      "train loss:0.25908552366227755\n",
      "train loss:0.21509967159438514\n",
      "train loss:0.13319723920426085\n",
      "train loss:0.15027319491829008\n",
      "train loss:0.15583445131250356\n",
      "train loss:0.1311041586729865\n",
      "train loss:0.21849876907803154\n",
      "train loss:0.16762972110431665\n",
      "train loss:0.1653805301955569\n",
      "train loss:0.13606413251278213\n",
      "train loss:0.08673196028437997\n",
      "train loss:0.1910288748153395\n",
      "train loss:0.08801999273371357\n",
      "train loss:0.13790730563636275\n",
      "train loss:0.1348109117099796\n",
      "train loss:0.12818721702244346\n",
      "train loss:0.1397714489136832\n",
      "train loss:0.09972307501600694\n",
      "train loss:0.13399959758718266\n",
      "train loss:0.15168095620884936\n",
      "train loss:0.2087313004460686\n",
      "train loss:0.1605793498170134\n",
      "train loss:0.12931231755080402\n",
      "train loss:0.183462230342077\n",
      "train loss:0.19963994559511733\n",
      "train loss:0.12556690494781322\n",
      "train loss:0.1587383369289861\n",
      "train loss:0.1588234738700676\n",
      "train loss:0.09183461202797794\n",
      "train loss:0.09072985175247043\n",
      "train loss:0.11217881383725263\n",
      "train loss:0.13815902956859197\n",
      "train loss:0.08558176335606137\n",
      "train loss:0.11316167295538854\n",
      "train loss:0.1504551551822117\n",
      "train loss:0.17932976894391028\n",
      "train loss:0.139079170234168\n",
      "train loss:0.08635687532619599\n",
      "train loss:0.1621465986338996\n",
      "train loss:0.18414345960995232\n",
      "train loss:0.16246093235146397\n",
      "train loss:0.1385582624635099\n",
      "train loss:0.17565409031509155\n",
      "train loss:0.133106733157644\n",
      "train loss:0.16461641579125297\n",
      "train loss:0.19219589932195758\n",
      "train loss:0.20410036129357462\n",
      "train loss:0.17991998790777017\n",
      "train loss:0.06171404609750831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.22552754863811375\n",
      "train loss:0.2425444322415333\n",
      "train loss:0.11056738784424251\n",
      "train loss:0.1487439608271074\n",
      "train loss:0.11341138511236641\n",
      "train loss:0.1838537152573806\n",
      "train loss:0.09771086283033066\n",
      "train loss:0.261559921559183\n",
      "train loss:0.22541252070868026\n",
      "train loss:0.14924638791375458\n",
      "train loss:0.09463596923798563\n",
      "train loss:0.13155194134765247\n",
      "train loss:0.13453966942350973\n",
      "train loss:0.23099328196496408\n",
      "train loss:0.1230842046285939\n",
      "train loss:0.20275300522085307\n",
      "train loss:0.11527230590659443\n",
      "train loss:0.14390532772502618\n",
      "train loss:0.09337884718254404\n",
      "train loss:0.1171831814591491\n",
      "train loss:0.15484692885700002\n",
      "train loss:0.1533584088079757\n",
      "train loss:0.1835851244178616\n",
      "train loss:0.21226478079111366\n",
      "train loss:0.25279294444001754\n",
      "train loss:0.15887787766992464\n",
      "train loss:0.13944137068734494\n",
      "train loss:0.17638461107918943\n",
      "train loss:0.18314999537727997\n",
      "train loss:0.08306773073876504\n",
      "train loss:0.13903451015730112\n",
      "train loss:0.1279671243150954\n",
      "train loss:0.1448646837126866\n",
      "train loss:0.0926926330713\n",
      "train loss:0.15764149243175005\n",
      "train loss:0.10333389700285718\n",
      "train loss:0.1998652974541006\n",
      "train loss:0.1291713815843885\n",
      "train loss:0.11090398096844668\n",
      "train loss:0.08451583313541661\n",
      "train loss:0.19494588313123537\n",
      "train loss:0.15808247500761818\n",
      "train loss:0.14308161728690877\n",
      "train loss:0.10625101981284286\n",
      "train loss:0.20426320038002668\n",
      "train loss:0.17793960332896208\n",
      "train loss:0.12827562647043395\n",
      "train loss:0.1308300243228551\n",
      "train loss:0.20613889717412928\n",
      "train loss:0.22768655077711025\n",
      "train loss:0.06083120561640012\n",
      "train loss:0.1768020311748799\n",
      "train loss:0.14476315993095934\n",
      "train loss:0.15606891569949952\n",
      "train loss:0.20773485136383868\n",
      "train loss:0.2341241289760832\n",
      "train loss:0.2137606118346889\n",
      "train loss:0.1045192922984063\n",
      "train loss:0.119535802697052\n",
      "train loss:0.22632877109747934\n",
      "train loss:0.16728407779189264\n",
      "train loss:0.15747094611810558\n",
      "train loss:0.15167595314367013\n",
      "train loss:0.11490265785341304\n",
      "train loss:0.1582443820103595\n",
      "train loss:0.1514120310809348\n",
      "train loss:0.09763800264438018\n",
      "train loss:0.16063039769154244\n",
      "train loss:0.19980252794094724\n",
      "train loss:0.18355182064399359\n",
      "train loss:0.32177096808329475\n",
      "train loss:0.15400643141291437\n",
      "train loss:0.07418359233393353\n",
      "train loss:0.19529540662324898\n",
      "train loss:0.15079577971435681\n",
      "train loss:0.2337149797328994\n",
      "train loss:0.11639852433562443\n",
      "train loss:0.10389567860742911\n",
      "train loss:0.1400548727071814\n",
      "train loss:0.2365637829062161\n",
      "train loss:0.10976441418448807\n",
      "train loss:0.12425606268446708\n",
      "train loss:0.1035862272544739\n",
      "train loss:0.12136814423082949\n",
      "train loss:0.10513291932083196\n",
      "train loss:0.2726596768306652\n",
      "train loss:0.24229474941485882\n",
      "train loss:0.20779387939596222\n",
      "train loss:0.1265860164103647\n",
      "train loss:0.17357509785284703\n",
      "train loss:0.09570501269572164\n",
      "train loss:0.17757777304487374\n",
      "train loss:0.1121981737075033\n",
      "train loss:0.14396260805532082\n",
      "train loss:0.260089935052017\n",
      "train loss:0.2016434284727202\n",
      "train loss:0.20881578261963235\n",
      "train loss:0.2101888405225281\n",
      "train loss:0.1227194281195\n",
      "train loss:0.05024680001792916\n",
      "train loss:0.14725906903816421\n",
      "train loss:0.18205307071883464\n",
      "train loss:0.08498197397347201\n",
      "train loss:0.14992520909917506\n",
      "train loss:0.07617123540435601\n",
      "train loss:0.15607487260776792\n",
      "train loss:0.2764047150132013\n",
      "train loss:0.11594816721261993\n",
      "train loss:0.1310306238907378\n",
      "train loss:0.12062265039944738\n",
      "train loss:0.17600991202249827\n",
      "train loss:0.2653756794946343\n",
      "train loss:0.1141414424033339\n",
      "train loss:0.18298547493697434\n",
      "train loss:0.23776883482207986\n",
      "train loss:0.19982996447705254\n",
      "train loss:0.2216268877917516\n",
      "train loss:0.21350501891888268\n",
      "train loss:0.16103552387335832\n",
      "train loss:0.11587391402775638\n",
      "train loss:0.10761100132820323\n",
      "train loss:0.18588739386060038\n",
      "train loss:0.18861191758013937\n",
      "train loss:0.15493904427670926\n",
      "train loss:0.08752261801426267\n",
      "train loss:0.12609623032934475\n",
      "train loss:0.14425956734274364\n",
      "train loss:0.11723690211703258\n",
      "train loss:0.1065259165869135\n",
      "train loss:0.144655577789384\n",
      "train loss:0.1667150707445972\n",
      "train loss:0.16097540642216068\n",
      "train loss:0.05305306906179478\n",
      "train loss:0.269142869410364\n",
      "train loss:0.1391549681413716\n",
      "train loss:0.16605240739164667\n",
      "train loss:0.08994752136966871\n",
      "train loss:0.14665586209483517\n",
      "train loss:0.11819668956087404\n",
      "train loss:0.1459276073644508\n",
      "train loss:0.15761116335567088\n",
      "train loss:0.16861636861806256\n",
      "train loss:0.11740619825644234\n",
      "train loss:0.20721253889896082\n",
      "train loss:0.10637015549414494\n",
      "train loss:0.23279322227911303\n",
      "train loss:0.1346922386167525\n",
      "train loss:0.18158880942011052\n",
      "train loss:0.22439270712320047\n",
      "train loss:0.07267827249190771\n",
      "train loss:0.15600260488925577\n",
      "train loss:0.1850613674812529\n",
      "train loss:0.08196410174264596\n",
      "train loss:0.1780774651834338\n",
      "train loss:0.17056230524857383\n",
      "train loss:0.17938599004743255\n",
      "train loss:0.21320122459257576\n",
      "train loss:0.15505272554053287\n",
      "train loss:0.20178644753346733\n",
      "train loss:0.19188570754695422\n",
      "train loss:0.11867466454186051\n",
      "train loss:0.15948811208054867\n",
      "train loss:0.20512400849087079\n",
      "train loss:0.16875668870502714\n",
      "train loss:0.17960037676411164\n",
      "train loss:0.2238735187776546\n",
      "train loss:0.1603241596467323\n",
      "train loss:0.16385589665796435\n",
      "train loss:0.10324613059897196\n",
      "train loss:0.2715560740631063\n",
      "train loss:0.1492872943925215\n",
      "train loss:0.11692988064170647\n",
      "train loss:0.13597879404899527\n",
      "train loss:0.14335463353402098\n",
      "train loss:0.2057372237998883\n",
      "train loss:0.13130026560961647\n",
      "train loss:0.21869441093597264\n",
      "train loss:0.14020132182805792\n",
      "train loss:0.12081571732352918\n",
      "train loss:0.2050208009606882\n",
      "train loss:0.11702411760539548\n",
      "train loss:0.22642071802373415\n",
      "train loss:0.13644396432275432\n",
      "train loss:0.11858591832424752\n",
      "train loss:0.09871963522045837\n",
      "train loss:0.11817623559578734\n",
      "train loss:0.2699024974398438\n",
      "train loss:0.10055629806975236\n",
      "train loss:0.1456891340205578\n",
      "train loss:0.12507325374684397\n",
      "train loss:0.12116467688655068\n",
      "train loss:0.11798060552432124\n",
      "train loss:0.08535358429948077\n",
      "train loss:0.25462800026685234\n",
      "train loss:0.12358807388322578\n",
      "train loss:0.1718990819942589\n",
      "train loss:0.18360023789597246\n",
      "train loss:0.12769920773435256\n",
      "train loss:0.20439544884820907\n",
      "train loss:0.18463536480100523\n",
      "train loss:0.10282010012562376\n",
      "train loss:0.11435264350149742\n",
      "train loss:0.1159791904795411\n",
      "train loss:0.10039730980712384\n",
      "train loss:0.12495146378910961\n",
      "train loss:0.2510906884111473\n",
      "train loss:0.19229601394214493\n",
      "train loss:0.12571035999567332\n",
      "train loss:0.10305432698922122\n",
      "train loss:0.13775446409093503\n",
      "train loss:0.08849366046645858\n",
      "train loss:0.19267111912471016\n",
      "train loss:0.1945193004770156\n",
      "train loss:0.11064173740909483\n",
      "train loss:0.07517665753822206\n",
      "train loss:0.19659578576580983\n",
      "train loss:0.1099427951063518\n",
      "train loss:0.1999958564115299\n",
      "train loss:0.17000416557991302\n",
      "train loss:0.07310156312534967\n",
      "train loss:0.09998949089028471\n",
      "train loss:0.2049588780796855\n",
      "train loss:0.10357027632663396\n",
      "train loss:0.17291880135349202\n",
      "train loss:0.12561472226241596\n",
      "train loss:0.09194919885372893\n",
      "train loss:0.09092923556157594\n",
      "train loss:0.16664498632510713\n",
      "train loss:0.18041639588829622\n",
      "train loss:0.14853120656288218\n",
      "train loss:0.12062308830073767\n",
      "train loss:0.15137776536198294\n",
      "train loss:0.09398034042385764\n",
      "train loss:0.05017441653384383\n",
      "train loss:0.14826083967989623\n",
      "train loss:0.2019513683293323\n",
      "train loss:0.13212457909790554\n",
      "train loss:0.13559465778584076\n",
      "train loss:0.11109668248762448\n",
      "train loss:0.13506648555926412\n",
      "train loss:0.1539639529445355\n",
      "train loss:0.07660270084584458\n",
      "train loss:0.11670218105388097\n",
      "train loss:0.10935474546003922\n",
      "train loss:0.1366250923028894\n",
      "train loss:0.11284701391594389\n",
      "train loss:0.20331955650499342\n",
      "train loss:0.07172539872583364\n",
      "train loss:0.13820005089754642\n",
      "train loss:0.18074670359231107\n",
      "train loss:0.1848070198773172\n",
      "train loss:0.10768423439598214\n",
      "train loss:0.18869179559871682\n",
      "train loss:0.16623146440247383\n",
      "train loss:0.13358776279218046\n",
      "train loss:0.12852917358996144\n",
      "train loss:0.11109005630109697\n",
      "train loss:0.138654688590657\n",
      "train loss:0.1859005124333656\n",
      "train loss:0.1682776828253345\n",
      "train loss:0.1736019484081445\n",
      "train loss:0.07497112664974118\n",
      "train loss:0.11966856582724963\n",
      "train loss:0.19372992864107258\n",
      "train loss:0.07538161870681774\n",
      "train loss:0.14248484482008586\n",
      "train loss:0.1562067158724642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.13589544873021867\n",
      "train loss:0.1116110163581449\n",
      "train loss:0.158311672376503\n",
      "train loss:0.14532790510475485\n",
      "train loss:0.09912417090592492\n",
      "train loss:0.16079667997989486\n",
      "train loss:0.12510534782861651\n",
      "train loss:0.12729315016442633\n",
      "train loss:0.13307086127890536\n",
      "train loss:0.15341370593588627\n",
      "train loss:0.15213324639165\n",
      "train loss:0.1782252680780388\n",
      "train loss:0.0490779447165979\n",
      "train loss:0.12056152108795203\n",
      "train loss:0.18972242830511635\n",
      "train loss:0.14076669213173118\n",
      "train loss:0.16791409777545277\n",
      "train loss:0.125747693993365\n",
      "train loss:0.1634535093979375\n",
      "train loss:0.26656399814863213\n",
      "train loss:0.10466947860155601\n",
      "train loss:0.08895617370767905\n",
      "train loss:0.15878627065804019\n",
      "train loss:0.18719837181691737\n",
      "train loss:0.07890603178774001\n",
      "train loss:0.14013599755947095\n",
      "train loss:0.20570657671017625\n",
      "train loss:0.17126822823935575\n",
      "train loss:0.27142922061994174\n",
      "train loss:0.15409488043172703\n",
      "train loss:0.20479357294779535\n",
      "train loss:0.160085930969502\n",
      "train loss:0.2427917575797856\n",
      "train loss:0.19509256247565393\n",
      "train loss:0.40752514204545276\n",
      "train loss:0.2511156083603436\n",
      "train loss:0.16707360434765406\n",
      "train loss:0.21355361704987566\n",
      "train loss:0.13612232463481827\n",
      "train loss:0.198535217109332\n",
      "train loss:0.16937352351218618\n",
      "train loss:0.10432410564994563\n",
      "train loss:0.1322648312051141\n",
      "train loss:0.21719686135581576\n",
      "train loss:0.11405508806275913\n",
      "train loss:0.13680146642074095\n",
      "train loss:0.18026133815393156\n",
      "train loss:0.16975111254456202\n",
      "train loss:0.11369089761834968\n",
      "train loss:0.17200911388358417\n",
      "train loss:0.12485935156668904\n",
      "train loss:0.1450536375377124\n",
      "train loss:0.11259197575295815\n",
      "train loss:0.10064338273258094\n",
      "train loss:0.11437896258595946\n",
      "train loss:0.07287964372984963\n",
      "train loss:0.11531166765461567\n",
      "train loss:0.13819966622470412\n",
      "train loss:0.10305914893841109\n",
      "train loss:0.09159383896948636\n",
      "train loss:0.12753442640882715\n",
      "train loss:0.14006844420351494\n",
      "train loss:0.2865931826463028\n",
      "train loss:0.12452099116679628\n",
      "train loss:0.18966391203067826\n",
      "train loss:0.11843009758735834\n",
      "train loss:0.140368622103214\n",
      "train loss:0.13047097130007962\n",
      "train loss:0.046933985655729336\n",
      "train loss:0.1456151904801065\n",
      "train loss:0.1592170611560616\n",
      "train loss:0.16901434427539516\n",
      "train loss:0.1277405779393645\n",
      "train loss:0.08740091640110244\n",
      "train loss:0.10024637038801591\n",
      "train loss:0.21320597956281023\n",
      "train loss:0.15739753702776726\n",
      "train loss:0.1107225522068333\n",
      "train loss:0.11083356165692564\n",
      "train loss:0.13793610869089404\n",
      "train loss:0.08101090355856709\n",
      "train loss:0.2081232999137205\n",
      "train loss:0.16550595714108637\n",
      "train loss:0.13494911964804163\n",
      "train loss:0.11049731903181705\n",
      "train loss:0.09319422274041898\n",
      "train loss:0.14228251030134076\n",
      "train loss:0.1214426276502744\n",
      "train loss:0.18994475047763681\n",
      "train loss:0.23981971713792588\n",
      "train loss:0.15232793358391145\n",
      "train loss:0.11884044391085485\n",
      "train loss:0.14247096060888623\n",
      "train loss:0.09669305129859955\n",
      "train loss:0.10908831410768291\n",
      "train loss:0.10767068946813961\n",
      "train loss:0.10062838752562012\n",
      "train loss:0.15324828940063404\n",
      "train loss:0.09463146653378221\n",
      "train loss:0.10854171889322617\n",
      "train loss:0.1104300446843547\n",
      "train loss:0.103689778645636\n",
      "train loss:0.10533002192214438\n",
      "train loss:0.2544123731287093\n",
      "train loss:0.13296484652850254\n",
      "train loss:0.061341153765528615\n",
      "train loss:0.1733535068369879\n",
      "train loss:0.12075928724123144\n",
      "train loss:0.10801929143371279\n",
      "train loss:0.1378002414537864\n",
      "train loss:0.12288164861479142\n",
      "train loss:0.1251115159044142\n",
      "train loss:0.324007255412463\n",
      "train loss:0.12948452426225554\n",
      "train loss:0.07631395598872123\n",
      "train loss:0.11538679751490394\n",
      "train loss:0.20700401463759086\n",
      "train loss:0.1914289336713337\n",
      "train loss:0.24691941216072213\n",
      "train loss:0.13334443983870453\n",
      "train loss:0.12705929351708634\n",
      "train loss:0.1715511591316288\n",
      "train loss:0.14192502058841325\n",
      "train loss:0.11047503192738117\n",
      "train loss:0.12461885236768143\n",
      "train loss:0.10645105441819279\n",
      "train loss:0.17746666891383855\n",
      "train loss:0.13746000997985028\n",
      "train loss:0.07219879492647623\n",
      "train loss:0.06324030274154824\n",
      "train loss:0.16992836546046966\n",
      "train loss:0.26465254493063817\n",
      "train loss:0.18262543772295345\n",
      "train loss:0.16927125371750507\n",
      "train loss:0.09686148584366748\n",
      "train loss:0.13246854015055007\n",
      "train loss:0.11423873776066303\n",
      "train loss:0.1803704389742169\n",
      "train loss:0.12198429590876443\n",
      "train loss:0.16171915108414697\n",
      "train loss:0.11702499155179238\n",
      "train loss:0.15763530045927523\n",
      "train loss:0.2725905157408202\n",
      "train loss:0.16482866656702477\n",
      "train loss:0.08550525850432905\n",
      "train loss:0.15356327873219458\n",
      "train loss:0.10773566943952748\n",
      "train loss:0.10290551974134686\n",
      "train loss:0.18243414219399487\n",
      "train loss:0.3360203760462148\n",
      "train loss:0.15617423777235162\n",
      "train loss:0.19493684119216464\n",
      "train loss:0.15889755373364786\n",
      "train loss:0.10835231807740252\n",
      "train loss:0.0895447585147082\n",
      "train loss:0.08928182406967516\n",
      "train loss:0.1109838144274545\n",
      "train loss:0.18745486418896484\n",
      "train loss:0.25398688334013036\n",
      "train loss:0.10510107241392705\n",
      "train loss:0.1843873229242407\n",
      "train loss:0.18456356099465668\n",
      "train loss:0.12318031530058979\n",
      "train loss:0.1551535954274161\n",
      "train loss:0.16879107243676683\n",
      "train loss:0.1942332952478548\n",
      "train loss:0.13998284964552796\n",
      "train loss:0.07364683618930229\n",
      "train loss:0.0892754409972005\n",
      "train loss:0.21372887673940674\n",
      "train loss:0.3356456246668994\n",
      "train loss:0.11534570455011772\n",
      "train loss:0.1809881302643802\n",
      "train loss:0.12948939357798842\n",
      "train loss:0.1779410620136818\n",
      "=== epoch:12, train acc:0.952, test acc:0.904 ===\n",
      "train loss:0.19779942383305482\n",
      "train loss:0.2184543476747705\n",
      "train loss:0.11250616581602796\n",
      "train loss:0.1612967363088475\n",
      "train loss:0.16669513065002353\n",
      "train loss:0.1320067707836979\n",
      "train loss:0.0803896660105471\n",
      "train loss:0.24702449944975516\n",
      "train loss:0.12285971005093209\n",
      "train loss:0.15418144419812513\n",
      "train loss:0.12077742272088476\n",
      "train loss:0.10405224083344637\n",
      "train loss:0.22284425357574475\n",
      "train loss:0.1194680338506953\n",
      "train loss:0.25663781703538613\n",
      "train loss:0.21662301570670395\n",
      "train loss:0.110714336032573\n",
      "train loss:0.12992090272954557\n",
      "train loss:0.19092518657670482\n",
      "train loss:0.3417567783944272\n",
      "train loss:0.15545536494384402\n",
      "train loss:0.10387012492539834\n",
      "train loss:0.19405799554590641\n",
      "train loss:0.15729332989340938\n",
      "train loss:0.1901500217013704\n",
      "train loss:0.10441809240255599\n",
      "train loss:0.13046517823942427\n",
      "train loss:0.2113346230559151\n",
      "train loss:0.28427896235222005\n",
      "train loss:0.13844620957649842\n",
      "train loss:0.16576965891293735\n",
      "train loss:0.1606339124195372\n",
      "train loss:0.13986371778063234\n",
      "train loss:0.17917466525372344\n",
      "train loss:0.09906358847490469\n",
      "train loss:0.09271491554662199\n",
      "train loss:0.14280878748720433\n",
      "train loss:0.16691390941831685\n",
      "train loss:0.1507625441372149\n",
      "train loss:0.13450169608023352\n",
      "train loss:0.15864107225709223\n",
      "train loss:0.13262074077212627\n",
      "train loss:0.11559014990702404\n",
      "train loss:0.2719431843376434\n",
      "train loss:0.1207552085524067\n",
      "train loss:0.13907918965109034\n",
      "train loss:0.1484186475997661\n",
      "train loss:0.16579434333731652\n",
      "train loss:0.1745142920559467\n",
      "train loss:0.20103787723259345\n",
      "train loss:0.1656447843450692\n",
      "train loss:0.20019398685334416\n",
      "train loss:0.2200991945489332\n",
      "train loss:0.0662634293443745\n",
      "train loss:0.15717104546706198\n",
      "train loss:0.10132222570847141\n",
      "train loss:0.27574104218308654\n",
      "train loss:0.17617878052228492\n",
      "train loss:0.1306975146264934\n",
      "train loss:0.08137674601681466\n",
      "train loss:0.09646965089694992\n",
      "train loss:0.0991469775554647\n",
      "train loss:0.29447810242186717\n",
      "train loss:0.19255555829161178\n",
      "train loss:0.11455616449160014\n",
      "train loss:0.12953930478672107\n",
      "train loss:0.21147380748003772\n",
      "train loss:0.17098843847437092\n",
      "train loss:0.1416697541226879\n",
      "train loss:0.14937653361080613\n",
      "train loss:0.13749511260675532\n",
      "train loss:0.13860751826446455\n",
      "train loss:0.08910107454035096\n",
      "train loss:0.11853921018728739\n",
      "train loss:0.11546996119151817\n",
      "train loss:0.12879807761072704\n",
      "train loss:0.16033671320309256\n",
      "train loss:0.24301843217139601\n",
      "train loss:0.13458694455123368\n",
      "train loss:0.18215016774534887\n",
      "train loss:0.16712863409100298\n",
      "train loss:0.0929829518944998\n",
      "train loss:0.18686644312154488\n",
      "train loss:0.18807542709437353\n",
      "train loss:0.10931745879844035\n",
      "train loss:0.09590399558850106\n",
      "train loss:0.23907872672608121\n",
      "train loss:0.11804365243323307\n",
      "train loss:0.08215472931779988\n",
      "train loss:0.10690615554783088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.20745759183775248\n",
      "train loss:0.08009709960355937\n",
      "train loss:0.22246745244355892\n",
      "train loss:0.19730275749722945\n",
      "train loss:0.100426637887895\n",
      "train loss:0.08896371630847826\n",
      "train loss:0.16264322501470205\n",
      "train loss:0.09954983235640738\n",
      "train loss:0.06056129763209126\n",
      "train loss:0.10743748904506514\n",
      "train loss:0.2186887177637264\n",
      "train loss:0.1624933890141205\n",
      "train loss:0.22167915895285456\n",
      "train loss:0.20206567031649902\n",
      "train loss:0.10074540402801473\n",
      "train loss:0.11923864849251102\n",
      "train loss:0.13047188125260578\n",
      "train loss:0.203667130126734\n",
      "train loss:0.13495611146049744\n",
      "train loss:0.13366057637723874\n",
      "train loss:0.17146194982750323\n",
      "train loss:0.13952431402756704\n",
      "train loss:0.12587548419688088\n",
      "train loss:0.19114358780615362\n",
      "train loss:0.043576192390285075\n",
      "train loss:0.1348139602796058\n",
      "train loss:0.26875947874047373\n",
      "train loss:0.06210080524276221\n",
      "train loss:0.173385458356246\n",
      "train loss:0.12908775327798108\n",
      "train loss:0.1060885995175738\n",
      "train loss:0.22897295571810455\n",
      "train loss:0.13922101016184274\n",
      "train loss:0.12859074665658687\n",
      "train loss:0.19764373927346088\n",
      "train loss:0.12106929269685113\n",
      "train loss:0.06531157047383475\n",
      "train loss:0.2044949507315479\n",
      "train loss:0.20781727544188533\n",
      "train loss:0.17981654243305242\n",
      "train loss:0.072973723742876\n",
      "train loss:0.15439660667369498\n",
      "train loss:0.14275626160953092\n",
      "train loss:0.19982098376159843\n",
      "train loss:0.11281114429456124\n",
      "train loss:0.22290879221157048\n",
      "train loss:0.2418673860546715\n",
      "train loss:0.13941047930228856\n",
      "train loss:0.09648267456850455\n",
      "train loss:0.18236872217269784\n",
      "train loss:0.17697147908124214\n",
      "train loss:0.13437063749624234\n",
      "train loss:0.11787244087358444\n",
      "train loss:0.07691667941910468\n",
      "train loss:0.19345047359177958\n",
      "train loss:0.09650382804561579\n",
      "train loss:0.1256208238817303\n",
      "train loss:0.1457997416408254\n",
      "train loss:0.09901116696191363\n",
      "train loss:0.08901539718038148\n",
      "train loss:0.16445177688762694\n",
      "train loss:0.11958019488888585\n",
      "train loss:0.10907110055165922\n",
      "train loss:0.17391237344664623\n",
      "train loss:0.12529787989919627\n",
      "train loss:0.1314856036483939\n",
      "train loss:0.19754092119385397\n",
      "train loss:0.08320218874616944\n",
      "train loss:0.15484131574355411\n",
      "train loss:0.10206199889445465\n",
      "train loss:0.08706037637335763\n",
      "train loss:0.17775298744417653\n",
      "train loss:0.14978436982655258\n",
      "train loss:0.24933521734717468\n",
      "train loss:0.22263271556108244\n",
      "train loss:0.04642862211288598\n",
      "train loss:0.11847413507486877\n",
      "train loss:0.05562724800501982\n",
      "train loss:0.22687066156696964\n",
      "train loss:0.15239230548596802\n",
      "train loss:0.07395802987362747\n",
      "train loss:0.12198152746941368\n",
      "train loss:0.15437981298216927\n",
      "train loss:0.13470073447334305\n",
      "train loss:0.12268630733763045\n",
      "train loss:0.11343118331458767\n",
      "train loss:0.09665483253577867\n",
      "train loss:0.3551154550741859\n",
      "train loss:0.0897406471062649\n",
      "train loss:0.27669268402828845\n",
      "train loss:0.12366404982936238\n",
      "train loss:0.14719512530462947\n",
      "train loss:0.1488441102187174\n",
      "train loss:0.08639598709107182\n",
      "train loss:0.14172355454188637\n",
      "train loss:0.13614691157415484\n",
      "train loss:0.1065934264131119\n",
      "train loss:0.14141967567921856\n",
      "train loss:0.14153191655438113\n",
      "train loss:0.09813070185919345\n",
      "train loss:0.19453492404586434\n",
      "train loss:0.12922315890321084\n",
      "train loss:0.07896466072403391\n",
      "train loss:0.13486957768467264\n",
      "train loss:0.16324137043932624\n",
      "train loss:0.1462975605397885\n",
      "train loss:0.13911320167093985\n",
      "train loss:0.1464245912062862\n",
      "train loss:0.13942151553959345\n",
      "train loss:0.15578742646061616\n",
      "train loss:0.12163053279155565\n",
      "train loss:0.17937740544315514\n",
      "train loss:0.09772192258783427\n",
      "train loss:0.12905888548451794\n",
      "train loss:0.12832018940470255\n",
      "train loss:0.05501587989082849\n",
      "train loss:0.08963878266234747\n",
      "train loss:0.11773679047557498\n",
      "train loss:0.09015352205433881\n",
      "train loss:0.24367712393820606\n",
      "train loss:0.0844401463908643\n",
      "train loss:0.18487556881435954\n",
      "train loss:0.06782587252598413\n",
      "train loss:0.14311895802186944\n",
      "train loss:0.1095667337031653\n",
      "train loss:0.14647255541714926\n",
      "train loss:0.08819116332213611\n",
      "train loss:0.14770134622256814\n",
      "train loss:0.15020796942603354\n",
      "train loss:0.07125318494947078\n",
      "train loss:0.1931307762226839\n",
      "train loss:0.12069727158896257\n",
      "train loss:0.18101950305338524\n",
      "train loss:0.11528559124538532\n",
      "train loss:0.14199939964637692\n",
      "train loss:0.14558435439513173\n",
      "train loss:0.15849829983893282\n",
      "train loss:0.20337234308246052\n",
      "train loss:0.0854327701211427\n",
      "train loss:0.14232773487656394\n",
      "train loss:0.15452175755142059\n",
      "train loss:0.19013213373279403\n",
      "train loss:0.1392888304221443\n",
      "train loss:0.20563169591667843\n",
      "train loss:0.09473351736072985\n",
      "train loss:0.19629489999764732\n",
      "train loss:0.1711984557156552\n",
      "train loss:0.12822900053570557\n",
      "train loss:0.14656954630962793\n",
      "train loss:0.09444908420417666\n",
      "train loss:0.12363880488830578\n",
      "train loss:0.17166215834465934\n",
      "train loss:0.0881063338621808\n",
      "train loss:0.09177129519000302\n",
      "train loss:0.10638840321977583\n",
      "train loss:0.14873660815866105\n",
      "train loss:0.12135717292914477\n",
      "train loss:0.13362979193126454\n",
      "train loss:0.15370939242614456\n",
      "train loss:0.08542447112960222\n",
      "train loss:0.16119911467012188\n",
      "train loss:0.16967390893481693\n",
      "train loss:0.12356478252752526\n",
      "train loss:0.13405690739976073\n",
      "train loss:0.15817110077355728\n",
      "train loss:0.13794794024627155\n",
      "train loss:0.09885687149050026\n",
      "train loss:0.05351602094803307\n",
      "train loss:0.12514847363056802\n",
      "train loss:0.08576659859360172\n",
      "train loss:0.10725809505533994\n",
      "train loss:0.12438839006879526\n",
      "train loss:0.09855594944287673\n",
      "train loss:0.14209223369282323\n",
      "train loss:0.25732303707241205\n",
      "train loss:0.1922579900299165\n",
      "train loss:0.12015555393503728\n",
      "train loss:0.2858778115784036\n",
      "train loss:0.10676534351983996\n",
      "train loss:0.17803333508325456\n",
      "train loss:0.17887793106599253\n",
      "train loss:0.1163247367472299\n",
      "train loss:0.12169380498376958\n",
      "train loss:0.12612304272365674\n",
      "train loss:0.15914645881285805\n",
      "train loss:0.18476800659667653\n",
      "train loss:0.12169536365571208\n",
      "train loss:0.1271478334494064\n",
      "train loss:0.1348263657660703\n",
      "train loss:0.20176273337487302\n",
      "train loss:0.062069982273885584\n",
      "train loss:0.22687483863699445\n",
      "train loss:0.07268234735514911\n",
      "train loss:0.10068880948703005\n",
      "train loss:0.26048384401194546\n",
      "train loss:0.2839167035109011\n",
      "train loss:0.11066611913753195\n",
      "train loss:0.14914555081852943\n",
      "train loss:0.12198069188844782\n",
      "train loss:0.09426644712198265\n",
      "train loss:0.0786130761345709\n",
      "train loss:0.09180605770412557\n",
      "train loss:0.16135968878596102\n",
      "train loss:0.19254738982594927\n",
      "train loss:0.207721997547528\n",
      "train loss:0.09186553235695753\n",
      "train loss:0.12905924540205696\n",
      "train loss:0.15467314707772803\n",
      "train loss:0.12972626936569895\n",
      "train loss:0.1649378444597685\n",
      "train loss:0.13853076063101127\n",
      "train loss:0.1113481156605695\n",
      "train loss:0.19918741793126835\n",
      "train loss:0.0556875966365196\n",
      "train loss:0.1239013756655667\n",
      "train loss:0.1264249940773533\n",
      "train loss:0.10394241251997839\n",
      "train loss:0.13236699920913794\n",
      "train loss:0.08494422052726797\n",
      "train loss:0.1564822627783364\n",
      "train loss:0.10504243753150551\n",
      "train loss:0.0911967518464874\n",
      "train loss:0.15264585374598522\n",
      "train loss:0.1502562385442473\n",
      "train loss:0.13405623715152445\n",
      "train loss:0.16933017427515687\n",
      "train loss:0.2048531809262568\n",
      "train loss:0.1385711013581125\n",
      "train loss:0.16429856779776666\n",
      "train loss:0.16469008903422858\n",
      "train loss:0.14559291058894597\n",
      "train loss:0.061508837861851774\n",
      "train loss:0.10768451982684081\n",
      "train loss:0.12781618134651404\n",
      "train loss:0.1314429815916296\n",
      "train loss:0.25220618216139756\n",
      "train loss:0.08622189812725231\n",
      "train loss:0.15301208394154478\n",
      "train loss:0.08414856029485335\n",
      "train loss:0.1421493414633547\n",
      "train loss:0.1161296823163974\n",
      "train loss:0.11228476406567395\n",
      "train loss:0.06587959278199755\n",
      "train loss:0.11605111238846068\n",
      "train loss:0.13234001022739278\n",
      "train loss:0.14820013713430671\n",
      "train loss:0.13417759947530877\n",
      "train loss:0.15022212445268163\n",
      "train loss:0.19460414879778895\n",
      "train loss:0.15275923349174644\n",
      "train loss:0.13644379969429335\n",
      "train loss:0.1791902016598132\n",
      "train loss:0.11306244766809811\n",
      "train loss:0.24487473833607754\n",
      "train loss:0.15492469956772978\n",
      "train loss:0.14778509471988777\n",
      "train loss:0.1544702514995181\n",
      "train loss:0.13194046648331148\n",
      "train loss:0.08611575111370846\n",
      "train loss:0.1717343673197535\n",
      "train loss:0.15349430448911044\n",
      "train loss:0.11949961085843437\n",
      "train loss:0.08560245269060802\n",
      "train loss:0.1494474157745277\n",
      "train loss:0.08327753130965088\n",
      "train loss:0.09448223058625534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.10214295121553922\n",
      "train loss:0.24123398509171445\n",
      "train loss:0.20652590510125243\n",
      "train loss:0.15941237456233617\n",
      "train loss:0.1560292858844253\n",
      "train loss:0.13110844799750918\n",
      "train loss:0.1648210762135911\n",
      "train loss:0.1090781476749659\n",
      "train loss:0.1524015402772203\n",
      "train loss:0.19896027656684243\n",
      "train loss:0.1184885478351416\n",
      "train loss:0.237936481419512\n",
      "train loss:0.11941443578391768\n",
      "train loss:0.08481046155655697\n",
      "train loss:0.03806167005789575\n",
      "train loss:0.22486084166242293\n",
      "train loss:0.22031195930137681\n",
      "train loss:0.064384332826265\n",
      "train loss:0.19734557472083175\n",
      "train loss:0.17792081492286105\n",
      "train loss:0.04231741242644991\n",
      "train loss:0.25045554235517875\n",
      "train loss:0.1944598135487762\n",
      "train loss:0.15433691339815458\n",
      "train loss:0.18560937354631046\n",
      "train loss:0.09067864222065472\n",
      "train loss:0.08069887840843007\n",
      "train loss:0.15079221915032406\n",
      "train loss:0.08841726303936033\n",
      "train loss:0.12392982872496834\n",
      "train loss:0.1507243845390013\n",
      "train loss:0.13738011937006767\n",
      "train loss:0.121349054395813\n",
      "train loss:0.10907216202255542\n",
      "train loss:0.21904202317991392\n",
      "train loss:0.05453319247334995\n",
      "train loss:0.17748135202955911\n",
      "train loss:0.12879554284483205\n",
      "train loss:0.12374886353853079\n",
      "train loss:0.11017931310762902\n",
      "train loss:0.17228998091676598\n",
      "train loss:0.19056620896136636\n",
      "train loss:0.15719999728110215\n",
      "train loss:0.08265469326915072\n",
      "train loss:0.09812544351140605\n",
      "train loss:0.134091125467448\n",
      "train loss:0.1320679600533118\n",
      "train loss:0.1276124803803382\n",
      "train loss:0.14930647920604995\n",
      "train loss:0.20623566808986593\n",
      "train loss:0.10010671881134707\n",
      "train loss:0.12488947507352087\n",
      "train loss:0.19314325885698416\n",
      "train loss:0.11567677731506594\n",
      "train loss:0.057326864922140404\n",
      "train loss:0.10603658612349431\n",
      "train loss:0.1256104777118891\n",
      "train loss:0.13856053014195313\n",
      "train loss:0.13511669272727458\n",
      "train loss:0.1343085543679541\n",
      "train loss:0.13740182850456026\n",
      "train loss:0.1867084076045389\n",
      "train loss:0.12032673662322227\n",
      "train loss:0.158341240764056\n",
      "train loss:0.09921649574987733\n",
      "train loss:0.17732443324112304\n",
      "train loss:0.17230189572290716\n",
      "train loss:0.14058688420776844\n",
      "train loss:0.14933249236218235\n",
      "train loss:0.22560526851878449\n",
      "train loss:0.1291219483773639\n",
      "train loss:0.14711723992474188\n",
      "train loss:0.19025606089411493\n",
      "train loss:0.13790717935681507\n",
      "train loss:0.1203952176574001\n",
      "train loss:0.2560787847121452\n",
      "train loss:0.14552064893756844\n",
      "train loss:0.1483917328381392\n",
      "train loss:0.08317001440083403\n",
      "train loss:0.1287216673241454\n",
      "train loss:0.20426734567295962\n",
      "train loss:0.1380200838123811\n",
      "train loss:0.05208748950323426\n",
      "train loss:0.2351932297335695\n",
      "train loss:0.09669228095189529\n",
      "train loss:0.13919287305740713\n",
      "train loss:0.16242319868987468\n",
      "train loss:0.09233598032932111\n",
      "train loss:0.20673233844635067\n",
      "train loss:0.15063070373684975\n",
      "train loss:0.1107075626239389\n",
      "train loss:0.11440652338529304\n",
      "train loss:0.12936066265336593\n",
      "train loss:0.20731878566693995\n",
      "train loss:0.14970006211231618\n",
      "train loss:0.10278382872448198\n",
      "train loss:0.17823036032903317\n",
      "train loss:0.1662025407577553\n",
      "train loss:0.14766465974193882\n",
      "train loss:0.16619131010922245\n",
      "train loss:0.14745545208929317\n",
      "train loss:0.1249979379043886\n",
      "train loss:0.19063068155655916\n",
      "train loss:0.11957540856052694\n",
      "train loss:0.08339272376740452\n",
      "train loss:0.12934838986621985\n",
      "train loss:0.11800127472542889\n",
      "train loss:0.13182188449103\n",
      "train loss:0.12460412290550936\n",
      "train loss:0.07444961901236363\n",
      "train loss:0.08506635908589867\n",
      "train loss:0.13001278478437245\n",
      "train loss:0.14207400095553901\n",
      "train loss:0.1523556038983517\n",
      "train loss:0.12477910230599967\n",
      "train loss:0.11875341559544154\n",
      "train loss:0.12174695883142907\n",
      "train loss:0.08900316081088469\n",
      "train loss:0.22884067407629746\n",
      "train loss:0.1723142521002094\n",
      "train loss:0.13347578739125363\n",
      "train loss:0.144706156621354\n",
      "train loss:0.1596647666265365\n",
      "train loss:0.04331516249303953\n",
      "train loss:0.10078721769178879\n",
      "train loss:0.1731440029680952\n",
      "train loss:0.08537853841755781\n",
      "train loss:0.15656167034970353\n",
      "train loss:0.14443588342280347\n",
      "train loss:0.11104054785149016\n",
      "train loss:0.08929030579431074\n",
      "train loss:0.21446199326039114\n",
      "train loss:0.0797262977289394\n",
      "train loss:0.07547100812809206\n",
      "train loss:0.10340989800031673\n",
      "train loss:0.11041299090193851\n",
      "train loss:0.07886676198840914\n",
      "train loss:0.0952438327395354\n",
      "train loss:0.1436594790208793\n",
      "train loss:0.12354794241891298\n",
      "train loss:0.05366507076775287\n",
      "train loss:0.21550952640970475\n",
      "train loss:0.1600073128553453\n",
      "train loss:0.13020648657918354\n",
      "train loss:0.167429996734889\n",
      "train loss:0.07409663150191066\n",
      "train loss:0.06984560659228811\n",
      "train loss:0.11004207783490078\n",
      "train loss:0.07873049506675021\n",
      "train loss:0.17669732476178676\n",
      "train loss:0.054243353436123604\n",
      "train loss:0.10569542086777249\n",
      "train loss:0.12414854486668718\n",
      "train loss:0.18096702547082047\n",
      "train loss:0.1426108372447711\n",
      "train loss:0.16259532124380185\n",
      "train loss:0.13045595625911732\n",
      "train loss:0.14174149673527597\n",
      "train loss:0.14027694348880654\n",
      "train loss:0.11257184148163052\n",
      "train loss:0.14005602942601722\n",
      "train loss:0.16000633825906507\n",
      "train loss:0.09110992725196417\n",
      "train loss:0.17639228940294555\n",
      "train loss:0.18232007698866176\n",
      "train loss:0.20770603592573497\n",
      "train loss:0.2238216963991052\n",
      "train loss:0.2504663759469782\n",
      "train loss:0.18559730893398058\n",
      "train loss:0.1243526466043202\n",
      "train loss:0.0987874418943446\n",
      "train loss:0.19734864316348116\n",
      "train loss:0.2069657310835846\n",
      "train loss:0.09636009783281414\n",
      "train loss:0.09980019899360468\n",
      "train loss:0.20697274200311613\n",
      "train loss:0.0989332209637918\n",
      "train loss:0.08374082258336578\n",
      "train loss:0.1235700412216968\n",
      "train loss:0.0894348079822932\n",
      "train loss:0.13346552938227899\n",
      "train loss:0.13185823208566771\n",
      "train loss:0.11620294494941975\n",
      "train loss:0.14308343036624527\n",
      "train loss:0.10384911065234577\n",
      "train loss:0.06611771892054702\n",
      "train loss:0.03932332007575631\n",
      "train loss:0.07889630059457364\n",
      "train loss:0.08941721769247499\n",
      "train loss:0.14638059493739025\n",
      "train loss:0.13586779329260132\n",
      "train loss:0.07944282132182688\n",
      "train loss:0.15737794634156185\n",
      "train loss:0.085471426028749\n",
      "train loss:0.1381233223064964\n",
      "train loss:0.09138404293353115\n",
      "train loss:0.10702748309582426\n",
      "train loss:0.1329482247357425\n",
      "train loss:0.127651912738844\n",
      "train loss:0.18218043799230252\n",
      "train loss:0.21150125083094712\n",
      "train loss:0.09357476181725553\n",
      "train loss:0.16597446381613487\n",
      "train loss:0.1375120661488252\n",
      "train loss:0.1565410200760149\n",
      "train loss:0.10418534949593053\n",
      "train loss:0.07523696728450557\n",
      "train loss:0.11342924278270079\n",
      "train loss:0.08689880705429825\n",
      "train loss:0.1847567721413675\n",
      "train loss:0.07964210587455033\n",
      "train loss:0.07522519264081835\n",
      "train loss:0.08541803153145139\n",
      "train loss:0.1443124041787433\n",
      "train loss:0.21066367073587108\n",
      "train loss:0.08080172652255455\n",
      "train loss:0.26910638774008794\n",
      "train loss:0.14608806275386127\n",
      "train loss:0.0741483351727005\n",
      "train loss:0.05839300875524744\n",
      "train loss:0.07488515967409164\n",
      "train loss:0.16803028830219316\n",
      "train loss:0.09299766506057332\n",
      "train loss:0.13777617393421382\n",
      "train loss:0.1441930129242652\n",
      "train loss:0.09430691489774012\n",
      "train loss:0.08956746751301545\n",
      "train loss:0.18161229454135136\n",
      "train loss:0.26492995540069075\n",
      "train loss:0.11114077208300556\n",
      "train loss:0.0700791630383668\n",
      "train loss:0.21755204482621351\n",
      "train loss:0.21342224679137686\n",
      "train loss:0.06838574656419691\n",
      "train loss:0.08464741998991877\n",
      "train loss:0.16937255748525584\n",
      "train loss:0.14193705733126066\n",
      "train loss:0.15129683385372622\n",
      "train loss:0.07946138551259904\n",
      "train loss:0.07492709647813048\n",
      "train loss:0.1902325458555032\n",
      "train loss:0.08582433753903079\n",
      "train loss:0.15439736041313354\n",
      "train loss:0.22494523947982864\n",
      "=== epoch:13, train acc:0.941, test acc:0.913 ===\n",
      "train loss:0.17293122323214546\n",
      "train loss:0.2346320672815241\n",
      "train loss:0.12395621182965905\n",
      "train loss:0.16820339384740662\n",
      "train loss:0.08442662027845622\n",
      "train loss:0.0974204104722137\n",
      "train loss:0.13711287982654996\n",
      "train loss:0.07605798882019954\n",
      "train loss:0.13037532638741564\n",
      "train loss:0.08305637201835026\n",
      "train loss:0.18018404696953536\n",
      "train loss:0.17763475223584127\n",
      "train loss:0.14555851525784866\n",
      "train loss:0.10702008367070277\n",
      "train loss:0.048413902814793575\n",
      "train loss:0.18273835622200896\n",
      "train loss:0.1440108411418748\n",
      "train loss:0.16364531319270503\n",
      "train loss:0.1416358518638946\n",
      "train loss:0.20258260523025\n",
      "train loss:0.23233284926143122\n",
      "train loss:0.15595507849369353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.17171708964537089\n",
      "train loss:0.14222743008102956\n",
      "train loss:0.12023684801722503\n",
      "train loss:0.1672970413879117\n",
      "train loss:0.17173138961686024\n",
      "train loss:0.1744927167794355\n",
      "train loss:0.2121819485394345\n",
      "train loss:0.18114637344235013\n",
      "train loss:0.11997779759685594\n",
      "train loss:0.15608993681957223\n",
      "train loss:0.14743035375351354\n",
      "train loss:0.04711778662578691\n",
      "train loss:0.10792968293439137\n",
      "train loss:0.10956649068079301\n",
      "train loss:0.1651125173875082\n",
      "train loss:0.1341908107446118\n",
      "train loss:0.18800433137870448\n",
      "train loss:0.08969124697048078\n",
      "train loss:0.15562729794348903\n",
      "train loss:0.15401209746508637\n",
      "train loss:0.11679143594950413\n",
      "train loss:0.13082011910202151\n",
      "train loss:0.11210435730545608\n",
      "train loss:0.10753973069037867\n",
      "train loss:0.1072545810598438\n",
      "train loss:0.14911894804331888\n",
      "train loss:0.12935814863362496\n",
      "train loss:0.1500938876471192\n",
      "train loss:0.07269967357613188\n",
      "train loss:0.1119063427051294\n",
      "train loss:0.09078567104524858\n",
      "train loss:0.15133091198046386\n",
      "train loss:0.06734314004403626\n",
      "train loss:0.12107696552794181\n",
      "train loss:0.22673436952010487\n",
      "train loss:0.19095358940795104\n",
      "train loss:0.19251260168449474\n",
      "train loss:0.0684649056848081\n",
      "train loss:0.14163602487237334\n",
      "train loss:0.11374684625512405\n",
      "train loss:0.12116888173650024\n",
      "train loss:0.18439235055022565\n",
      "train loss:0.157835130296803\n",
      "train loss:0.18208824481823907\n",
      "train loss:0.13643507060225094\n",
      "train loss:0.1355594548862307\n",
      "train loss:0.14270949864862512\n",
      "train loss:0.07620565498474627\n",
      "train loss:0.10290811917212815\n",
      "train loss:0.19283249874746172\n",
      "train loss:0.06359338431184919\n",
      "train loss:0.14049311481793217\n",
      "train loss:0.1861011943776733\n",
      "train loss:0.1418578404842078\n",
      "train loss:0.13637452259913155\n",
      "train loss:0.11115108435902261\n",
      "train loss:0.0920677020389121\n",
      "train loss:0.14832086222233448\n",
      "train loss:0.10933799684829232\n",
      "train loss:0.09273172415663102\n",
      "train loss:0.12025110779017643\n",
      "train loss:0.06106160673600921\n",
      "train loss:0.15588842209692083\n",
      "train loss:0.1348671436799935\n",
      "train loss:0.16490248972352503\n",
      "train loss:0.11228232963019026\n",
      "train loss:0.11433558763927244\n",
      "train loss:0.10944429498216227\n",
      "train loss:0.07871620343805645\n",
      "train loss:0.20485947503783358\n",
      "train loss:0.08535753753721076\n",
      "train loss:0.06862017107616948\n",
      "train loss:0.12369225875794722\n",
      "train loss:0.17299300759911457\n",
      "train loss:0.1740683468779236\n",
      "train loss:0.09773280731985544\n",
      "train loss:0.12618826690126558\n",
      "train loss:0.18292702819779305\n",
      "train loss:0.16326933247692563\n",
      "train loss:0.07533050221976087\n",
      "train loss:0.10302171133092695\n",
      "train loss:0.17539764148518533\n",
      "train loss:0.10248164611455496\n",
      "train loss:0.12918009231868707\n",
      "train loss:0.17022902086098182\n",
      "train loss:0.1362749359041798\n",
      "train loss:0.13669243307980733\n",
      "train loss:0.11322685687191462\n",
      "train loss:0.14641011866283463\n",
      "train loss:0.2589844384887291\n",
      "train loss:0.15043169306908022\n",
      "train loss:0.13426265494532927\n",
      "train loss:0.14495121494110033\n",
      "train loss:0.13702351700350485\n",
      "train loss:0.13906189103627553\n",
      "train loss:0.18496861971299805\n",
      "train loss:0.1620425237314917\n",
      "train loss:0.15188900754005372\n",
      "train loss:0.180258161017095\n",
      "train loss:0.12115964734728289\n",
      "train loss:0.1384552629700469\n",
      "train loss:0.1603259328691271\n",
      "train loss:0.10312477945241394\n",
      "train loss:0.12018693520844949\n",
      "train loss:0.17090271850932662\n",
      "train loss:0.13238468166498824\n",
      "train loss:0.12869752666905673\n",
      "train loss:0.13310621544435464\n",
      "train loss:0.13081194968460275\n",
      "train loss:0.08452617410473363\n",
      "train loss:0.17383062807426292\n",
      "train loss:0.17153452493803983\n",
      "train loss:0.10266666185003133\n",
      "train loss:0.21934857109342104\n",
      "train loss:0.11794292360693179\n",
      "train loss:0.06318682237245224\n",
      "train loss:0.14634030023270309\n",
      "train loss:0.11792004214206693\n",
      "train loss:0.12043747145763094\n",
      "train loss:0.11845304938133604\n",
      "train loss:0.13027571155957765\n",
      "train loss:0.14781076723345565\n",
      "train loss:0.07694157468469001\n",
      "train loss:0.049784884450761534\n",
      "train loss:0.16758935174991002\n",
      "train loss:0.12270994998877317\n",
      "train loss:0.19785309952983346\n",
      "train loss:0.10320124465423702\n",
      "train loss:0.07301850394279358\n",
      "train loss:0.1680449070852692\n",
      "train loss:0.10838157632082324\n",
      "train loss:0.16473429095917375\n",
      "train loss:0.08718327029783897\n",
      "train loss:0.25414658653557465\n",
      "train loss:0.13807946046969333\n",
      "train loss:0.1656267558105329\n",
      "train loss:0.12109703291493489\n",
      "train loss:0.15834030072105656\n",
      "train loss:0.16502775355752233\n",
      "train loss:0.1347099986608087\n",
      "train loss:0.12716643267784167\n",
      "train loss:0.0702135677673578\n",
      "train loss:0.08729694093096059\n",
      "train loss:0.1129665854648326\n",
      "train loss:0.11240884523757949\n",
      "train loss:0.20088569626936983\n",
      "train loss:0.1100300579423834\n",
      "train loss:0.11455504970747966\n",
      "train loss:0.13643184991134488\n",
      "train loss:0.0847810899577492\n",
      "train loss:0.1162780221685276\n",
      "train loss:0.12166986931007502\n",
      "train loss:0.13113661626166098\n",
      "train loss:0.21141374359670678\n",
      "train loss:0.1346762036058207\n",
      "train loss:0.1459679948361046\n",
      "train loss:0.11980775757282508\n",
      "train loss:0.09903734123211042\n",
      "train loss:0.08103751501629752\n",
      "train loss:0.2642411304918879\n",
      "train loss:0.09787498795832446\n",
      "train loss:0.08355171923908612\n",
      "train loss:0.10553340915958774\n",
      "train loss:0.06606488824883641\n",
      "train loss:0.14783500065751845\n",
      "train loss:0.1347530828136326\n",
      "train loss:0.19921486792983825\n",
      "train loss:0.10349493114854035\n",
      "train loss:0.15120988970377167\n",
      "train loss:0.1440376108134829\n",
      "train loss:0.09848418392681221\n",
      "train loss:0.10682229617411605\n",
      "train loss:0.2382005165187593\n",
      "train loss:0.16463942554119865\n",
      "train loss:0.07465281275578452\n",
      "train loss:0.10762041733733635\n",
      "train loss:0.11655363470861475\n",
      "train loss:0.14026082002948578\n",
      "train loss:0.08201499112374887\n",
      "train loss:0.17819777642011925\n",
      "train loss:0.11680963047992114\n",
      "train loss:0.06763751287057133\n",
      "train loss:0.10887830665181986\n",
      "train loss:0.10621100664897959\n",
      "train loss:0.14870912787111545\n",
      "train loss:0.16555577828815807\n",
      "train loss:0.10198814099053498\n",
      "train loss:0.10764048296383857\n",
      "train loss:0.15778051615902472\n",
      "train loss:0.11663020376420995\n",
      "train loss:0.12027213420797381\n",
      "train loss:0.12817209691916007\n",
      "train loss:0.16168243964657772\n",
      "train loss:0.17226021328554367\n",
      "train loss:0.08927607178065643\n",
      "train loss:0.16044278161486625\n",
      "train loss:0.08114652750617168\n",
      "train loss:0.09515532230135795\n",
      "train loss:0.145471013360868\n",
      "train loss:0.1254286655557474\n",
      "train loss:0.07900904862182484\n",
      "train loss:0.10946764161215265\n",
      "train loss:0.15071534758771815\n",
      "train loss:0.062244339433011636\n",
      "train loss:0.173643065524236\n",
      "train loss:0.0768774989905533\n",
      "train loss:0.12419203397358596\n",
      "train loss:0.07492726944520021\n",
      "train loss:0.07539876092093492\n",
      "train loss:0.07132738432871726\n",
      "train loss:0.07826448785237096\n",
      "train loss:0.06261307735814094\n",
      "train loss:0.047602322181786026\n",
      "train loss:0.13917778459427096\n",
      "train loss:0.09460463045609577\n",
      "train loss:0.12266075099998053\n",
      "train loss:0.20191892992003668\n",
      "train loss:0.2165024102543206\n",
      "train loss:0.13164028168822503\n",
      "train loss:0.1566495744306306\n",
      "train loss:0.1268991421618221\n",
      "train loss:0.22315498238200784\n",
      "train loss:0.2138958913388018\n",
      "train loss:0.16861768826040624\n",
      "train loss:0.15558268449742385\n",
      "train loss:0.16255082657603925\n",
      "train loss:0.16708077283960027\n",
      "train loss:0.2002534855031068\n",
      "train loss:0.07589782278950091\n",
      "train loss:0.11161090172455836\n",
      "train loss:0.08188355928676476\n",
      "train loss:0.11570712850675641\n",
      "train loss:0.10811980830246198\n",
      "train loss:0.18677280219735345\n",
      "train loss:0.10708991805903807\n",
      "train loss:0.16304643047378725\n",
      "train loss:0.18855553876972553\n",
      "train loss:0.16658450229895158\n",
      "train loss:0.1063470585611639\n",
      "train loss:0.16676179103384645\n",
      "train loss:0.06436855795878929\n",
      "train loss:0.10465284510199091\n",
      "train loss:0.11070263183119447\n",
      "train loss:0.17908092872096718\n",
      "train loss:0.16206521448605826\n",
      "train loss:0.04453778435352725\n",
      "train loss:0.14941274657280823\n",
      "train loss:0.18007161135340316\n",
      "train loss:0.14825067071202663\n",
      "train loss:0.12779270529291648\n",
      "train loss:0.3202011501874328\n",
      "train loss:0.10799707648891575\n",
      "train loss:0.1640304459710233\n",
      "train loss:0.18023073663716885\n",
      "train loss:0.14619455797741399\n",
      "train loss:0.18848479263841914\n",
      "train loss:0.13857985768991096\n",
      "train loss:0.1461894379407726\n",
      "train loss:0.12137098916252778\n",
      "train loss:0.0955495391598369\n",
      "train loss:0.16030599484919975\n",
      "train loss:0.07689986837089732\n",
      "train loss:0.12942910130140484\n",
      "train loss:0.13810040798787895\n",
      "train loss:0.17520896698677074\n",
      "train loss:0.0829175029574674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.07234564079749259\n",
      "train loss:0.07965702611836403\n",
      "train loss:0.21185327350230096\n",
      "train loss:0.13433988325318397\n",
      "train loss:0.08548576593345164\n",
      "train loss:0.07514345116896068\n",
      "train loss:0.10600372257982438\n",
      "train loss:0.1405275356666578\n",
      "train loss:0.12890964907004018\n",
      "train loss:0.09176527947747502\n",
      "train loss:0.16858292245443476\n",
      "train loss:0.1207159168768753\n",
      "train loss:0.08846218004905675\n",
      "train loss:0.05416013389350085\n",
      "train loss:0.09652354373237293\n",
      "train loss:0.14211478264217714\n",
      "train loss:0.14719816760743415\n",
      "train loss:0.05861711972637187\n",
      "train loss:0.0930773481463156\n",
      "train loss:0.06848008667109753\n",
      "train loss:0.08807570119356735\n",
      "train loss:0.10797422547940284\n",
      "train loss:0.17300166754061624\n",
      "train loss:0.13445547507482952\n",
      "train loss:0.19355636959663103\n",
      "train loss:0.17491913324086145\n",
      "train loss:0.10945761504720214\n",
      "train loss:0.11922169828904947\n",
      "train loss:0.12172033132099346\n",
      "train loss:0.19781131889881676\n",
      "train loss:0.143078332875307\n",
      "train loss:0.10327021802038275\n",
      "train loss:0.16508887827677834\n",
      "train loss:0.17823035701524542\n",
      "train loss:0.1816949144040297\n",
      "train loss:0.08091628146780092\n",
      "train loss:0.07013860762483488\n",
      "train loss:0.06042840122990982\n",
      "train loss:0.16140795426622614\n",
      "train loss:0.13931349387255032\n",
      "train loss:0.05628539990749751\n",
      "train loss:0.07588634471537255\n",
      "train loss:0.09671247766124731\n",
      "train loss:0.23312033069962296\n",
      "train loss:0.14092105558311016\n",
      "train loss:0.06203214820182973\n",
      "train loss:0.08581364045982612\n",
      "train loss:0.11882189366569273\n",
      "train loss:0.06454987778746403\n",
      "train loss:0.08704649968673259\n",
      "train loss:0.2649201036989884\n",
      "train loss:0.10235023062860782\n",
      "train loss:0.1051079048434394\n",
      "train loss:0.15353953019600777\n",
      "train loss:0.07330472458075285\n",
      "train loss:0.07351961217486983\n",
      "train loss:0.16960916684948835\n",
      "train loss:0.08524520544040222\n",
      "train loss:0.08793385874472008\n",
      "train loss:0.16265570521820297\n",
      "train loss:0.12674176331690787\n",
      "train loss:0.1651001717585314\n",
      "train loss:0.16177790867050096\n",
      "train loss:0.1638639536054526\n",
      "train loss:0.12207833759297088\n",
      "train loss:0.0587949293200791\n",
      "train loss:0.14407624549971293\n",
      "train loss:0.08200296272923831\n",
      "train loss:0.13481960980487806\n",
      "train loss:0.12600247829129468\n",
      "train loss:0.05111303777706911\n",
      "train loss:0.1820025335600392\n",
      "train loss:0.06807063949215361\n",
      "train loss:0.1035108979495674\n",
      "train loss:0.08459415651861114\n",
      "train loss:0.12884518831243358\n",
      "train loss:0.1952485220347427\n",
      "train loss:0.07425929471146452\n",
      "train loss:0.09571520571196328\n",
      "train loss:0.11577357239229528\n",
      "train loss:0.11636488610169092\n",
      "train loss:0.0621040758386868\n",
      "train loss:0.08553906960480888\n",
      "train loss:0.1007995346780523\n",
      "train loss:0.07115908335404555\n",
      "train loss:0.2096168849462357\n",
      "train loss:0.06288311219841923\n",
      "train loss:0.1257120929575944\n",
      "train loss:0.10788539241109367\n",
      "train loss:0.11353918532006636\n",
      "train loss:0.11546228651834305\n",
      "train loss:0.1290736844211165\n",
      "train loss:0.09228234611480991\n",
      "train loss:0.1579689224816058\n",
      "train loss:0.11341442597633698\n",
      "train loss:0.07033396812499702\n",
      "train loss:0.10620066634810399\n",
      "train loss:0.16566803924578025\n",
      "train loss:0.15244693467505155\n",
      "train loss:0.07820692168192502\n",
      "train loss:0.1353627404762648\n",
      "train loss:0.09718592009554355\n",
      "train loss:0.06792159329116092\n",
      "train loss:0.08107121598434525\n",
      "train loss:0.1436526271109352\n",
      "train loss:0.12244057414899386\n",
      "train loss:0.14840981914116924\n",
      "train loss:0.09804946410988427\n",
      "train loss:0.12206791299753515\n",
      "train loss:0.14811736569821077\n",
      "train loss:0.12225869746373709\n",
      "train loss:0.07993512461152802\n",
      "train loss:0.1466838940244745\n",
      "train loss:0.13103819844944162\n",
      "train loss:0.08867704246178876\n",
      "train loss:0.14989489823088223\n",
      "train loss:0.09592652760375385\n",
      "train loss:0.05189569069602206\n",
      "train loss:0.19216860022190654\n",
      "train loss:0.15880660006026093\n",
      "train loss:0.16929770757641088\n",
      "train loss:0.0827286170034695\n",
      "train loss:0.15458122305397573\n",
      "train loss:0.12334938729218743\n",
      "train loss:0.05125803279651998\n",
      "train loss:0.11447602019965343\n",
      "train loss:0.16048496795679185\n",
      "train loss:0.08424736896990292\n",
      "train loss:0.12727846115463026\n",
      "train loss:0.1360420339461061\n",
      "train loss:0.1409569461572042\n",
      "train loss:0.09912782707015834\n",
      "train loss:0.11024951385254543\n",
      "train loss:0.17083736456532708\n",
      "train loss:0.06576279179323749\n",
      "train loss:0.09149169039206473\n",
      "train loss:0.05984388838646477\n",
      "train loss:0.12320712027854216\n",
      "train loss:0.15659658961017855\n",
      "train loss:0.043459734625547544\n",
      "train loss:0.0780863184840596\n",
      "train loss:0.11236398198101771\n",
      "train loss:0.10560450408790324\n",
      "train loss:0.1304618132512373\n",
      "train loss:0.12951547281914685\n",
      "train loss:0.09423191585151208\n",
      "train loss:0.09285953875440374\n",
      "train loss:0.0763037715418226\n",
      "train loss:0.051482136925472925\n",
      "train loss:0.10748774756432244\n",
      "train loss:0.13511415823051592\n",
      "train loss:0.2632374183561965\n",
      "train loss:0.14305051448818176\n",
      "train loss:0.1316143307638348\n",
      "train loss:0.11872930820081708\n",
      "train loss:0.2097622633849549\n",
      "train loss:0.10345615990208178\n",
      "train loss:0.04520007291466942\n",
      "train loss:0.09868343705060979\n",
      "train loss:0.07810409839794334\n",
      "train loss:0.14367565786615905\n",
      "train loss:0.10797964650279117\n",
      "train loss:0.09614883691666216\n",
      "train loss:0.13835047869235276\n",
      "train loss:0.0925449541874698\n",
      "train loss:0.10225118459359873\n",
      "train loss:0.16455498256199036\n",
      "train loss:0.09331960892844755\n",
      "train loss:0.09991016027490295\n",
      "train loss:0.12148901486080733\n",
      "train loss:0.058502366203599596\n",
      "train loss:0.0725972247126353\n",
      "train loss:0.1183116748364354\n",
      "train loss:0.09474396770092264\n",
      "train loss:0.06606519777538175\n",
      "train loss:0.08361008545103706\n",
      "train loss:0.07986431808552845\n",
      "train loss:0.09777772842300816\n",
      "train loss:0.07730750956126797\n",
      "train loss:0.0859915080069404\n",
      "train loss:0.0789235976801842\n",
      "train loss:0.060450695327646\n",
      "train loss:0.11562140248999912\n",
      "train loss:0.05720613793172749\n",
      "train loss:0.1453955958863132\n",
      "train loss:0.07257683011569777\n",
      "train loss:0.18380414137381154\n",
      "train loss:0.11774910423799727\n",
      "train loss:0.17554185237533065\n",
      "train loss:0.1494684075979038\n",
      "train loss:0.1512867387851818\n",
      "train loss:0.08618935717787668\n",
      "train loss:0.13133469146614238\n",
      "train loss:0.0649958804981169\n",
      "train loss:0.17374463395990727\n",
      "train loss:0.13669320550526146\n",
      "train loss:0.1494176462268309\n",
      "train loss:0.20595069534984542\n",
      "train loss:0.08566135628480881\n",
      "train loss:0.14556574769350936\n",
      "train loss:0.10237811853865832\n",
      "train loss:0.2470752618133498\n",
      "train loss:0.08329718846834959\n",
      "train loss:0.15420839200065917\n",
      "train loss:0.15812409630454988\n",
      "train loss:0.09259933136446113\n",
      "train loss:0.0956676761177986\n",
      "train loss:0.1588792729619918\n",
      "train loss:0.18928905362232687\n",
      "train loss:0.07011436734516413\n",
      "train loss:0.14234965577501438\n",
      "train loss:0.15819357640142861\n",
      "train loss:0.11035575014462752\n",
      "train loss:0.17981300532166017\n",
      "train loss:0.09653569943585842\n",
      "train loss:0.11800491030418941\n",
      "train loss:0.0927501285866625\n",
      "train loss:0.14781793961815473\n",
      "train loss:0.16886662955919396\n",
      "train loss:0.1485010790147243\n",
      "train loss:0.1730767735952057\n",
      "train loss:0.2244525237354777\n",
      "train loss:0.16740383436853132\n",
      "train loss:0.08609930022345585\n",
      "train loss:0.13534479682869813\n",
      "train loss:0.08179138260147373\n",
      "train loss:0.1234520907279941\n",
      "train loss:0.18811016295603497\n",
      "train loss:0.14658500635132335\n",
      "train loss:0.12888325135512596\n",
      "train loss:0.15970548775875654\n",
      "train loss:0.12546982931680517\n",
      "train loss:0.18178686467231914\n",
      "train loss:0.10735488922164688\n",
      "train loss:0.19923810955388593\n",
      "train loss:0.0966107389949821\n",
      "train loss:0.125697749104773\n",
      "train loss:0.17927868704556868\n",
      "train loss:0.10958018408992956\n",
      "train loss:0.1874111733356959\n",
      "train loss:0.13115151125675054\n",
      "train loss:0.04874926833090025\n",
      "train loss:0.05943966945936797\n",
      "train loss:0.2411101536437443\n",
      "train loss:0.0978655170850475\n",
      "train loss:0.11362713170523779\n",
      "train loss:0.13347155260981095\n",
      "train loss:0.09864309957702531\n",
      "train loss:0.1324897765118091\n",
      "train loss:0.12298392868271382\n",
      "train loss:0.05289851168176214\n",
      "train loss:0.1102533788432438\n",
      "train loss:0.0876429369236737\n",
      "train loss:0.08696227429674122\n",
      "train loss:0.1263191654820157\n",
      "train loss:0.11088867900000762\n",
      "train loss:0.16333382740014332\n",
      "train loss:0.15151676809457043\n",
      "train loss:0.07314384857851239\n",
      "train loss:0.14178827318763254\n",
      "train loss:0.1598513182355237\n",
      "train loss:0.07736271451359823\n",
      "train loss:0.13408192028695445\n",
      "train loss:0.11577464674094216\n",
      "train loss:0.08908429577635518\n",
      "train loss:0.11931293254938287\n",
      "train loss:0.14156312955644393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.11553435000459875\n",
      "train loss:0.08658460849286165\n",
      "train loss:0.08453409814171088\n",
      "train loss:0.1645886030819167\n",
      "train loss:0.11018963967180934\n",
      "train loss:0.08758057483891787\n",
      "train loss:0.18524441879878087\n",
      "train loss:0.10614707466470964\n",
      "train loss:0.18947577623894366\n",
      "train loss:0.15047279415927586\n",
      "train loss:0.09756748288158827\n",
      "train loss:0.06864720093680138\n",
      "train loss:0.12150681551116758\n",
      "train loss:0.09634673826022172\n",
      "train loss:0.08405080209492556\n",
      "train loss:0.08900683144395236\n",
      "train loss:0.15597287900463314\n",
      "train loss:0.08736820215400064\n",
      "train loss:0.1501925080029218\n",
      "train loss:0.07167331218569775\n",
      "train loss:0.19353940101256412\n",
      "train loss:0.08340550929820865\n",
      "train loss:0.12014092350263116\n",
      "train loss:0.11464340089793192\n",
      "train loss:0.04390137138239053\n",
      "train loss:0.063054583092524\n",
      "train loss:0.06326371491614383\n",
      "train loss:0.09265385334078252\n",
      "train loss:0.04298223706589882\n",
      "train loss:0.23311162053900358\n",
      "train loss:0.1112853357589323\n",
      "train loss:0.11505269703129387\n",
      "train loss:0.1266788864298231\n",
      "train loss:0.13816292022499468\n",
      "train loss:0.06975722095582743\n",
      "train loss:0.08917609849623737\n",
      "train loss:0.0786269289108429\n",
      "train loss:0.08580098545593781\n",
      "train loss:0.12214768156708429\n",
      "train loss:0.11253560666793094\n",
      "train loss:0.1215511181078374\n",
      "train loss:0.17304233818316045\n",
      "train loss:0.12878451400098004\n",
      "train loss:0.1625746975786103\n",
      "train loss:0.10751053584986328\n",
      "=== epoch:14, train acc:0.963, test acc:0.91 ===\n",
      "train loss:0.0782974186957028\n",
      "train loss:0.05995568885297332\n",
      "train loss:0.12387469893749811\n",
      "train loss:0.08687522298619361\n",
      "train loss:0.07729043674604279\n",
      "train loss:0.11615542198468347\n",
      "train loss:0.10663490596184974\n",
      "train loss:0.24148822112752058\n",
      "train loss:0.1163932160433591\n",
      "train loss:0.08999621694529698\n",
      "train loss:0.15872405183508634\n",
      "train loss:0.24385837341434732\n",
      "train loss:0.09925102492873945\n",
      "train loss:0.07865123706781948\n",
      "train loss:0.0968618123980793\n",
      "train loss:0.11690564631833535\n",
      "train loss:0.05781861183421811\n",
      "train loss:0.20856095405678143\n",
      "train loss:0.07605938431591626\n",
      "train loss:0.13587001902157497\n",
      "train loss:0.07098540687892871\n",
      "train loss:0.07185836348770701\n",
      "train loss:0.1362156448344487\n",
      "train loss:0.10342317115287994\n",
      "train loss:0.14243488690856704\n",
      "train loss:0.08269752072784367\n",
      "train loss:0.12933353490258523\n",
      "train loss:0.08378418140537874\n",
      "train loss:0.20540878753645997\n",
      "train loss:0.04907955513212912\n",
      "train loss:0.13507712328588858\n",
      "train loss:0.09121249870541652\n",
      "train loss:0.03409997107371729\n",
      "train loss:0.09623630093812147\n",
      "train loss:0.14363989473209837\n",
      "train loss:0.11825112763940492\n",
      "train loss:0.14204076235292182\n",
      "train loss:0.058904992746781445\n",
      "train loss:0.07060619663524578\n",
      "train loss:0.04002543437270455\n",
      "train loss:0.07132849268013589\n",
      "train loss:0.1232859004946472\n",
      "train loss:0.06496917672679406\n",
      "train loss:0.11979597299575188\n",
      "train loss:0.13320838023133097\n",
      "train loss:0.06151667959480176\n",
      "train loss:0.07054830277474128\n",
      "train loss:0.25988334310050354\n",
      "train loss:0.06865443236130743\n",
      "train loss:0.1213828812162007\n",
      "train loss:0.08687841292488527\n",
      "train loss:0.11446738094633195\n",
      "train loss:0.09175296421644832\n",
      "train loss:0.14311876425387768\n",
      "train loss:0.20116396025144165\n",
      "train loss:0.12988881056905824\n",
      "train loss:0.05182487581098091\n",
      "train loss:0.14330489379020528\n",
      "train loss:0.17150223500574524\n",
      "train loss:0.13575005714800847\n",
      "train loss:0.14184515666069022\n",
      "train loss:0.13312850078865524\n",
      "train loss:0.12141391548498699\n",
      "train loss:0.06832871249637118\n",
      "train loss:0.12944993762469031\n",
      "train loss:0.07724940994209685\n",
      "train loss:0.12293195298586705\n",
      "train loss:0.0873736143361433\n",
      "train loss:0.12093118416282167\n",
      "train loss:0.12428599110097098\n",
      "train loss:0.1132578796583036\n",
      "train loss:0.12597291795423535\n",
      "train loss:0.06016858756538479\n",
      "train loss:0.18252950206184143\n",
      "train loss:0.08503117573150172\n",
      "train loss:0.11124665835140651\n",
      "train loss:0.0995986682049034\n",
      "train loss:0.15985162024440588\n",
      "train loss:0.11685227149365225\n",
      "train loss:0.20813310775226715\n",
      "train loss:0.14865815893584508\n",
      "train loss:0.1252322439795034\n",
      "train loss:0.11338690280114287\n",
      "train loss:0.18696527773737734\n",
      "train loss:0.04817987118295564\n",
      "train loss:0.16731344768160844\n",
      "train loss:0.10845172694547706\n",
      "train loss:0.13960813634226615\n",
      "train loss:0.12109190476411757\n",
      "train loss:0.06566780985850533\n",
      "train loss:0.06267221441012145\n",
      "train loss:0.14237143680849168\n",
      "train loss:0.09075003393909489\n",
      "train loss:0.13854889150108465\n",
      "train loss:0.1491438121976813\n",
      "train loss:0.11650363090810269\n",
      "train loss:0.11031263950231171\n",
      "train loss:0.11979179414930552\n",
      "train loss:0.06671878251303603\n",
      "train loss:0.06873837754702666\n",
      "train loss:0.06983887248456798\n",
      "train loss:0.13724186497683732\n",
      "train loss:0.08426755397307505\n",
      "train loss:0.05762913126131956\n",
      "train loss:0.1259462135906584\n",
      "train loss:0.13025281972299899\n",
      "train loss:0.06607953716317758\n",
      "train loss:0.046940936079784994\n",
      "train loss:0.10381050676216425\n",
      "train loss:0.09270292329514555\n",
      "train loss:0.13183302043406778\n",
      "train loss:0.0725804195275002\n",
      "train loss:0.11730847973514251\n",
      "train loss:0.1273034374918996\n",
      "train loss:0.14776163273949622\n",
      "train loss:0.16946406399148223\n",
      "train loss:0.07464593762663459\n",
      "train loss:0.0809128879067996\n",
      "train loss:0.1404736453150015\n",
      "train loss:0.15456096724174176\n",
      "train loss:0.14001525504043819\n",
      "train loss:0.12690996427880344\n",
      "train loss:0.14366980127427945\n",
      "train loss:0.13750334419118496\n",
      "train loss:0.10891548971234273\n",
      "train loss:0.05012428822938422\n",
      "train loss:0.17630538990782763\n",
      "train loss:0.13536998601946323\n",
      "train loss:0.04126718308092703\n",
      "train loss:0.08918320777093475\n",
      "train loss:0.10308353921295817\n",
      "train loss:0.14440989919665786\n",
      "train loss:0.08954182457606448\n",
      "train loss:0.06627793633682427\n",
      "train loss:0.05108546941009404\n",
      "train loss:0.18413857325873179\n",
      "train loss:0.11331587703980364\n",
      "train loss:0.2032559109256591\n",
      "train loss:0.058575864348643016\n",
      "train loss:0.16324665612576578\n",
      "train loss:0.12027892087920267\n",
      "train loss:0.17039133935822773\n",
      "train loss:0.08001556061216888\n",
      "train loss:0.09698416959801015\n",
      "train loss:0.07321824272620321\n",
      "train loss:0.14787912475000475\n",
      "train loss:0.1153180014174877\n",
      "train loss:0.10965960285377353\n",
      "train loss:0.1438449875855051\n",
      "train loss:0.1239810533100742\n",
      "train loss:0.20950961718438219\n",
      "train loss:0.082358188052533\n",
      "train loss:0.07287367352187174\n",
      "train loss:0.1517829832804722\n",
      "train loss:0.05603802019675963\n",
      "train loss:0.07569586009601448\n",
      "train loss:0.09211833642501033\n",
      "train loss:0.07544259900489708\n",
      "train loss:0.1180545542577123\n",
      "train loss:0.08070091673034932\n",
      "train loss:0.09272279042344964\n",
      "train loss:0.12338652922927437\n",
      "train loss:0.16061618409194417\n",
      "train loss:0.057063067707963266\n",
      "train loss:0.19043190306068639\n",
      "train loss:0.09686846210691101\n",
      "train loss:0.05164288456736377\n",
      "train loss:0.10862433952464727\n",
      "train loss:0.07296433876149981\n",
      "train loss:0.1827292604153137\n",
      "train loss:0.22592269918903563\n",
      "train loss:0.10693531288609441\n",
      "train loss:0.0759148427480699\n",
      "train loss:0.09750532282889993\n",
      "train loss:0.15783208535149332\n",
      "train loss:0.09468656883757492\n",
      "train loss:0.11962523332995509\n",
      "train loss:0.10446307383444633\n",
      "train loss:0.11825495446007542\n",
      "train loss:0.060759380690220216\n",
      "train loss:0.13564302878703857\n",
      "train loss:0.06423633066145219\n",
      "train loss:0.19665258960941684\n",
      "train loss:0.14792891035964612\n",
      "train loss:0.06459548034101979\n",
      "train loss:0.06606164842685873\n",
      "train loss:0.143777463214361\n",
      "train loss:0.13011934053577037\n",
      "train loss:0.11401728412056965\n",
      "train loss:0.08940285668266533\n",
      "train loss:0.1658936019590472\n",
      "train loss:0.12545665600804715\n",
      "train loss:0.09647306416195502\n",
      "train loss:0.13990454414931236\n",
      "train loss:0.10180506278378344\n",
      "train loss:0.146075450102487\n",
      "train loss:0.052073756397992416\n",
      "train loss:0.17769432779016914\n",
      "train loss:0.09910840711328485\n",
      "train loss:0.09715455700199321\n",
      "train loss:0.0888952337897388\n",
      "train loss:0.17477412657312535\n",
      "train loss:0.1251018933168566\n",
      "train loss:0.09919003143314514\n",
      "train loss:0.09143783933214589\n",
      "train loss:0.12565344101770198\n",
      "train loss:0.0969783283990021\n",
      "train loss:0.10305150972367301\n",
      "train loss:0.09708209702211114\n",
      "train loss:0.14600188203619782\n",
      "train loss:0.19389664297515685\n",
      "train loss:0.17451871498666333\n",
      "train loss:0.10924779432345468\n",
      "train loss:0.17407435639246796\n",
      "train loss:0.12502182025317776\n",
      "train loss:0.1433911827040466\n",
      "train loss:0.15156174279571238\n",
      "train loss:0.14410003962738957\n",
      "train loss:0.10829409018553089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.06850239163593641\n",
      "train loss:0.10086835101779759\n",
      "train loss:0.08935105574346254\n",
      "train loss:0.15578258378402182\n",
      "train loss:0.09491531574089081\n",
      "train loss:0.13561063123268968\n",
      "train loss:0.09794998280655459\n",
      "train loss:0.09093045749400294\n",
      "train loss:0.10642143292748824\n",
      "train loss:0.13347509688638082\n",
      "train loss:0.11129711568297569\n",
      "train loss:0.0772640627381772\n",
      "train loss:0.07663717625130523\n",
      "train loss:0.11617532903940765\n",
      "train loss:0.10321489630854248\n",
      "train loss:0.06830084944457658\n",
      "train loss:0.034782137893030945\n",
      "train loss:0.06603357910555062\n",
      "train loss:0.14711612073741495\n",
      "train loss:0.18305088980311662\n",
      "train loss:0.10913345456564602\n",
      "train loss:0.08995501635805458\n",
      "train loss:0.15032377078565717\n",
      "train loss:0.05358518616212621\n",
      "train loss:0.06110399807754656\n",
      "train loss:0.1170674179107179\n",
      "train loss:0.16183953212375649\n",
      "train loss:0.09380417834464437\n",
      "train loss:0.1858881106950523\n",
      "train loss:0.13356891908719226\n",
      "train loss:0.042798441025179546\n",
      "train loss:0.13509145336104797\n",
      "train loss:0.07609510978243601\n",
      "train loss:0.12384896035634013\n",
      "train loss:0.08216792298959062\n",
      "train loss:0.1160181555016435\n",
      "train loss:0.1400301802519097\n",
      "train loss:0.08488757002427773\n",
      "train loss:0.09646429093843986\n",
      "train loss:0.1261979063530507\n",
      "train loss:0.06986330801072478\n",
      "train loss:0.09304917065203058\n",
      "train loss:0.09289594151410276\n",
      "train loss:0.06331636937078503\n",
      "train loss:0.14122556632484606\n",
      "train loss:0.11042348609719722\n",
      "train loss:0.04945281786107444\n",
      "train loss:0.07226272265194\n",
      "train loss:0.12557233698174186\n",
      "train loss:0.10138389226232432\n",
      "train loss:0.15832760495515102\n",
      "train loss:0.07113738377428001\n",
      "train loss:0.10999083358126427\n",
      "train loss:0.11684403253767878\n",
      "train loss:0.10500357939601\n",
      "train loss:0.1618635391300839\n",
      "train loss:0.10426028974828151\n",
      "train loss:0.15695742097824333\n",
      "train loss:0.09066944792720051\n",
      "train loss:0.06180070435588123\n",
      "train loss:0.12724936685072774\n",
      "train loss:0.16288873561256367\n",
      "train loss:0.08586886178911944\n",
      "train loss:0.0727076469022348\n",
      "train loss:0.0852959972528086\n",
      "train loss:0.16842709395453093\n",
      "train loss:0.12202934715106668\n",
      "train loss:0.0959693959518236\n",
      "train loss:0.07057892612666669\n",
      "train loss:0.06539005307027886\n",
      "train loss:0.1403952977925943\n",
      "train loss:0.047223600765888996\n",
      "train loss:0.24944642289005667\n",
      "train loss:0.050720807899380584\n",
      "train loss:0.112146937848744\n",
      "train loss:0.08868428056252256\n",
      "train loss:0.07602420416861372\n",
      "train loss:0.15648559392402606\n",
      "train loss:0.13382943708880932\n",
      "train loss:0.09399877333366004\n",
      "train loss:0.19887590912825628\n",
      "train loss:0.0749332542138895\n",
      "train loss:0.07109937286920286\n",
      "train loss:0.14022834262858247\n",
      "train loss:0.08501207384647254\n",
      "train loss:0.08224691175744636\n",
      "train loss:0.12084184808434718\n",
      "train loss:0.0688199131344151\n",
      "train loss:0.04924373791264979\n",
      "train loss:0.10861758829329349\n",
      "train loss:0.16279938693396453\n",
      "train loss:0.14782803794561775\n",
      "train loss:0.10075867841879066\n",
      "train loss:0.09557667190072797\n",
      "train loss:0.14712100663225453\n",
      "train loss:0.13056868682813752\n",
      "train loss:0.22318083677488576\n",
      "train loss:0.09491560996756922\n",
      "train loss:0.0843287474379858\n",
      "train loss:0.15580257406573292\n",
      "train loss:0.058865593355344095\n",
      "train loss:0.04326583314040153\n",
      "train loss:0.10202727221995296\n",
      "train loss:0.08238822832937778\n",
      "train loss:0.05812004499975637\n",
      "train loss:0.07008897760485387\n",
      "train loss:0.07177200999487075\n",
      "train loss:0.2953365497698309\n",
      "train loss:0.05959162686033663\n",
      "train loss:0.12075431362835444\n",
      "train loss:0.08145309101452168\n",
      "train loss:0.06663458837421071\n",
      "train loss:0.09680075262692457\n",
      "train loss:0.10625000513461595\n",
      "train loss:0.11402525185539147\n",
      "train loss:0.15109859797859612\n",
      "train loss:0.10813597066064601\n",
      "train loss:0.14006323033333754\n",
      "train loss:0.08869603108631205\n",
      "train loss:0.11183284612263769\n",
      "train loss:0.04295084685300173\n",
      "train loss:0.12957009442882536\n",
      "train loss:0.12761054912842215\n",
      "train loss:0.12940056811797834\n",
      "train loss:0.13125441230610232\n",
      "train loss:0.09430021887090122\n",
      "train loss:0.11064014431805608\n",
      "train loss:0.11827028583852885\n",
      "train loss:0.13120355248775625\n",
      "train loss:0.14252282803449043\n",
      "train loss:0.18395402267761152\n",
      "train loss:0.04434329636951539\n",
      "train loss:0.08851729823895094\n",
      "train loss:0.09119296378825846\n",
      "train loss:0.12995749039357837\n",
      "train loss:0.10348790884956735\n",
      "train loss:0.1404454571960967\n",
      "train loss:0.14228222570764182\n",
      "train loss:0.09775295849193656\n",
      "train loss:0.14619220199384547\n",
      "train loss:0.12890909552578653\n",
      "train loss:0.11540256859666805\n",
      "train loss:0.12280768640658384\n",
      "train loss:0.12093928118564891\n",
      "train loss:0.24575644138984817\n",
      "train loss:0.16047206024332702\n",
      "train loss:0.08461108900938984\n",
      "train loss:0.07516572075448966\n",
      "train loss:0.046257705435339316\n",
      "train loss:0.09996333903870845\n",
      "train loss:0.13560171111727595\n",
      "train loss:0.24664350096078028\n",
      "train loss:0.16610193965480913\n",
      "train loss:0.11299452372382052\n",
      "train loss:0.15828181824061702\n",
      "train loss:0.20403796712535743\n",
      "train loss:0.15187930912773312\n",
      "train loss:0.08593322469340009\n",
      "train loss:0.05404725226676714\n",
      "train loss:0.0529901741821967\n",
      "train loss:0.10603592819990569\n",
      "train loss:0.15978030398228601\n",
      "train loss:0.11538580516685636\n",
      "train loss:0.17532790968536677\n",
      "train loss:0.08515893461799484\n",
      "train loss:0.1119015995550437\n",
      "train loss:0.15831882856501378\n",
      "train loss:0.14076941858699554\n",
      "train loss:0.11328016701887413\n",
      "train loss:0.12916498800494203\n",
      "train loss:0.10611830398985043\n",
      "train loss:0.11508512905895739\n",
      "train loss:0.13077830752615227\n",
      "train loss:0.08140463289704337\n",
      "train loss:0.08249735250946193\n",
      "train loss:0.11874715142685571\n",
      "train loss:0.06750775237753101\n",
      "train loss:0.05840137381258364\n",
      "train loss:0.10756688512683299\n",
      "train loss:0.09862499609955627\n",
      "train loss:0.15369536188895835\n",
      "train loss:0.050933041334241515\n",
      "train loss:0.09962248212184611\n",
      "train loss:0.14182248271944098\n",
      "train loss:0.05879835812731384\n",
      "train loss:0.2244915128295475\n",
      "train loss:0.10557110664048203\n",
      "train loss:0.11287518538728342\n",
      "train loss:0.06483296726461774\n",
      "train loss:0.121563703294125\n",
      "train loss:0.08682780616259148\n",
      "train loss:0.10836150496032902\n",
      "train loss:0.08585088980106988\n",
      "train loss:0.12678831651939487\n",
      "train loss:0.1559843391786377\n",
      "train loss:0.07691009374860264\n",
      "train loss:0.1693914016929356\n",
      "train loss:0.110328657439221\n",
      "train loss:0.12623301717241708\n",
      "train loss:0.04791549755628394\n",
      "train loss:0.09623631357329727\n",
      "train loss:0.10951005795649672\n",
      "train loss:0.10454409212853849\n",
      "train loss:0.08783168745889068\n",
      "train loss:0.2193324384975689\n",
      "train loss:0.10823500365592716\n",
      "train loss:0.15792846728923407\n",
      "train loss:0.11646698492994774\n",
      "train loss:0.11554326841463455\n",
      "train loss:0.11841890676321226\n",
      "train loss:0.06419115329142797\n",
      "train loss:0.1066169162127467\n",
      "train loss:0.05659340736323623\n",
      "train loss:0.12290739461721464\n",
      "train loss:0.11143919643923875\n",
      "train loss:0.11310155793373972\n",
      "train loss:0.07456105527789562\n",
      "train loss:0.10861489980146728\n",
      "train loss:0.10397973100214478\n",
      "train loss:0.15115908547106602\n",
      "train loss:0.13168307695477124\n",
      "train loss:0.10543629111080781\n",
      "train loss:0.2472820731354173\n",
      "train loss:0.12153087688815062\n",
      "train loss:0.09781276432706726\n",
      "train loss:0.1558890856687143\n",
      "train loss:0.18897315195966782\n",
      "train loss:0.06446002776081979\n",
      "train loss:0.08913983282471918\n",
      "train loss:0.10706374123889688\n",
      "train loss:0.07287836958045095\n",
      "train loss:0.10472092415559159\n",
      "train loss:0.08447491747795426\n",
      "train loss:0.14145389569744213\n",
      "train loss:0.10704492480248318\n",
      "train loss:0.09866583087072651\n",
      "train loss:0.09016345921865662\n",
      "train loss:0.06475099098694863\n",
      "train loss:0.11172594434088323\n",
      "train loss:0.09063484665229059\n",
      "train loss:0.13711569700202975\n",
      "train loss:0.13970662491046346\n",
      "train loss:0.13993755711509956\n",
      "train loss:0.13965704617277896\n",
      "train loss:0.09630363992630445\n",
      "train loss:0.12995416488248684\n",
      "train loss:0.15110010840952837\n",
      "train loss:0.07720233098260862\n",
      "train loss:0.07649907955360752\n",
      "train loss:0.0775493850095898\n",
      "train loss:0.21826806576265523\n",
      "train loss:0.1228471997027565\n",
      "train loss:0.13282663609102185\n",
      "train loss:0.12955543104912812\n",
      "train loss:0.10584513144967402\n",
      "train loss:0.06910531333005789\n",
      "train loss:0.10071507506235056\n",
      "train loss:0.10416732386043673\n",
      "train loss:0.07907637675608814\n",
      "train loss:0.12433661328550898\n",
      "train loss:0.10375052372044126\n",
      "train loss:0.0566195197274619\n",
      "train loss:0.08318426687657833\n",
      "train loss:0.05629486752645765\n",
      "train loss:0.04590108829839752\n",
      "train loss:0.14547407421221725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.17832980985929506\n",
      "train loss:0.1419351646547625\n",
      "train loss:0.0871467933382541\n",
      "train loss:0.10465268733689216\n",
      "train loss:0.13754293390379993\n",
      "train loss:0.10160290639117533\n",
      "train loss:0.0629704123762139\n",
      "train loss:0.06825126101627205\n",
      "train loss:0.08909396921184082\n",
      "train loss:0.1352921007801952\n",
      "train loss:0.07786389415357042\n",
      "train loss:0.06760948613910132\n",
      "train loss:0.11826494471155201\n",
      "train loss:0.08503912725992971\n",
      "train loss:0.12958761637884364\n",
      "train loss:0.07728663207054845\n",
      "train loss:0.06723913678312131\n",
      "train loss:0.1539740609463722\n",
      "train loss:0.06481887071382951\n",
      "train loss:0.16353452639770327\n",
      "train loss:0.17425107512384616\n",
      "train loss:0.09311199029892835\n",
      "train loss:0.15546264187548625\n",
      "train loss:0.10599056773413108\n",
      "train loss:0.16136303003664448\n",
      "train loss:0.03730726768316194\n",
      "train loss:0.10150699284490715\n",
      "train loss:0.11933496352250636\n",
      "train loss:0.07397492242178474\n",
      "train loss:0.14600463000060707\n",
      "train loss:0.09339050026271359\n",
      "train loss:0.10231421204054826\n",
      "train loss:0.08385565648788117\n",
      "train loss:0.06660051768072496\n",
      "train loss:0.12605846842440258\n",
      "train loss:0.07711128815965818\n",
      "train loss:0.11416806367625984\n",
      "train loss:0.027890110273499445\n",
      "train loss:0.13701228148912917\n",
      "train loss:0.09217847290589049\n",
      "train loss:0.11170817709185905\n",
      "train loss:0.1161871854701182\n",
      "train loss:0.1215750444866157\n",
      "train loss:0.14174204823951578\n",
      "train loss:0.09534223482639162\n",
      "train loss:0.0473025925779239\n",
      "train loss:0.10571477894101801\n",
      "train loss:0.118377747580315\n",
      "train loss:0.02972171982240528\n",
      "train loss:0.064207330986586\n",
      "train loss:0.10244252345641129\n",
      "train loss:0.200277574437018\n",
      "train loss:0.11933513294584022\n",
      "train loss:0.10982404909266621\n",
      "train loss:0.13268484426606553\n",
      "train loss:0.062391485724335054\n",
      "train loss:0.17518869771946513\n",
      "train loss:0.07981689402910354\n",
      "train loss:0.06684031008595612\n",
      "train loss:0.07663100962202121\n",
      "train loss:0.14931305059831762\n",
      "train loss:0.11440722875111836\n",
      "train loss:0.12488447304067725\n",
      "train loss:0.09725665621889296\n",
      "train loss:0.11977685914013322\n",
      "train loss:0.09252985724416962\n",
      "train loss:0.1187223935626429\n",
      "train loss:0.07792677473896399\n",
      "train loss:0.052290507240531914\n",
      "train loss:0.18944715582433747\n",
      "train loss:0.15183687003570154\n",
      "train loss:0.12472700095623973\n",
      "train loss:0.07461375747955483\n",
      "train loss:0.08733267142005119\n",
      "train loss:0.08192914902726457\n",
      "train loss:0.11819524247832222\n",
      "train loss:0.11685003100403188\n",
      "train loss:0.12384492525598075\n",
      "train loss:0.08197079925295095\n",
      "train loss:0.07209613109012168\n",
      "train loss:0.06479462942422094\n",
      "train loss:0.1601147755354587\n",
      "train loss:0.19027236301305855\n",
      "train loss:0.08917464665055615\n",
      "train loss:0.12938908646708044\n",
      "train loss:0.09611131965445803\n",
      "train loss:0.1047038936607677\n",
      "train loss:0.13113604093304354\n",
      "train loss:0.09901264610505996\n",
      "train loss:0.1522323264840108\n",
      "train loss:0.06219249676312022\n",
      "train loss:0.06242439933319818\n",
      "train loss:0.09624538254761554\n",
      "train loss:0.1340744490463618\n",
      "train loss:0.054561908960318845\n",
      "train loss:0.10008382782587731\n",
      "train loss:0.16009106124961106\n",
      "train loss:0.03826237398707846\n",
      "train loss:0.120675223318664\n",
      "train loss:0.1388326474168176\n",
      "train loss:0.11551786286467378\n",
      "train loss:0.1601454373262669\n",
      "train loss:0.09402425912208834\n",
      "train loss:0.15127583170590578\n",
      "train loss:0.04691553217072791\n",
      "train loss:0.060249226971504255\n",
      "train loss:0.1686704613842134\n",
      "train loss:0.15948576551973728\n",
      "train loss:0.15699097957362715\n",
      "train loss:0.10518111168434087\n",
      "train loss:0.14252781251885382\n",
      "train loss:0.12618814034154416\n",
      "train loss:0.1239373872357524\n",
      "train loss:0.17140473911758125\n",
      "train loss:0.10812207214278087\n",
      "=== epoch:15, train acc:0.966, test acc:0.912 ===\n",
      "train loss:0.09384467118793736\n",
      "train loss:0.17284017588958583\n",
      "train loss:0.11145518359895273\n",
      "train loss:0.12165013072996773\n",
      "train loss:0.10265596062810435\n",
      "train loss:0.05923339057192162\n",
      "train loss:0.09271108238957837\n",
      "train loss:0.09662696879742239\n",
      "train loss:0.12005545592281137\n",
      "train loss:0.07145754720967157\n",
      "train loss:0.09840555928698903\n",
      "train loss:0.1839767780279586\n",
      "train loss:0.15434132579771798\n",
      "train loss:0.11362853899315872\n",
      "train loss:0.07394755317942915\n",
      "train loss:0.04565058384421298\n",
      "train loss:0.06551446470423104\n",
      "train loss:0.16173963362212226\n",
      "train loss:0.06246922962103776\n",
      "train loss:0.06194973628697406\n",
      "train loss:0.04678584053576931\n",
      "train loss:0.11230277089434099\n",
      "train loss:0.07416594062452972\n",
      "train loss:0.14132845396866064\n",
      "train loss:0.12303457635762163\n",
      "train loss:0.037085443817410205\n",
      "train loss:0.0641913273023766\n",
      "train loss:0.09473161680738346\n",
      "train loss:0.03900260408369133\n",
      "train loss:0.10537184937010602\n",
      "train loss:0.2216106810237982\n",
      "train loss:0.09291588774552322\n",
      "train loss:0.06491964919881615\n",
      "train loss:0.06849567202036229\n",
      "train loss:0.09923953496204194\n",
      "train loss:0.10052810336492875\n",
      "train loss:0.0815999688468248\n",
      "train loss:0.10355115794362468\n",
      "train loss:0.08756674842258723\n",
      "train loss:0.15263172833902217\n",
      "train loss:0.24004045394223852\n",
      "train loss:0.18506889879576327\n",
      "train loss:0.147503061765144\n",
      "train loss:0.08678272809411794\n",
      "train loss:0.1658612892248453\n",
      "train loss:0.04855320145770833\n",
      "train loss:0.14055575330174938\n",
      "train loss:0.08029872232524711\n",
      "train loss:0.12716121174625944\n",
      "train loss:0.10464289718176646\n",
      "train loss:0.09857924768318728\n",
      "train loss:0.12391904105951644\n",
      "train loss:0.1256990451559525\n",
      "train loss:0.08161398448753576\n",
      "train loss:0.08891369686719088\n",
      "train loss:0.1955806115283149\n",
      "train loss:0.08699932470869365\n",
      "train loss:0.15052142241101452\n",
      "train loss:0.09266512135827604\n",
      "train loss:0.06996764080835022\n",
      "train loss:0.1436095275964576\n",
      "train loss:0.11018855809237162\n",
      "train loss:0.11907903224623408\n",
      "train loss:0.08624677988828569\n",
      "train loss:0.10012781695728226\n",
      "train loss:0.06919544571858223\n",
      "train loss:0.07725773513316568\n",
      "train loss:0.12620374395501327\n",
      "train loss:0.06157335706868084\n",
      "train loss:0.05186571094082713\n",
      "train loss:0.052990597863108696\n",
      "train loss:0.08403942629263345\n",
      "train loss:0.11797799028542681\n",
      "train loss:0.1650157346827646\n",
      "train loss:0.15174485405955201\n",
      "train loss:0.14084051338762615\n",
      "train loss:0.08109227614520939\n",
      "train loss:0.132643681070497\n",
      "train loss:0.07247928534532484\n",
      "train loss:0.1252788236067991\n",
      "train loss:0.09683571229234936\n",
      "train loss:0.11491982930602189\n",
      "train loss:0.08918038935430526\n",
      "train loss:0.13879020085815516\n",
      "train loss:0.13692114678193337\n",
      "train loss:0.06820768699641433\n",
      "train loss:0.12783269620396667\n",
      "train loss:0.1299383741534133\n",
      "train loss:0.06181745146054391\n",
      "train loss:0.09901094982506382\n",
      "train loss:0.1084491564986464\n",
      "train loss:0.07833595444527153\n",
      "train loss:0.09133332589113341\n",
      "train loss:0.08227453578897846\n",
      "train loss:0.15336358615362028\n",
      "train loss:0.0641815443511406\n",
      "train loss:0.09093655381037308\n",
      "train loss:0.09285060835666162\n",
      "train loss:0.09250686609458089\n",
      "train loss:0.11759808884688701\n",
      "train loss:0.16286643906830633\n",
      "train loss:0.09107125033644221\n",
      "train loss:0.12716724401533433\n",
      "train loss:0.14495552783307783\n",
      "train loss:0.12116857106067672\n",
      "train loss:0.09636041591746922\n",
      "train loss:0.11623360608942113\n",
      "train loss:0.0629903703054027\n",
      "train loss:0.05637471399824609\n",
      "train loss:0.09046289535961244\n",
      "train loss:0.08141676879738004\n",
      "train loss:0.04464613774793594\n",
      "train loss:0.07630574009448682\n",
      "train loss:0.1107031721016526\n",
      "train loss:0.18551948420290013\n",
      "train loss:0.06927838493509524\n",
      "train loss:0.13001649047345964\n",
      "train loss:0.07535768732637994\n",
      "train loss:0.14040296397330684\n",
      "train loss:0.08170934179632706\n",
      "train loss:0.12444966826929471\n",
      "train loss:0.13926548295837168\n",
      "train loss:0.09624889001213015\n",
      "train loss:0.06862345567548696\n",
      "train loss:0.07893746973544118\n",
      "train loss:0.09708648179237014\n",
      "train loss:0.08463477930544866\n",
      "train loss:0.1329612091307988\n",
      "train loss:0.1951785862644567\n",
      "train loss:0.11133802653214031\n",
      "train loss:0.07789699438013854\n",
      "train loss:0.09201163443088374\n",
      "train loss:0.09865134324104438\n",
      "train loss:0.1517506739890201\n",
      "train loss:0.06943159326386251\n",
      "train loss:0.06400811021403538\n",
      "train loss:0.0928052712573913\n",
      "train loss:0.13973546764066186\n",
      "train loss:0.1527017942876064\n",
      "train loss:0.06381244615869237\n",
      "train loss:0.07224493863094185\n",
      "train loss:0.07964258649933356\n",
      "train loss:0.1315935900379454\n",
      "train loss:0.11089810193979394\n",
      "train loss:0.08519220967527413\n",
      "train loss:0.09451542033732765\n",
      "train loss:0.05612655062599162\n",
      "train loss:0.10450990588897684\n",
      "train loss:0.1094175075415839\n",
      "train loss:0.07073081710664025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.06970593033917777\n",
      "train loss:0.04898282838629708\n",
      "train loss:0.0737002272458105\n",
      "train loss:0.16334129840186334\n",
      "train loss:0.19309496326258388\n",
      "train loss:0.08135323272403058\n",
      "train loss:0.14680116222519268\n",
      "train loss:0.10444933517528808\n",
      "train loss:0.15616616717793572\n",
      "train loss:0.07527469930980775\n",
      "train loss:0.05390805048250863\n",
      "train loss:0.05797902416272963\n",
      "train loss:0.1858513184712058\n",
      "train loss:0.09295397852861367\n",
      "train loss:0.057142663401120564\n",
      "train loss:0.18619918690633827\n",
      "train loss:0.1222759878321227\n",
      "train loss:0.03698774533709387\n",
      "train loss:0.06412831332644894\n",
      "train loss:0.13671828223978516\n",
      "train loss:0.1725031208787513\n",
      "train loss:0.07128619964916584\n",
      "train loss:0.038329199163225545\n",
      "train loss:0.14668343293735214\n",
      "train loss:0.11721194874407771\n",
      "train loss:0.20974663257613746\n",
      "train loss:0.17429951922251052\n",
      "train loss:0.08744954739221576\n",
      "train loss:0.20089851357347072\n",
      "train loss:0.08570281052743796\n",
      "train loss:0.10636359181805131\n",
      "train loss:0.056153724646255794\n",
      "train loss:0.09725320742495196\n",
      "train loss:0.10673803617285495\n",
      "train loss:0.1933811200161448\n",
      "train loss:0.0839370402004031\n",
      "train loss:0.18930928440731398\n",
      "train loss:0.07522445856831927\n",
      "train loss:0.11474035277934747\n",
      "train loss:0.09007775846598384\n",
      "train loss:0.08819093694101272\n",
      "train loss:0.08626714827084818\n",
      "train loss:0.11140502263454741\n",
      "train loss:0.0843877458335062\n",
      "train loss:0.11586539994995991\n",
      "train loss:0.06458428096632701\n",
      "train loss:0.12557028625319872\n",
      "train loss:0.10799723368686394\n",
      "train loss:0.10668499930317545\n",
      "train loss:0.061918739441659036\n",
      "train loss:0.13415129226471947\n",
      "train loss:0.10479521406271962\n",
      "train loss:0.12714173164074732\n",
      "train loss:0.13637791081574802\n",
      "train loss:0.09411918799401274\n",
      "train loss:0.08681356292717787\n",
      "train loss:0.09342545842225387\n",
      "train loss:0.11603167182498035\n",
      "train loss:0.37148442922181113\n",
      "train loss:0.047416670481632964\n",
      "train loss:0.1280874355541777\n",
      "train loss:0.07968147789642253\n",
      "train loss:0.12751939092601808\n",
      "train loss:0.06633842507624414\n",
      "train loss:0.14447324792039715\n",
      "train loss:0.11491682015144739\n",
      "train loss:0.1001200526582541\n",
      "train loss:0.12024388466071505\n",
      "train loss:0.09489951574038516\n",
      "train loss:0.10114266152338997\n",
      "train loss:0.07231085989550826\n",
      "train loss:0.051108899445572946\n",
      "train loss:0.11279416946623554\n",
      "train loss:0.08233842834858969\n",
      "train loss:0.12216330662686514\n",
      "train loss:0.09644108551420577\n",
      "train loss:0.11613652832448892\n",
      "train loss:0.13225513027081168\n",
      "train loss:0.15397332944488404\n",
      "train loss:0.04148534049114636\n",
      "train loss:0.1335053142158161\n",
      "train loss:0.10553149107750538\n",
      "train loss:0.10978504386674205\n",
      "train loss:0.09470395549475284\n",
      "train loss:0.04677061359294906\n",
      "train loss:0.09233914021872919\n",
      "train loss:0.09743411656161195\n",
      "train loss:0.06550117549861206\n",
      "train loss:0.09887892807786042\n",
      "train loss:0.12359215686807373\n",
      "train loss:0.11475581850701042\n",
      "train loss:0.1559948035799053\n",
      "train loss:0.076513751151967\n",
      "train loss:0.08377181447406713\n",
      "train loss:0.07397011261428474\n",
      "train loss:0.07671273773954165\n",
      "train loss:0.20622554385072392\n",
      "train loss:0.1306702882985468\n",
      "train loss:0.11759977851281606\n",
      "train loss:0.11357558461055652\n",
      "train loss:0.0883757659476373\n",
      "train loss:0.04810385788734013\n",
      "train loss:0.07809531974903612\n",
      "train loss:0.10188615763957372\n",
      "train loss:0.09311022770570858\n",
      "train loss:0.0977435319608363\n",
      "train loss:0.07940303510457589\n",
      "train loss:0.1591258173615081\n",
      "train loss:0.055494388831375564\n",
      "train loss:0.060609848502710534\n",
      "train loss:0.11744273893207836\n",
      "train loss:0.11296120845925667\n",
      "train loss:0.09802956914306625\n",
      "train loss:0.09321663498238549\n",
      "train loss:0.12630558722543847\n",
      "train loss:0.16229296622050832\n",
      "train loss:0.13406237565034826\n",
      "train loss:0.12181084560931653\n",
      "train loss:0.12789404923418587\n",
      "train loss:0.09715586016722741\n",
      "train loss:0.09928589684324512\n",
      "train loss:0.1174247816815622\n",
      "train loss:0.12050965646616145\n",
      "train loss:0.13989536449227485\n",
      "train loss:0.11668592022973483\n",
      "train loss:0.10544667835040526\n",
      "train loss:0.05692030812879417\n",
      "train loss:0.15212138115358606\n",
      "train loss:0.13240693371391427\n",
      "train loss:0.1090294461405167\n",
      "train loss:0.12511428398515753\n",
      "train loss:0.06062927189013918\n",
      "train loss:0.07691316372723193\n",
      "train loss:0.07498780428719538\n",
      "train loss:0.13102026176211268\n",
      "train loss:0.04629848391685373\n",
      "train loss:0.08759269975302439\n",
      "train loss:0.041908842280521295\n",
      "train loss:0.05914256194962033\n",
      "train loss:0.08571840766356427\n",
      "train loss:0.11885866096189099\n",
      "train loss:0.10789776015911495\n",
      "train loss:0.11907044634485636\n",
      "train loss:0.11719209822740168\n",
      "train loss:0.12156320612903503\n",
      "train loss:0.09785921677969771\n",
      "train loss:0.14343736118288133\n",
      "train loss:0.10921184921983004\n",
      "train loss:0.108002318927427\n",
      "train loss:0.06305192178787046\n",
      "train loss:0.1401171331024515\n",
      "train loss:0.10602336852867947\n",
      "train loss:0.0914748157458453\n",
      "train loss:0.11926842512049733\n",
      "train loss:0.1026481424376916\n",
      "train loss:0.057710320320551796\n",
      "train loss:0.10935593356192656\n",
      "train loss:0.08663677386805549\n",
      "train loss:0.04725150806993072\n",
      "train loss:0.06849937900816966\n",
      "train loss:0.1258176263885546\n",
      "train loss:0.14552234009544474\n",
      "train loss:0.10569906402379797\n",
      "train loss:0.04523183370290191\n",
      "train loss:0.22832418529174717\n",
      "train loss:0.08674796042020025\n",
      "train loss:0.2032932202181869\n",
      "train loss:0.05898532546607558\n",
      "train loss:0.1247694744835815\n",
      "train loss:0.13871090622083088\n",
      "train loss:0.12596466637530745\n",
      "train loss:0.11967504448566466\n",
      "train loss:0.09539191951763241\n",
      "train loss:0.10528542033766332\n",
      "train loss:0.14981582154177045\n",
      "train loss:0.10173963571139659\n",
      "train loss:0.13414229113687248\n",
      "train loss:0.16064789978975436\n",
      "train loss:0.12729359868285348\n",
      "train loss:0.14578861045340377\n",
      "train loss:0.10698528852286784\n",
      "train loss:0.06802360703418531\n",
      "train loss:0.08152403466233923\n",
      "train loss:0.11852071052012\n",
      "train loss:0.08584696908503521\n",
      "train loss:0.14543088993969788\n",
      "train loss:0.05900384096031577\n",
      "train loss:0.08433530100306774\n",
      "train loss:0.08039287143475293\n",
      "train loss:0.042677924341909555\n",
      "train loss:0.09523714317131216\n",
      "train loss:0.06350129062207975\n",
      "train loss:0.11812234954170901\n",
      "train loss:0.11684336242757457\n",
      "train loss:0.05284828888852194\n",
      "train loss:0.07205815264866848\n",
      "train loss:0.1122188483899956\n",
      "train loss:0.11717664179839771\n",
      "train loss:0.09636807337378109\n",
      "train loss:0.11334762837164554\n",
      "train loss:0.09451355924625215\n",
      "train loss:0.029837145111620108\n",
      "train loss:0.07589518004144505\n",
      "train loss:0.06564075308932876\n",
      "train loss:0.11274697711686091\n",
      "train loss:0.1099002878182695\n",
      "train loss:0.07836223265134666\n",
      "train loss:0.13497940134086622\n",
      "train loss:0.1082985484334914\n",
      "train loss:0.10765670607358364\n",
      "train loss:0.05436310916607837\n",
      "train loss:0.09352900673144862\n",
      "train loss:0.10550623602766876\n",
      "train loss:0.10910703629741446\n",
      "train loss:0.08160849004370434\n",
      "train loss:0.13420925573107045\n",
      "train loss:0.10190710211589084\n",
      "train loss:0.13848799137278556\n",
      "train loss:0.07813112409338967\n",
      "train loss:0.1541378887269795\n",
      "train loss:0.06939643686875174\n",
      "train loss:0.07991392467754109\n",
      "train loss:0.08210680822517459\n",
      "train loss:0.10608163098641356\n",
      "train loss:0.12562352352040626\n",
      "train loss:0.06327638677346104\n",
      "train loss:0.10158492383071181\n",
      "train loss:0.10267889335930303\n",
      "train loss:0.1073554694066603\n",
      "train loss:0.12455690963533081\n",
      "train loss:0.0600395718322253\n",
      "train loss:0.1272609644246897\n",
      "train loss:0.17431462324007171\n",
      "train loss:0.10653907830033148\n",
      "train loss:0.09775088328259213\n",
      "train loss:0.1628850714943618\n",
      "train loss:0.13654388680613813\n",
      "train loss:0.040350246000341\n",
      "train loss:0.0683190449426286\n",
      "train loss:0.08935047356425735\n",
      "train loss:0.058545469584339094\n",
      "train loss:0.0585423620847145\n",
      "train loss:0.1505379668708823\n",
      "train loss:0.03660795965128915\n",
      "train loss:0.10586329272583336\n",
      "train loss:0.11246893888570517\n",
      "train loss:0.17943678249945022\n",
      "train loss:0.05859485974987035\n",
      "train loss:0.13363490409129572\n",
      "train loss:0.06946101464964373\n",
      "train loss:0.09602487560832122\n",
      "train loss:0.06117018249845283\n",
      "train loss:0.09680378898292791\n",
      "train loss:0.03175448195125943\n",
      "train loss:0.06633707430194093\n",
      "train loss:0.14178536728985217\n",
      "train loss:0.14537584530349718\n",
      "train loss:0.18340048703276682\n",
      "train loss:0.09733928515724617\n",
      "train loss:0.11193237042667761\n",
      "train loss:0.1428977848425269\n",
      "train loss:0.1524596150609942\n",
      "train loss:0.10985793277361822\n",
      "train loss:0.1406848242331736\n",
      "train loss:0.08602128080180224\n",
      "train loss:0.09744005498889104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.14307102061933416\n",
      "train loss:0.10468889373666453\n",
      "train loss:0.07790707451818422\n",
      "train loss:0.11115388533861964\n",
      "train loss:0.048093503516415906\n",
      "train loss:0.055183794725477915\n",
      "train loss:0.11653120333582061\n",
      "train loss:0.17788831766592617\n",
      "train loss:0.10731046783945603\n",
      "train loss:0.19899979835312379\n",
      "train loss:0.08896630092657676\n",
      "train loss:0.05055209091957349\n",
      "train loss:0.09279304561624785\n",
      "train loss:0.11722987443647598\n",
      "train loss:0.12151615488173496\n",
      "train loss:0.07298457036060682\n",
      "train loss:0.10688409064251803\n",
      "train loss:0.05949148052686102\n",
      "train loss:0.072119144301086\n",
      "train loss:0.061419844112894674\n",
      "train loss:0.12033370394986243\n",
      "train loss:0.09966845444578688\n",
      "train loss:0.08361015485828753\n",
      "train loss:0.09107956830467505\n",
      "train loss:0.1087011127029837\n",
      "train loss:0.18423213894818957\n",
      "train loss:0.11167718949559341\n",
      "train loss:0.21303452345843174\n",
      "train loss:0.10093880068649635\n",
      "train loss:0.11657057716730378\n",
      "train loss:0.10270168914985037\n",
      "train loss:0.07045721872076278\n",
      "train loss:0.08743360072085955\n",
      "train loss:0.07884640303350991\n",
      "train loss:0.10485844000760407\n",
      "train loss:0.09192985972838004\n",
      "train loss:0.042385298974645984\n",
      "train loss:0.0689387856711846\n",
      "train loss:0.08173497364213897\n",
      "train loss:0.10653016338449847\n",
      "train loss:0.08775256348531309\n",
      "train loss:0.09449867423250036\n",
      "train loss:0.08019785192365696\n",
      "train loss:0.08495023116937181\n",
      "train loss:0.10125211180151958\n",
      "train loss:0.0718084389270311\n",
      "train loss:0.06840838586953672\n",
      "train loss:0.08192916593845782\n",
      "train loss:0.15104302765243033\n",
      "train loss:0.0533248036782016\n",
      "train loss:0.1345221079491373\n",
      "train loss:0.04960819439085767\n",
      "train loss:0.0849458745397078\n",
      "train loss:0.10717066389798578\n",
      "train loss:0.08695879418638265\n",
      "train loss:0.1021102031282062\n",
      "train loss:0.11312575254168962\n",
      "train loss:0.10916242675087993\n",
      "train loss:0.08164310584414877\n",
      "train loss:0.07198989402427426\n",
      "train loss:0.19237513938944603\n",
      "train loss:0.066538966793857\n",
      "train loss:0.11676104735480346\n",
      "train loss:0.0812318334180651\n",
      "train loss:0.08771133493433089\n",
      "train loss:0.10571084379946724\n",
      "train loss:0.1416823725144037\n",
      "train loss:0.14337463268824033\n",
      "train loss:0.12462552844199859\n",
      "train loss:0.039130015082040524\n",
      "train loss:0.08471351867542946\n",
      "train loss:0.0791946524825832\n",
      "train loss:0.11753382373351108\n",
      "train loss:0.09312512178007902\n",
      "train loss:0.10693591579755775\n",
      "train loss:0.06293371959008029\n",
      "train loss:0.10076769456852723\n",
      "train loss:0.06451592119973776\n",
      "train loss:0.03375132885968238\n",
      "train loss:0.10129470923640897\n",
      "train loss:0.11140573199932163\n",
      "train loss:0.20155535062110272\n",
      "train loss:0.06308222213162469\n",
      "train loss:0.08451103797846912\n",
      "train loss:0.09989990920072282\n",
      "train loss:0.16984902800889287\n",
      "train loss:0.062411587263383056\n",
      "train loss:0.19199700941428383\n",
      "train loss:0.0649068769920893\n",
      "train loss:0.13938660437235442\n",
      "train loss:0.17039620829833718\n",
      "train loss:0.04924611477128797\n",
      "train loss:0.05961872669292798\n",
      "train loss:0.2320410999816334\n",
      "train loss:0.07429605618010524\n",
      "train loss:0.09978585963698167\n",
      "train loss:0.0488173102462711\n",
      "train loss:0.0889475056621754\n",
      "train loss:0.04654368309428689\n",
      "train loss:0.13486966311064996\n",
      "train loss:0.07130290528171361\n",
      "train loss:0.15479018289082228\n",
      "train loss:0.08764220603384983\n",
      "train loss:0.06642161679017107\n",
      "train loss:0.08844912049176808\n",
      "train loss:0.10857139127877488\n",
      "train loss:0.07306763885959235\n",
      "train loss:0.05871325135643966\n",
      "train loss:0.06265881496254494\n",
      "train loss:0.068635360225709\n",
      "train loss:0.061757690949967775\n",
      "train loss:0.13256420072174235\n",
      "train loss:0.170587972427882\n",
      "train loss:0.08155647659568821\n",
      "train loss:0.07329967976198139\n",
      "train loss:0.04319204340866202\n",
      "train loss:0.13391186062510843\n",
      "train loss:0.11766367187624237\n",
      "train loss:0.13353376882192497\n",
      "train loss:0.0937466593951109\n",
      "train loss:0.077145569222157\n",
      "train loss:0.1015191753771459\n",
      "train loss:0.03287002793989342\n",
      "train loss:0.13424295373286615\n",
      "train loss:0.15210048540284268\n",
      "train loss:0.050760049860636654\n",
      "train loss:0.17362118623634043\n",
      "train loss:0.06808470122670146\n",
      "train loss:0.1074261322052304\n",
      "train loss:0.09270752872680202\n",
      "train loss:0.2080331818046978\n",
      "train loss:0.04899194037256393\n",
      "train loss:0.06449278710199655\n",
      "train loss:0.1265070171285024\n",
      "train loss:0.11781286730228872\n",
      "train loss:0.12410924247041091\n",
      "train loss:0.08629733430286207\n",
      "train loss:0.13053319356133516\n",
      "train loss:0.07440558222179412\n",
      "train loss:0.09224514534938263\n",
      "train loss:0.09053617865823611\n",
      "train loss:0.09724937293423172\n",
      "train loss:0.10588735543754164\n",
      "train loss:0.11395947045560549\n",
      "train loss:0.09858369554853924\n",
      "train loss:0.12151844752190294\n",
      "train loss:0.05973445944172497\n",
      "train loss:0.048090806276377684\n",
      "train loss:0.11567466322161823\n",
      "train loss:0.08428382933973813\n",
      "train loss:0.07674750232611423\n",
      "train loss:0.11028164004805552\n",
      "train loss:0.07445568470806592\n",
      "train loss:0.05328098285593007\n",
      "train loss:0.12894933227312996\n",
      "train loss:0.05999467469765409\n",
      "train loss:0.10171734565121902\n",
      "train loss:0.10877680225128467\n",
      "train loss:0.09866259268296687\n",
      "train loss:0.04529985226412414\n",
      "train loss:0.0710409367493311\n",
      "train loss:0.0655799265916937\n",
      "train loss:0.1915496707143137\n",
      "train loss:0.14091074145941337\n",
      "train loss:0.11411956409108585\n",
      "train loss:0.0535626068670366\n",
      "train loss:0.1388317555588385\n",
      "train loss:0.11385535564521022\n",
      "train loss:0.050273424496026224\n",
      "train loss:0.15327708334186643\n",
      "train loss:0.05578378462616152\n",
      "train loss:0.12258994197771816\n",
      "train loss:0.04621118925771643\n",
      "train loss:0.13726685078726\n",
      "train loss:0.09067359958153673\n",
      "train loss:0.0761169694073921\n",
      "train loss:0.08265090426298506\n",
      "train loss:0.09309430175207262\n",
      "train loss:0.09275874689890651\n",
      "train loss:0.05166494267114383\n",
      "train loss:0.09077289854097023\n",
      "train loss:0.14562025965873734\n",
      "train loss:0.11752549544320189\n",
      "train loss:0.07415060356231268\n",
      "=== epoch:16, train acc:0.966, test acc:0.911 ===\n",
      "train loss:0.10860446892226722\n",
      "train loss:0.03690332170975383\n",
      "train loss:0.11537075247931566\n",
      "train loss:0.06789108593018249\n",
      "train loss:0.11827922100170624\n",
      "train loss:0.10343605316811061\n",
      "train loss:0.05800693492690697\n",
      "train loss:0.17003395998028306\n",
      "train loss:0.15348096977880432\n",
      "train loss:0.06138572522450602\n",
      "train loss:0.15224456067151487\n",
      "train loss:0.07206827714007859\n",
      "train loss:0.04168666292771257\n",
      "train loss:0.0435277448818956\n",
      "train loss:0.10204144918297813\n",
      "train loss:0.0852774531550826\n",
      "train loss:0.05516502786179349\n",
      "train loss:0.09158430409246639\n",
      "train loss:0.15938060023006506\n",
      "train loss:0.11229523531361814\n",
      "train loss:0.16439815611149566\n",
      "train loss:0.06282366489414931\n",
      "train loss:0.07457461213101754\n",
      "train loss:0.07216676020333294\n",
      "train loss:0.1251171240720281\n",
      "train loss:0.12809887173056414\n",
      "train loss:0.07374859713750277\n",
      "train loss:0.10409184414606988\n",
      "train loss:0.08431580208401082\n",
      "train loss:0.1319810708906002\n",
      "train loss:0.08995940265921266\n",
      "train loss:0.06446434780346472\n",
      "train loss:0.06777386575272287\n",
      "train loss:0.1556439653977946\n",
      "train loss:0.15104730014459972\n",
      "train loss:0.06855065931429735\n",
      "train loss:0.06819753731240458\n",
      "train loss:0.1383647720467092\n",
      "train loss:0.0676493562206314\n",
      "train loss:0.1707142450891492\n",
      "train loss:0.03738966940236202\n",
      "train loss:0.07771635440704353\n",
      "train loss:0.04759956444430449\n",
      "train loss:0.06394150019562346\n",
      "train loss:0.12351356548577637\n",
      "train loss:0.120255782754207\n",
      "train loss:0.11858105385418057\n",
      "train loss:0.1077374308821881\n",
      "train loss:0.10397450137563595\n",
      "train loss:0.13818665551045523\n",
      "train loss:0.09793788095903894\n",
      "train loss:0.11131289950621012\n",
      "train loss:0.08232673922628711\n",
      "train loss:0.07412118430396258\n",
      "train loss:0.07257071240099751\n",
      "train loss:0.09526730757734474\n",
      "train loss:0.08135352639430264\n",
      "train loss:0.08401506069976364\n",
      "train loss:0.14541700488989182\n",
      "train loss:0.04430960036010188\n",
      "train loss:0.06342913776457268\n",
      "train loss:0.15887989868255542\n",
      "train loss:0.18404336816191416\n",
      "train loss:0.13605999551649253\n",
      "train loss:0.07103408707138034\n",
      "train loss:0.09993557955975518\n",
      "train loss:0.09791235545618275\n",
      "train loss:0.08876080707153594\n",
      "train loss:0.10938524917176745\n",
      "train loss:0.14756297164543475\n",
      "train loss:0.1075642682008445\n",
      "train loss:0.22304799085131097\n",
      "train loss:0.06287616552309125\n",
      "train loss:0.08807430215404834\n",
      "train loss:0.10775083028416473\n",
      "train loss:0.06516720682043906\n",
      "train loss:0.08372121145597855\n",
      "train loss:0.14787075186535054\n",
      "train loss:0.07868246743996575\n",
      "train loss:0.18179496988614197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.1282706123749997\n",
      "train loss:0.20746858365048468\n",
      "train loss:0.09076694110261777\n",
      "train loss:0.11159516785838218\n",
      "train loss:0.06734843584248995\n",
      "train loss:0.0932625671718891\n",
      "train loss:0.08868193882538328\n",
      "train loss:0.048396429853915214\n",
      "train loss:0.06121754695102115\n",
      "train loss:0.0661930615783356\n",
      "train loss:0.08574499263416457\n",
      "train loss:0.09924628213093557\n",
      "train loss:0.14881985492054656\n",
      "train loss:0.11100411794522104\n",
      "train loss:0.0916252748008338\n",
      "train loss:0.06866855833211774\n",
      "train loss:0.05264741444028294\n",
      "train loss:0.12909238288493508\n",
      "train loss:0.05264588266353904\n",
      "train loss:0.10612901666105466\n",
      "train loss:0.06630081161631884\n",
      "train loss:0.08304918565231384\n",
      "train loss:0.08645614453406025\n",
      "train loss:0.11715613748518759\n",
      "train loss:0.041219423481108394\n",
      "train loss:0.06832178506763983\n",
      "train loss:0.06818432962979387\n",
      "train loss:0.11469602142652752\n",
      "train loss:0.0531341076005467\n",
      "train loss:0.0663601229612041\n",
      "train loss:0.12052815727847464\n",
      "train loss:0.18776551226207153\n",
      "train loss:0.11775379482700121\n",
      "train loss:0.11051644849884329\n",
      "train loss:0.056734845239903756\n",
      "train loss:0.05976991408484263\n",
      "train loss:0.06028425820339598\n",
      "train loss:0.05556882140281805\n",
      "train loss:0.09257371336147419\n",
      "train loss:0.09180320866593908\n",
      "train loss:0.11359593563386486\n",
      "train loss:0.0669519687315748\n",
      "train loss:0.1442358382109653\n",
      "train loss:0.06470394965133824\n",
      "train loss:0.15333467529286207\n",
      "train loss:0.08820579268228763\n",
      "train loss:0.1099219587861462\n",
      "train loss:0.09765492810833447\n",
      "train loss:0.08124650205915693\n",
      "train loss:0.086436401518021\n",
      "train loss:0.05677823521263207\n",
      "train loss:0.10012434174146075\n",
      "train loss:0.04518857657357506\n",
      "train loss:0.05825129449216476\n",
      "train loss:0.1707923926914651\n",
      "train loss:0.08621034957319082\n",
      "train loss:0.09585319738635453\n",
      "train loss:0.08447264828896144\n",
      "train loss:0.17853773935720718\n",
      "train loss:0.1020320588101229\n",
      "train loss:0.05790426054324284\n",
      "train loss:0.03935658515051043\n",
      "train loss:0.07163905731807244\n",
      "train loss:0.026676207660911055\n",
      "train loss:0.051116641136440745\n",
      "train loss:0.08440449127178123\n",
      "train loss:0.1848612741596329\n",
      "train loss:0.10500215516285975\n",
      "train loss:0.11323203208741851\n",
      "train loss:0.140920912132956\n",
      "train loss:0.1383450504354181\n",
      "train loss:0.08362546941805439\n",
      "train loss:0.07101401471288991\n",
      "train loss:0.07751899247231223\n",
      "train loss:0.1105249458915769\n",
      "train loss:0.09257732703033429\n",
      "train loss:0.10592798789672392\n",
      "train loss:0.11757088937205463\n",
      "train loss:0.04260792788148548\n",
      "train loss:0.1137686441018556\n",
      "train loss:0.12599706075451783\n",
      "train loss:0.09893148505807664\n",
      "train loss:0.06542948493122461\n",
      "train loss:0.09283976961517831\n",
      "train loss:0.09926499820171529\n",
      "train loss:0.1789439560703637\n",
      "train loss:0.09729500136679878\n",
      "train loss:0.15212726269046362\n",
      "train loss:0.079218776130878\n",
      "train loss:0.06836645792059967\n",
      "train loss:0.09318088082678418\n",
      "train loss:0.06916880606875743\n",
      "train loss:0.10403385392189779\n",
      "train loss:0.1643540644969861\n",
      "train loss:0.10420491009633565\n",
      "train loss:0.09329280760786837\n",
      "train loss:0.05911431751771099\n",
      "train loss:0.0983972271944931\n",
      "train loss:0.09708209159352521\n",
      "train loss:0.11470139902093475\n",
      "train loss:0.19395366497602265\n",
      "train loss:0.04676584033390031\n",
      "train loss:0.0639713448058475\n",
      "train loss:0.07391824552459336\n",
      "train loss:0.07291113407753497\n",
      "train loss:0.061478640301389574\n",
      "train loss:0.06389073238924817\n",
      "train loss:0.13122756871119243\n",
      "train loss:0.07421844429939699\n",
      "train loss:0.044948953775883975\n",
      "train loss:0.09500075363251209\n",
      "train loss:0.07476845836111909\n",
      "train loss:0.0521193848218454\n",
      "train loss:0.21614035319165648\n",
      "train loss:0.21171097727478905\n",
      "train loss:0.04695986560467743\n",
      "train loss:0.07478925492601479\n",
      "train loss:0.1402499941225537\n",
      "train loss:0.07575596449553156\n",
      "train loss:0.16569785079010743\n",
      "train loss:0.0823352169018835\n",
      "train loss:0.12978746062770563\n",
      "train loss:0.0760626278224467\n",
      "train loss:0.09923918702629773\n",
      "train loss:0.10468285641247284\n",
      "train loss:0.08439661411256251\n",
      "train loss:0.14789020706950445\n",
      "train loss:0.09070827719298574\n",
      "train loss:0.11786203684104296\n",
      "train loss:0.10248218710761105\n",
      "train loss:0.07723955540233671\n",
      "train loss:0.03703182395313694\n",
      "train loss:0.06531357560111857\n",
      "train loss:0.08281491577742604\n",
      "train loss:0.04091399536146069\n",
      "train loss:0.08175897677236478\n",
      "train loss:0.07623650336927884\n",
      "train loss:0.12839259546189702\n",
      "train loss:0.07123518416991591\n",
      "train loss:0.022193528978287323\n",
      "train loss:0.039027189434738443\n",
      "train loss:0.13068631879872797\n",
      "train loss:0.06300366013563884\n",
      "train loss:0.06104323440957679\n",
      "train loss:0.058106386020097316\n",
      "train loss:0.023265570713162667\n",
      "train loss:0.08970151220574624\n",
      "train loss:0.09238117724082918\n",
      "train loss:0.039812835884433385\n",
      "train loss:0.05489748339801767\n",
      "train loss:0.05403572777490462\n",
      "train loss:0.09798694830269543\n",
      "train loss:0.06443582201506395\n",
      "train loss:0.09019923749593751\n",
      "train loss:0.04994202498633637\n",
      "train loss:0.08867175598435346\n",
      "train loss:0.04034031298993149\n",
      "train loss:0.047515557727910836\n",
      "train loss:0.10597025738948158\n",
      "train loss:0.11517044813771626\n",
      "train loss:0.04427111869710394\n",
      "train loss:0.053059485275884194\n",
      "train loss:0.05716569450120081\n",
      "train loss:0.06846306017674253\n",
      "train loss:0.13108750797208082\n",
      "train loss:0.04153544081192175\n",
      "train loss:0.06276015593421422\n",
      "train loss:0.08545590084782592\n",
      "train loss:0.08227110374590951\n",
      "train loss:0.08726190666856741\n",
      "train loss:0.1956692601940388\n",
      "train loss:0.21100124965964626\n",
      "train loss:0.08840139551403732\n",
      "train loss:0.03148634179095247\n",
      "train loss:0.12294305356696049\n",
      "train loss:0.08006952707350838\n",
      "train loss:0.06902183865341213\n",
      "train loss:0.10472352294475092\n",
      "train loss:0.10872302609307471\n",
      "train loss:0.13113678513991586\n",
      "train loss:0.08174244807788898\n",
      "train loss:0.08636818153758535\n",
      "train loss:0.14903280501328597\n",
      "train loss:0.06782158576848868\n",
      "train loss:0.09193362155442025\n",
      "train loss:0.06796660733386889\n",
      "train loss:0.14537155669746957\n",
      "train loss:0.053961052917307815\n",
      "train loss:0.04345762321718177\n",
      "train loss:0.09680488301581228\n",
      "train loss:0.08274968215463321\n",
      "train loss:0.1987695887834413\n",
      "train loss:0.15112214314054853\n",
      "train loss:0.053357577184409984\n",
      "train loss:0.08146208788530031\n",
      "train loss:0.07710637712998945\n",
      "train loss:0.14652439470367642\n",
      "train loss:0.13843580136269062\n",
      "train loss:0.13438501280504772\n",
      "train loss:0.12305816583074768\n",
      "train loss:0.0534455575248563\n",
      "train loss:0.134300824924058\n",
      "train loss:0.11183826169584307\n",
      "train loss:0.026162026539039165\n",
      "train loss:0.13886622757952938\n",
      "train loss:0.05899007041707536\n",
      "train loss:0.12030799940549537\n",
      "train loss:0.028389101435683232\n",
      "train loss:0.12129535450189027\n",
      "train loss:0.09384424388117607\n",
      "train loss:0.04735009475326026\n",
      "train loss:0.11135823277593175\n",
      "train loss:0.11924253494297316\n",
      "train loss:0.08638733575252389\n",
      "train loss:0.1086105769032936\n",
      "train loss:0.11411130125901829\n",
      "train loss:0.10532411176857231\n",
      "train loss:0.044819617234764256\n",
      "train loss:0.08436083675050648\n",
      "train loss:0.1265041154178988\n",
      "train loss:0.13675512778311363\n",
      "train loss:0.07953603295038326\n",
      "train loss:0.08171237006250084\n",
      "train loss:0.13335858833910774\n",
      "train loss:0.049002121044782\n",
      "train loss:0.11062239992596473\n",
      "train loss:0.09922588910452572\n",
      "train loss:0.09064289969682894\n",
      "train loss:0.08220015229024549\n",
      "train loss:0.05828643305526108\n",
      "train loss:0.07664315731990794\n",
      "train loss:0.06329515427804218\n",
      "train loss:0.09132393147890859\n",
      "train loss:0.08778704358776934\n",
      "train loss:0.048338306157595004\n",
      "train loss:0.0600583179403781\n",
      "train loss:0.05330355620307034\n",
      "train loss:0.08004352724237712\n",
      "train loss:0.056060477141721084\n",
      "train loss:0.1408577933934076\n",
      "train loss:0.06901921397546863\n",
      "train loss:0.0838091145110897\n",
      "train loss:0.061192608256948985\n",
      "train loss:0.06319448575984629\n",
      "train loss:0.048993150113690806\n",
      "train loss:0.07787745069947612\n",
      "train loss:0.08360221193668424\n",
      "train loss:0.10235800341806468\n",
      "train loss:0.10219465515477016\n",
      "train loss:0.12164006891788219\n",
      "train loss:0.059460442852402685\n",
      "train loss:0.1279402547621116\n",
      "train loss:0.13457752980276838\n",
      "train loss:0.08971858437975368\n",
      "train loss:0.13560299144354823\n",
      "train loss:0.07534065413007013\n",
      "train loss:0.06947990168780144\n",
      "train loss:0.06562174623206955\n",
      "train loss:0.07244283099290665\n",
      "train loss:0.08176898808670434\n",
      "train loss:0.047261407989037794\n",
      "train loss:0.10571077592314233\n",
      "train loss:0.03717702326547281\n",
      "train loss:0.12347769115386095\n",
      "train loss:0.10126309932723122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.06529321552513656\n",
      "train loss:0.07156972758874437\n",
      "train loss:0.15508986964085358\n",
      "train loss:0.07747994901750482\n",
      "train loss:0.08684338701261671\n",
      "train loss:0.12556012370076391\n",
      "train loss:0.0997322862466462\n",
      "train loss:0.09689617839257755\n",
      "train loss:0.09010033671116177\n",
      "train loss:0.05324874225309748\n",
      "train loss:0.12335709576789683\n",
      "train loss:0.07111950272625953\n",
      "train loss:0.04824614020434485\n",
      "train loss:0.06271355840176172\n",
      "train loss:0.06532387400257252\n",
      "train loss:0.1475128590860324\n",
      "train loss:0.07908599359692348\n",
      "train loss:0.08636125636308307\n",
      "train loss:0.0941666529787044\n",
      "train loss:0.0854689146556729\n",
      "train loss:0.10275815922227824\n",
      "train loss:0.08240790937765881\n",
      "train loss:0.1196725329236335\n",
      "train loss:0.10630128830526987\n",
      "train loss:0.087368477982186\n",
      "train loss:0.06856694394407803\n",
      "train loss:0.10754590591744918\n",
      "train loss:0.08817768531787404\n",
      "train loss:0.07028022843399769\n",
      "train loss:0.07413214347170977\n",
      "train loss:0.11552193148874836\n",
      "train loss:0.05055124881178935\n",
      "train loss:0.06055483887441157\n",
      "train loss:0.06039303808917133\n",
      "train loss:0.040915962609999655\n",
      "train loss:0.09197060084295622\n",
      "train loss:0.08884432264779325\n",
      "train loss:0.13291622313099938\n",
      "train loss:0.056632725471580075\n",
      "train loss:0.08104942915129591\n",
      "train loss:0.11942924034075032\n",
      "train loss:0.041269908565232286\n",
      "train loss:0.07029084148781495\n",
      "train loss:0.061719447635387156\n",
      "train loss:0.16317667551266835\n",
      "train loss:0.06817392364893876\n",
      "train loss:0.10500078925060391\n",
      "train loss:0.03576731456509671\n",
      "train loss:0.045652264195301634\n",
      "train loss:0.12863535086860747\n",
      "train loss:0.04959217646586675\n",
      "train loss:0.10580278758496339\n",
      "train loss:0.06549118905777733\n",
      "train loss:0.08528004931748359\n",
      "train loss:0.06518874502495572\n",
      "train loss:0.10233022745531382\n",
      "train loss:0.1554211969017034\n",
      "train loss:0.07139499470775063\n",
      "train loss:0.13053968655725212\n",
      "train loss:0.05559168215177354\n",
      "train loss:0.07904485839461711\n",
      "train loss:0.05910918084354057\n",
      "train loss:0.10447954448053375\n",
      "train loss:0.07566107352451863\n",
      "train loss:0.06175253593741837\n",
      "train loss:0.10762854345690295\n",
      "train loss:0.043014539985991244\n",
      "train loss:0.04094636053274406\n",
      "train loss:0.14806181024118248\n",
      "train loss:0.09774807494972187\n",
      "train loss:0.07669369624655184\n",
      "train loss:0.12356132830022833\n",
      "train loss:0.0931624967774305\n",
      "train loss:0.0476729224866295\n",
      "train loss:0.1250669958240221\n",
      "train loss:0.048101128638338\n",
      "train loss:0.10370427677679876\n",
      "train loss:0.1331428278323895\n",
      "train loss:0.12059389204635541\n",
      "train loss:0.040436839648068344\n",
      "train loss:0.06971083144344499\n",
      "train loss:0.0561439836244588\n",
      "train loss:0.12155043899631425\n",
      "train loss:0.06255814108150581\n",
      "train loss:0.11254284424444187\n",
      "train loss:0.09501887483390488\n",
      "train loss:0.05262748058302091\n",
      "train loss:0.13107408921202457\n",
      "train loss:0.049128820023831246\n",
      "train loss:0.0927693009526081\n",
      "train loss:0.07373823386468716\n",
      "train loss:0.06013807612085133\n",
      "train loss:0.08084150755961081\n",
      "train loss:0.04918039857146858\n",
      "train loss:0.03942335570412865\n",
      "train loss:0.08414105334698659\n",
      "train loss:0.1450884230168518\n",
      "train loss:0.05984538474783254\n",
      "train loss:0.14002004044209898\n",
      "train loss:0.12173796694510024\n",
      "train loss:0.08668023597575393\n",
      "train loss:0.042827078309399864\n",
      "train loss:0.07853896432242395\n",
      "train loss:0.11465675110688146\n",
      "train loss:0.07710989866324149\n",
      "train loss:0.04993005397230732\n",
      "train loss:0.07903328330450292\n",
      "train loss:0.1377421760403818\n",
      "train loss:0.11905989087891403\n",
      "train loss:0.04745865253140742\n",
      "train loss:0.07352291099219252\n",
      "train loss:0.11219715746280837\n",
      "train loss:0.051739608841941766\n",
      "train loss:0.07973481270871713\n",
      "train loss:0.09608830298876209\n",
      "train loss:0.17042645501441567\n",
      "train loss:0.20929261231664723\n",
      "train loss:0.04621412012816939\n",
      "train loss:0.043536361821515844\n",
      "train loss:0.09559875746640303\n",
      "train loss:0.09369677060103944\n",
      "train loss:0.1077412243651452\n",
      "train loss:0.18124896411967015\n",
      "train loss:0.07991985285413972\n",
      "train loss:0.09598930560489574\n",
      "train loss:0.16223641490554477\n",
      "train loss:0.08741502497933083\n",
      "train loss:0.026899752768350296\n",
      "train loss:0.1018419037373531\n",
      "train loss:0.20492229163852316\n",
      "train loss:0.04594818257043061\n",
      "train loss:0.04878616493601009\n",
      "train loss:0.070472284027012\n",
      "train loss:0.046797256659870466\n",
      "train loss:0.08393972267354483\n",
      "train loss:0.1511207615990912\n",
      "train loss:0.0860887214673709\n",
      "train loss:0.08801925970034759\n",
      "train loss:0.10166664944973115\n",
      "train loss:0.10608539090864186\n",
      "train loss:0.196858183712568\n",
      "train loss:0.10373312026074352\n",
      "train loss:0.096154497698501\n",
      "train loss:0.059853334148724534\n",
      "train loss:0.051316440622256286\n",
      "train loss:0.08129580011856605\n",
      "train loss:0.0685691706450791\n",
      "train loss:0.10145354846576286\n",
      "train loss:0.07678692419222838\n",
      "train loss:0.19332780722684917\n",
      "train loss:0.05733448042246235\n",
      "train loss:0.09226386882852351\n",
      "train loss:0.1326540496023455\n",
      "train loss:0.051610284682173685\n",
      "train loss:0.07070694836575665\n",
      "train loss:0.08129224963787107\n",
      "train loss:0.11949443904213058\n",
      "train loss:0.08935058037780165\n",
      "train loss:0.0608568452049643\n",
      "train loss:0.07383932018637392\n",
      "train loss:0.06933767325191925\n",
      "train loss:0.09379039540728161\n",
      "train loss:0.08639716483108359\n",
      "train loss:0.0665589003576702\n",
      "train loss:0.09511916966390721\n",
      "train loss:0.13338502203892383\n",
      "train loss:0.050597862827471356\n",
      "train loss:0.06788817043215853\n",
      "train loss:0.1462432100031446\n",
      "train loss:0.12705022896887136\n",
      "train loss:0.12402171484349317\n",
      "train loss:0.07406540433357733\n",
      "train loss:0.09422053892440926\n",
      "train loss:0.17409218390525513\n",
      "train loss:0.09550386813868413\n",
      "train loss:0.05425089339265427\n",
      "train loss:0.04289990967304285\n",
      "train loss:0.0393873999001927\n",
      "train loss:0.13970334803135806\n",
      "train loss:0.0603170748697854\n",
      "train loss:0.12382304049787096\n",
      "train loss:0.07308284880149354\n",
      "train loss:0.07821142110424045\n",
      "train loss:0.06924503260763196\n",
      "train loss:0.11369961249083226\n",
      "train loss:0.10572059115248124\n",
      "train loss:0.10257762184042077\n",
      "train loss:0.102773219444557\n",
      "train loss:0.12119256745318525\n",
      "train loss:0.10884358887300628\n",
      "train loss:0.1232166830301355\n",
      "train loss:0.07356604315506478\n",
      "train loss:0.15223759952487248\n",
      "train loss:0.09587537990401529\n",
      "train loss:0.07633715663443026\n",
      "train loss:0.10093674367799377\n",
      "train loss:0.19542904055078558\n",
      "train loss:0.1024611564290358\n",
      "train loss:0.08905422618510325\n",
      "train loss:0.20527211545874416\n",
      "train loss:0.08847164602613683\n",
      "train loss:0.023197028376866234\n",
      "train loss:0.11702010239700829\n",
      "train loss:0.06699583488727287\n",
      "train loss:0.08309287804290502\n",
      "train loss:0.060893492365070113\n",
      "train loss:0.08062943103680892\n",
      "train loss:0.045593194935230244\n",
      "train loss:0.12176700305437237\n",
      "train loss:0.10824788504623876\n",
      "train loss:0.03977073824593123\n",
      "train loss:0.052021540617245204\n",
      "train loss:0.08820561611150991\n",
      "train loss:0.08511971037476572\n",
      "train loss:0.06260819254592115\n",
      "train loss:0.10376563925072098\n",
      "train loss:0.04502402118821938\n",
      "train loss:0.0688509853263459\n",
      "train loss:0.132394917695215\n",
      "train loss:0.05184378883054817\n",
      "train loss:0.14415541489679903\n",
      "train loss:0.11679847382755719\n",
      "train loss:0.10006217534923058\n",
      "train loss:0.08814535178255208\n",
      "train loss:0.1174334424445131\n",
      "train loss:0.06344449937547349\n",
      "train loss:0.07519271989810423\n",
      "train loss:0.07011484563349991\n",
      "train loss:0.1470845856719273\n",
      "train loss:0.09674239381443189\n",
      "train loss:0.11377781304756528\n",
      "train loss:0.05997053000980498\n",
      "train loss:0.0692853538948504\n",
      "train loss:0.028691954537863613\n",
      "train loss:0.05517852979638618\n",
      "train loss:0.1309199811740132\n",
      "train loss:0.07524246468557803\n",
      "train loss:0.05409746945600674\n",
      "train loss:0.07089720463633943\n",
      "train loss:0.11118397868622766\n",
      "train loss:0.12247766101624924\n",
      "train loss:0.06279367404456641\n",
      "train loss:0.07533662960891246\n",
      "train loss:0.09457273778537256\n",
      "train loss:0.0718590119466232\n",
      "train loss:0.04851341557667697\n",
      "train loss:0.11324743141456411\n",
      "train loss:0.10132525138812032\n",
      "train loss:0.10066516246892249\n",
      "train loss:0.055385776830909526\n",
      "train loss:0.11909311326707123\n",
      "train loss:0.17778813344465172\n",
      "train loss:0.09601770419708183\n",
      "train loss:0.10802110639611723\n",
      "train loss:0.12437547543840122\n",
      "=== epoch:17, train acc:0.964, test acc:0.904 ===\n",
      "train loss:0.11407360903581765\n",
      "train loss:0.085206956701751\n",
      "train loss:0.05442752275772737\n",
      "train loss:0.09364032770158616\n",
      "train loss:0.049500028967048346\n",
      "train loss:0.05343431534205516\n",
      "train loss:0.09970425124467386\n",
      "train loss:0.06976001062252692\n",
      "train loss:0.06986767259793476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.11233709294996058\n",
      "train loss:0.10170833080710215\n",
      "train loss:0.060695091409249946\n",
      "train loss:0.07542300905335952\n",
      "train loss:0.11662666880954968\n",
      "train loss:0.1445513326314188\n",
      "train loss:0.07171905427515123\n",
      "train loss:0.10307311446740418\n",
      "train loss:0.09264616834968727\n",
      "train loss:0.16603309288668425\n",
      "train loss:0.06549529000491125\n",
      "train loss:0.13792011952060731\n",
      "train loss:0.0707125873628144\n",
      "train loss:0.10851906331723697\n",
      "train loss:0.1330617020623018\n",
      "train loss:0.0948993413116928\n",
      "train loss:0.04803691206926215\n",
      "train loss:0.10471767974556326\n",
      "train loss:0.20360841813100974\n",
      "train loss:0.04256850462750652\n",
      "train loss:0.10412852549439011\n",
      "train loss:0.09647184385027063\n",
      "train loss:0.15168343719390395\n",
      "train loss:0.09293926466486684\n",
      "train loss:0.09289923511957604\n",
      "train loss:0.038102292532428944\n",
      "train loss:0.06923366859866471\n",
      "train loss:0.1247325720229868\n",
      "train loss:0.064391591565815\n",
      "train loss:0.07032178633687651\n",
      "train loss:0.057135588168233574\n",
      "train loss:0.0987690957273686\n",
      "train loss:0.040065089516563804\n",
      "train loss:0.11334312186914733\n",
      "train loss:0.06268152174572736\n",
      "train loss:0.08541397560213052\n",
      "train loss:0.10970570586676337\n",
      "train loss:0.04557186319172499\n",
      "train loss:0.06360888016181732\n",
      "train loss:0.15213691882070202\n",
      "train loss:0.0684811431257317\n",
      "train loss:0.07275697060243878\n",
      "train loss:0.0388514846402539\n",
      "train loss:0.04896472507228409\n",
      "train loss:0.05773080720975074\n",
      "train loss:0.09938108684801254\n",
      "train loss:0.1817023641961672\n",
      "train loss:0.11637515340783787\n",
      "train loss:0.08219154653684728\n",
      "train loss:0.05108493267628905\n",
      "train loss:0.0650663419391469\n",
      "train loss:0.059034213081652714\n",
      "train loss:0.10546262720118094\n",
      "train loss:0.14002067473679652\n",
      "train loss:0.0691919343205475\n",
      "train loss:0.025723096416410206\n",
      "train loss:0.04898722054006281\n",
      "train loss:0.04658816666512\n",
      "train loss:0.11359804664554388\n",
      "train loss:0.13957215394044512\n",
      "train loss:0.08642078166422591\n",
      "train loss:0.11706378789996102\n",
      "train loss:0.0842127701229717\n",
      "train loss:0.05685568143937186\n",
      "train loss:0.07573287945436938\n",
      "train loss:0.058247177852743075\n",
      "train loss:0.14103300753723097\n",
      "train loss:0.07769995981244641\n",
      "train loss:0.10027311015549147\n",
      "train loss:0.1609710932657726\n",
      "train loss:0.1888665959062452\n",
      "train loss:0.11407333020483115\n",
      "train loss:0.08565051547148947\n",
      "train loss:0.05804807179631727\n",
      "train loss:0.18621304719226778\n",
      "train loss:0.08916578080585971\n",
      "train loss:0.16432018111657704\n",
      "train loss:0.05914648331762996\n",
      "train loss:0.11590605043390317\n",
      "train loss:0.06832752948167659\n",
      "train loss:0.15796055200709777\n",
      "train loss:0.05153287891056823\n",
      "train loss:0.15654566881876877\n",
      "train loss:0.16274825238314322\n",
      "train loss:0.08203565080120749\n",
      "train loss:0.08826903817529239\n",
      "train loss:0.0671632934082872\n",
      "train loss:0.06375541246840362\n",
      "train loss:0.08043755781186934\n",
      "train loss:0.0864813164236656\n",
      "train loss:0.062000376259634296\n",
      "train loss:0.06160499331994035\n",
      "train loss:0.0924871949422342\n",
      "train loss:0.07187862640388026\n",
      "train loss:0.08334528110563634\n",
      "train loss:0.048683371090292124\n",
      "train loss:0.1145944333149316\n",
      "train loss:0.08088564288158473\n",
      "train loss:0.07651173855162098\n",
      "train loss:0.07696788124343269\n",
      "train loss:0.04791626437768973\n",
      "train loss:0.10883228244405536\n",
      "train loss:0.10711579155590428\n",
      "train loss:0.07188513163881904\n",
      "train loss:0.08763765686946375\n",
      "train loss:0.08567710018056801\n",
      "train loss:0.059703142595250475\n",
      "train loss:0.14827346568968205\n",
      "train loss:0.07595601991648906\n",
      "train loss:0.10180464361797022\n",
      "train loss:0.13641646456034148\n",
      "train loss:0.08742262475565615\n",
      "train loss:0.05936531957916184\n",
      "train loss:0.09774441139321771\n",
      "train loss:0.07574650870206985\n",
      "train loss:0.036387078299631725\n",
      "train loss:0.06505524381612453\n",
      "train loss:0.07712112630000627\n",
      "train loss:0.07119518802102007\n",
      "train loss:0.06839549107844907\n",
      "train loss:0.06943257036693601\n",
      "train loss:0.11474531852362255\n",
      "train loss:0.04501076270542978\n",
      "train loss:0.028323046073887602\n",
      "train loss:0.055974772626962696\n",
      "train loss:0.035209685553714114\n",
      "train loss:0.08372505561391445\n",
      "train loss:0.029834542187074865\n",
      "train loss:0.047247275482616535\n",
      "train loss:0.03822203830474536\n",
      "train loss:0.050666459947411834\n",
      "train loss:0.036766424054879905\n",
      "train loss:0.07681970595376174\n",
      "train loss:0.0371110400959491\n",
      "train loss:0.059599915334785154\n",
      "train loss:0.14355204175254901\n",
      "train loss:0.07229512098502952\n",
      "train loss:0.1335926736994915\n",
      "train loss:0.08004650562547523\n",
      "train loss:0.07914580393324513\n",
      "train loss:0.07288706824153607\n",
      "train loss:0.07984605804789592\n",
      "train loss:0.073098414194691\n",
      "train loss:0.036254075021382136\n",
      "train loss:0.11472888511679155\n",
      "train loss:0.09119848857088186\n",
      "train loss:0.05831787237621392\n",
      "train loss:0.090174457393267\n",
      "train loss:0.02833993366935452\n",
      "train loss:0.2069436973673691\n",
      "train loss:0.07049737737584952\n",
      "train loss:0.07738759397556022\n",
      "train loss:0.10697255979870554\n",
      "train loss:0.07872487782980453\n",
      "train loss:0.030399007790585755\n",
      "train loss:0.02145321511230964\n",
      "train loss:0.043973458083230846\n",
      "train loss:0.084942719837534\n",
      "train loss:0.05474461059267321\n",
      "train loss:0.09147582707241497\n",
      "train loss:0.07505200759340282\n",
      "train loss:0.08433690878445901\n",
      "train loss:0.11742942049886977\n",
      "train loss:0.14670519807486432\n",
      "train loss:0.04778142450261116\n",
      "train loss:0.1160359155225006\n",
      "train loss:0.07161273789477109\n",
      "train loss:0.10027183903671187\n",
      "train loss:0.06926471032871499\n",
      "train loss:0.08843576808922501\n",
      "train loss:0.16066241450599372\n",
      "train loss:0.12275999774876717\n",
      "train loss:0.11484774971455325\n",
      "train loss:0.06575774060910283\n",
      "train loss:0.0342993576005278\n",
      "train loss:0.06970645737694246\n",
      "train loss:0.06430697485614821\n",
      "train loss:0.08602464701636413\n",
      "train loss:0.07501615253970527\n",
      "train loss:0.06328710851133121\n",
      "train loss:0.11207830240118907\n",
      "train loss:0.07346167547415856\n",
      "train loss:0.19182298477307205\n",
      "train loss:0.08629311026179534\n",
      "train loss:0.077738067838885\n",
      "train loss:0.10594957561468156\n",
      "train loss:0.07386158716679106\n",
      "train loss:0.06842789948196878\n",
      "train loss:0.08069986036787302\n",
      "train loss:0.07715634361069693\n",
      "train loss:0.061993435578467065\n",
      "train loss:0.10279220207430206\n",
      "train loss:0.053503238918895475\n",
      "train loss:0.17004992549543904\n",
      "train loss:0.04015469869538973\n",
      "train loss:0.05831309663293742\n",
      "train loss:0.05458326431609646\n",
      "train loss:0.10042585629072857\n",
      "train loss:0.08548933564663509\n",
      "train loss:0.08988574414889562\n",
      "train loss:0.07659231551994371\n",
      "train loss:0.08630936120543613\n",
      "train loss:0.07069945829668749\n",
      "train loss:0.09160520331598856\n",
      "train loss:0.14558952436633926\n",
      "train loss:0.10525952139596835\n",
      "train loss:0.07088625683851422\n",
      "train loss:0.1371756905029993\n",
      "train loss:0.07648544436104947\n",
      "train loss:0.07908370129353891\n",
      "train loss:0.05191676685792307\n",
      "train loss:0.09623500032959469\n",
      "train loss:0.0820258627855608\n",
      "train loss:0.08829507386574653\n",
      "train loss:0.06222092555610885\n",
      "train loss:0.10016184421585031\n",
      "train loss:0.04305634094494633\n",
      "train loss:0.212558403661738\n",
      "train loss:0.149100780527401\n",
      "train loss:0.06904517560263962\n",
      "train loss:0.05616884880394268\n",
      "train loss:0.06079594957294862\n",
      "train loss:0.05641523458346368\n",
      "train loss:0.18194062975198258\n",
      "train loss:0.06662595850755662\n",
      "train loss:0.11139856955913474\n",
      "train loss:0.17146409031710227\n",
      "train loss:0.09706826143135361\n",
      "train loss:0.14022611429385937\n",
      "train loss:0.1759014400336394\n",
      "train loss:0.04854407428375211\n",
      "train loss:0.07775372269531036\n",
      "train loss:0.1130025514094207\n",
      "train loss:0.07232272683280758\n",
      "train loss:0.16002814893227796\n",
      "train loss:0.1171151236292889\n",
      "train loss:0.14876557045858818\n",
      "train loss:0.06981273796081788\n",
      "train loss:0.07033983688444093\n",
      "train loss:0.05252847712237688\n",
      "train loss:0.0675128096561747\n",
      "train loss:0.07049478898473505\n",
      "train loss:0.09544964035296429\n",
      "train loss:0.10101610789801682\n",
      "train loss:0.09674145882277534\n",
      "train loss:0.09481190556894015\n",
      "train loss:0.07778405629089469\n",
      "train loss:0.1228276019311449\n",
      "train loss:0.09551313774425767\n",
      "train loss:0.12652399722713528\n",
      "train loss:0.08383441548212518\n",
      "train loss:0.12761789115102123\n",
      "train loss:0.0680720187460932\n",
      "train loss:0.13063640384387357\n",
      "train loss:0.14793712100185646\n",
      "train loss:0.034681052472938456\n",
      "train loss:0.08494056781980829\n",
      "train loss:0.06566218568574521\n",
      "train loss:0.10583856035159268\n",
      "train loss:0.08138376413546611\n",
      "train loss:0.13271587420975203\n",
      "train loss:0.07173654193399208\n",
      "train loss:0.03978671345106815\n",
      "train loss:0.057567641083775364\n",
      "train loss:0.12247852981392932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0752188068253523\n",
      "train loss:0.10627936234602448\n",
      "train loss:0.0750425494796308\n",
      "train loss:0.06438019319983872\n",
      "train loss:0.03475492118123053\n",
      "train loss:0.13607252269958567\n",
      "train loss:0.032042717615574666\n",
      "train loss:0.03203834200034719\n",
      "train loss:0.03896986111149408\n",
      "train loss:0.09681320381586592\n",
      "train loss:0.13477613364523552\n",
      "train loss:0.05591699611261111\n",
      "train loss:0.07895806473146473\n",
      "train loss:0.10915442689991188\n",
      "train loss:0.03255888344599221\n",
      "train loss:0.05801986607485654\n",
      "train loss:0.07668267328860467\n",
      "train loss:0.08917020175775871\n",
      "train loss:0.09312917633030222\n",
      "train loss:0.041264027234185256\n",
      "train loss:0.06846560452514544\n",
      "train loss:0.06974067618581004\n",
      "train loss:0.06584971448155744\n",
      "train loss:0.14264388211944803\n",
      "train loss:0.1077424188873369\n",
      "train loss:0.07065593731814677\n",
      "train loss:0.06706719040500682\n",
      "train loss:0.12920870735258805\n",
      "train loss:0.15587193308053368\n",
      "train loss:0.10584087115143212\n",
      "train loss:0.04054059349353462\n",
      "train loss:0.04530348131664986\n",
      "train loss:0.09475205213633005\n",
      "train loss:0.0833525828248656\n",
      "train loss:0.12106108177568073\n",
      "train loss:0.06257063623376996\n",
      "train loss:0.04409932514933751\n",
      "train loss:0.13401462198028705\n",
      "train loss:0.06950498963520448\n",
      "train loss:0.08121085461970054\n",
      "train loss:0.05860626967084357\n",
      "train loss:0.17264156098809283\n",
      "train loss:0.1213753087723743\n",
      "train loss:0.06903113953825653\n",
      "train loss:0.07744069904036496\n",
      "train loss:0.09951477650235076\n",
      "train loss:0.09861264315228535\n",
      "train loss:0.13388565450437384\n",
      "train loss:0.14321230889251374\n",
      "train loss:0.046141991030096446\n",
      "train loss:0.0850770471273579\n",
      "train loss:0.09325355453883485\n",
      "train loss:0.05579601690851394\n",
      "train loss:0.10496278101559468\n",
      "train loss:0.06277477329267145\n",
      "train loss:0.06193384919826521\n",
      "train loss:0.12240781744077775\n",
      "train loss:0.14178793203710494\n",
      "train loss:0.07614938944200463\n",
      "train loss:0.08028360451253759\n",
      "train loss:0.17023921050974852\n",
      "train loss:0.061855716365133206\n",
      "train loss:0.04460804500788265\n",
      "train loss:0.07210010180830792\n",
      "train loss:0.05955900479345834\n",
      "train loss:0.11556909374524432\n",
      "train loss:0.10699844116782377\n",
      "train loss:0.05859322311967825\n",
      "train loss:0.07219656176998818\n",
      "train loss:0.11654228436724973\n",
      "train loss:0.09348625318808367\n",
      "train loss:0.06182615543345213\n",
      "train loss:0.0559972430756264\n",
      "train loss:0.06756969238957254\n",
      "train loss:0.095961481864808\n",
      "train loss:0.0802260382462547\n",
      "train loss:0.08028311658363639\n",
      "train loss:0.20242079053475884\n",
      "train loss:0.07666521561750779\n",
      "train loss:0.05770771532971614\n",
      "train loss:0.12597299320708752\n",
      "train loss:0.10159939308988082\n",
      "train loss:0.09134415021493858\n",
      "train loss:0.05950802443468147\n",
      "train loss:0.1342550243815008\n",
      "train loss:0.06820485300327633\n",
      "train loss:0.08034685068951763\n",
      "train loss:0.1350935769879538\n",
      "train loss:0.0628880321625293\n",
      "train loss:0.05815627360516506\n",
      "train loss:0.11429231396575996\n",
      "train loss:0.10905704376209101\n",
      "train loss:0.07904914713772462\n",
      "train loss:0.024242847937271748\n",
      "train loss:0.08520604423669748\n",
      "train loss:0.08773804660490375\n",
      "train loss:0.038617854655298024\n",
      "train loss:0.08578583544520242\n",
      "train loss:0.06701959078701948\n",
      "train loss:0.09087832635563645\n",
      "train loss:0.04345051392510627\n",
      "train loss:0.056291694660939716\n",
      "train loss:0.10449652224936416\n",
      "train loss:0.08448319954642879\n",
      "train loss:0.08482201771702545\n",
      "train loss:0.09387753811315645\n",
      "train loss:0.03403055104717196\n",
      "train loss:0.03847722372247309\n",
      "train loss:0.06440206505231118\n",
      "train loss:0.08510863599737567\n",
      "train loss:0.08794916967972442\n",
      "train loss:0.048534819612281316\n",
      "train loss:0.03992439729333874\n",
      "train loss:0.06312087732974851\n",
      "train loss:0.060060954900814645\n",
      "train loss:0.07234966369690589\n",
      "train loss:0.11157661901624115\n",
      "train loss:0.036701673955327266\n",
      "train loss:0.054389661653903784\n",
      "train loss:0.15013706944804955\n",
      "train loss:0.08898517226903191\n",
      "train loss:0.08547199728279625\n",
      "train loss:0.06866225382974486\n",
      "train loss:0.08238406197720441\n",
      "train loss:0.07713789484546293\n",
      "train loss:0.07468403057547732\n",
      "train loss:0.07406454310033485\n",
      "train loss:0.07371992601981357\n",
      "train loss:0.04703222921916966\n",
      "train loss:0.04433665299162531\n",
      "train loss:0.07237560725390317\n",
      "train loss:0.05252586286911131\n",
      "train loss:0.06160648843500697\n",
      "train loss:0.02984063249275949\n",
      "train loss:0.11561235608528735\n",
      "train loss:0.04098559635163305\n",
      "train loss:0.08127469046894877\n",
      "train loss:0.10187464539929193\n",
      "train loss:0.14786841977288745\n",
      "train loss:0.07842607565990123\n",
      "train loss:0.10588880982065003\n",
      "train loss:0.09756201662178919\n",
      "train loss:0.05468603756261751\n",
      "train loss:0.061926140299267456\n",
      "train loss:0.09104308087721914\n",
      "train loss:0.049078821552810875\n",
      "train loss:0.0864491246662742\n",
      "train loss:0.06254746134477351\n",
      "train loss:0.06355248023220887\n",
      "train loss:0.08871901795801854\n",
      "train loss:0.15342971501149047\n",
      "train loss:0.16589746624481386\n",
      "train loss:0.15808568351088845\n",
      "train loss:0.09463119370553333\n",
      "train loss:0.06404146732787491\n",
      "train loss:0.06511041569805757\n",
      "train loss:0.0645985139562434\n",
      "train loss:0.11826121069709714\n",
      "train loss:0.034399461792247295\n",
      "train loss:0.07080073934043878\n",
      "train loss:0.024561113555483446\n",
      "train loss:0.048167555732715084\n",
      "train loss:0.0897246238225699\n",
      "train loss:0.10136278715285812\n",
      "train loss:0.060329547605350226\n",
      "train loss:0.06788127315513758\n",
      "train loss:0.037978854456308025\n",
      "train loss:0.08454226413560048\n",
      "train loss:0.038653979881964146\n",
      "train loss:0.17305399679718392\n",
      "train loss:0.08763099348659331\n",
      "train loss:0.08084348808270007\n",
      "train loss:0.08436022904202492\n",
      "train loss:0.05158163200362779\n",
      "train loss:0.1667847309696365\n",
      "train loss:0.040135907762270454\n",
      "train loss:0.05212528497198877\n",
      "train loss:0.0491212022320234\n",
      "train loss:0.0650621340958755\n",
      "train loss:0.06949239499904845\n",
      "train loss:0.06551206782175557\n",
      "train loss:0.06199568027715148\n",
      "train loss:0.03704993659417954\n",
      "train loss:0.09836160506335996\n",
      "train loss:0.05320817964386755\n",
      "train loss:0.09224758429596125\n",
      "train loss:0.08816499267356832\n",
      "train loss:0.07554704244119159\n",
      "train loss:0.07191235273276032\n",
      "train loss:0.022789884498160044\n",
      "train loss:0.061077792454712336\n",
      "train loss:0.05956095588031724\n",
      "train loss:0.08475706506414284\n",
      "train loss:0.11811950374823141\n",
      "train loss:0.06258624582386785\n",
      "train loss:0.09450587982343983\n",
      "train loss:0.1277383801360337\n",
      "train loss:0.05878494329482531\n",
      "train loss:0.06919755993712859\n",
      "train loss:0.10868343209725788\n",
      "train loss:0.05039415346478383\n",
      "train loss:0.06669833521967587\n",
      "train loss:0.07653996560926468\n",
      "train loss:0.11292470660414893\n",
      "train loss:0.05399725303349879\n",
      "train loss:0.07644676149447081\n",
      "train loss:0.07193419311668144\n",
      "train loss:0.036953204786299175\n",
      "train loss:0.06821159738179175\n",
      "train loss:0.08477888121968277\n",
      "train loss:0.1441574181883683\n",
      "train loss:0.13822233661549707\n",
      "train loss:0.06380988414083863\n",
      "train loss:0.07978298987194812\n",
      "train loss:0.0933875266029103\n",
      "train loss:0.06690100460865955\n",
      "train loss:0.06111271216482489\n",
      "train loss:0.14685975147871916\n",
      "train loss:0.18111022902429116\n",
      "train loss:0.09872530427974571\n",
      "train loss:0.08320666884120437\n",
      "train loss:0.0432274268393644\n",
      "train loss:0.14647233099338672\n",
      "train loss:0.0962160287028868\n",
      "train loss:0.08166046222726778\n",
      "train loss:0.12035846680091095\n",
      "train loss:0.08267568929726879\n",
      "train loss:0.10767391028656029\n",
      "train loss:0.0531089627142903\n",
      "train loss:0.07232947247646063\n",
      "train loss:0.10543383302193675\n",
      "train loss:0.029592777763039802\n",
      "train loss:0.12745860381701546\n",
      "train loss:0.04517027242433163\n",
      "train loss:0.078945836060218\n",
      "train loss:0.09219184938541906\n",
      "train loss:0.06834312662932056\n",
      "train loss:0.10914938275584707\n",
      "train loss:0.08512678382154519\n",
      "train loss:0.02724645696037247\n",
      "train loss:0.0892302125387508\n",
      "train loss:0.06924402142859994\n",
      "train loss:0.08818048701604297\n",
      "train loss:0.02850329734423126\n",
      "train loss:0.03993820450603235\n",
      "train loss:0.030784194719398375\n",
      "train loss:0.10741646727779433\n",
      "train loss:0.0774755544037285\n",
      "train loss:0.0596573571833255\n",
      "train loss:0.06557360659971032\n",
      "train loss:0.1039440788979422\n",
      "train loss:0.08633044240082693\n",
      "train loss:0.09119982616776014\n",
      "train loss:0.04821559139470644\n",
      "train loss:0.06386278724468128\n",
      "train loss:0.058939853291520336\n",
      "train loss:0.08135384532671389\n",
      "train loss:0.055444621101979015\n",
      "train loss:0.06738560585005392\n",
      "train loss:0.06972555433062212\n",
      "train loss:0.14718172983363564\n",
      "train loss:0.03513346872140833\n",
      "train loss:0.06100724669601613\n",
      "train loss:0.14092421660703558\n",
      "train loss:0.14661372262216368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0558389110692983\n",
      "train loss:0.05212078330426901\n",
      "train loss:0.1389384622912565\n",
      "train loss:0.10731214938803005\n",
      "train loss:0.04111410196545709\n",
      "train loss:0.07362287775254996\n",
      "train loss:0.0652596146057165\n",
      "train loss:0.09977435124999008\n",
      "train loss:0.11014666247269612\n",
      "train loss:0.0885728413247133\n",
      "train loss:0.07477351679362966\n",
      "train loss:0.14533042634159443\n",
      "train loss:0.03800793077932584\n",
      "train loss:0.052668831250185316\n",
      "train loss:0.10525798029916408\n",
      "train loss:0.08321572092572183\n",
      "train loss:0.05192523215805357\n",
      "train loss:0.0921098355994529\n",
      "train loss:0.06576848759673554\n",
      "train loss:0.05213606015338382\n",
      "train loss:0.055210133174071876\n",
      "train loss:0.0466260435324563\n",
      "train loss:0.10272611867733389\n",
      "train loss:0.09282421012867227\n",
      "train loss:0.046141071065702415\n",
      "train loss:0.09322061512996256\n",
      "train loss:0.05562932774772048\n",
      "train loss:0.05870532567698022\n",
      "train loss:0.0669526454841216\n",
      "train loss:0.07456313124610107\n",
      "train loss:0.06442685287438384\n",
      "train loss:0.06992707210445256\n",
      "train loss:0.06419044040163147\n",
      "train loss:0.054880632701121354\n",
      "train loss:0.0708753448075754\n",
      "train loss:0.07742641463035346\n",
      "train loss:0.20060931181231215\n",
      "train loss:0.0343038432073681\n",
      "train loss:0.02278305466430353\n",
      "train loss:0.04280530554655668\n",
      "train loss:0.0600277630458623\n",
      "train loss:0.12595208429308427\n",
      "train loss:0.045785836366157184\n",
      "train loss:0.11758715325050374\n",
      "train loss:0.10051545869763219\n",
      "train loss:0.08987795425540714\n",
      "train loss:0.07317462621150138\n",
      "train loss:0.108425915865842\n",
      "train loss:0.09387975008537408\n",
      "train loss:0.05487667657486856\n",
      "train loss:0.07982357103141187\n",
      "train loss:0.0397934041325371\n",
      "train loss:0.07382671807765923\n",
      "train loss:0.040885573377163344\n",
      "train loss:0.029504504994373598\n",
      "train loss:0.055367161265709494\n",
      "train loss:0.14245044918455138\n",
      "train loss:0.017618534267171308\n",
      "train loss:0.08829543793827886\n",
      "train loss:0.02888955951044018\n",
      "train loss:0.07798119223293208\n",
      "=== epoch:18, train acc:0.974, test acc:0.915 ===\n",
      "train loss:0.05227642759301949\n",
      "train loss:0.09885751769194051\n",
      "train loss:0.05099644297057714\n",
      "train loss:0.06575708218685124\n",
      "train loss:0.09226311280724503\n",
      "train loss:0.15122611882376988\n",
      "train loss:0.027900861140506033\n",
      "train loss:0.1124928483087336\n",
      "train loss:0.054066970526593094\n",
      "train loss:0.047044570259316014\n",
      "train loss:0.04819144104151108\n",
      "train loss:0.05622216541960853\n",
      "train loss:0.0603278923756001\n",
      "train loss:0.06577427572242942\n",
      "train loss:0.10004009269997217\n",
      "train loss:0.1367997386568648\n",
      "train loss:0.07562548966755107\n",
      "train loss:0.07726749964802714\n",
      "train loss:0.06348057243230974\n",
      "train loss:0.05152037359989005\n",
      "train loss:0.11236486692221716\n",
      "train loss:0.062149351071059684\n",
      "train loss:0.06476989929956463\n",
      "train loss:0.05559417498231138\n",
      "train loss:0.0822069266713065\n",
      "train loss:0.0744552818998614\n",
      "train loss:0.1406601477074038\n",
      "train loss:0.08104887352676161\n",
      "train loss:0.0851812528489043\n",
      "train loss:0.03454778965998713\n",
      "train loss:0.03766014567244194\n",
      "train loss:0.10281503719754674\n",
      "train loss:0.09015976294678854\n",
      "train loss:0.08729882866189\n",
      "train loss:0.05130562677414591\n",
      "train loss:0.06957964486061813\n",
      "train loss:0.12627719087204678\n",
      "train loss:0.09405382970666543\n",
      "train loss:0.054098829807237035\n",
      "train loss:0.051360178060764615\n",
      "train loss:0.07462503235771292\n",
      "train loss:0.1302634774796042\n",
      "train loss:0.03535634591258659\n",
      "train loss:0.14444279113218403\n",
      "train loss:0.06450906067501817\n",
      "train loss:0.10587637091445297\n",
      "train loss:0.043774428997844686\n",
      "train loss:0.0790968308794614\n",
      "train loss:0.04606266290441915\n",
      "train loss:0.11310840035797279\n",
      "train loss:0.03966472077069493\n",
      "train loss:0.05160896442964966\n",
      "train loss:0.07616504919645277\n",
      "train loss:0.0786537387565063\n",
      "train loss:0.05987071609722427\n",
      "train loss:0.0824580605628549\n",
      "train loss:0.17176978744569063\n",
      "train loss:0.05249718758498552\n",
      "train loss:0.06289824220722874\n",
      "train loss:0.06032669213635747\n",
      "train loss:0.038378368410602985\n",
      "train loss:0.09408705717725056\n",
      "train loss:0.06724203239958723\n",
      "train loss:0.11179110905649281\n",
      "train loss:0.05928113759105507\n",
      "train loss:0.12602020602306874\n",
      "train loss:0.1452882922452963\n",
      "train loss:0.10272121873342392\n",
      "train loss:0.06943181997978617\n",
      "train loss:0.05246438775603862\n",
      "train loss:0.06326735796470812\n",
      "train loss:0.11608677020369214\n",
      "train loss:0.047264692517842335\n",
      "train loss:0.11222336599937474\n",
      "train loss:0.08585564643661525\n",
      "train loss:0.03700265664980913\n",
      "train loss:0.09008363739909735\n",
      "train loss:0.0629899049106046\n",
      "train loss:0.1076723948550989\n",
      "train loss:0.0626283372783845\n",
      "train loss:0.08523243771031169\n",
      "train loss:0.05607867892475843\n",
      "train loss:0.07835964566602362\n",
      "train loss:0.11390606258401453\n",
      "train loss:0.11032839070824937\n",
      "train loss:0.07439463109566666\n",
      "train loss:0.06287873224778039\n",
      "train loss:0.054879708167229584\n",
      "train loss:0.03814210541779229\n",
      "train loss:0.18760816968146662\n",
      "train loss:0.08346186598188138\n",
      "train loss:0.11317856980553488\n",
      "train loss:0.06438291165930654\n",
      "train loss:0.057718728466469506\n",
      "train loss:0.08445613607544585\n",
      "train loss:0.056553380048468015\n",
      "train loss:0.0657205341361649\n",
      "train loss:0.09899168570397142\n",
      "train loss:0.038592483746291956\n",
      "train loss:0.07136770817170453\n",
      "train loss:0.07650050751488027\n",
      "train loss:0.06336754437619406\n",
      "train loss:0.08272912799073259\n",
      "train loss:0.10043417233493653\n",
      "train loss:0.07664402597249724\n",
      "train loss:0.04668949927096852\n",
      "train loss:0.08438836377805488\n",
      "train loss:0.07039238336782525\n",
      "train loss:0.04535377545339185\n",
      "train loss:0.061800925646768985\n",
      "train loss:0.08366625199142964\n",
      "train loss:0.11727174352040315\n",
      "train loss:0.12904184053949153\n",
      "train loss:0.12004996623890127\n",
      "train loss:0.0638408534037227\n",
      "train loss:0.054792853177381806\n",
      "train loss:0.024440567013571356\n",
      "train loss:0.03272026594489879\n",
      "train loss:0.08451676392730127\n",
      "train loss:0.06513615665752433\n",
      "train loss:0.020735822784865077\n",
      "train loss:0.06070460772022034\n",
      "train loss:0.039323856506642094\n",
      "train loss:0.029366099546716172\n",
      "train loss:0.08818560025404494\n",
      "train loss:0.042665408850988636\n",
      "train loss:0.07341125346491556\n",
      "train loss:0.16208807943016665\n",
      "train loss:0.08899350053225069\n",
      "train loss:0.058981190045201054\n",
      "train loss:0.07483482755451912\n",
      "train loss:0.07999762921258098\n",
      "train loss:0.10870944423232903\n",
      "train loss:0.07298961736400922\n",
      "train loss:0.053549086088996375\n",
      "train loss:0.04779997110660675\n",
      "train loss:0.03072088813762174\n",
      "train loss:0.08594184755983106\n",
      "train loss:0.0489850791705482\n",
      "train loss:0.08175244009586169\n",
      "train loss:0.044607286713648116\n",
      "train loss:0.02260261288141257\n",
      "train loss:0.0731604904050343\n",
      "train loss:0.0483860843484678\n",
      "train loss:0.10861061792112484\n",
      "train loss:0.09169674587930926\n",
      "train loss:0.17938643583483188\n",
      "train loss:0.06219502448382833\n",
      "train loss:0.13890914137841015\n",
      "train loss:0.09784827528258494\n",
      "train loss:0.07439118635566096\n",
      "train loss:0.044037479847780704\n",
      "train loss:0.044482201386705486\n",
      "train loss:0.18829109489100732\n",
      "train loss:0.050883615116168006\n",
      "train loss:0.09764707088497335\n",
      "train loss:0.10647006617587096\n",
      "train loss:0.09765898838870088\n",
      "train loss:0.07720458709797481\n",
      "train loss:0.09107391714300103\n",
      "train loss:0.03449926684405401\n",
      "train loss:0.1241291547707816\n",
      "train loss:0.08944909152641893\n",
      "train loss:0.05565221987861668\n",
      "train loss:0.07553378066974191\n",
      "train loss:0.11119905491579227\n",
      "train loss:0.08804580221235568\n",
      "train loss:0.07440618127829461\n",
      "train loss:0.04986313928389207\n",
      "train loss:0.18371380338303328\n",
      "train loss:0.07259352595604439\n",
      "train loss:0.09493086286361803\n",
      "train loss:0.034110178636758824\n",
      "train loss:0.12695029414160466\n",
      "train loss:0.0722719839964001\n",
      "train loss:0.08686145530755636\n",
      "train loss:0.059643298295858564\n",
      "train loss:0.039820673582486144\n",
      "train loss:0.07919188662795061\n",
      "train loss:0.18261194356545699\n",
      "train loss:0.09109208542508247\n",
      "train loss:0.08422577680703996\n",
      "train loss:0.06223808669645013\n",
      "train loss:0.0957733446554147\n",
      "train loss:0.04603789201713802\n",
      "train loss:0.06861417822456202\n",
      "train loss:0.07531980961635334\n",
      "train loss:0.09812179885562983\n",
      "train loss:0.10485789376197582\n",
      "train loss:0.02619470247272894\n",
      "train loss:0.06968188830916669\n",
      "train loss:0.13657314698731374\n",
      "train loss:0.13176957605457087\n",
      "train loss:0.07704214925634217\n",
      "train loss:0.06635157052740903\n",
      "train loss:0.054613309350627054\n",
      "train loss:0.07907394392571833\n",
      "train loss:0.1633822728843916\n",
      "train loss:0.10564622868301429\n",
      "train loss:0.04894510934366399\n",
      "train loss:0.06585330979628941\n",
      "train loss:0.07577879548403192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.10038003803557442\n",
      "train loss:0.11575969460412797\n",
      "train loss:0.07512760630506816\n",
      "train loss:0.11140257651708016\n",
      "train loss:0.11126337990740899\n",
      "train loss:0.10409765236648365\n",
      "train loss:0.17188891272414797\n",
      "train loss:0.049917866099813135\n",
      "train loss:0.12236402409043025\n",
      "train loss:0.07820637505417541\n",
      "train loss:0.060552132243824316\n",
      "train loss:0.09904029429232729\n",
      "train loss:0.1132955221677085\n",
      "train loss:0.047744475614871135\n",
      "train loss:0.10566168415918957\n",
      "train loss:0.07015441244118652\n",
      "train loss:0.05445647251560835\n",
      "train loss:0.10750328469755834\n",
      "train loss:0.10941606606859451\n",
      "train loss:0.10032650617685293\n",
      "train loss:0.07683258016068158\n",
      "train loss:0.07180476403733436\n",
      "train loss:0.11591944476396497\n",
      "train loss:0.12372903875810515\n",
      "train loss:0.07170725444786373\n",
      "train loss:0.12607411723878756\n",
      "train loss:0.061880926734964856\n",
      "train loss:0.11349274272156018\n",
      "train loss:0.08169772246758407\n",
      "train loss:0.09523421983011797\n",
      "train loss:0.15224595234715294\n",
      "train loss:0.058236657286290204\n",
      "train loss:0.03279971342804926\n",
      "train loss:0.08784663497099153\n",
      "train loss:0.02896905724178469\n",
      "train loss:0.07957924605314387\n",
      "train loss:0.10858686936411771\n",
      "train loss:0.07596090053266975\n",
      "train loss:0.08823247572496515\n",
      "train loss:0.09336681465253999\n",
      "train loss:0.021975705632675334\n",
      "train loss:0.11620926022546017\n",
      "train loss:0.053425173651452246\n",
      "train loss:0.06717127269897401\n",
      "train loss:0.09494280454646516\n",
      "train loss:0.07753469556320854\n",
      "train loss:0.05615922043232887\n",
      "train loss:0.0671909006297736\n",
      "train loss:0.07841051516318162\n",
      "train loss:0.10127019535723722\n",
      "train loss:0.0671315704796527\n",
      "train loss:0.09507748950225765\n",
      "train loss:0.027513373569006974\n",
      "train loss:0.05627264707195159\n",
      "train loss:0.1374349181334957\n",
      "train loss:0.030022350693155387\n",
      "train loss:0.06765445060849515\n",
      "train loss:0.03636283754539959\n",
      "train loss:0.07408399957629165\n",
      "train loss:0.037385022206978855\n",
      "train loss:0.06388581079367167\n",
      "train loss:0.12257902420330172\n",
      "train loss:0.12311411816827514\n",
      "train loss:0.043197522423202746\n",
      "train loss:0.08499120873367615\n",
      "train loss:0.0779518610346517\n",
      "train loss:0.06734516225203598\n",
      "train loss:0.087725214653136\n",
      "train loss:0.09371812375562977\n",
      "train loss:0.1772712995323289\n",
      "train loss:0.04803486629029861\n",
      "train loss:0.03211865872971554\n",
      "train loss:0.059155508273952\n",
      "train loss:0.060959122524668195\n",
      "train loss:0.13187345272825776\n",
      "train loss:0.054742581209323474\n",
      "train loss:0.05277947267971433\n",
      "train loss:0.11184873202123978\n",
      "train loss:0.1255504652408481\n",
      "train loss:0.07808257617796699\n",
      "train loss:0.0910437765211554\n",
      "train loss:0.07250578588962259\n",
      "train loss:0.09277698250688146\n",
      "train loss:0.04331897091426118\n",
      "train loss:0.06028771902763269\n",
      "train loss:0.10632286466312146\n",
      "train loss:0.059952981848489156\n",
      "train loss:0.029482978865842682\n",
      "train loss:0.08218562369176104\n",
      "train loss:0.044806132182535645\n",
      "train loss:0.08585537451004698\n",
      "train loss:0.05260922956785158\n",
      "train loss:0.11857945934841357\n",
      "train loss:0.08092853912435395\n",
      "train loss:0.059874399188003434\n",
      "train loss:0.12427493699962235\n",
      "train loss:0.08778790697001662\n",
      "train loss:0.13649800236522924\n",
      "train loss:0.048432823526804426\n",
      "train loss:0.08145759686795412\n",
      "train loss:0.14148487354858721\n",
      "train loss:0.06650972828690485\n",
      "train loss:0.11449493927525368\n",
      "train loss:0.1122125863310036\n",
      "train loss:0.060258105960894176\n",
      "train loss:0.07343265310568542\n",
      "train loss:0.08998218955547128\n",
      "train loss:0.08271567855759449\n",
      "train loss:0.059795139333943724\n",
      "train loss:0.07781131499367097\n",
      "train loss:0.14503635262268724\n",
      "train loss:0.06350802327282844\n",
      "train loss:0.14621680191338682\n",
      "train loss:0.06605882174935329\n",
      "train loss:0.07851410624036481\n",
      "train loss:0.08073996106274374\n",
      "train loss:0.07461224974362245\n",
      "train loss:0.06059275264086062\n",
      "train loss:0.08304998897185432\n",
      "train loss:0.09503001991633962\n",
      "train loss:0.0505382528673568\n",
      "train loss:0.04514616484643494\n",
      "train loss:0.08839494220463516\n",
      "train loss:0.07291499703029868\n",
      "train loss:0.11499910921176379\n",
      "train loss:0.08376688440774231\n",
      "train loss:0.0518312972714754\n",
      "train loss:0.08602765246186966\n",
      "train loss:0.08385591447351227\n",
      "train loss:0.0402090178425632\n",
      "train loss:0.029643181199822777\n",
      "train loss:0.05612632467119652\n",
      "train loss:0.06630945006850138\n",
      "train loss:0.05683093414567251\n",
      "train loss:0.0687955674502069\n",
      "train loss:0.07547366970760411\n",
      "train loss:0.06151033717269696\n",
      "train loss:0.03985331948241068\n",
      "train loss:0.11221409618216616\n",
      "train loss:0.11035404136303663\n",
      "train loss:0.057855263745274804\n",
      "train loss:0.09025000236790817\n",
      "train loss:0.062254891108899715\n",
      "train loss:0.06756954749559248\n",
      "train loss:0.03620566538908834\n",
      "train loss:0.0735451841196597\n",
      "train loss:0.061388464590728734\n",
      "train loss:0.09646991636926076\n",
      "train loss:0.04468509497528986\n",
      "train loss:0.049367465441755874\n",
      "train loss:0.04566751563873876\n",
      "train loss:0.0697163242708534\n",
      "train loss:0.03105985106709547\n",
      "train loss:0.02690001605434953\n",
      "train loss:0.07496658844246709\n",
      "train loss:0.05150642833656881\n",
      "train loss:0.06695916469517833\n",
      "train loss:0.057144391027008724\n",
      "train loss:0.039473870765304786\n",
      "train loss:0.07060324451857056\n",
      "train loss:0.08396822930028351\n",
      "train loss:0.06516441334561497\n",
      "train loss:0.05216626072007394\n",
      "train loss:0.08383447528461346\n",
      "train loss:0.10137151859121012\n",
      "train loss:0.16644161140610408\n",
      "train loss:0.0973485265061766\n",
      "train loss:0.0732016237528522\n",
      "train loss:0.11873519163146538\n",
      "train loss:0.05459615250616216\n",
      "train loss:0.06760275742507472\n",
      "train loss:0.02946222862873366\n",
      "train loss:0.07042439595557537\n",
      "train loss:0.07844561594777903\n",
      "train loss:0.06706321422183575\n",
      "train loss:0.04615013644031525\n",
      "train loss:0.06248811865080719\n",
      "train loss:0.027374249357699623\n",
      "train loss:0.06943428188336817\n",
      "train loss:0.08513742851239016\n",
      "train loss:0.05559140866349538\n",
      "train loss:0.09354851108269853\n",
      "train loss:0.15687987808999238\n",
      "train loss:0.046729727871719\n",
      "train loss:0.04500795667517311\n",
      "train loss:0.0863731665549324\n",
      "train loss:0.0564023710362129\n",
      "train loss:0.16372401092228375\n",
      "train loss:0.09987615214834371\n",
      "train loss:0.08319176626484934\n",
      "train loss:0.052412150326928454\n",
      "train loss:0.04184968711942411\n",
      "train loss:0.0616764983370541\n",
      "train loss:0.09951387624565174\n",
      "train loss:0.1488640163850912\n",
      "train loss:0.06986643741274416\n",
      "train loss:0.0686523996928181\n",
      "train loss:0.08156586443177628\n",
      "train loss:0.10897648897172992\n",
      "train loss:0.13827763468087928\n",
      "train loss:0.08915879743045409\n",
      "train loss:0.04635682309419316\n",
      "train loss:0.04161768294567621\n",
      "train loss:0.13047029388801798\n",
      "train loss:0.03444488066984941\n",
      "train loss:0.08255375248809045\n",
      "train loss:0.10391869714643334\n",
      "train loss:0.0835561045197186\n",
      "train loss:0.09361910677364854\n",
      "train loss:0.18032824884666535\n",
      "train loss:0.08949438692980159\n",
      "train loss:0.10119673295751706\n",
      "train loss:0.05078605468979995\n",
      "train loss:0.1259379907728968\n",
      "train loss:0.02491261616702591\n",
      "train loss:0.04880288620603961\n",
      "train loss:0.05489783973316453\n",
      "train loss:0.15161466494323458\n",
      "train loss:0.10859875110383413\n",
      "train loss:0.06993485900161998\n",
      "train loss:0.1018069163339792\n",
      "train loss:0.07120363915825913\n",
      "train loss:0.041321839715761505\n",
      "train loss:0.09495921262342019\n",
      "train loss:0.09910815230876764\n",
      "train loss:0.07033403697365875\n",
      "train loss:0.06594023374592142\n",
      "train loss:0.013294524048492282\n",
      "train loss:0.1627495062208987\n",
      "train loss:0.07861245671369316\n",
      "train loss:0.10424327664534618\n",
      "train loss:0.1394786871151476\n",
      "train loss:0.04802095735223388\n",
      "train loss:0.06997909874912833\n",
      "train loss:0.12461013124516006\n",
      "train loss:0.04834039006096541\n",
      "train loss:0.13692461335749395\n",
      "train loss:0.10833314808533727\n",
      "train loss:0.09060684476598439\n",
      "train loss:0.04443943227559636\n",
      "train loss:0.0622236881779462\n",
      "train loss:0.0596130301440455\n",
      "train loss:0.05579351470227824\n",
      "train loss:0.04286822027835342\n",
      "train loss:0.18819919734116936\n",
      "train loss:0.05486300680206616\n",
      "train loss:0.05030377496897237\n",
      "train loss:0.10229262811051897\n",
      "train loss:0.15466635698328896\n",
      "train loss:0.04059224591828645\n",
      "train loss:0.05273276375653817\n",
      "train loss:0.027915154995682406\n",
      "train loss:0.04698465460489737\n",
      "train loss:0.05591762502950151\n",
      "train loss:0.037791592876965124\n",
      "train loss:0.03148850274203484\n",
      "train loss:0.06269351032896696\n",
      "train loss:0.06949665057864268\n",
      "train loss:0.03968918714425782\n",
      "train loss:0.14964720393500075\n",
      "train loss:0.08677372506182726\n",
      "train loss:0.049253844164659444\n",
      "train loss:0.03690559142561022\n",
      "train loss:0.07310574458257048\n",
      "train loss:0.08648427346578953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.06425984368151363\n",
      "train loss:0.09231812693451183\n",
      "train loss:0.08704746886696645\n",
      "train loss:0.1019507024882725\n",
      "train loss:0.08059708239956766\n",
      "train loss:0.061544128848020796\n",
      "train loss:0.06981308987315325\n",
      "train loss:0.08822756474910523\n",
      "train loss:0.05526006829771852\n",
      "train loss:0.043050723714767224\n",
      "train loss:0.029011440934620367\n",
      "train loss:0.12262096955859458\n",
      "train loss:0.059394760680133565\n",
      "train loss:0.08463040151108228\n",
      "train loss:0.06180553772339027\n",
      "train loss:0.19191691742168776\n",
      "train loss:0.07861033096597912\n",
      "train loss:0.16107157040001194\n",
      "train loss:0.09020279714495315\n",
      "train loss:0.09832641990249663\n",
      "train loss:0.06631748051560535\n",
      "train loss:0.04385327534159515\n",
      "train loss:0.042855347021022346\n",
      "train loss:0.06788042000274887\n",
      "train loss:0.043518729065639083\n",
      "train loss:0.054203370647221444\n",
      "train loss:0.07337858000113405\n",
      "train loss:0.06616511477249788\n",
      "train loss:0.09060563438222577\n",
      "train loss:0.03344184520519934\n",
      "train loss:0.06435531896488217\n",
      "train loss:0.06097337269243237\n",
      "train loss:0.114219115721135\n",
      "train loss:0.07928963200251186\n",
      "train loss:0.06469890699424255\n",
      "train loss:0.04777742618341843\n",
      "train loss:0.04238415408788927\n",
      "train loss:0.06266729800842265\n",
      "train loss:0.06818844555277996\n",
      "train loss:0.08244400484114008\n",
      "train loss:0.11259600591772737\n",
      "train loss:0.1096135972971059\n",
      "train loss:0.030267080800788118\n",
      "train loss:0.11095483385945698\n",
      "train loss:0.08608723182590504\n",
      "train loss:0.07781660716633618\n",
      "train loss:0.08909802946210844\n",
      "train loss:0.10589598241761636\n",
      "train loss:0.11840249626601698\n",
      "train loss:0.08308277276271259\n",
      "train loss:0.0643059874579443\n",
      "train loss:0.025462659886507196\n",
      "train loss:0.10754327402792571\n",
      "train loss:0.024766020839578896\n",
      "train loss:0.10524589531405161\n",
      "train loss:0.06276796702526447\n",
      "train loss:0.12256859840955452\n",
      "train loss:0.06887629209933778\n",
      "train loss:0.05336865650901906\n",
      "train loss:0.05254047209241903\n",
      "train loss:0.06941738152639282\n",
      "train loss:0.09319302884813874\n",
      "train loss:0.07713365539617362\n",
      "train loss:0.05636788343549538\n",
      "train loss:0.08398174113722759\n",
      "train loss:0.05102194965480148\n",
      "train loss:0.10106344345346986\n",
      "train loss:0.02983207724677978\n",
      "train loss:0.0995211561165187\n",
      "train loss:0.1021276043199675\n",
      "train loss:0.02418149843079219\n",
      "train loss:0.12848353572937532\n",
      "train loss:0.07159914782511148\n",
      "train loss:0.06025950524459592\n",
      "train loss:0.052539167632517\n",
      "train loss:0.0687556783183419\n",
      "train loss:0.07039768393471373\n",
      "train loss:0.0903695513793562\n",
      "train loss:0.06533236700721953\n",
      "train loss:0.04081518414302629\n",
      "train loss:0.06644993475879728\n",
      "train loss:0.052957580397422994\n",
      "train loss:0.07733573371011611\n",
      "train loss:0.05414017051846418\n",
      "train loss:0.04371813518902281\n",
      "train loss:0.19919728986334387\n",
      "train loss:0.07671961503056517\n",
      "train loss:0.09809849505427419\n",
      "train loss:0.0479216771035388\n",
      "train loss:0.042017297574191426\n",
      "train loss:0.1624144587851546\n",
      "train loss:0.020801086058080117\n",
      "train loss:0.08086877497527159\n",
      "train loss:0.04785821386223636\n",
      "train loss:0.0761607037554067\n",
      "train loss:0.060015384501822026\n",
      "train loss:0.09896395054999467\n",
      "train loss:0.05450335869063041\n",
      "train loss:0.08585896616071405\n",
      "train loss:0.05385991593864908\n",
      "train loss:0.07808987976065224\n",
      "train loss:0.08914813973434116\n",
      "train loss:0.05404457408375306\n",
      "train loss:0.051511596949277275\n",
      "train loss:0.046474236523583075\n",
      "train loss:0.13829799037835339\n",
      "train loss:0.09859867162177764\n",
      "train loss:0.06962617045579453\n",
      "train loss:0.041443595154271644\n",
      "train loss:0.038800357735474904\n",
      "train loss:0.03670604583046447\n",
      "train loss:0.05285157257784261\n",
      "train loss:0.09914777692487645\n",
      "train loss:0.06298244348850404\n",
      "train loss:0.0830914999483772\n",
      "train loss:0.06887815096781123\n",
      "train loss:0.051952693250952774\n",
      "train loss:0.0353742297614388\n",
      "train loss:0.030965003066985262\n",
      "train loss:0.06392023007209342\n",
      "train loss:0.09014049251641819\n",
      "train loss:0.039844528210682705\n",
      "train loss:0.053475640893112616\n",
      "train loss:0.0811534352688712\n",
      "train loss:0.159736456245857\n",
      "train loss:0.13648360729386436\n",
      "train loss:0.08162840841581968\n",
      "train loss:0.04261393470601459\n",
      "train loss:0.09315342858143984\n",
      "train loss:0.05569712478782911\n",
      "train loss:0.065494434365692\n",
      "train loss:0.1120281356555447\n",
      "train loss:0.08222405839696918\n",
      "=== epoch:19, train acc:0.976, test acc:0.914 ===\n",
      "train loss:0.08196655332423339\n",
      "train loss:0.06183160203879149\n",
      "train loss:0.0950074634337157\n",
      "train loss:0.059058330245749247\n",
      "train loss:0.060452745298212374\n",
      "train loss:0.08735378357886585\n",
      "train loss:0.06501016452087635\n",
      "train loss:0.043436887041683\n",
      "train loss:0.04298921753072859\n",
      "train loss:0.06809008072654806\n",
      "train loss:0.04199369134504605\n",
      "train loss:0.045507977044535325\n",
      "train loss:0.10839701989043699\n",
      "train loss:0.13305784747089158\n",
      "train loss:0.1000047267208074\n",
      "train loss:0.07444680062626613\n",
      "train loss:0.0546560421568371\n",
      "train loss:0.14086638892625597\n",
      "train loss:0.04504999595343876\n",
      "train loss:0.08946108030351135\n",
      "train loss:0.09005479637161078\n",
      "train loss:0.15385928569610066\n",
      "train loss:0.07730590858391156\n",
      "train loss:0.06553604275907819\n",
      "train loss:0.07566555733133969\n",
      "train loss:0.09347499531657227\n",
      "train loss:0.0507072666026804\n",
      "train loss:0.05723465071249696\n",
      "train loss:0.0583679708510368\n",
      "train loss:0.027086415269126234\n",
      "train loss:0.06742585421290131\n",
      "train loss:0.018307925773944186\n",
      "train loss:0.0962052947172816\n",
      "train loss:0.014467782759683922\n",
      "train loss:0.02065294506969217\n",
      "train loss:0.055262827502324946\n",
      "train loss:0.08799169385217322\n",
      "train loss:0.06302216661557379\n",
      "train loss:0.033580711878872606\n",
      "train loss:0.031161772684190212\n",
      "train loss:0.11687112774486058\n",
      "train loss:0.030544075580956943\n",
      "train loss:0.08784358673291914\n",
      "train loss:0.05534786222856681\n",
      "train loss:0.04431664885168827\n",
      "train loss:0.08465267818263006\n",
      "train loss:0.0395745674825851\n",
      "train loss:0.11021591662883899\n",
      "train loss:0.0967018494849121\n",
      "train loss:0.04684925179810903\n",
      "train loss:0.06914460345747382\n",
      "train loss:0.024250791495656236\n",
      "train loss:0.030035057826085284\n",
      "train loss:0.06210234177556351\n",
      "train loss:0.07476141308686976\n",
      "train loss:0.06807895887480235\n",
      "train loss:0.08388853382840235\n",
      "train loss:0.08044319784967052\n",
      "train loss:0.06650770708130786\n",
      "train loss:0.17055266508165562\n",
      "train loss:0.07142535326534773\n",
      "train loss:0.0725883302604418\n",
      "train loss:0.050086073196489556\n",
      "train loss:0.03375283485471454\n",
      "train loss:0.032096476452824124\n",
      "train loss:0.06525466613005906\n",
      "train loss:0.034464029658894973\n",
      "train loss:0.09317750926585112\n",
      "train loss:0.045362343435807084\n",
      "train loss:0.08306119385382629\n",
      "train loss:0.048179797181100194\n",
      "train loss:0.09270969766832769\n",
      "train loss:0.041292377086850636\n",
      "train loss:0.0571294769427837\n",
      "train loss:0.0344189186200229\n",
      "train loss:0.07364528635434944\n",
      "train loss:0.089493524677763\n",
      "train loss:0.1168809594949564\n",
      "train loss:0.06124405498979845\n",
      "train loss:0.0660963996826311\n",
      "train loss:0.0771606885292376\n",
      "train loss:0.07277793123957829\n",
      "train loss:0.03487543855966254\n",
      "train loss:0.07160894511608175\n",
      "train loss:0.04857696155441973\n",
      "train loss:0.06647191699304857\n",
      "train loss:0.09978963686646049\n",
      "train loss:0.07529757092920865\n",
      "train loss:0.09975711149611252\n",
      "train loss:0.029200950748481364\n",
      "train loss:0.04527876702841098\n",
      "train loss:0.08861690872508761\n",
      "train loss:0.08064751176027077\n",
      "train loss:0.07640804472557149\n",
      "train loss:0.06944281001093863\n",
      "train loss:0.07747280157212529\n",
      "train loss:0.10918470120046969\n",
      "train loss:0.0858750968834841\n",
      "train loss:0.03837834405947784\n",
      "train loss:0.09438640673264033\n",
      "train loss:0.0670237895403972\n",
      "train loss:0.06037794892803012\n",
      "train loss:0.03777148114866582\n",
      "train loss:0.06570057167613082\n",
      "train loss:0.07002838276963676\n",
      "train loss:0.05585348171918411\n",
      "train loss:0.07792496169282827\n",
      "train loss:0.047730343368415\n",
      "train loss:0.016321806921609887\n",
      "train loss:0.14626783150594427\n",
      "train loss:0.02341635316697141\n",
      "train loss:0.02479058335370736\n",
      "train loss:0.07621073538141064\n",
      "train loss:0.07563695153003225\n",
      "train loss:0.05266863187706384\n",
      "train loss:0.11666589122303897\n",
      "train loss:0.12035666949556917\n",
      "train loss:0.10163283087332797\n",
      "train loss:0.1688190958584576\n",
      "train loss:0.12905285975688288\n",
      "train loss:0.06424577560682472\n",
      "train loss:0.0405797490800357\n",
      "train loss:0.06573120713490575\n",
      "train loss:0.06729157525354036\n",
      "train loss:0.10067657355369096\n",
      "train loss:0.09016572441005594\n",
      "train loss:0.06510715547396435\n",
      "train loss:0.06522853853834863\n",
      "train loss:0.07742772941179793\n",
      "train loss:0.051267682110185155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.1806300054751376\n",
      "train loss:0.018608864598652134\n",
      "train loss:0.09243413409015258\n",
      "train loss:0.0696158624609061\n",
      "train loss:0.038336359355364995\n",
      "train loss:0.11615326148454037\n",
      "train loss:0.03959164062157067\n",
      "train loss:0.07114978674361701\n",
      "train loss:0.06194305724950008\n",
      "train loss:0.08144564251687887\n",
      "train loss:0.10111432335145597\n",
      "train loss:0.08474775143836487\n",
      "train loss:0.044528837561515155\n",
      "train loss:0.06998996602627222\n",
      "train loss:0.06180511495618754\n",
      "train loss:0.04259297218237495\n",
      "train loss:0.1195705096476285\n",
      "train loss:0.058215291357793165\n",
      "train loss:0.05850368182533702\n",
      "train loss:0.07788095465019511\n",
      "train loss:0.038545833020135464\n",
      "train loss:0.06169238856295825\n",
      "train loss:0.09068914397029508\n",
      "train loss:0.04524929844802354\n",
      "train loss:0.0996539648829515\n",
      "train loss:0.07259242247118358\n",
      "train loss:0.029720793471071986\n",
      "train loss:0.06865584941016682\n",
      "train loss:0.055378192188976126\n",
      "train loss:0.06264480540578317\n",
      "train loss:0.03442924074799094\n",
      "train loss:0.06327987597550977\n",
      "train loss:0.07031035143172099\n",
      "train loss:0.12898246769145888\n",
      "train loss:0.04194290073800256\n",
      "train loss:0.059864520488508204\n",
      "train loss:0.04985271244097707\n",
      "train loss:0.06832343063572287\n",
      "train loss:0.0524402707518197\n",
      "train loss:0.08182524470491492\n",
      "train loss:0.09890390164131642\n",
      "train loss:0.10586731644688267\n",
      "train loss:0.1005119078150835\n",
      "train loss:0.08316214008169188\n",
      "train loss:0.07667514594880555\n",
      "train loss:0.158047969190087\n",
      "train loss:0.057204562682907724\n",
      "train loss:0.05779230980509469\n",
      "train loss:0.06987651850301685\n",
      "train loss:0.034606267925562983\n",
      "train loss:0.06617831589004297\n",
      "train loss:0.11046095579463511\n",
      "train loss:0.03697132647577261\n",
      "train loss:0.05387885006734334\n",
      "train loss:0.03418718205360896\n",
      "train loss:0.04686005296314961\n",
      "train loss:0.1048332399578213\n",
      "train loss:0.04708695624232259\n",
      "train loss:0.04729512713138992\n",
      "train loss:0.07262104710175983\n",
      "train loss:0.07402850565806668\n",
      "train loss:0.04304325187596653\n",
      "train loss:0.08177608735195097\n",
      "train loss:0.0768201656429425\n",
      "train loss:0.13705163291730135\n",
      "train loss:0.08239374150945533\n",
      "train loss:0.06373163874946904\n",
      "train loss:0.07616270270398798\n",
      "train loss:0.05220927392771177\n",
      "train loss:0.20664121883826528\n",
      "train loss:0.06895469441385664\n",
      "train loss:0.07048054149609755\n",
      "train loss:0.03868158076932833\n",
      "train loss:0.09107327053780521\n",
      "train loss:0.0630749719603476\n",
      "train loss:0.08554604895355937\n",
      "train loss:0.052818265432116214\n",
      "train loss:0.1328156434448787\n",
      "train loss:0.07369785656714664\n",
      "train loss:0.17446378783235197\n",
      "train loss:0.051746424357143904\n",
      "train loss:0.06711015281749425\n",
      "train loss:0.09441752801933195\n",
      "train loss:0.03767585638809842\n",
      "train loss:0.09484213117994686\n",
      "train loss:0.10146836157860069\n",
      "train loss:0.060447817517981915\n",
      "train loss:0.08993587270457581\n",
      "train loss:0.08276943639630004\n",
      "train loss:0.05778640318664281\n",
      "train loss:0.11140749411334198\n",
      "train loss:0.042346171348524086\n",
      "train loss:0.09105436391484474\n",
      "train loss:0.0967684404813992\n",
      "train loss:0.11827829498436669\n",
      "train loss:0.049080411544693864\n",
      "train loss:0.05042810554738472\n",
      "train loss:0.034192958942040316\n",
      "train loss:0.040690515241472464\n",
      "train loss:0.0413299110504631\n",
      "train loss:0.0656065564099184\n",
      "train loss:0.057394395146688024\n",
      "train loss:0.060743504174869775\n",
      "train loss:0.018362182379439356\n",
      "train loss:0.02799752212708081\n",
      "train loss:0.026925480795479167\n",
      "train loss:0.048972386130768306\n",
      "train loss:0.024068678923666736\n",
      "train loss:0.09850867358109516\n",
      "train loss:0.08120987839503443\n",
      "train loss:0.036352893768522465\n",
      "train loss:0.06165962000217101\n",
      "train loss:0.06080159866610904\n",
      "train loss:0.0971676986807724\n",
      "train loss:0.0681502668401805\n",
      "train loss:0.05607324414184443\n",
      "train loss:0.08015407965905127\n",
      "train loss:0.05233063663283819\n",
      "train loss:0.1574449978196101\n",
      "train loss:0.12894431426467073\n",
      "train loss:0.06317437847622193\n",
      "train loss:0.09961238898856196\n",
      "train loss:0.04698747451695387\n",
      "train loss:0.15756533112281712\n",
      "train loss:0.03110665428130969\n",
      "train loss:0.06683031108509459\n",
      "train loss:0.05996038344101702\n",
      "train loss:0.08268838675520138\n",
      "train loss:0.029944281363982847\n",
      "train loss:0.04279760158511204\n",
      "train loss:0.07423812159527123\n",
      "train loss:0.10153152705533491\n",
      "train loss:0.04745704406127455\n",
      "train loss:0.05596474911899619\n",
      "train loss:0.12065587695881957\n",
      "train loss:0.0733461261208108\n",
      "train loss:0.08961110588957906\n",
      "train loss:0.043595071495774074\n",
      "train loss:0.09514386918514259\n",
      "train loss:0.09429650935939625\n",
      "train loss:0.05140831989712471\n",
      "train loss:0.05788564400843422\n",
      "train loss:0.06038737892749643\n",
      "train loss:0.10076068192512809\n",
      "train loss:0.12577870129232493\n",
      "train loss:0.059332277324441095\n",
      "train loss:0.06709496602889037\n",
      "train loss:0.13358889093698964\n",
      "train loss:0.08108465482869859\n",
      "train loss:0.062091873772872924\n",
      "train loss:0.04680291979189041\n",
      "train loss:0.0981617561124466\n",
      "train loss:0.05321158092455912\n",
      "train loss:0.029712852157754682\n",
      "train loss:0.07719126368826934\n",
      "train loss:0.03253579625391436\n",
      "train loss:0.05737579859737059\n",
      "train loss:0.06238952379831129\n",
      "train loss:0.057171603656737416\n",
      "train loss:0.08049841997390526\n",
      "train loss:0.07740834977502752\n",
      "train loss:0.06996263784729584\n",
      "train loss:0.11040943743654127\n",
      "train loss:0.03778664815235947\n",
      "train loss:0.05223560527992993\n",
      "train loss:0.0534406342958468\n",
      "train loss:0.043779560657316925\n",
      "train loss:0.07723122225313185\n",
      "train loss:0.06103247888130683\n",
      "train loss:0.03673014646777816\n",
      "train loss:0.06242137777943003\n",
      "train loss:0.1031705444101365\n",
      "train loss:0.11484401466745009\n",
      "train loss:0.09329374853290412\n",
      "train loss:0.09450520695547505\n",
      "train loss:0.09128094313580191\n",
      "train loss:0.03516879404870956\n",
      "train loss:0.13054829813339988\n",
      "train loss:0.03273473200825769\n",
      "train loss:0.059062195341239014\n",
      "train loss:0.024543903093398618\n",
      "train loss:0.08774238776799186\n",
      "train loss:0.05532311173183238\n",
      "train loss:0.05189645173440442\n",
      "train loss:0.08543630000784301\n",
      "train loss:0.02414740915247362\n",
      "train loss:0.04947164254621992\n",
      "train loss:0.07665698836866947\n",
      "train loss:0.034753705305253436\n",
      "train loss:0.01637737476636282\n",
      "train loss:0.07133815757123797\n",
      "train loss:0.11068200318172083\n",
      "train loss:0.05367277290521816\n",
      "train loss:0.064016055819434\n",
      "train loss:0.07295271061635555\n",
      "train loss:0.12170114872183455\n",
      "train loss:0.07523207893080124\n",
      "train loss:0.06233018127419143\n",
      "train loss:0.08512637788582016\n",
      "train loss:0.10791649441765155\n",
      "train loss:0.06746948721786451\n",
      "train loss:0.025347967590400575\n",
      "train loss:0.044599778083316666\n",
      "train loss:0.0466895007396014\n",
      "train loss:0.02957039085956716\n",
      "train loss:0.08733695382562093\n",
      "train loss:0.11180843946601719\n",
      "train loss:0.03795397028585645\n",
      "train loss:0.050881695137116593\n",
      "train loss:0.0785307709802955\n",
      "train loss:0.08766254703106321\n",
      "train loss:0.028532482578972423\n",
      "train loss:0.11583092945088329\n",
      "train loss:0.07193365964331647\n",
      "train loss:0.05850601684100292\n",
      "train loss:0.09354439999034259\n",
      "train loss:0.060869034095950784\n",
      "train loss:0.07803276850944438\n",
      "train loss:0.059240959217811355\n",
      "train loss:0.034747070199937925\n",
      "train loss:0.12857040666382447\n",
      "train loss:0.03772130000625828\n",
      "train loss:0.027594681335961456\n",
      "train loss:0.100729408680251\n",
      "train loss:0.05987069305110773\n",
      "train loss:0.05939111811351396\n",
      "train loss:0.116277763212808\n",
      "train loss:0.05156486226868228\n",
      "train loss:0.09672090674291663\n",
      "train loss:0.06305263848953299\n",
      "train loss:0.10088813627720639\n",
      "train loss:0.03340034670105227\n",
      "train loss:0.07292148217403162\n",
      "train loss:0.0974879994731335\n",
      "train loss:0.042413833717825485\n",
      "train loss:0.08703388511749827\n",
      "train loss:0.09139966227630168\n",
      "train loss:0.07270816644465151\n",
      "train loss:0.07498498495354297\n",
      "train loss:0.0462828929190362\n",
      "train loss:0.049942366255393604\n",
      "train loss:0.03667134079684074\n",
      "train loss:0.07927079729727762\n",
      "train loss:0.05094941286529583\n",
      "train loss:0.06450239060184304\n",
      "train loss:0.09610187400994923\n",
      "train loss:0.039923027074316775\n",
      "train loss:0.0849192323103675\n",
      "train loss:0.09425959874006974\n",
      "train loss:0.03946925417820453\n",
      "train loss:0.0885197527914604\n",
      "train loss:0.18883210007901433\n",
      "train loss:0.02576588673450186\n",
      "train loss:0.12696223231568005\n",
      "train loss:0.04673841295414159\n",
      "train loss:0.15232565363688091\n",
      "train loss:0.08036960081478024\n",
      "train loss:0.05331264326239384\n",
      "train loss:0.09510287281605768\n",
      "train loss:0.13266604036501228\n",
      "train loss:0.13290300760444665\n",
      "train loss:0.04814178100941458\n",
      "train loss:0.05307627627513764\n",
      "train loss:0.05489149767525617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0963161415013055\n",
      "train loss:0.09136363438613819\n",
      "train loss:0.07559644807461278\n",
      "train loss:0.0669094211098205\n",
      "train loss:0.12134924824410868\n",
      "train loss:0.04045560143798243\n",
      "train loss:0.0723171715534547\n",
      "train loss:0.07848049328273132\n",
      "train loss:0.06530081041265476\n",
      "train loss:0.04993019905431926\n",
      "train loss:0.1375387619313231\n",
      "train loss:0.04151279614453058\n",
      "train loss:0.037228211568344466\n",
      "train loss:0.0429238796741019\n",
      "train loss:0.045370331360664394\n",
      "train loss:0.03229871638374803\n",
      "train loss:0.08359730724505393\n",
      "train loss:0.09224517604079048\n",
      "train loss:0.07980379139060435\n",
      "train loss:0.09522822080450787\n",
      "train loss:0.05902143220264119\n",
      "train loss:0.11320537502965639\n",
      "train loss:0.06052160429813561\n",
      "train loss:0.06537827054739885\n",
      "train loss:0.0683225496106386\n",
      "train loss:0.055181406974521084\n",
      "train loss:0.08768759852952186\n",
      "train loss:0.04141768098143662\n",
      "train loss:0.05786639960772757\n",
      "train loss:0.0839529008288526\n",
      "train loss:0.06863243510386559\n",
      "train loss:0.030933265350975278\n",
      "train loss:0.04792661549105024\n",
      "train loss:0.02743301118600101\n",
      "train loss:0.08191928513626053\n",
      "train loss:0.040111966816742554\n",
      "train loss:0.06579817937303863\n",
      "train loss:0.08309008437920813\n",
      "train loss:0.0843715503305807\n",
      "train loss:0.053528465105549074\n",
      "train loss:0.06335405441916447\n",
      "train loss:0.06587446762847422\n",
      "train loss:0.02980764613906211\n",
      "train loss:0.11115434572053681\n",
      "train loss:0.07771962942736392\n",
      "train loss:0.16955747695003534\n",
      "train loss:0.04436928107643868\n",
      "train loss:0.06168094266151654\n",
      "train loss:0.10331798685258865\n",
      "train loss:0.03756795255454957\n",
      "train loss:0.03413809708163117\n",
      "train loss:0.05708559496965478\n",
      "train loss:0.05062333707079922\n",
      "train loss:0.057773313680528515\n",
      "train loss:0.05349678485265738\n",
      "train loss:0.09754272282677612\n",
      "train loss:0.04172806585233201\n",
      "train loss:0.09840526877684125\n",
      "train loss:0.04215743520775657\n",
      "train loss:0.04127476916304079\n",
      "train loss:0.15519941997963346\n",
      "train loss:0.11869306175200625\n",
      "train loss:0.05322085821913301\n",
      "train loss:0.11118288765399136\n",
      "train loss:0.07897421004374523\n",
      "train loss:0.044393885793591936\n",
      "train loss:0.07532217159887386\n",
      "train loss:0.06370557409293079\n",
      "train loss:0.0716377210487586\n",
      "train loss:0.04280546539629026\n",
      "train loss:0.036799069681026274\n",
      "train loss:0.031147621594194073\n",
      "train loss:0.07114075066173885\n",
      "train loss:0.06205761902748195\n",
      "train loss:0.05502017119274792\n",
      "train loss:0.027271717048963574\n",
      "train loss:0.028229047975035924\n",
      "train loss:0.06044503220887891\n",
      "train loss:0.08687328733616378\n",
      "train loss:0.05917459611545894\n",
      "train loss:0.04719603544801032\n",
      "train loss:0.05618983529984744\n",
      "train loss:0.05171057936054372\n",
      "train loss:0.129696686673521\n",
      "train loss:0.048475197041902306\n",
      "train loss:0.10019607835779337\n",
      "train loss:0.0355057248500863\n",
      "train loss:0.07908852161218963\n",
      "train loss:0.08098096592428183\n",
      "train loss:0.08504530822575129\n",
      "train loss:0.06952139266856633\n",
      "train loss:0.09425077029105733\n",
      "train loss:0.1097300747218247\n",
      "train loss:0.07774903963122731\n",
      "train loss:0.04922858817060253\n",
      "train loss:0.13566103580147024\n",
      "train loss:0.10818345287867948\n",
      "train loss:0.06599016328218138\n",
      "train loss:0.07027995996059862\n",
      "train loss:0.16444576734390556\n",
      "train loss:0.06226466607939245\n",
      "train loss:0.02987043747688162\n",
      "train loss:0.07869658539353608\n",
      "train loss:0.04187954057299043\n",
      "train loss:0.032872831826757924\n",
      "train loss:0.06604812866117621\n",
      "train loss:0.06027205730680135\n",
      "train loss:0.16626492075100122\n",
      "train loss:0.09299376794990968\n",
      "train loss:0.11188869817912636\n",
      "train loss:0.061377430134105154\n",
      "train loss:0.06568940239844513\n",
      "train loss:0.05064986698375255\n",
      "train loss:0.048232413301765586\n",
      "train loss:0.05251220936664769\n",
      "train loss:0.03459937295146811\n",
      "train loss:0.056636139072352425\n",
      "train loss:0.07724339626095245\n",
      "train loss:0.09181469209576563\n",
      "train loss:0.07520192296451125\n",
      "train loss:0.05874672200073079\n",
      "train loss:0.10213520783136892\n",
      "train loss:0.05427906932625562\n",
      "train loss:0.06620550261906309\n",
      "train loss:0.09702363306635146\n",
      "train loss:0.05679536687562539\n",
      "train loss:0.09729823969628855\n",
      "train loss:0.03632837175229785\n",
      "train loss:0.05503207892054443\n",
      "train loss:0.02306441914003678\n",
      "train loss:0.08496886534860065\n",
      "train loss:0.14117971695244896\n",
      "train loss:0.10293039401930613\n",
      "train loss:0.09253981355892796\n",
      "train loss:0.031949591141599176\n",
      "train loss:0.07825194619992082\n",
      "train loss:0.08146174844263726\n",
      "train loss:0.0784200220785668\n",
      "train loss:0.05845616425657583\n",
      "train loss:0.1242410880754823\n",
      "train loss:0.15721631859725121\n",
      "train loss:0.0629617939544231\n",
      "train loss:0.07374895849149712\n",
      "train loss:0.07405669420784726\n",
      "train loss:0.07572126296372303\n",
      "train loss:0.06551977926537161\n",
      "train loss:0.09528538406001313\n",
      "train loss:0.08704150384806743\n",
      "train loss:0.05776404735100247\n",
      "train loss:0.14955142369030197\n",
      "train loss:0.02963393689619632\n",
      "train loss:0.039838966720084336\n",
      "train loss:0.10413125101468798\n",
      "train loss:0.0893729776528364\n",
      "train loss:0.08214565106582286\n",
      "train loss:0.07103795942369091\n",
      "train loss:0.05643278219815867\n",
      "train loss:0.06819362958533491\n",
      "train loss:0.014989730332647557\n",
      "train loss:0.04943274466721552\n",
      "train loss:0.12241267792007886\n",
      "train loss:0.046121009876467015\n",
      "train loss:0.05691907030157867\n",
      "train loss:0.05647246957914848\n",
      "train loss:0.05214222861783119\n",
      "train loss:0.03143203302060509\n",
      "train loss:0.040221636925705566\n",
      "train loss:0.04256945697850866\n",
      "train loss:0.04103719780484091\n",
      "train loss:0.036572593797273456\n",
      "train loss:0.08523321360638039\n",
      "train loss:0.060983355442738106\n",
      "train loss:0.03944535136688041\n",
      "train loss:0.09146668228033972\n",
      "train loss:0.017697078852874117\n",
      "train loss:0.066137446148371\n",
      "train loss:0.10400330427416168\n",
      "train loss:0.026078106484373344\n",
      "train loss:0.04069909553797057\n",
      "train loss:0.03708388010913317\n",
      "train loss:0.049945181110368386\n",
      "train loss:0.042963982018877245\n",
      "train loss:0.05913670313098738\n",
      "train loss:0.13359153705441246\n",
      "train loss:0.04672147989302482\n",
      "train loss:0.052840859335398234\n",
      "train loss:0.02490557297776291\n",
      "train loss:0.051083475994714425\n",
      "train loss:0.0528166205762921\n",
      "train loss:0.05983673563632884\n",
      "train loss:0.04245882620584509\n",
      "train loss:0.04118418269130946\n",
      "train loss:0.1167710963623279\n",
      "train loss:0.019567293491705714\n",
      "train loss:0.07322385129536389\n",
      "train loss:0.08363783069880258\n",
      "train loss:0.0556346660432147\n",
      "train loss:0.08514246438882794\n",
      "train loss:0.0651594283196018\n",
      "train loss:0.07097676679200066\n",
      "train loss:0.05391935525145234\n",
      "train loss:0.07764588504228119\n",
      "train loss:0.11915590979280387\n",
      "train loss:0.13860664704783848\n",
      "train loss:0.06450925960770461\n",
      "train loss:0.07590831928068074\n",
      "=== epoch:20, train acc:0.977, test acc:0.914 ===\n",
      "train loss:0.06466884205812483\n",
      "train loss:0.08203871656765506\n",
      "train loss:0.1810253690198498\n",
      "train loss:0.09780059407529305\n",
      "train loss:0.045783017207152776\n",
      "train loss:0.042847887842721456\n",
      "train loss:0.061237758479174634\n",
      "train loss:0.15047757596099207\n",
      "train loss:0.07584963743967997\n",
      "train loss:0.07183782668531664\n",
      "train loss:0.11885323401756803\n",
      "train loss:0.04029771615679246\n",
      "train loss:0.04501326757047\n",
      "train loss:0.04622302680624463\n",
      "train loss:0.05984353295828341\n",
      "train loss:0.05966141003200797\n",
      "train loss:0.04791378171092709\n",
      "train loss:0.05162680448105287\n",
      "train loss:0.05588272394757224\n",
      "train loss:0.06637619797385731\n",
      "train loss:0.11743129729383721\n",
      "train loss:0.042092495748203375\n",
      "train loss:0.029835173467766044\n",
      "train loss:0.061325599997899966\n",
      "train loss:0.06815707523975044\n",
      "train loss:0.07573483055710563\n",
      "train loss:0.053569193939513406\n",
      "train loss:0.03685881413905419\n",
      "train loss:0.02241989591088049\n",
      "train loss:0.06261484300930562\n",
      "train loss:0.0341315279240838\n",
      "train loss:0.09268440126793259\n",
      "train loss:0.05980087120987923\n",
      "train loss:0.04686136438607818\n",
      "train loss:0.0828348382144895\n",
      "train loss:0.03511938398720324\n",
      "train loss:0.033152104792898596\n",
      "train loss:0.08766603111523612\n",
      "train loss:0.05396073922805003\n",
      "train loss:0.05368525818706957\n",
      "train loss:0.06011419185451235\n",
      "train loss:0.0542272665188539\n",
      "train loss:0.059951337926231967\n",
      "train loss:0.043142869284414014\n",
      "train loss:0.04038187347770252\n",
      "train loss:0.07263711892178748\n",
      "train loss:0.09498623749642622\n",
      "train loss:0.1142224355686184\n",
      "train loss:0.06236546654969377\n",
      "train loss:0.13023981404051957\n",
      "train loss:0.06350499794115273\n",
      "train loss:0.017331429560529292\n",
      "train loss:0.08553639120947924\n",
      "train loss:0.0783064391206797\n",
      "train loss:0.08807206881706732\n",
      "train loss:0.049768357820089475\n",
      "train loss:0.07307763827846826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.07910330480635107\n",
      "train loss:0.03851133046739796\n",
      "train loss:0.10665967552022158\n",
      "train loss:0.039203539884591465\n",
      "train loss:0.028293754900786533\n",
      "train loss:0.08062153585891102\n",
      "train loss:0.0891353839445279\n",
      "train loss:0.061509157259950216\n",
      "train loss:0.06431447043493446\n",
      "train loss:0.11051441291630933\n",
      "train loss:0.06373662896472544\n",
      "train loss:0.03677006961524067\n",
      "train loss:0.08862100451453316\n",
      "train loss:0.045073728840732914\n",
      "train loss:0.036942214530949716\n",
      "train loss:0.08235471485515979\n",
      "train loss:0.04836351438720933\n",
      "train loss:0.049495355323268264\n",
      "train loss:0.06288746885311132\n",
      "train loss:0.047048897756023\n",
      "train loss:0.11869453086711745\n",
      "train loss:0.07909361805998757\n",
      "train loss:0.05381548893070079\n",
      "train loss:0.06807625276553803\n",
      "train loss:0.04763787789487175\n",
      "train loss:0.07435390431220251\n",
      "train loss:0.0906680585835092\n",
      "train loss:0.06781556419769608\n",
      "train loss:0.04291782179414511\n",
      "train loss:0.02680579402850888\n",
      "train loss:0.056884644479108994\n",
      "train loss:0.05319649448848855\n",
      "train loss:0.04977929911654188\n",
      "train loss:0.032282151263759246\n",
      "train loss:0.09368187703763863\n",
      "train loss:0.0705954757392507\n",
      "train loss:0.05729700325300646\n",
      "train loss:0.06958574208979382\n",
      "train loss:0.0424683687824172\n",
      "train loss:0.03866720044255195\n",
      "train loss:0.07053066307455665\n",
      "train loss:0.05080729647582156\n",
      "train loss:0.06582812361936077\n",
      "train loss:0.07867333891453915\n",
      "train loss:0.13306214782247522\n",
      "train loss:0.14818029898513033\n",
      "train loss:0.08315109047992268\n",
      "train loss:0.05859046477106961\n",
      "train loss:0.06631104697329764\n",
      "train loss:0.05238079495488418\n",
      "train loss:0.0730408032004425\n",
      "train loss:0.03529609893621401\n",
      "train loss:0.07229069463994212\n",
      "train loss:0.06099209462971081\n",
      "train loss:0.07164523890905544\n",
      "train loss:0.038192094657340366\n",
      "train loss:0.038601142234328284\n",
      "train loss:0.05300657655890034\n",
      "train loss:0.10501839203535819\n",
      "train loss:0.07217999325739222\n",
      "train loss:0.020415975471347676\n",
      "train loss:0.0642412098095726\n",
      "train loss:0.038272244580944165\n",
      "train loss:0.030251965514588114\n",
      "train loss:0.11806072864761678\n",
      "train loss:0.06449962482491137\n",
      "train loss:0.03650647313297524\n",
      "train loss:0.06566539188510118\n",
      "train loss:0.10709240760487565\n",
      "train loss:0.04104845605986649\n",
      "train loss:0.046392169973568285\n",
      "train loss:0.02012062013638928\n",
      "train loss:0.06167927877097061\n",
      "train loss:0.02357517059262767\n",
      "train loss:0.05783672390567699\n",
      "train loss:0.05505031424938935\n",
      "train loss:0.049136610846140856\n",
      "train loss:0.1080476656568779\n",
      "train loss:0.11834680824497662\n",
      "train loss:0.061004925129992164\n",
      "train loss:0.07598552404536138\n",
      "train loss:0.06337261134932139\n",
      "train loss:0.043096770546441523\n",
      "train loss:0.05400761880887295\n",
      "train loss:0.10096098732851139\n",
      "train loss:0.16197024996206996\n",
      "train loss:0.14662043217158113\n",
      "train loss:0.03728911526643092\n",
      "train loss:0.1193960994494864\n",
      "train loss:0.09261552270641485\n",
      "train loss:0.04151789051348155\n",
      "train loss:0.08283215685411109\n",
      "train loss:0.09275781531682553\n",
      "train loss:0.1240937985255709\n",
      "train loss:0.12105508010283708\n",
      "train loss:0.03618732138572408\n",
      "train loss:0.06183327173940383\n",
      "train loss:0.10800574179740224\n",
      "train loss:0.031850027304570344\n",
      "train loss:0.07097112873121898\n",
      "train loss:0.025325654673903745\n",
      "train loss:0.08558310611139891\n",
      "train loss:0.03502030675370207\n",
      "train loss:0.06178996106343148\n",
      "train loss:0.10287756632016329\n",
      "train loss:0.10157249733806437\n",
      "train loss:0.06477471870673193\n",
      "train loss:0.08369225919653664\n",
      "train loss:0.08544911130468492\n",
      "train loss:0.059235288988026644\n",
      "train loss:0.07745927867482186\n",
      "train loss:0.07645422022350702\n",
      "train loss:0.06273519150493817\n",
      "train loss:0.043550003060009536\n",
      "train loss:0.05548857268164435\n",
      "train loss:0.07981955425546193\n",
      "train loss:0.056842500848188024\n",
      "train loss:0.05216875122952144\n",
      "train loss:0.025290193857141343\n",
      "train loss:0.06025429482260236\n",
      "train loss:0.07649875259882008\n",
      "train loss:0.04011819009862068\n",
      "train loss:0.041567607267730955\n",
      "train loss:0.049860318136000774\n",
      "train loss:0.04478458596531754\n",
      "train loss:0.033814071239504806\n",
      "train loss:0.07006290393523731\n",
      "train loss:0.03340212604290065\n",
      "train loss:0.07258076650579735\n",
      "train loss:0.05281970178199599\n",
      "train loss:0.04090604904705211\n",
      "train loss:0.03971375403571545\n",
      "train loss:0.030589381380417762\n",
      "train loss:0.05990659589676316\n",
      "train loss:0.05984301653230589\n",
      "train loss:0.05310182999433225\n",
      "train loss:0.10190534466586235\n",
      "train loss:0.05765164153205505\n",
      "train loss:0.046316204007345894\n",
      "train loss:0.05645959203236118\n",
      "train loss:0.04815607665792742\n",
      "train loss:0.05364073803039473\n",
      "train loss:0.108192416603068\n",
      "train loss:0.05380725416035835\n",
      "train loss:0.025878404352002983\n",
      "train loss:0.07721458886622119\n",
      "train loss:0.054436205697858696\n",
      "train loss:0.07440957224501785\n",
      "train loss:0.06576992416154154\n",
      "train loss:0.06541365640699376\n",
      "train loss:0.03097331426781656\n",
      "train loss:0.08622390310879577\n",
      "train loss:0.05485084220589817\n",
      "train loss:0.09686579139547118\n",
      "train loss:0.0631335649571365\n",
      "train loss:0.04278443490649378\n",
      "train loss:0.05536999115109901\n",
      "train loss:0.08011079672399939\n",
      "train loss:0.05449476909863589\n",
      "train loss:0.01838505599199991\n",
      "train loss:0.0858815379481016\n",
      "train loss:0.03111236989906939\n",
      "train loss:0.12371757206897203\n",
      "train loss:0.06418498751654002\n",
      "train loss:0.10589028210587963\n",
      "train loss:0.07258541255864076\n",
      "train loss:0.02571509612587035\n",
      "train loss:0.05769715945183391\n",
      "train loss:0.12022466230082328\n",
      "train loss:0.09013817146195136\n",
      "train loss:0.0528861701359117\n",
      "train loss:0.029636172384561246\n",
      "train loss:0.041375246875925004\n",
      "train loss:0.07225617780588535\n",
      "train loss:0.05975644417705514\n",
      "train loss:0.049874262832838835\n",
      "train loss:0.06407165245621525\n",
      "train loss:0.09530144901357397\n",
      "train loss:0.025421516431576353\n",
      "train loss:0.09053701615893119\n",
      "train loss:0.02860366350881162\n",
      "train loss:0.03189752461861421\n",
      "train loss:0.08959105202978077\n",
      "train loss:0.04370694479999834\n",
      "train loss:0.16964208039224396\n",
      "train loss:0.04433874143507764\n",
      "train loss:0.04416559932753402\n",
      "train loss:0.08134368330632431\n",
      "train loss:0.04738713702357424\n",
      "train loss:0.04624335498257957\n",
      "train loss:0.029857861578104137\n",
      "train loss:0.060289574922725644\n",
      "train loss:0.04347587124760085\n",
      "train loss:0.05300396312868764\n",
      "train loss:0.029423208374485612\n",
      "train loss:0.021064203478632835\n",
      "train loss:0.03682531669761785\n",
      "train loss:0.057246460457280886\n",
      "train loss:0.092287255549617\n",
      "train loss:0.08748152579336294\n",
      "train loss:0.058970650118332794\n",
      "train loss:0.05460665315924028\n",
      "train loss:0.0930004564033275\n",
      "train loss:0.03234139669543398\n",
      "train loss:0.0668273885249176\n",
      "train loss:0.042175300350001034\n",
      "train loss:0.050127470086018505\n",
      "train loss:0.09135791375672288\n",
      "train loss:0.09530851029897625\n",
      "train loss:0.01911866453641597\n",
      "train loss:0.026644966654296706\n",
      "train loss:0.0729520642081117\n",
      "train loss:0.053982229623750475\n",
      "train loss:0.10127678390737264\n",
      "train loss:0.03883995421677859\n",
      "train loss:0.013728128231368361\n",
      "train loss:0.0563269396472065\n",
      "train loss:0.07155879404211773\n",
      "train loss:0.08240598586752702\n",
      "train loss:0.06897540347231368\n",
      "train loss:0.027500399611421734\n",
      "train loss:0.045991927222552714\n",
      "train loss:0.07946296688370443\n",
      "train loss:0.04089761473389636\n",
      "train loss:0.05363990144029063\n",
      "train loss:0.12286230672643632\n",
      "train loss:0.045755304659838736\n",
      "train loss:0.10059061626063917\n",
      "train loss:0.0682230502925653\n",
      "train loss:0.09245494305877335\n",
      "train loss:0.10548536055281964\n",
      "train loss:0.10568404971099357\n",
      "train loss:0.06165578186888085\n",
      "train loss:0.049124788920490756\n",
      "train loss:0.05752727190551529\n",
      "train loss:0.05042341041878515\n",
      "train loss:0.05299346539095006\n",
      "train loss:0.07581154667841929\n",
      "train loss:0.11155908572877958\n",
      "train loss:0.08562885134424979\n",
      "train loss:0.029239092586284966\n",
      "train loss:0.024614025579949822\n",
      "train loss:0.04920046162246163\n",
      "train loss:0.05759021640939785\n",
      "train loss:0.04246835866130793\n",
      "train loss:0.036780383849762635\n",
      "train loss:0.031222985890967666\n",
      "train loss:0.0968022218919518\n",
      "train loss:0.04558519317647462\n",
      "train loss:0.05939980038873066\n",
      "train loss:0.04514351292731357\n",
      "train loss:0.02883111074589737\n",
      "train loss:0.12164193562174967\n",
      "train loss:0.06061088326788032\n",
      "train loss:0.11190324362849356\n",
      "train loss:0.04922043115788977\n",
      "train loss:0.12866860671344127\n",
      "train loss:0.11000800501637223\n",
      "train loss:0.013477156149752721\n",
      "train loss:0.03662398077820952\n",
      "train loss:0.03749057738590108\n",
      "train loss:0.0982292339116454\n",
      "train loss:0.038844135182077105\n",
      "train loss:0.04724498935888394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.10130609117029171\n",
      "train loss:0.01611590473553438\n",
      "train loss:0.06548095696658413\n",
      "train loss:0.16280257837999723\n",
      "train loss:0.06114848502684751\n",
      "train loss:0.0380915964698923\n",
      "train loss:0.04825869125231879\n",
      "train loss:0.11854966934066334\n",
      "train loss:0.10288149162215184\n",
      "train loss:0.06563591601120573\n",
      "train loss:0.09737446545476375\n",
      "train loss:0.09505948734876765\n",
      "train loss:0.029542819425587424\n",
      "train loss:0.07548512232591562\n",
      "train loss:0.03245488589909659\n",
      "train loss:0.041309790494459334\n",
      "train loss:0.03442347168562107\n",
      "train loss:0.076886784234085\n",
      "train loss:0.043340708496418454\n",
      "train loss:0.08012545772914675\n",
      "train loss:0.024783166695184353\n",
      "train loss:0.029320415022765105\n",
      "train loss:0.06040231017020434\n",
      "train loss:0.044311085133218076\n",
      "train loss:0.016792418827922845\n",
      "train loss:0.028610696526821532\n",
      "train loss:0.05343804741783741\n",
      "train loss:0.05823939042120231\n",
      "train loss:0.040374663761309756\n",
      "train loss:0.08723198341748123\n",
      "train loss:0.10952575868316769\n",
      "train loss:0.011497430340256083\n",
      "train loss:0.043720649666080344\n",
      "train loss:0.07486264670324565\n",
      "train loss:0.042630797326956495\n",
      "train loss:0.027022999264164654\n",
      "train loss:0.10304449841517885\n",
      "train loss:0.07230963919661983\n",
      "train loss:0.03271848526514277\n",
      "train loss:0.15896302326774042\n",
      "train loss:0.04065988979862607\n",
      "train loss:0.05750770460545032\n",
      "train loss:0.09804500898869514\n",
      "train loss:0.01913557844440464\n",
      "train loss:0.022289063877761358\n",
      "train loss:0.07881180881439805\n",
      "train loss:0.028780084757268294\n",
      "train loss:0.0822618787257002\n",
      "train loss:0.040068382209240166\n",
      "train loss:0.09580599187721887\n",
      "train loss:0.08871826004891091\n",
      "train loss:0.10438022194378116\n",
      "train loss:0.024300286209725578\n",
      "train loss:0.04995033377537637\n",
      "train loss:0.03137283819343171\n",
      "train loss:0.04218675784995267\n",
      "train loss:0.039237510207977375\n",
      "train loss:0.057789159743478515\n",
      "train loss:0.06915268835973028\n",
      "train loss:0.03023940555795658\n",
      "train loss:0.05096422743121054\n",
      "train loss:0.1052678197311137\n",
      "train loss:0.050481850851366875\n",
      "train loss:0.03603731157392315\n",
      "train loss:0.02376705189433358\n",
      "train loss:0.1373636419829918\n",
      "train loss:0.04866541222498641\n",
      "train loss:0.11501235028251618\n",
      "train loss:0.06376565721454683\n",
      "train loss:0.07724477469659714\n",
      "train loss:0.051936201240526225\n",
      "train loss:0.03814474785900568\n",
      "train loss:0.1031937797983793\n",
      "train loss:0.07740484367135887\n",
      "train loss:0.050491246191726825\n",
      "train loss:0.032873881311647216\n",
      "train loss:0.07119721659130601\n",
      "train loss:0.09069604343708577\n",
      "train loss:0.09684526329198791\n",
      "train loss:0.04670981959384867\n",
      "train loss:0.1573628996392037\n",
      "train loss:0.052152786779785985\n",
      "train loss:0.09268984199409751\n",
      "train loss:0.11324678220786932\n",
      "train loss:0.03931174436323946\n",
      "train loss:0.15753514606866262\n",
      "train loss:0.04422196723011442\n",
      "train loss:0.018443903808598346\n",
      "train loss:0.04666793768534103\n",
      "train loss:0.05847902895344312\n",
      "train loss:0.05819329031017681\n",
      "train loss:0.16314159696005157\n",
      "train loss:0.06989565686116009\n",
      "train loss:0.03169609021106938\n",
      "train loss:0.0599661931836488\n",
      "train loss:0.06635055724186839\n",
      "train loss:0.09966818531197032\n",
      "train loss:0.05021720813469881\n",
      "train loss:0.05949618929666011\n",
      "train loss:0.08883201166231336\n",
      "train loss:0.0781842409447993\n",
      "train loss:0.027488624463584597\n",
      "train loss:0.12316766095456211\n",
      "train loss:0.10213417680844143\n",
      "train loss:0.05617260428818062\n",
      "train loss:0.06797599465308908\n",
      "train loss:0.03773624653765115\n",
      "train loss:0.021048423277484542\n",
      "train loss:0.042792747886120995\n",
      "train loss:0.10375902675939841\n",
      "train loss:0.06488388357287661\n",
      "train loss:0.07616555405798348\n",
      "train loss:0.07372775634164384\n",
      "train loss:0.056519134583213254\n",
      "train loss:0.0782197410420365\n",
      "train loss:0.058288765426606604\n",
      "train loss:0.09491910361627748\n",
      "train loss:0.1067758697290769\n",
      "train loss:0.04404088338622635\n",
      "train loss:0.10802481206100736\n",
      "train loss:0.035884442728637854\n",
      "train loss:0.031759360455030444\n",
      "train loss:0.04042034342724743\n",
      "train loss:0.08348374717699623\n",
      "train loss:0.09507625143432002\n",
      "train loss:0.05386649725806843\n",
      "train loss:0.02639980178216612\n",
      "train loss:0.08294774167078431\n",
      "train loss:0.08953246716302056\n",
      "train loss:0.04901359000979388\n",
      "train loss:0.02424909564206189\n",
      "train loss:0.043759960480261595\n",
      "train loss:0.057381342828910255\n",
      "train loss:0.11657355605769118\n",
      "train loss:0.067941978602475\n",
      "train loss:0.0661527506279366\n",
      "train loss:0.04410405106729585\n",
      "train loss:0.017464413798568217\n",
      "train loss:0.050951757288729166\n",
      "train loss:0.11403041297842806\n",
      "train loss:0.056812703738489685\n",
      "train loss:0.019243161186362264\n",
      "train loss:0.10569168127363601\n",
      "train loss:0.13765587781517497\n",
      "train loss:0.052247741466858726\n",
      "train loss:0.06251785561228415\n",
      "train loss:0.030902243517195966\n",
      "train loss:0.10052130000462765\n",
      "train loss:0.028968040377589297\n",
      "train loss:0.0886693813868951\n",
      "train loss:0.07234522783448992\n",
      "train loss:0.05816608531667897\n",
      "train loss:0.09383432305887551\n",
      "train loss:0.03376594603945363\n",
      "train loss:0.0627945622523529\n",
      "train loss:0.05967614896290464\n",
      "train loss:0.01920328475678745\n",
      "train loss:0.03868578571880037\n",
      "train loss:0.04122932454140113\n",
      "train loss:0.11953357810710763\n",
      "train loss:0.08177862604768757\n",
      "train loss:0.038806490025738445\n",
      "train loss:0.07945305308090911\n",
      "train loss:0.05794797044967326\n",
      "train loss:0.06173291442872964\n",
      "train loss:0.15341065349729158\n",
      "train loss:0.06462534637238869\n",
      "train loss:0.060706294840756604\n",
      "train loss:0.06701881129066811\n",
      "train loss:0.04149362588923955\n",
      "train loss:0.08642836139911436\n",
      "train loss:0.08223339508372092\n",
      "train loss:0.050519110572992354\n",
      "train loss:0.028491233179567872\n",
      "train loss:0.09761093695126222\n",
      "train loss:0.04561547642607258\n",
      "train loss:0.030890764132554756\n",
      "train loss:0.05054152509042047\n",
      "train loss:0.05732179481943667\n",
      "train loss:0.08598637136138848\n",
      "train loss:0.053776984447523046\n",
      "train loss:0.0858384060407149\n",
      "train loss:0.10486483552408338\n",
      "train loss:0.10154715049654658\n",
      "train loss:0.06424573868887805\n",
      "train loss:0.08967646754024157\n",
      "train loss:0.0448740648227587\n",
      "train loss:0.09784866021454217\n",
      "train loss:0.06535893835827855\n",
      "train loss:0.05442186852165274\n",
      "train loss:0.034755008684963354\n",
      "train loss:0.05250486724507563\n",
      "train loss:0.07157882951982336\n",
      "train loss:0.05420744904152542\n",
      "train loss:0.022702945874297904\n",
      "train loss:0.03920998319676487\n",
      "train loss:0.028021113268058225\n",
      "train loss:0.08556416053247658\n",
      "train loss:0.05335947319017904\n",
      "train loss:0.030370301567228614\n",
      "train loss:0.05113508002358766\n",
      "train loss:0.11634611662977581\n",
      "train loss:0.04149044081312156\n",
      "train loss:0.0544137104255287\n",
      "train loss:0.030735922431003603\n",
      "train loss:0.041596712080771994\n",
      "train loss:0.05920778349647142\n",
      "train loss:0.05902106415002171\n",
      "train loss:0.034179351023082484\n",
      "train loss:0.10665644778874395\n",
      "train loss:0.04778727674538061\n",
      "train loss:0.01580813668280321\n",
      "train loss:0.05054114491575609\n",
      "train loss:0.05218637150108192\n",
      "train loss:0.05928081937922885\n",
      "train loss:0.08635612920984644\n",
      "train loss:0.04761328221804953\n",
      "train loss:0.05981702989946838\n",
      "train loss:0.09374874380356606\n",
      "train loss:0.049484228636327315\n",
      "train loss:0.0961198207244729\n",
      "train loss:0.04874603661143945\n",
      "train loss:0.04763133694858904\n",
      "train loss:0.14212714622940253\n",
      "train loss:0.08669467519961051\n",
      "train loss:0.06947956943034227\n",
      "train loss:0.0666007901674884\n",
      "train loss:0.04225041146691853\n",
      "train loss:0.07518208099805326\n",
      "train loss:0.035754510212948405\n",
      "train loss:0.05912521322960712\n",
      "train loss:0.04171694503358818\n",
      "train loss:0.049974824738980565\n",
      "train loss:0.06223425354337591\n",
      "train loss:0.05247241964398886\n",
      "train loss:0.06659205553696607\n",
      "train loss:0.047889205356651116\n",
      "train loss:0.046157004157159266\n",
      "train loss:0.06097572777652714\n",
      "train loss:0.04205321899054329\n",
      "train loss:0.06941890444535759\n",
      "train loss:0.038269832743177294\n",
      "train loss:0.06496560003020288\n",
      "train loss:0.049187617886256536\n",
      "train loss:0.06923289661299771\n",
      "train loss:0.08018084667638149\n",
      "train loss:0.10177027989578347\n",
      "train loss:0.02396796479476942\n",
      "train loss:0.0510991116401577\n",
      "train loss:0.02634920054371302\n",
      "train loss:0.08027226566889598\n",
      "train loss:0.022569767172226855\n",
      "train loss:0.025026953542162386\n",
      "train loss:0.04546090728470391\n",
      "train loss:0.02293341214601021\n",
      "train loss:0.051630788845459664\n",
      "train loss:0.10678004438939269\n",
      "train loss:0.041546793905338816\n",
      "train loss:0.013558862218652733\n",
      "train loss:0.015214474207249458\n",
      "train loss:0.06976179942292117\n",
      "train loss:0.016404095704704545\n",
      "train loss:0.06167237009704194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.08670774704492629\n",
      "train loss:0.05894796384470193\n",
      "train loss:0.03895633131703908\n",
      "train loss:0.05122228620018025\n",
      "train loss:0.05074482290831324\n",
      "train loss:0.01575803566992445\n",
      "train loss:0.11430589188725879\n",
      "train loss:0.07554849080527029\n",
      "train loss:0.029829205724487343\n",
      "train loss:0.07513652669301846\n",
      "train loss:0.04033643883758446\n",
      "train loss:0.044584733098396744\n",
      "train loss:0.06265224486746951\n",
      "train loss:0.046532943459536444\n",
      "train loss:0.04010023722580232\n",
      "train loss:0.04865702309495866\n",
      "=== epoch:21, train acc:0.986, test acc:0.915 ===\n",
      "train loss:0.03979667278054824\n",
      "train loss:0.03664499333498414\n",
      "train loss:0.04538779846894872\n",
      "train loss:0.05244561917296047\n",
      "train loss:0.04806769111990948\n",
      "train loss:0.09377366868300202\n",
      "train loss:0.03164090371122952\n",
      "train loss:0.05799226567746242\n",
      "train loss:0.12834931748666206\n",
      "train loss:0.0728848044015734\n",
      "train loss:0.03001922843865199\n",
      "train loss:0.04655717673147332\n",
      "train loss:0.03707090856264095\n",
      "train loss:0.04051473998738657\n",
      "train loss:0.02245372418195444\n",
      "train loss:0.0177199932497574\n",
      "train loss:0.04159899542268369\n",
      "train loss:0.02158405824621258\n",
      "train loss:0.057495849482467325\n",
      "train loss:0.046908152768537686\n",
      "train loss:0.09898188856680751\n",
      "train loss:0.0664681688414451\n",
      "train loss:0.04987190488981816\n",
      "train loss:0.04024618788891801\n",
      "train loss:0.0879361808914568\n",
      "train loss:0.06079222358325967\n",
      "train loss:0.03990728866093571\n",
      "train loss:0.031388925424834555\n",
      "train loss:0.050584817964134145\n",
      "train loss:0.09542496032731601\n",
      "train loss:0.07887024218794858\n",
      "train loss:0.1109545404563563\n",
      "train loss:0.057517817350642354\n",
      "train loss:0.03391650002324327\n",
      "train loss:0.07036867505570493\n",
      "train loss:0.02821971007166586\n",
      "train loss:0.07678635697202355\n",
      "train loss:0.02412700086473916\n",
      "train loss:0.12578063721821545\n",
      "train loss:0.031086432543233733\n",
      "train loss:0.04945152574268583\n",
      "train loss:0.046568839277296895\n",
      "train loss:0.061987082284110366\n",
      "train loss:0.02547921551837579\n",
      "train loss:0.05320512919514658\n",
      "train loss:0.06270660260522525\n",
      "train loss:0.055882768533661135\n",
      "train loss:0.08163434593266157\n",
      "train loss:0.06223768040557636\n",
      "train loss:0.0421262952154108\n",
      "train loss:0.038347030155016046\n",
      "train loss:0.04856706430998602\n",
      "train loss:0.06711973011767569\n",
      "train loss:0.07877032337160751\n",
      "train loss:0.057483737594525325\n",
      "train loss:0.04161728519049556\n",
      "train loss:0.038664657624328455\n",
      "train loss:0.0130844306235958\n",
      "train loss:0.01939557419881537\n",
      "train loss:0.03669408253189317\n",
      "train loss:0.1295933030449662\n",
      "train loss:0.024426080128489645\n",
      "train loss:0.05610774073282629\n",
      "train loss:0.007572474004284636\n",
      "train loss:0.06617802733799408\n",
      "train loss:0.039802429458444005\n",
      "train loss:0.04536570309512777\n",
      "train loss:0.05564163363601137\n",
      "train loss:0.02408772392591854\n",
      "train loss:0.09849226703546796\n",
      "train loss:0.07813555875357305\n",
      "train loss:0.045608381260706835\n",
      "train loss:0.03799697058649243\n",
      "train loss:0.06647719361651375\n",
      "train loss:0.05356521059680012\n",
      "train loss:0.0589480578312981\n",
      "train loss:0.08660885886538218\n",
      "train loss:0.06505724991760868\n",
      "train loss:0.042228044337250574\n",
      "train loss:0.02440594743699915\n",
      "train loss:0.08776776960269642\n",
      "train loss:0.038862689580151\n",
      "train loss:0.010275707413759834\n",
      "train loss:0.0187337769276458\n",
      "train loss:0.06137136292099966\n",
      "train loss:0.05420669047317721\n",
      "train loss:0.02231486966230007\n",
      "train loss:0.0452967184458251\n",
      "train loss:0.06511406886072599\n",
      "train loss:0.06953229211729373\n",
      "train loss:0.07153948975947451\n",
      "train loss:0.03431834049623562\n",
      "train loss:0.03228267886186659\n",
      "train loss:0.025311595477146086\n",
      "train loss:0.09767733022128688\n",
      "train loss:0.062640078541305\n",
      "train loss:0.08399511225294588\n",
      "train loss:0.028737596141641782\n",
      "train loss:0.03869439085369651\n",
      "train loss:0.056401479118075463\n",
      "train loss:0.04714355144238677\n",
      "train loss:0.052987686292652755\n",
      "train loss:0.05517949505988084\n",
      "train loss:0.03591140246658799\n",
      "train loss:0.07558648784041554\n",
      "train loss:0.09889913063320728\n",
      "train loss:0.07076011136520505\n",
      "train loss:0.03483232293686454\n",
      "train loss:0.06452154671441457\n",
      "train loss:0.07233292172509186\n",
      "train loss:0.019977952201426924\n",
      "train loss:0.11243805734582572\n",
      "train loss:0.05196348307948282\n",
      "train loss:0.06760422584366715\n",
      "train loss:0.04322959366158672\n",
      "train loss:0.028962822343818154\n",
      "train loss:0.03771043719645649\n",
      "train loss:0.05022073767244538\n",
      "train loss:0.047274078594818844\n",
      "train loss:0.07373571009883147\n",
      "train loss:0.0847875483446879\n",
      "train loss:0.059780095897837796\n",
      "train loss:0.11736655366676756\n",
      "train loss:0.10551262773514804\n",
      "train loss:0.03781922936205766\n",
      "train loss:0.021325300457164943\n",
      "train loss:0.048115876914297466\n",
      "train loss:0.044851916919459035\n",
      "train loss:0.09687572913264103\n",
      "train loss:0.06397758021407851\n",
      "train loss:0.03566618711648251\n",
      "train loss:0.06980003656283564\n",
      "train loss:0.05559865872554098\n",
      "train loss:0.03140637811383815\n",
      "train loss:0.07879322176825534\n",
      "train loss:0.045102666291156\n",
      "train loss:0.08672909670432576\n",
      "train loss:0.043361183610388876\n",
      "train loss:0.02092562796371885\n",
      "train loss:0.06914426392285229\n",
      "train loss:0.06305289897617526\n",
      "train loss:0.042352665511138976\n",
      "train loss:0.027360659657008367\n",
      "train loss:0.04623570341368267\n",
      "train loss:0.05514272490261078\n",
      "train loss:0.04416485893966787\n",
      "train loss:0.04007267727225758\n",
      "train loss:0.038354830407556044\n",
      "train loss:0.07712246292696603\n",
      "train loss:0.07426758414132792\n",
      "train loss:0.031148402455308\n",
      "train loss:0.07087090727090478\n",
      "train loss:0.050177038912249144\n",
      "train loss:0.03927066046520619\n",
      "train loss:0.09129592175901995\n",
      "train loss:0.07976944578777884\n",
      "train loss:0.059234011061291315\n",
      "train loss:0.060544890202694754\n",
      "train loss:0.03238841199045124\n",
      "train loss:0.07117890168379871\n",
      "train loss:0.045267423007300175\n",
      "train loss:0.08350720938008274\n",
      "train loss:0.04258048998345777\n",
      "train loss:0.062444317651544706\n",
      "train loss:0.03552954239451501\n",
      "train loss:0.026795614834220074\n",
      "train loss:0.04027681722339744\n",
      "train loss:0.07731805153217733\n",
      "train loss:0.0402607232852181\n",
      "train loss:0.030022721774845332\n",
      "train loss:0.03849822072618316\n",
      "train loss:0.054203675601026985\n",
      "train loss:0.04120151498469712\n",
      "train loss:0.05074531981130368\n",
      "train loss:0.02967252135780948\n",
      "train loss:0.08203163679568061\n",
      "train loss:0.07235318949200484\n",
      "train loss:0.04955222541302984\n",
      "train loss:0.03011495505961305\n",
      "train loss:0.02559526220686668\n",
      "train loss:0.017432511815593046\n",
      "train loss:0.07398256719330071\n",
      "train loss:0.04567073156152126\n",
      "train loss:0.1409729365492131\n",
      "train loss:0.048653762015928345\n",
      "train loss:0.04843502102250701\n",
      "train loss:0.057933842633681946\n",
      "train loss:0.04938858789841153\n",
      "train loss:0.033675542192207385\n",
      "train loss:0.06825796257934058\n",
      "train loss:0.0802824644129846\n",
      "train loss:0.01335729384558805\n",
      "train loss:0.0672243760508816\n",
      "train loss:0.059981537946139335\n",
      "train loss:0.03194178421476399\n",
      "train loss:0.05451018888530673\n",
      "train loss:0.08334012232073765\n",
      "train loss:0.10629057981063829\n",
      "train loss:0.09790837487850534\n",
      "train loss:0.06908826706929337\n",
      "train loss:0.05757362879190559\n",
      "train loss:0.039434064072078494\n",
      "train loss:0.053131840187453365\n",
      "train loss:0.027407895914746613\n",
      "train loss:0.07961964195468782\n",
      "train loss:0.05890441195256766\n",
      "train loss:0.04184016533926507\n",
      "train loss:0.07690645363270797\n",
      "train loss:0.034319201876536705\n",
      "train loss:0.10273789093339572\n",
      "train loss:0.05159674470589651\n",
      "train loss:0.051695112560517155\n",
      "train loss:0.13509265210022567\n",
      "train loss:0.013283529347148595\n",
      "train loss:0.026686404670494622\n",
      "train loss:0.03452038132677651\n",
      "train loss:0.057445672020689786\n",
      "train loss:0.028483440132447434\n",
      "train loss:0.05370248160034011\n",
      "train loss:0.03154638509079167\n",
      "train loss:0.024281041025426546\n",
      "train loss:0.02757154328797331\n",
      "train loss:0.04803105993059448\n",
      "train loss:0.0669759762205314\n",
      "train loss:0.09438943103108953\n",
      "train loss:0.03108020914522241\n",
      "train loss:0.028884070052718473\n",
      "train loss:0.029700055169124055\n",
      "train loss:0.10070676942818237\n",
      "train loss:0.03483018334018958\n",
      "train loss:0.08588907457000676\n",
      "train loss:0.09636187434207828\n",
      "train loss:0.0801131154462069\n",
      "train loss:0.0735595197360182\n",
      "train loss:0.04571054734950969\n",
      "train loss:0.02968429636630947\n",
      "train loss:0.04402342025326982\n",
      "train loss:0.02652295635065084\n",
      "train loss:0.052506961432588886\n",
      "train loss:0.04031453620526389\n",
      "train loss:0.044544325424187535\n",
      "train loss:0.04318503456069393\n",
      "train loss:0.027473290777533185\n",
      "train loss:0.0785938950479569\n",
      "train loss:0.05312222690722375\n",
      "train loss:0.05930227613755142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.08892241584624734\n",
      "train loss:0.06616045967003799\n",
      "train loss:0.07196462231401929\n",
      "train loss:0.034777935014870275\n",
      "train loss:0.07300102207220718\n",
      "train loss:0.023339176466965962\n",
      "train loss:0.10094257103219352\n",
      "train loss:0.051811410323728796\n",
      "train loss:0.028164727461841975\n",
      "train loss:0.02115069926585211\n",
      "train loss:0.04326338314222876\n",
      "train loss:0.018559533718127665\n",
      "train loss:0.07420578743435832\n",
      "train loss:0.03873235135492139\n",
      "train loss:0.06911126645132792\n",
      "train loss:0.0379424040735942\n",
      "train loss:0.033829700774587794\n",
      "train loss:0.022317421770839143\n",
      "train loss:0.09856093921566615\n",
      "train loss:0.08302470208076693\n",
      "train loss:0.028544230795548284\n",
      "train loss:0.09704690306167833\n",
      "train loss:0.03708196511196408\n",
      "train loss:0.035871371553027144\n",
      "train loss:0.14526883412966377\n",
      "train loss:0.04720933123475456\n",
      "train loss:0.04324154613682774\n",
      "train loss:0.04339820595073536\n",
      "train loss:0.04390635258306614\n",
      "train loss:0.07497896904652485\n",
      "train loss:0.046086046962803495\n",
      "train loss:0.06234393402873736\n",
      "train loss:0.048286916147348855\n",
      "train loss:0.06366942238947997\n",
      "train loss:0.041292872752401524\n",
      "train loss:0.059819127642088514\n",
      "train loss:0.06515735295538716\n",
      "train loss:0.055978946470571694\n",
      "train loss:0.027037465701562926\n",
      "train loss:0.04739438150604061\n",
      "train loss:0.12381102836182784\n",
      "train loss:0.031169731539433407\n",
      "train loss:0.06869317047785893\n",
      "train loss:0.055995189490321534\n",
      "train loss:0.024725839331669677\n",
      "train loss:0.03550773379631418\n",
      "train loss:0.07501961931884689\n",
      "train loss:0.03583776454950769\n",
      "train loss:0.027554503249187307\n",
      "train loss:0.0284658798714132\n",
      "train loss:0.03201447682334323\n",
      "train loss:0.03801249423086922\n",
      "train loss:0.07822176034504985\n",
      "train loss:0.05743492837384773\n",
      "train loss:0.07182746036060095\n",
      "train loss:0.061609561745911846\n",
      "train loss:0.042567995806269375\n",
      "train loss:0.1076538621641505\n",
      "train loss:0.09677607056375395\n",
      "train loss:0.03353755016312888\n",
      "train loss:0.03805577100206593\n",
      "train loss:0.04123336223898608\n",
      "train loss:0.04345412575191677\n",
      "train loss:0.07102121701663316\n",
      "train loss:0.04403140271599812\n",
      "train loss:0.08067263281447674\n",
      "train loss:0.040827553105716445\n",
      "train loss:0.08227159161774841\n",
      "train loss:0.037667094100426714\n",
      "train loss:0.049598213099377425\n",
      "train loss:0.08162350713540986\n",
      "train loss:0.04756548476105213\n",
      "train loss:0.08554578779071806\n",
      "train loss:0.07797777126376147\n",
      "train loss:0.04776729117086174\n",
      "train loss:0.04968223905019053\n",
      "train loss:0.03283858815607966\n",
      "train loss:0.0348440734848501\n",
      "train loss:0.09257678405599334\n",
      "train loss:0.059727859189649506\n",
      "train loss:0.038642358237711685\n",
      "train loss:0.017848797468181892\n",
      "train loss:0.08594504858423652\n",
      "train loss:0.10135370900698916\n",
      "train loss:0.1669286036336408\n",
      "train loss:0.020725246494686357\n",
      "train loss:0.04946081649474107\n",
      "train loss:0.02170636496441913\n",
      "train loss:0.0436546011295251\n",
      "train loss:0.0698526178186779\n",
      "train loss:0.07220156546533948\n",
      "train loss:0.05089743026002202\n",
      "train loss:0.0800685718561198\n",
      "train loss:0.07431170297167324\n",
      "train loss:0.05173599037556892\n",
      "train loss:0.022503817702545646\n",
      "train loss:0.0633177146215236\n",
      "train loss:0.07274704215862807\n",
      "train loss:0.03728627628069074\n",
      "train loss:0.04532445578351022\n",
      "train loss:0.08693021821228598\n",
      "train loss:0.032635485800355905\n",
      "train loss:0.03209994537062878\n",
      "train loss:0.07023694696716984\n",
      "train loss:0.06902115724207873\n",
      "train loss:0.08834929402644094\n",
      "train loss:0.05079853093653331\n",
      "train loss:0.10811571626183417\n",
      "train loss:0.0422779348555911\n",
      "train loss:0.07356530564898552\n",
      "train loss:0.08257008447534626\n",
      "train loss:0.04120456060232531\n",
      "train loss:0.05465793023128051\n",
      "train loss:0.020400654185188775\n",
      "train loss:0.030664189943031408\n",
      "train loss:0.045425551823056465\n",
      "train loss:0.06829131076860151\n",
      "train loss:0.02866663913248591\n",
      "train loss:0.05007801294197287\n",
      "train loss:0.031013447416601725\n",
      "train loss:0.05623605194336812\n",
      "train loss:0.11156420085956525\n",
      "train loss:0.07655865918117058\n",
      "train loss:0.08830431607639593\n",
      "train loss:0.06336021993470731\n",
      "train loss:0.07593346717336423\n",
      "train loss:0.038037482067444756\n",
      "train loss:0.21805306690749585\n",
      "train loss:0.0506024243416554\n",
      "train loss:0.050168867685833174\n",
      "train loss:0.031509333028742495\n",
      "train loss:0.07114169040872714\n",
      "train loss:0.06014699357257574\n",
      "train loss:0.12837958903622032\n",
      "train loss:0.08591828660119633\n",
      "train loss:0.10374596373387275\n",
      "train loss:0.07064827012702862\n",
      "train loss:0.047757485797610945\n",
      "train loss:0.05985136974534757\n",
      "train loss:0.02910912750968193\n",
      "train loss:0.04880664084117511\n",
      "train loss:0.040027381272758226\n",
      "train loss:0.08172297251491538\n",
      "train loss:0.07303643007413858\n",
      "train loss:0.09280328988925594\n",
      "train loss:0.1065326750939267\n",
      "train loss:0.08690527297045908\n",
      "train loss:0.06270123024695821\n",
      "train loss:0.08837435188804536\n",
      "train loss:0.0959193297357387\n",
      "train loss:0.06039823596518504\n",
      "train loss:0.06021750184596125\n",
      "train loss:0.04965234391234559\n",
      "train loss:0.06333527741241007\n",
      "train loss:0.10281658091718977\n",
      "train loss:0.10095254759340054\n",
      "train loss:0.08609176999465618\n",
      "train loss:0.1325730497350126\n",
      "train loss:0.06081774380848406\n",
      "train loss:0.08858806779672848\n",
      "train loss:0.04985168192821554\n",
      "train loss:0.052044729336642934\n",
      "train loss:0.029819851756367238\n",
      "train loss:0.04351401195429468\n",
      "train loss:0.09077423238403858\n",
      "train loss:0.0929515209295266\n",
      "train loss:0.07587550519475487\n",
      "train loss:0.07716740090470378\n",
      "train loss:0.026285825424529185\n",
      "train loss:0.03955802001685766\n",
      "train loss:0.07362151092958694\n",
      "train loss:0.03157245269252229\n",
      "train loss:0.05134198119484477\n",
      "train loss:0.0891989156753433\n",
      "train loss:0.04576904710382907\n",
      "train loss:0.05425140175172997\n",
      "train loss:0.07842393563378575\n",
      "train loss:0.04683717600100899\n",
      "train loss:0.03157461953774947\n",
      "train loss:0.06961689893374463\n",
      "train loss:0.052523009916706415\n",
      "train loss:0.06759855092873245\n",
      "train loss:0.06597278083688746\n",
      "train loss:0.02918368656951793\n",
      "train loss:0.017525994238552577\n",
      "train loss:0.026041851686494838\n",
      "train loss:0.03668518998972823\n",
      "train loss:0.03329779537249431\n",
      "train loss:0.020545134970194022\n",
      "train loss:0.015175088239626426\n",
      "train loss:0.03883902115704154\n",
      "train loss:0.027598469512384698\n",
      "train loss:0.06221762311068943\n",
      "train loss:0.13224286806556063\n",
      "train loss:0.04480124985895662\n",
      "train loss:0.02884769942537913\n",
      "train loss:0.060674634080187084\n",
      "train loss:0.08564962790574433\n",
      "train loss:0.08141998466471581\n",
      "train loss:0.049087512226035086\n",
      "train loss:0.1091889552033975\n",
      "train loss:0.028423871134158705\n",
      "train loss:0.04094668211486475\n",
      "train loss:0.05232133662594873\n",
      "train loss:0.0404936957339973\n",
      "train loss:0.06177766795724107\n",
      "train loss:0.04681351301473377\n",
      "train loss:0.055342105366879696\n",
      "train loss:0.1342269641958584\n",
      "train loss:0.09202909147228736\n",
      "train loss:0.06282828275835098\n",
      "train loss:0.1226924904079716\n",
      "train loss:0.08144771463633753\n",
      "train loss:0.048412715331554466\n",
      "train loss:0.0572636693495521\n",
      "train loss:0.06375587439887652\n",
      "train loss:0.075391743068946\n",
      "train loss:0.04773885832420291\n",
      "train loss:0.055967219492023\n",
      "train loss:0.06340673262943328\n",
      "train loss:0.06497931275815798\n",
      "train loss:0.09595182063586906\n",
      "train loss:0.06772049667291226\n",
      "train loss:0.036557741820373496\n",
      "train loss:0.06544820963574959\n",
      "train loss:0.014431603445614966\n",
      "train loss:0.09020692893052408\n",
      "train loss:0.06197370469765955\n",
      "train loss:0.05235419447856015\n",
      "train loss:0.05656271526781292\n",
      "train loss:0.10826090737442519\n",
      "train loss:0.06264375624131041\n",
      "train loss:0.1025644258814427\n",
      "train loss:0.04119640392703244\n",
      "train loss:0.07851096533516828\n",
      "train loss:0.033358367154046865\n",
      "train loss:0.032961869025253714\n",
      "train loss:0.03395158946376244\n",
      "train loss:0.045603389466503844\n",
      "train loss:0.06565496454453494\n",
      "train loss:0.041497805051607085\n",
      "train loss:0.03170437097901005\n",
      "train loss:0.009777398954048005\n",
      "train loss:0.03842047286623405\n",
      "train loss:0.06782628030450884\n",
      "train loss:0.022985724852660733\n",
      "train loss:0.03782592989940087\n",
      "train loss:0.047335633460935826\n",
      "train loss:0.04165554094989897\n",
      "train loss:0.041610315924470995\n",
      "train loss:0.08152162728510987\n",
      "train loss:0.07231853939642069\n",
      "train loss:0.0858284440105131\n",
      "train loss:0.03644583555350754\n",
      "train loss:0.08658380502277645\n",
      "train loss:0.04968707004708235\n",
      "train loss:0.0771763514065486\n",
      "train loss:0.08266812604555039\n",
      "train loss:0.06940508801044441\n",
      "train loss:0.03774518532741175\n",
      "train loss:0.04056452610164395\n",
      "train loss:0.03467717206600537\n",
      "train loss:0.05484912365620418\n",
      "train loss:0.07875660984162501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.08015978357160647\n",
      "train loss:0.05900425393191488\n",
      "train loss:0.03277924014159538\n",
      "train loss:0.045202123768778524\n",
      "train loss:0.05523301914325649\n",
      "train loss:0.07322803974023567\n",
      "train loss:0.05066353111001939\n",
      "train loss:0.08088554367695412\n",
      "train loss:0.015636278944399083\n",
      "train loss:0.023565751143963597\n",
      "train loss:0.09571996183605833\n",
      "train loss:0.05602254925949734\n",
      "train loss:0.016158066646008086\n",
      "train loss:0.04876712934087313\n",
      "train loss:0.03740163233216475\n",
      "train loss:0.04810571208794096\n",
      "train loss:0.020651819012342053\n",
      "train loss:0.021372732332765928\n",
      "train loss:0.0873738117249347\n",
      "train loss:0.036627564683943056\n",
      "train loss:0.01791287801411369\n",
      "train loss:0.025433678746445282\n",
      "train loss:0.029645556088967812\n",
      "train loss:0.03981084435639813\n",
      "train loss:0.02833318951183697\n",
      "train loss:0.03542913188344714\n",
      "train loss:0.09203426718822527\n",
      "train loss:0.0762282903593378\n",
      "train loss:0.05445113643159709\n",
      "train loss:0.08186591206425423\n",
      "train loss:0.039949787282191146\n",
      "train loss:0.06693555534991642\n",
      "train loss:0.04260480399478712\n",
      "train loss:0.06680685288629234\n",
      "train loss:0.05209613707606584\n",
      "train loss:0.049426825903860314\n",
      "train loss:0.05722188153751019\n",
      "train loss:0.11469658742597291\n",
      "train loss:0.0286122685736282\n",
      "train loss:0.10842310090627764\n",
      "train loss:0.03029422585691999\n",
      "train loss:0.05527636180156036\n",
      "train loss:0.04589029751645091\n",
      "train loss:0.015721851897544888\n",
      "train loss:0.04521101496038352\n",
      "train loss:0.07710151592456405\n",
      "train loss:0.07843272828527667\n",
      "train loss:0.021426443837307806\n",
      "train loss:0.03472598642429613\n",
      "train loss:0.038705837604902024\n",
      "train loss:0.03766320682725843\n",
      "train loss:0.06247041145725543\n",
      "train loss:0.07102486691570646\n",
      "train loss:0.11035074560600475\n",
      "train loss:0.02667689680010361\n",
      "train loss:0.025880557730900578\n",
      "train loss:0.024085515561750443\n",
      "train loss:0.052556542172313175\n",
      "train loss:0.050164606190512745\n",
      "train loss:0.06592966055563959\n",
      "train loss:0.07245446736201983\n",
      "train loss:0.04226764987821257\n",
      "train loss:0.020920043944615312\n",
      "train loss:0.07382508641008025\n",
      "train loss:0.039466309514552995\n",
      "train loss:0.06350432453890044\n",
      "train loss:0.05751945630280552\n",
      "train loss:0.04687956870850424\n",
      "train loss:0.04982546324661841\n",
      "train loss:0.03915206021877236\n",
      "train loss:0.10463595737064284\n",
      "train loss:0.06023458426181404\n",
      "train loss:0.03992658945826841\n",
      "train loss:0.07174573984157454\n",
      "train loss:0.10110784800177701\n",
      "train loss:0.1375142515563954\n",
      "train loss:0.057177666721364824\n",
      "train loss:0.06759323637049622\n",
      "train loss:0.06316521081271248\n",
      "train loss:0.03059026937473742\n",
      "train loss:0.038974124829218304\n",
      "train loss:0.054748192187764604\n",
      "train loss:0.08436571185553852\n",
      "train loss:0.05708209269962247\n",
      "train loss:0.06780537456391073\n",
      "train loss:0.06452138379368756\n",
      "train loss:0.03038421624169469\n",
      "train loss:0.05870897321666565\n",
      "train loss:0.029637817254776166\n",
      "train loss:0.05678210335440899\n",
      "=== epoch:22, train acc:0.976, test acc:0.918 ===\n",
      "train loss:0.036822868133627895\n",
      "train loss:0.05062685564114447\n",
      "train loss:0.037548771581241064\n",
      "train loss:0.03584264856642134\n",
      "train loss:0.057733536986050465\n",
      "train loss:0.0421801043911319\n",
      "train loss:0.1326601822988896\n",
      "train loss:0.06406422379797631\n",
      "train loss:0.07187662696096504\n",
      "train loss:0.07447165004568677\n",
      "train loss:0.035589945447830396\n",
      "train loss:0.07863942581023636\n",
      "train loss:0.0586996698574574\n",
      "train loss:0.03052447341938966\n",
      "train loss:0.04954378459112324\n",
      "train loss:0.026304026791994603\n",
      "train loss:0.047424788897222785\n",
      "train loss:0.024444350761320625\n",
      "train loss:0.05698062863457781\n",
      "train loss:0.13949152216419955\n",
      "train loss:0.04129030827983416\n",
      "train loss:0.05653861542131288\n",
      "train loss:0.07220700319832017\n",
      "train loss:0.08133003849685555\n",
      "train loss:0.056116065980102235\n",
      "train loss:0.04408901824885545\n",
      "train loss:0.04885151166535713\n",
      "train loss:0.061672636628236945\n",
      "train loss:0.04249131563716221\n",
      "train loss:0.04822415944853862\n",
      "train loss:0.03494691816953918\n",
      "train loss:0.06890210317789056\n",
      "train loss:0.12512590074749094\n",
      "train loss:0.08804790344080927\n",
      "train loss:0.06298582162244307\n",
      "train loss:0.05654309907846529\n",
      "train loss:0.01940494409917152\n",
      "train loss:0.07044954502483596\n",
      "train loss:0.043319745017022314\n",
      "train loss:0.061232126729802216\n",
      "train loss:0.04595112059026235\n",
      "train loss:0.026960546631552767\n",
      "train loss:0.022361426167415793\n",
      "train loss:0.06345659993240957\n",
      "train loss:0.051043281365254475\n",
      "train loss:0.08555144715258342\n",
      "train loss:0.032742922668239756\n",
      "train loss:0.045178858236588425\n",
      "train loss:0.05451577646298513\n",
      "train loss:0.04769290453006416\n",
      "train loss:0.05082116261208194\n",
      "train loss:0.05435523128735908\n",
      "train loss:0.05169679188323954\n",
      "train loss:0.024530197324223346\n",
      "train loss:0.053716375145236306\n",
      "train loss:0.05659213820401412\n",
      "train loss:0.030660418110134747\n",
      "train loss:0.06689918579540491\n",
      "train loss:0.04071379265432586\n",
      "train loss:0.039995944863877565\n",
      "train loss:0.0750874824963325\n",
      "train loss:0.058309257239843995\n",
      "train loss:0.13579207027101747\n",
      "train loss:0.06108662935708017\n",
      "train loss:0.07380147537927666\n",
      "train loss:0.056245694021211684\n",
      "train loss:0.03230310875689671\n",
      "train loss:0.060054730670319495\n",
      "train loss:0.09765440049489625\n",
      "train loss:0.055665433016064345\n",
      "train loss:0.04804688210379325\n",
      "train loss:0.05987266216401799\n",
      "train loss:0.009971968734327978\n",
      "train loss:0.06260422787397063\n",
      "train loss:0.053390254006341425\n",
      "train loss:0.02119351976456826\n",
      "train loss:0.0734342337194237\n",
      "train loss:0.08038541433737295\n",
      "train loss:0.03780582391307181\n",
      "train loss:0.009626366005907331\n",
      "train loss:0.014177413438250918\n",
      "train loss:0.06567373833872937\n",
      "train loss:0.04379558435169256\n",
      "train loss:0.03625174601874192\n",
      "train loss:0.03660830179417497\n",
      "train loss:0.07259538601496261\n",
      "train loss:0.060428817350801245\n",
      "train loss:0.06293971190994446\n",
      "train loss:0.02904650880559344\n",
      "train loss:0.05729010050888261\n",
      "train loss:0.022774973906553905\n",
      "train loss:0.07586199111584126\n",
      "train loss:0.091501515810161\n",
      "train loss:0.036198384779504836\n",
      "train loss:0.04149463113059502\n",
      "train loss:0.02584715901513634\n",
      "train loss:0.04686003267258626\n",
      "train loss:0.05609212414373555\n",
      "train loss:0.09071007358576372\n",
      "train loss:0.08353674868663312\n",
      "train loss:0.048602084792331815\n",
      "train loss:0.04262624947500862\n",
      "train loss:0.012681961489015183\n",
      "train loss:0.0688242465126247\n",
      "train loss:0.04929748525586859\n",
      "train loss:0.06970375694207757\n",
      "train loss:0.030673228520400043\n",
      "train loss:0.049080427268633355\n",
      "train loss:0.03294230825657912\n",
      "train loss:0.08905510868465286\n",
      "train loss:0.022114016495964797\n",
      "train loss:0.03283936377130194\n",
      "train loss:0.10075626618567307\n",
      "train loss:0.055635133241648295\n",
      "train loss:0.07142765123126965\n",
      "train loss:0.09248750987439308\n",
      "train loss:0.03582265362320464\n",
      "train loss:0.06601801220889818\n",
      "train loss:0.06345917871326194\n",
      "train loss:0.06347013967081112\n",
      "train loss:0.05378943491572279\n",
      "train loss:0.059564695624094416\n",
      "train loss:0.020958084412930882\n",
      "train loss:0.06323870520376478\n",
      "train loss:0.01737501993253016\n",
      "train loss:0.03116130289733864\n",
      "train loss:0.038323862666273675\n",
      "train loss:0.08393471066651054\n",
      "train loss:0.055145240522358335\n",
      "train loss:0.03763505807565901\n",
      "train loss:0.0378172147456095\n",
      "train loss:0.08638271362229681\n",
      "train loss:0.08723832573587754\n",
      "train loss:0.04009817769592423\n",
      "train loss:0.04487501249962837\n",
      "train loss:0.025724436695778806\n",
      "train loss:0.056716596917153514\n",
      "train loss:0.014446884866691392\n",
      "train loss:0.07580327537624403\n",
      "train loss:0.03351466077980709\n",
      "train loss:0.07281081300094047\n",
      "train loss:0.0330197620612988\n",
      "train loss:0.04434577598444423\n",
      "train loss:0.045008431668626676\n",
      "train loss:0.051106922458192997\n",
      "train loss:0.058240203143759016\n",
      "train loss:0.020831723613499428\n",
      "train loss:0.09850164484912202\n",
      "train loss:0.03721699270123339\n",
      "train loss:0.028258681045414336\n",
      "train loss:0.04806777115357442\n",
      "train loss:0.025607552017385012\n",
      "train loss:0.03775605036787631\n",
      "train loss:0.021334777134001746\n",
      "train loss:0.06770878682439747\n",
      "train loss:0.03706502210804313\n",
      "train loss:0.11320763502124062\n",
      "train loss:0.08615748594392969\n",
      "train loss:0.057848537557932456\n",
      "train loss:0.03799788018534317\n",
      "train loss:0.08961673522654307\n",
      "train loss:0.020675267559540463\n",
      "train loss:0.03541453975706007\n",
      "train loss:0.04142658932662185\n",
      "train loss:0.02665072618155806\n",
      "train loss:0.06382830671015399\n",
      "train loss:0.012792233953080349\n",
      "train loss:0.04148484980223449\n",
      "train loss:0.028066517414428685\n",
      "train loss:0.026450504773633338\n",
      "train loss:0.017033696584147107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.049749128300706894\n",
      "train loss:0.03555137351831405\n",
      "train loss:0.05827199713926725\n",
      "train loss:0.06676952169090498\n",
      "train loss:0.04944478623001394\n",
      "train loss:0.11826508828826869\n",
      "train loss:0.047496478119517585\n",
      "train loss:0.0933007035719734\n",
      "train loss:0.07112170245424063\n",
      "train loss:0.05491538386930475\n",
      "train loss:0.07890519038491181\n",
      "train loss:0.06751066398354748\n",
      "train loss:0.07799066974556004\n",
      "train loss:0.061079547824663474\n",
      "train loss:0.04018800482754656\n",
      "train loss:0.09923895395518682\n",
      "train loss:0.034994876440210966\n",
      "train loss:0.08805298991800509\n",
      "train loss:0.0747666837204025\n",
      "train loss:0.05011208581902004\n",
      "train loss:0.03128070818976227\n",
      "train loss:0.1081961916774039\n",
      "train loss:0.026758217289551856\n",
      "train loss:0.07546645475517795\n",
      "train loss:0.03405236898372416\n",
      "train loss:0.09875461730650584\n",
      "train loss:0.04453862043171761\n",
      "train loss:0.08565256187227657\n",
      "train loss:0.0987121966633565\n",
      "train loss:0.0590969468594772\n",
      "train loss:0.048053466869147236\n",
      "train loss:0.04663999011093025\n",
      "train loss:0.03440755622310916\n",
      "train loss:0.021315962462593294\n",
      "train loss:0.05045993482403028\n",
      "train loss:0.0568450037111458\n",
      "train loss:0.03942935775852692\n",
      "train loss:0.05669189901595134\n",
      "train loss:0.06790363627181982\n",
      "train loss:0.038188616726503435\n",
      "train loss:0.05443355204259486\n",
      "train loss:0.03539306253520119\n",
      "train loss:0.04035707792517667\n",
      "train loss:0.0250315925257503\n",
      "train loss:0.10093507471402537\n",
      "train loss:0.0959541063643882\n",
      "train loss:0.032991581420128646\n",
      "train loss:0.04500458592357219\n",
      "train loss:0.06926355373258737\n",
      "train loss:0.03336785552212546\n",
      "train loss:0.07483114812312333\n",
      "train loss:0.10071101467148927\n",
      "train loss:0.06897253321836166\n",
      "train loss:0.020421603626946096\n",
      "train loss:0.05788226253180012\n",
      "train loss:0.014381894028867812\n",
      "train loss:0.0545791310357088\n",
      "train loss:0.030138957691295185\n",
      "train loss:0.05381868735846083\n",
      "train loss:0.055903363398405806\n",
      "train loss:0.08628765921893118\n",
      "train loss:0.041809128235493764\n",
      "train loss:0.03092658268059126\n",
      "train loss:0.048509027060210104\n",
      "train loss:0.04605975803405313\n",
      "train loss:0.05481647929217531\n",
      "train loss:0.036920995411066075\n",
      "train loss:0.04945124610426696\n",
      "train loss:0.03841292333372154\n",
      "train loss:0.08175206052614134\n",
      "train loss:0.07277383159757587\n",
      "train loss:0.033337399449854796\n",
      "train loss:0.029282606641004412\n",
      "train loss:0.03661614772370686\n",
      "train loss:0.037821265559544896\n",
      "train loss:0.04223227154810202\n",
      "train loss:0.02784020294781048\n",
      "train loss:0.03084273596124197\n",
      "train loss:0.03999485947346515\n",
      "train loss:0.08344369644588463\n",
      "train loss:0.04077497645713845\n",
      "train loss:0.06293834111177925\n",
      "train loss:0.07637693903444301\n",
      "train loss:0.061938486865205776\n",
      "train loss:0.07610408785362327\n",
      "train loss:0.052382325448930026\n",
      "train loss:0.027386404159529424\n",
      "train loss:0.014911811423823433\n",
      "train loss:0.08309176444459633\n",
      "train loss:0.0645515706589672\n",
      "train loss:0.03709439618355601\n",
      "train loss:0.026808827059418325\n",
      "train loss:0.023339817440589036\n",
      "train loss:0.17893812470877882\n",
      "train loss:0.036329518572034945\n",
      "train loss:0.03687552197158912\n",
      "train loss:0.019694391171697696\n",
      "train loss:0.05041971246291132\n",
      "train loss:0.026737291951825882\n",
      "train loss:0.06430948331826933\n",
      "train loss:0.040275734003917\n",
      "train loss:0.013032935883671064\n",
      "train loss:0.013544957974503353\n",
      "train loss:0.07706019449252316\n",
      "train loss:0.16855067328259898\n",
      "train loss:0.019592739666284564\n",
      "train loss:0.02690073306704664\n",
      "train loss:0.059176508785900986\n",
      "train loss:0.04718264385141722\n",
      "train loss:0.025224830690731746\n",
      "train loss:0.04068776222042685\n",
      "train loss:0.035357526803061305\n",
      "train loss:0.06705812653619617\n",
      "train loss:0.02308262829203857\n",
      "train loss:0.032103733009094214\n",
      "train loss:0.1123596055998347\n",
      "train loss:0.03163282001169233\n",
      "train loss:0.058579152810736265\n",
      "train loss:0.020728402909195105\n",
      "train loss:0.06523675306840054\n",
      "train loss:0.06831784500254837\n",
      "train loss:0.07714894319115907\n",
      "train loss:0.01706489976568487\n",
      "train loss:0.04121329594372955\n",
      "train loss:0.07763919606273556\n",
      "train loss:0.07823127944603932\n",
      "train loss:0.0796178255255443\n",
      "train loss:0.021448696676717626\n",
      "train loss:0.01956245264585535\n",
      "train loss:0.04284969423808758\n",
      "train loss:0.03680083497164406\n",
      "train loss:0.028945233986885352\n",
      "train loss:0.027651471627526302\n",
      "train loss:0.016131083356880196\n",
      "train loss:0.03039761674660291\n",
      "train loss:0.07950453066945876\n",
      "train loss:0.06339981616791705\n",
      "train loss:0.023154558568730145\n",
      "train loss:0.07014131332928547\n",
      "train loss:0.04968294707142329\n",
      "train loss:0.030873894444069527\n",
      "train loss:0.04767911454141201\n",
      "train loss:0.02582487250196584\n",
      "train loss:0.046829989482063905\n",
      "train loss:0.06670578574640414\n",
      "train loss:0.03297380170458235\n",
      "train loss:0.032472653179369766\n",
      "train loss:0.11027335624860375\n",
      "train loss:0.018169653937483196\n",
      "train loss:0.03551150023215846\n",
      "train loss:0.0885780292436907\n",
      "train loss:0.0282304587996301\n",
      "train loss:0.04822911329462614\n",
      "train loss:0.053332005440553984\n",
      "train loss:0.02031954094226623\n",
      "train loss:0.023688466348413876\n",
      "train loss:0.04664038452327885\n",
      "train loss:0.0677909107042397\n",
      "train loss:0.037515116729234174\n",
      "train loss:0.06143236615195934\n",
      "train loss:0.14157394301414838\n",
      "train loss:0.03365177831294452\n",
      "train loss:0.03874496055017878\n",
      "train loss:0.040770457772980134\n",
      "train loss:0.04972682669514021\n",
      "train loss:0.06927508331332566\n",
      "train loss:0.05399593863521316\n",
      "train loss:0.06062421238840534\n",
      "train loss:0.04833078586005667\n",
      "train loss:0.07760716451628773\n",
      "train loss:0.02571705735745248\n",
      "train loss:0.05721111677174898\n",
      "train loss:0.06457497340409878\n",
      "train loss:0.03692400401938524\n",
      "train loss:0.10071613476159483\n",
      "train loss:0.047374161260708654\n",
      "train loss:0.04505623669629422\n",
      "train loss:0.056499575658551376\n",
      "train loss:0.03393104103995372\n",
      "train loss:0.05923902583064135\n",
      "train loss:0.10975750051243593\n",
      "train loss:0.039801363757513405\n",
      "train loss:0.04349863711647935\n",
      "train loss:0.04442086645967993\n",
      "train loss:0.15318754366754248\n",
      "train loss:0.044779771185231805\n",
      "train loss:0.0644492294973876\n",
      "train loss:0.015594902395986675\n",
      "train loss:0.027153480813762\n",
      "train loss:0.0402170570429047\n",
      "train loss:0.08265022617589671\n",
      "train loss:0.04856854149143745\n",
      "train loss:0.047365986198465826\n",
      "train loss:0.07985266361184219\n",
      "train loss:0.07021263144402169\n",
      "train loss:0.03673895711538911\n",
      "train loss:0.01732653448169785\n",
      "train loss:0.053890222396885436\n",
      "train loss:0.05462836505017691\n",
      "train loss:0.023905050829348712\n",
      "train loss:0.03778204263738347\n",
      "train loss:0.08357350555257088\n",
      "train loss:0.041443133838440026\n",
      "train loss:0.04421749120421162\n",
      "train loss:0.01551928158483179\n",
      "train loss:0.1189237303919711\n",
      "train loss:0.0438813553385605\n",
      "train loss:0.05653203224928109\n",
      "train loss:0.02323191522673859\n",
      "train loss:0.053766303834540397\n",
      "train loss:0.03644571504299457\n",
      "train loss:0.030548465749563047\n",
      "train loss:0.017430022894641455\n",
      "train loss:0.012383644413913882\n",
      "train loss:0.01821995599385827\n",
      "train loss:0.057943163737481956\n",
      "train loss:0.06040844067190962\n",
      "train loss:0.028913453077724766\n",
      "train loss:0.08292719370905102\n",
      "train loss:0.03334271746931519\n",
      "train loss:0.033728903577106915\n",
      "train loss:0.03584862335974655\n",
      "train loss:0.05677637616286976\n",
      "train loss:0.01205936031080179\n",
      "train loss:0.03510214670063481\n",
      "train loss:0.04456003319460823\n",
      "train loss:0.08299266420103718\n",
      "train loss:0.046974322448240916\n",
      "train loss:0.07611226532022002\n",
      "train loss:0.07048503771006863\n",
      "train loss:0.03080703433366667\n",
      "train loss:0.02854351839484656\n",
      "train loss:0.03785238117507887\n",
      "train loss:0.09335669029924615\n",
      "train loss:0.02954191596696495\n",
      "train loss:0.05421603684691237\n",
      "train loss:0.04083996760329168\n",
      "train loss:0.057579403611237326\n",
      "train loss:0.025200713625216267\n",
      "train loss:0.07049105018717308\n",
      "train loss:0.07935451331587969\n",
      "train loss:0.037096811843129344\n",
      "train loss:0.09770050958712075\n",
      "train loss:0.04638783197144084\n",
      "train loss:0.04932223513452885\n",
      "train loss:0.04116337244349916\n",
      "train loss:0.051955684860188395\n",
      "train loss:0.06224390406670698\n",
      "train loss:0.04614656102199765\n",
      "train loss:0.037023928830058214\n",
      "train loss:0.1352501347296036\n",
      "train loss:0.03310892910038481\n",
      "train loss:0.050609872700521114\n",
      "train loss:0.09817631468847621\n",
      "train loss:0.022606016644523105\n",
      "train loss:0.053319831857106016\n",
      "train loss:0.05188624379744691\n",
      "train loss:0.06261793223338652\n",
      "train loss:0.04686298097836374\n",
      "train loss:0.03281433700097497\n",
      "train loss:0.02948914081083666\n",
      "train loss:0.03470942694637013\n",
      "train loss:0.05607792669865448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.040989957925147716\n",
      "train loss:0.0543990707207338\n",
      "train loss:0.052254446664929725\n",
      "train loss:0.05767433029447578\n",
      "train loss:0.05599140351241027\n",
      "train loss:0.032935693350995096\n",
      "train loss:0.05758986755030983\n",
      "train loss:0.05957046239576846\n",
      "train loss:0.030922000415428422\n",
      "train loss:0.03818156258957306\n",
      "train loss:0.03925160926181489\n",
      "train loss:0.04804032279933364\n",
      "train loss:0.04587449613643828\n",
      "train loss:0.03475248884433815\n",
      "train loss:0.0825564125129661\n",
      "train loss:0.0739327510553544\n",
      "train loss:0.10063241406047803\n",
      "train loss:0.04086613521408202\n",
      "train loss:0.02627057409019441\n",
      "train loss:0.02436672835585469\n",
      "train loss:0.07004416002198259\n",
      "train loss:0.0385786925100632\n",
      "train loss:0.03243617683316429\n",
      "train loss:0.05244723768057067\n",
      "train loss:0.055346718291229696\n",
      "train loss:0.04778730440578293\n",
      "train loss:0.029735316312235867\n",
      "train loss:0.06297742745441981\n",
      "train loss:0.06837194135106556\n",
      "train loss:0.021594628627109907\n",
      "train loss:0.04963124013608004\n",
      "train loss:0.014839485524644971\n",
      "train loss:0.0492379189640678\n",
      "train loss:0.08370369592499749\n",
      "train loss:0.023639445850084453\n",
      "train loss:0.02525643172406589\n",
      "train loss:0.03957030272259861\n",
      "train loss:0.03894893234818471\n",
      "train loss:0.07844993984370163\n",
      "train loss:0.06759734261241507\n",
      "train loss:0.022856993324184102\n",
      "train loss:0.03277826414421332\n",
      "train loss:0.06474864846855706\n",
      "train loss:0.09230965418855443\n",
      "train loss:0.03973259076052501\n",
      "train loss:0.038654480355185934\n",
      "train loss:0.04349079138720109\n",
      "train loss:0.027544355570824977\n",
      "train loss:0.06392373585419206\n",
      "train loss:0.03599385023955537\n",
      "train loss:0.04380352981126059\n",
      "train loss:0.025986675387689995\n",
      "train loss:0.02816680589249946\n",
      "train loss:0.04531059027228177\n",
      "train loss:0.03999801633875742\n",
      "train loss:0.053571399822666566\n",
      "train loss:0.09184326418323849\n",
      "train loss:0.03986351237029051\n",
      "train loss:0.058685029469450437\n",
      "train loss:0.10169992613386722\n",
      "train loss:0.03797469462634414\n",
      "train loss:0.054504428439206755\n",
      "train loss:0.045144120237988555\n",
      "train loss:0.12258441934982772\n",
      "train loss:0.04606516699917289\n",
      "train loss:0.04066386296863225\n",
      "train loss:0.03295139785092171\n",
      "train loss:0.06826724896659205\n",
      "train loss:0.04046336004569698\n",
      "train loss:0.03752172093161765\n",
      "train loss:0.06822265429730401\n",
      "train loss:0.022094260461789347\n",
      "train loss:0.0579509915636328\n",
      "train loss:0.04992528581224031\n",
      "train loss:0.018964868674444108\n",
      "train loss:0.03939816167269082\n",
      "train loss:0.05748130897133477\n",
      "train loss:0.04498383578461907\n",
      "train loss:0.04980596961728289\n",
      "train loss:0.05299133815240063\n",
      "train loss:0.02295505846416493\n",
      "train loss:0.05436637922471148\n",
      "train loss:0.04804608657408628\n",
      "train loss:0.027920557937345856\n",
      "train loss:0.04051919088444528\n",
      "train loss:0.034449945980014794\n",
      "train loss:0.021137199550391075\n",
      "train loss:0.027742870092829355\n",
      "train loss:0.04307825391846949\n",
      "train loss:0.09255594470326654\n",
      "train loss:0.04041334029552938\n",
      "train loss:0.04409826276196621\n",
      "train loss:0.06971564155755569\n",
      "train loss:0.026422303909008845\n",
      "train loss:0.04409262506020477\n",
      "train loss:0.05889829300321841\n",
      "train loss:0.04413123847273507\n",
      "train loss:0.025208810266212453\n",
      "train loss:0.0374365714570236\n",
      "train loss:0.0367081000063026\n",
      "train loss:0.07131661845893676\n",
      "train loss:0.041469739438822914\n",
      "train loss:0.06121793841607368\n",
      "train loss:0.03342396999210612\n",
      "train loss:0.08088954610015894\n",
      "train loss:0.01795578720659836\n",
      "train loss:0.0408535983593403\n",
      "train loss:0.08372480629923373\n",
      "train loss:0.14338172328040386\n",
      "train loss:0.030162039970478786\n",
      "train loss:0.025731402759809053\n",
      "train loss:0.030811383101474\n",
      "train loss:0.027611534750616163\n",
      "train loss:0.025301468217625085\n",
      "train loss:0.01695851575371934\n",
      "train loss:0.04038540268543069\n",
      "train loss:0.039443472828096404\n",
      "train loss:0.02423386525058584\n",
      "train loss:0.036149462671018234\n",
      "train loss:0.07667400021758064\n",
      "train loss:0.06830079572555996\n",
      "train loss:0.031134830168367975\n",
      "train loss:0.07306118189015103\n",
      "train loss:0.03366180187895549\n",
      "train loss:0.0985845311197962\n",
      "train loss:0.057493415191627664\n",
      "train loss:0.04076111620690031\n",
      "train loss:0.12334137364167473\n",
      "train loss:0.06284414066514903\n",
      "train loss:0.043414965170804044\n",
      "train loss:0.048650936370682\n",
      "train loss:0.054574018882858864\n",
      "train loss:0.06266484325495544\n",
      "train loss:0.0380514408798543\n",
      "train loss:0.04653182921603761\n",
      "train loss:0.0508747738023982\n",
      "train loss:0.026228929552436088\n",
      "train loss:0.035676204486212074\n",
      "train loss:0.05756176776564355\n",
      "train loss:0.0251373050462376\n",
      "train loss:0.04446653772500162\n",
      "train loss:0.029576236257375762\n",
      "train loss:0.03966853657343141\n",
      "train loss:0.035100734273768835\n",
      "train loss:0.02334733986477541\n",
      "train loss:0.06060841123110544\n",
      "train loss:0.04722416443333054\n",
      "train loss:0.05217220553489718\n",
      "train loss:0.030235426568117906\n",
      "train loss:0.05025506073659868\n",
      "train loss:0.14035407970866667\n",
      "train loss:0.06533930335711412\n",
      "train loss:0.047815183866381256\n",
      "train loss:0.04956147819618941\n",
      "train loss:0.0595741581105931\n",
      "train loss:0.03671047777690099\n",
      "train loss:0.028206285045642807\n",
      "train loss:0.07994315087611889\n",
      "train loss:0.07427444779059443\n",
      "train loss:0.12045377948361503\n",
      "train loss:0.042682724895016906\n",
      "train loss:0.12491002073622605\n",
      "train loss:0.05436605190127357\n",
      "train loss:0.05403383230288502\n",
      "train loss:0.0554063339364886\n",
      "train loss:0.03873655885242028\n",
      "=== epoch:23, train acc:0.979, test acc:0.912 ===\n",
      "train loss:0.052472273841303645\n",
      "train loss:0.0812394947390519\n",
      "train loss:0.083779200533937\n",
      "train loss:0.13340823169233018\n",
      "train loss:0.06799352671801553\n",
      "train loss:0.06815646598319439\n",
      "train loss:0.03382976016344743\n",
      "train loss:0.03577256747868722\n",
      "train loss:0.05013569837978991\n",
      "train loss:0.11253562330648652\n",
      "train loss:0.05400284018672389\n",
      "train loss:0.03642194985294608\n",
      "train loss:0.09225662672590756\n",
      "train loss:0.03469572482167636\n",
      "train loss:0.0259411293882343\n",
      "train loss:0.05973322156829103\n",
      "train loss:0.021725359026899364\n",
      "train loss:0.05632044848289179\n",
      "train loss:0.05196023728127817\n",
      "train loss:0.055785404479159514\n",
      "train loss:0.05918419625203684\n",
      "train loss:0.0375402759324752\n",
      "train loss:0.05583237028151388\n",
      "train loss:0.029513416674021485\n",
      "train loss:0.05118462739234615\n",
      "train loss:0.03297334291577048\n",
      "train loss:0.016753806059450888\n",
      "train loss:0.0952542963275308\n",
      "train loss:0.028510758204641298\n",
      "train loss:0.042863921527387994\n",
      "train loss:0.03340823214563373\n",
      "train loss:0.10509797618385995\n",
      "train loss:0.05411204213925676\n",
      "train loss:0.05241297324218414\n",
      "train loss:0.053849076904744074\n",
      "train loss:0.03127046600232588\n",
      "train loss:0.0265207200408709\n",
      "train loss:0.04719231095886046\n",
      "train loss:0.035480893381988864\n",
      "train loss:0.04551543302187315\n",
      "train loss:0.06974873664400393\n",
      "train loss:0.04856530447971941\n",
      "train loss:0.03497882888957225\n",
      "train loss:0.0840591789557834\n",
      "train loss:0.04470522700879297\n",
      "train loss:0.037179938456601815\n",
      "train loss:0.023772139427314723\n",
      "train loss:0.03864446131872033\n",
      "train loss:0.11517728457305722\n",
      "train loss:0.01172669372245619\n",
      "train loss:0.04803500924590882\n",
      "train loss:0.07065559150021838\n",
      "train loss:0.04876509270257071\n",
      "train loss:0.04973055885495309\n",
      "train loss:0.04893690311807867\n",
      "train loss:0.04002548592176379\n",
      "train loss:0.07600908872804629\n",
      "train loss:0.04241936869121119\n",
      "train loss:0.03587471006081416\n",
      "train loss:0.033676727696911345\n",
      "train loss:0.1094561269990713\n",
      "train loss:0.023122889946572932\n",
      "train loss:0.06982026077602815\n",
      "train loss:0.044614393934611786\n",
      "train loss:0.021283112540592654\n",
      "train loss:0.021769554351634694\n",
      "train loss:0.031002444579093867\n",
      "train loss:0.059456906303140496\n",
      "train loss:0.03093209094082629\n",
      "train loss:0.053163836196742115\n",
      "train loss:0.04734222969591831\n",
      "train loss:0.036370448965763275\n",
      "train loss:0.04612838721868231\n",
      "train loss:0.03393367783318864\n",
      "train loss:0.04321481206325502\n",
      "train loss:0.023670804686076196\n",
      "train loss:0.04811233231583545\n",
      "train loss:0.09878871618674438\n",
      "train loss:0.05404105852926025\n",
      "train loss:0.04953614616019266\n",
      "train loss:0.03421656668313513\n",
      "train loss:0.06465954401215063\n",
      "train loss:0.029878067043745314\n",
      "train loss:0.051826048303852366\n",
      "train loss:0.07919139766713348\n",
      "train loss:0.026453602038382807\n",
      "train loss:0.052250772068976846\n",
      "train loss:0.020382712945231876\n",
      "train loss:0.03637367324522993\n",
      "train loss:0.049545803847798754\n",
      "train loss:0.018410913880278476\n",
      "train loss:0.044061044367128224\n",
      "train loss:0.02954478798595974\n",
      "train loss:0.0513405535048275\n",
      "train loss:0.03613651385251255\n",
      "train loss:0.017337464471921256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.035084058445503406\n",
      "train loss:0.04229133330865308\n",
      "train loss:0.018364923885549566\n",
      "train loss:0.020378152883352218\n",
      "train loss:0.03340826359086453\n",
      "train loss:0.02873997651560778\n",
      "train loss:0.03711211470173511\n",
      "train loss:0.037201643442346874\n",
      "train loss:0.05469677885759887\n",
      "train loss:0.06972998960645412\n",
      "train loss:0.037304012180645475\n",
      "train loss:0.02161443609186582\n",
      "train loss:0.07958806675751012\n",
      "train loss:0.029475298791700993\n",
      "train loss:0.030755258691918447\n",
      "train loss:0.018779513227849372\n",
      "train loss:0.022503651942792958\n",
      "train loss:0.046738775663730775\n",
      "train loss:0.057368108748207594\n",
      "train loss:0.0544735236290649\n",
      "train loss:0.05958387049273256\n",
      "train loss:0.07682149053012098\n",
      "train loss:0.15664121900358216\n",
      "train loss:0.03588654611707801\n",
      "train loss:0.05154186667129352\n",
      "train loss:0.04899271739306364\n",
      "train loss:0.043811241920413975\n",
      "train loss:0.08204411757480537\n",
      "train loss:0.025074021378646737\n",
      "train loss:0.10881201377892757\n",
      "train loss:0.052237474946227457\n",
      "train loss:0.015034534940636795\n",
      "train loss:0.04279223656751989\n",
      "train loss:0.06755759105121956\n",
      "train loss:0.02608615949622883\n",
      "train loss:0.03890261460573998\n",
      "train loss:0.04592258860453733\n",
      "train loss:0.03532369642648396\n",
      "train loss:0.09062502509608265\n",
      "train loss:0.029602435903800132\n",
      "train loss:0.05703320403518124\n",
      "train loss:0.033612248656007974\n",
      "train loss:0.08166296759355042\n",
      "train loss:0.015679626550792913\n",
      "train loss:0.020140308074989576\n",
      "train loss:0.06763848336678147\n",
      "train loss:0.037306818531607756\n",
      "train loss:0.09994644855703254\n",
      "train loss:0.1034723957208651\n",
      "train loss:0.029511713237558614\n",
      "train loss:0.07586081637738692\n",
      "train loss:0.04587615628123697\n",
      "train loss:0.040610311271842836\n",
      "train loss:0.07693910895213565\n",
      "train loss:0.02435538796505326\n",
      "train loss:0.05100036689890935\n",
      "train loss:0.03057198530047262\n",
      "train loss:0.05796269662224998\n",
      "train loss:0.03955839632017083\n",
      "train loss:0.0368547448088368\n",
      "train loss:0.028763762762667677\n",
      "train loss:0.02454560622831651\n",
      "train loss:0.047223771166027245\n",
      "train loss:0.0651878071978979\n",
      "train loss:0.0700221004393991\n",
      "train loss:0.10045980810745439\n",
      "train loss:0.021843456283106532\n",
      "train loss:0.05453560900519621\n",
      "train loss:0.013582448524346253\n",
      "train loss:0.02417165371255922\n",
      "train loss:0.037846332129732596\n",
      "train loss:0.06611573575223649\n",
      "train loss:0.03754933859387319\n",
      "train loss:0.10578516661154913\n",
      "train loss:0.06236778782619965\n",
      "train loss:0.07755720026592805\n",
      "train loss:0.02593746839346717\n",
      "train loss:0.06101969055834092\n",
      "train loss:0.05422209492527735\n",
      "train loss:0.03368304827839669\n",
      "train loss:0.051820503458335415\n",
      "train loss:0.03873888077993406\n",
      "train loss:0.03318464265337948\n",
      "train loss:0.08642848638667014\n",
      "train loss:0.09118765792268567\n",
      "train loss:0.02483290115892998\n",
      "train loss:0.046054216086035805\n",
      "train loss:0.037990085993572176\n",
      "train loss:0.03194574484210624\n",
      "train loss:0.08622628904853408\n",
      "train loss:0.03016727895063934\n",
      "train loss:0.06398964731911722\n",
      "train loss:0.06968634021184235\n",
      "train loss:0.05290315601115129\n",
      "train loss:0.031361587648074896\n",
      "train loss:0.06851148616536029\n",
      "train loss:0.033665472070253555\n",
      "train loss:0.03467728140605847\n",
      "train loss:0.09325435892140149\n",
      "train loss:0.03718720221311709\n",
      "train loss:0.0170019117954439\n",
      "train loss:0.0358763695815887\n",
      "train loss:0.036372075161058025\n",
      "train loss:0.024449042311609114\n",
      "train loss:0.045864568047368215\n",
      "train loss:0.03992581847639565\n",
      "train loss:0.05054587008242801\n",
      "train loss:0.012102200976300636\n",
      "train loss:0.020571111517598162\n",
      "train loss:0.028485099211922688\n",
      "train loss:0.03352166494891945\n",
      "train loss:0.06319281915610019\n",
      "train loss:0.020136651111697438\n",
      "train loss:0.08287188067052821\n",
      "train loss:0.03253648293578884\n",
      "train loss:0.09770654630735397\n",
      "train loss:0.02422674078663363\n",
      "train loss:0.015763451649332502\n",
      "train loss:0.07928948588836465\n",
      "train loss:0.04865469426522683\n",
      "train loss:0.0313039463994944\n",
      "train loss:0.07307992956665003\n",
      "train loss:0.03445576410506569\n",
      "train loss:0.028654225866291516\n",
      "train loss:0.021159826486590476\n",
      "train loss:0.0362566983306446\n",
      "train loss:0.02725343217108997\n",
      "train loss:0.028994624682822403\n",
      "train loss:0.027515194064828052\n",
      "train loss:0.04496864007604312\n",
      "train loss:0.0386026346856777\n",
      "train loss:0.12172838832280318\n",
      "train loss:0.03726154354921792\n",
      "train loss:0.08636566946821535\n",
      "train loss:0.1496098632122808\n",
      "train loss:0.07296885531876016\n",
      "train loss:0.055082378182716836\n",
      "train loss:0.09070532101378195\n",
      "train loss:0.0507382211584563\n",
      "train loss:0.049506101502123874\n",
      "train loss:0.03377439935402405\n",
      "train loss:0.08661725835224912\n",
      "train loss:0.044282399451511543\n",
      "train loss:0.0447272053247477\n",
      "train loss:0.021158460619761333\n",
      "train loss:0.03620002387318526\n",
      "train loss:0.030375782681877433\n",
      "train loss:0.05792572921186653\n",
      "train loss:0.045047992090532986\n",
      "train loss:0.071661816238773\n",
      "train loss:0.03754173065232181\n",
      "train loss:0.0417003429404682\n",
      "train loss:0.05885577493602719\n",
      "train loss:0.08097630529636204\n",
      "train loss:0.05988676445985295\n",
      "train loss:0.04866672903885646\n",
      "train loss:0.02131101269245364\n",
      "train loss:0.021453010723946352\n",
      "train loss:0.03825875968500844\n",
      "train loss:0.02690377518266856\n",
      "train loss:0.05312668584157256\n",
      "train loss:0.03945803701678427\n",
      "train loss:0.051115667749404486\n",
      "train loss:0.020045743219744935\n",
      "train loss:0.05200676965938016\n",
      "train loss:0.01848185515658274\n",
      "train loss:0.056635889213765375\n",
      "train loss:0.02463307052704041\n",
      "train loss:0.07510348120880021\n",
      "train loss:0.03366295233872478\n",
      "train loss:0.032327217733103666\n",
      "train loss:0.07709905581434338\n",
      "train loss:0.060254241286271534\n",
      "train loss:0.06517906189258672\n",
      "train loss:0.03376034336331418\n",
      "train loss:0.06270985514528742\n",
      "train loss:0.051799305656764966\n",
      "train loss:0.02545231535705277\n",
      "train loss:0.02374140423887856\n",
      "train loss:0.0319795157540591\n",
      "train loss:0.06873622839876742\n",
      "train loss:0.035248917173878555\n",
      "train loss:0.04094053736405824\n",
      "train loss:0.07897524413632157\n",
      "train loss:0.04404205939326676\n",
      "train loss:0.06490092626514188\n",
      "train loss:0.030640678055702194\n",
      "train loss:0.026938644179445977\n",
      "train loss:0.026170850726483376\n",
      "train loss:0.009993481016890396\n",
      "train loss:0.0592421714591763\n",
      "train loss:0.04133003930139614\n",
      "train loss:0.029493499234184425\n",
      "train loss:0.06387648164510738\n",
      "train loss:0.04404324909937581\n",
      "train loss:0.03958280830934162\n",
      "train loss:0.04092717407185644\n",
      "train loss:0.02115641511288294\n",
      "train loss:0.02903130373793737\n",
      "train loss:0.0331026739362936\n",
      "train loss:0.052133181020001265\n",
      "train loss:0.05612753018519245\n",
      "train loss:0.037293690140609896\n",
      "train loss:0.017331753480283568\n",
      "train loss:0.03463662448620131\n",
      "train loss:0.10079834589359389\n",
      "train loss:0.03128197007711532\n",
      "train loss:0.04901646672780709\n",
      "train loss:0.06293076758550882\n",
      "train loss:0.04103627828243678\n",
      "train loss:0.04454656111608588\n",
      "train loss:0.02526476295674297\n",
      "train loss:0.02969830874824745\n",
      "train loss:0.03524142438697019\n",
      "train loss:0.03025798397599926\n",
      "train loss:0.07918036766605638\n",
      "train loss:0.035258709887337585\n",
      "train loss:0.06390748037038393\n",
      "train loss:0.024799922901783344\n",
      "train loss:0.04429702000602605\n",
      "train loss:0.037259610083664636\n",
      "train loss:0.019687374560474993\n",
      "train loss:0.04885857160355989\n",
      "train loss:0.0318611247462834\n",
      "train loss:0.037391742706235694\n",
      "train loss:0.016304142026916876\n",
      "train loss:0.01990587532870422\n",
      "train loss:0.02109554698494579\n",
      "train loss:0.04635745664296882\n",
      "train loss:0.03825344962342697\n",
      "train loss:0.021444325690543817\n",
      "train loss:0.03329715495586779\n",
      "train loss:0.03564063261897064\n",
      "train loss:0.04687489294590517\n",
      "train loss:0.04742771998697179\n",
      "train loss:0.029299769084874736\n",
      "train loss:0.03639863183909424\n",
      "train loss:0.06918716861364274\n",
      "train loss:0.02566065449270866\n",
      "train loss:0.03485823634478916\n",
      "train loss:0.07837062552084202\n",
      "train loss:0.0969457639403899\n",
      "train loss:0.02432730829472464\n",
      "train loss:0.06176157398134171\n",
      "train loss:0.041865393352720465\n",
      "train loss:0.03257223365983719\n",
      "train loss:0.022754777057702572\n",
      "train loss:0.03235553771988659\n",
      "train loss:0.02057325079785169\n",
      "train loss:0.08163170602714045\n",
      "train loss:0.04371121324356471\n",
      "train loss:0.03617429239151989\n",
      "train loss:0.04435823933994424\n",
      "train loss:0.028912468267264152\n",
      "train loss:0.07488851818017504\n",
      "train loss:0.027994744627865026\n",
      "train loss:0.032567244305578585\n",
      "train loss:0.04399425257722395\n",
      "train loss:0.06616247010813933\n",
      "train loss:0.0275133553775768\n",
      "train loss:0.02832346530407472\n",
      "train loss:0.04516510197934876\n",
      "train loss:0.05671732389085874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.10026534124403436\n",
      "train loss:0.018675091113545744\n",
      "train loss:0.03269615746741281\n",
      "train loss:0.024713407095060605\n",
      "train loss:0.057964437284619086\n",
      "train loss:0.017325966840384222\n",
      "train loss:0.04028482267453455\n",
      "train loss:0.03429436348200179\n",
      "train loss:0.025670298279466028\n",
      "train loss:0.009137829765272252\n",
      "train loss:0.050810502390777515\n",
      "train loss:0.0630087822678556\n",
      "train loss:0.03973722883959096\n",
      "train loss:0.026822627604339257\n",
      "train loss:0.017955095207478587\n",
      "train loss:0.02771789015723298\n",
      "train loss:0.019361649625511027\n",
      "train loss:0.030805736213263456\n",
      "train loss:0.04739210506366044\n",
      "train loss:0.051139935962991115\n",
      "train loss:0.040545687801330894\n",
      "train loss:0.007877567171688592\n",
      "train loss:0.023950706153644377\n",
      "train loss:0.08716958501177459\n",
      "train loss:0.04006988763321803\n",
      "train loss:0.011842094403827622\n",
      "train loss:0.01860025529756878\n",
      "train loss:0.03597594311993822\n",
      "train loss:0.03132453072860744\n",
      "train loss:0.07406592283078989\n",
      "train loss:0.09359224573801775\n",
      "train loss:0.022238473851612373\n",
      "train loss:0.021462997433628613\n",
      "train loss:0.02652290066513879\n",
      "train loss:0.051695429462261744\n",
      "train loss:0.08902773556603377\n",
      "train loss:0.022234094813102748\n",
      "train loss:0.021664601091863793\n",
      "train loss:0.03515125122211248\n",
      "train loss:0.017408870966285902\n",
      "train loss:0.025505125566651455\n",
      "train loss:0.02394074418950601\n",
      "train loss:0.023478083454997502\n",
      "train loss:0.08218032722074332\n",
      "train loss:0.07432601808726061\n",
      "train loss:0.01812096689208315\n",
      "train loss:0.022927410999506587\n",
      "train loss:0.012109252085487788\n",
      "train loss:0.03574639327104849\n",
      "train loss:0.027732029020752474\n",
      "train loss:0.024388682586541022\n",
      "train loss:0.02412866449349458\n",
      "train loss:0.03619742375654806\n",
      "train loss:0.05926320230721802\n",
      "train loss:0.0241909952799071\n",
      "train loss:0.09565931237328724\n",
      "train loss:0.037444034113112146\n",
      "train loss:0.0592759866696391\n",
      "train loss:0.05445798302963866\n",
      "train loss:0.024127967055363336\n",
      "train loss:0.06244490526418899\n",
      "train loss:0.027022865048114422\n",
      "train loss:0.048892314582201175\n",
      "train loss:0.037885115324106045\n",
      "train loss:0.07717482459916648\n",
      "train loss:0.027890916039531796\n",
      "train loss:0.013271773796677471\n",
      "train loss:0.020345333164711894\n",
      "train loss:0.058806977794264935\n",
      "train loss:0.049225499664900044\n",
      "train loss:0.046609490947181184\n",
      "train loss:0.026693318778188382\n",
      "train loss:0.04254583325687159\n",
      "train loss:0.0320263412481499\n",
      "train loss:0.025810483995615835\n",
      "train loss:0.07220653647028653\n",
      "train loss:0.043904605110357375\n",
      "train loss:0.020626190043180427\n",
      "train loss:0.03133786453354613\n",
      "train loss:0.04479057119142962\n",
      "train loss:0.03813087666685014\n",
      "train loss:0.08405749433123201\n",
      "train loss:0.05533450704792197\n",
      "train loss:0.03012381726161275\n",
      "train loss:0.032872756390802\n",
      "train loss:0.0618082487787086\n",
      "train loss:0.02131967134270829\n",
      "train loss:0.029800441323806055\n",
      "train loss:0.024513946996635658\n",
      "train loss:0.07863214210444058\n",
      "train loss:0.10715174351560919\n",
      "train loss:0.03716470080948304\n",
      "train loss:0.11129016964216415\n",
      "train loss:0.0699137693588721\n",
      "train loss:0.02274895391389036\n",
      "train loss:0.020871403874712483\n",
      "train loss:0.032783065117534205\n",
      "train loss:0.040059079799762996\n",
      "train loss:0.033946651421481545\n",
      "train loss:0.03329035312353207\n",
      "train loss:0.028634552047064377\n",
      "train loss:0.029251190206009775\n",
      "train loss:0.09697977063022764\n",
      "train loss:0.023178789268054244\n",
      "train loss:0.06722785077319686\n",
      "train loss:0.03029189183072264\n",
      "train loss:0.04178485574491018\n",
      "train loss:0.08543653543334377\n",
      "train loss:0.04972475736458868\n",
      "train loss:0.027203266637805607\n",
      "train loss:0.05745863259390204\n",
      "train loss:0.03738415658540288\n",
      "train loss:0.05962077233836207\n",
      "train loss:0.06529115388192559\n",
      "train loss:0.018598948810118598\n",
      "train loss:0.03979922603213851\n",
      "train loss:0.023680224503860755\n",
      "train loss:0.0784001140932139\n",
      "train loss:0.036936178312181676\n",
      "train loss:0.07607065011470344\n",
      "train loss:0.022203582062732496\n",
      "train loss:0.04629587489490222\n",
      "train loss:0.015623199304031242\n",
      "train loss:0.03634998519020193\n",
      "train loss:0.0669671538481008\n",
      "train loss:0.0338794979791332\n",
      "train loss:0.06996893577878951\n",
      "train loss:0.05250921969511405\n",
      "train loss:0.04717733325787863\n",
      "train loss:0.03060349693821115\n",
      "train loss:0.040067575459187925\n",
      "train loss:0.035146212530513476\n",
      "train loss:0.028688449616578713\n",
      "train loss:0.006760717441599561\n",
      "train loss:0.06416177802075569\n",
      "train loss:0.06788864436429821\n",
      "train loss:0.11488469306676326\n",
      "train loss:0.026151189343166577\n",
      "train loss:0.025881545972300083\n",
      "train loss:0.09535713136914299\n",
      "train loss:0.04072054462134434\n",
      "train loss:0.03447680387412951\n",
      "train loss:0.031243920305526345\n",
      "train loss:0.036850239411796014\n",
      "train loss:0.05613639046466492\n",
      "train loss:0.01880065729385832\n",
      "train loss:0.04405170120139598\n",
      "train loss:0.01615754699482195\n",
      "train loss:0.05004611410310799\n",
      "train loss:0.0751778344943811\n",
      "train loss:0.02153049162408613\n",
      "train loss:0.03539376099503632\n",
      "train loss:0.029987592280532244\n",
      "train loss:0.05040261502047709\n",
      "train loss:0.05081256843039342\n",
      "train loss:0.08854803045375086\n",
      "train loss:0.04550474455127764\n",
      "train loss:0.03394002357262907\n",
      "train loss:0.08855507208073089\n",
      "train loss:0.0538743402923581\n",
      "train loss:0.04146003235962418\n",
      "train loss:0.041704686620242286\n",
      "train loss:0.05765926657365896\n",
      "train loss:0.04778190683505938\n",
      "train loss:0.03798188923852721\n",
      "train loss:0.027684593887427156\n",
      "train loss:0.07423909244133459\n",
      "train loss:0.033495456250485216\n",
      "train loss:0.019252758707304515\n",
      "train loss:0.061706206356405204\n",
      "train loss:0.03911129817319876\n",
      "train loss:0.04580227493695536\n",
      "train loss:0.03579059815857872\n",
      "train loss:0.05435261530725841\n",
      "train loss:0.023764463272624742\n",
      "train loss:0.04862965242213452\n",
      "train loss:0.06207460024485427\n",
      "train loss:0.023358499482907292\n",
      "train loss:0.08299116833736582\n",
      "train loss:0.0451750873761678\n",
      "train loss:0.04784456944022279\n",
      "train loss:0.02383107266319056\n",
      "train loss:0.017508904322581575\n",
      "train loss:0.06380624542744501\n",
      "train loss:0.07712044837607662\n",
      "train loss:0.031781318892566426\n",
      "train loss:0.01936649405626785\n",
      "train loss:0.032996941367424565\n",
      "train loss:0.04858710602571791\n",
      "train loss:0.019520994210032942\n",
      "train loss:0.06479855705424746\n",
      "train loss:0.046076570609712694\n",
      "train loss:0.03979734443670215\n",
      "train loss:0.0859224136445185\n",
      "train loss:0.02770719125511589\n",
      "train loss:0.04016443896307591\n",
      "train loss:0.042030299593749654\n",
      "train loss:0.03688989502696957\n",
      "train loss:0.054988062657800235\n",
      "train loss:0.05501717620976701\n",
      "train loss:0.06136960147235879\n",
      "train loss:0.04919299346066217\n",
      "train loss:0.04176482074352236\n",
      "train loss:0.0539869058730066\n",
      "train loss:0.05285598330144037\n",
      "train loss:0.03847887740804662\n",
      "train loss:0.06248253495553291\n",
      "train loss:0.027959357278439803\n",
      "train loss:0.04038979203300558\n",
      "train loss:0.05671188336372973\n",
      "train loss:0.030709717446074033\n",
      "train loss:0.026736028048070834\n",
      "train loss:0.01970169316948843\n",
      "train loss:0.052317236558305655\n",
      "train loss:0.10373627048935338\n",
      "train loss:0.03375779214682813\n",
      "train loss:0.0757071715416587\n",
      "train loss:0.042017557968918394\n",
      "train loss:0.06235124092924291\n",
      "train loss:0.08599729349811819\n",
      "train loss:0.03228810975320076\n",
      "train loss:0.019400627352224097\n",
      "train loss:0.03386245905111113\n",
      "train loss:0.04083025686817823\n",
      "train loss:0.04548757197964653\n",
      "train loss:0.01858692997140587\n",
      "train loss:0.047153154064937676\n",
      "train loss:0.04260743265681116\n",
      "train loss:0.08582681946793333\n",
      "train loss:0.024493567935708845\n",
      "train loss:0.02944471436165946\n",
      "train loss:0.18551514840323036\n",
      "train loss:0.07963552774865205\n",
      "train loss:0.09333732927309563\n",
      "train loss:0.07182003404907136\n",
      "train loss:0.04962381680706709\n",
      "train loss:0.019925681356059502\n",
      "train loss:0.06003080417727969\n",
      "train loss:0.12438235728773395\n",
      "train loss:0.09198974183982248\n",
      "train loss:0.037043436341979395\n",
      "=== epoch:24, train acc:0.98, test acc:0.908 ===\n",
      "train loss:0.14273415546329166\n",
      "train loss:0.04351095134600885\n",
      "train loss:0.0324751525723168\n",
      "train loss:0.05216431922157934\n",
      "train loss:0.029538325396473084\n",
      "train loss:0.05451328083617179\n",
      "train loss:0.04278823949514138\n",
      "train loss:0.0435545188484298\n",
      "train loss:0.03880192589455611\n",
      "train loss:0.05779899154366266\n",
      "train loss:0.09870851138222707\n",
      "train loss:0.036514992166363315\n",
      "train loss:0.05365627282335028\n",
      "train loss:0.035064498220066104\n",
      "train loss:0.06363477483007639\n",
      "train loss:0.09053978604719866\n",
      "train loss:0.06774254740049386\n",
      "train loss:0.04505450188528234\n",
      "train loss:0.07798037655345133\n",
      "train loss:0.03489085764744044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.026544630578072846\n",
      "train loss:0.04897852715085171\n",
      "train loss:0.05542872043570259\n",
      "train loss:0.05312084464122543\n",
      "train loss:0.03910436874244936\n",
      "train loss:0.0897513915287367\n",
      "train loss:0.07340207366120148\n",
      "train loss:0.06298968505725439\n",
      "train loss:0.01633259516863482\n",
      "train loss:0.04833289603121755\n",
      "train loss:0.06705332775024135\n",
      "train loss:0.016911207724434024\n",
      "train loss:0.05757018447204979\n",
      "train loss:0.11619656938554014\n",
      "train loss:0.03799027328382759\n",
      "train loss:0.029506847274810608\n",
      "train loss:0.0835246105067548\n",
      "train loss:0.035730810309380495\n",
      "train loss:0.01701978155755636\n",
      "train loss:0.05009278968624717\n",
      "train loss:0.031156527738145298\n",
      "train loss:0.03212147157002875\n",
      "train loss:0.02991367567405707\n",
      "train loss:0.07812660939196772\n",
      "train loss:0.05166069511540495\n",
      "train loss:0.09723713894666117\n",
      "train loss:0.024256591997877882\n",
      "train loss:0.05772020321006312\n",
      "train loss:0.01198116155124065\n",
      "train loss:0.025494864293230193\n",
      "train loss:0.01690030142983477\n",
      "train loss:0.09622673319552119\n",
      "train loss:0.04726055484356144\n",
      "train loss:0.04212008419380904\n",
      "train loss:0.031169819416812638\n",
      "train loss:0.038995890871274745\n",
      "train loss:0.038765537547855326\n",
      "train loss:0.04515949578187946\n",
      "train loss:0.027240572790871175\n",
      "train loss:0.023254716531556228\n",
      "train loss:0.04789478120100136\n",
      "train loss:0.04442966069004957\n",
      "train loss:0.027166603474625465\n",
      "train loss:0.029091002870173247\n",
      "train loss:0.048137665970695576\n",
      "train loss:0.05988800972836636\n",
      "train loss:0.03722614034652084\n",
      "train loss:0.03432427784488709\n",
      "train loss:0.03554567997504956\n",
      "train loss:0.08356969603989282\n",
      "train loss:0.02915844767782112\n",
      "train loss:0.08176254316114796\n",
      "train loss:0.03942429225348674\n",
      "train loss:0.05074962243217109\n",
      "train loss:0.07286458131856778\n",
      "train loss:0.04837150721194758\n",
      "train loss:0.016161943068375175\n",
      "train loss:0.02427763545068093\n",
      "train loss:0.014209170093738127\n",
      "train loss:0.03504463589284662\n",
      "train loss:0.0402188212119132\n",
      "train loss:0.04692715038615274\n",
      "train loss:0.031983281241925406\n",
      "train loss:0.05112131234188382\n",
      "train loss:0.0198782701804163\n",
      "train loss:0.05810513306885093\n",
      "train loss:0.04314444965721873\n",
      "train loss:0.01983513779805721\n",
      "train loss:0.02582558138323341\n",
      "train loss:0.02469958072499244\n",
      "train loss:0.08149134986807241\n",
      "train loss:0.02010647000625741\n",
      "train loss:0.04091579113028538\n",
      "train loss:0.054095856576292685\n",
      "train loss:0.030434167173192708\n",
      "train loss:0.040920849015518616\n",
      "train loss:0.07111090410624354\n",
      "train loss:0.039152288196966284\n",
      "train loss:0.0471569661579198\n",
      "train loss:0.04046631134499003\n",
      "train loss:0.04740532581306759\n",
      "train loss:0.04568218718514697\n",
      "train loss:0.019141527762516576\n",
      "train loss:0.03622265661551021\n",
      "train loss:0.013300515874049621\n",
      "train loss:0.04664943039964897\n",
      "train loss:0.052530540967491685\n",
      "train loss:0.025509515690995334\n",
      "train loss:0.03449505019824572\n",
      "train loss:0.019854611265829276\n",
      "train loss:0.06379827454097779\n",
      "train loss:0.022561979120670355\n",
      "train loss:0.07995867558147182\n",
      "train loss:0.025772014294985622\n",
      "train loss:0.024891752153424575\n",
      "train loss:0.0408073424878378\n",
      "train loss:0.02486517187804517\n",
      "train loss:0.04290097569618213\n",
      "train loss:0.04233941562924825\n",
      "train loss:0.054952989644136835\n",
      "train loss:0.06492350739846237\n",
      "train loss:0.0561055142152194\n",
      "train loss:0.034318333396107605\n",
      "train loss:0.05195757153195686\n",
      "train loss:0.03417741338437058\n",
      "train loss:0.014451998464256745\n",
      "train loss:0.05445337241292903\n",
      "train loss:0.0331888953885197\n",
      "train loss:0.027879789165709445\n",
      "train loss:0.05262021945841651\n",
      "train loss:0.018378576467616297\n",
      "train loss:0.04778678449641739\n",
      "train loss:0.05429115362970619\n",
      "train loss:0.018139463459841375\n",
      "train loss:0.047356848798679095\n",
      "train loss:0.04459692268293952\n",
      "train loss:0.06511566467401761\n",
      "train loss:0.05275056745853588\n",
      "train loss:0.013354637547961188\n",
      "train loss:0.049975679747152474\n",
      "train loss:0.039329686006088764\n",
      "train loss:0.02512966189769109\n",
      "train loss:0.09489002191987925\n",
      "train loss:0.05370852855788848\n",
      "train loss:0.035171144593544555\n",
      "train loss:0.03249410108241953\n",
      "train loss:0.06524272530666574\n",
      "train loss:0.040266106408809385\n",
      "train loss:0.057472200579773404\n",
      "train loss:0.03390176896468353\n",
      "train loss:0.04402757036051873\n",
      "train loss:0.024541841624028265\n",
      "train loss:0.06719239679486506\n",
      "train loss:0.06093647517934775\n",
      "train loss:0.06347647846861179\n",
      "train loss:0.03258307520764836\n",
      "train loss:0.06105265050668422\n",
      "train loss:0.04050895923687128\n",
      "train loss:0.026851121047333403\n",
      "train loss:0.050915573889294706\n",
      "train loss:0.017861571807181544\n",
      "train loss:0.03503961200081668\n",
      "train loss:0.047012070829889806\n",
      "train loss:0.06658556403073723\n",
      "train loss:0.01668640831407168\n",
      "train loss:0.05015066156776665\n",
      "train loss:0.021089777413240442\n",
      "train loss:0.03451430974707823\n",
      "train loss:0.04620851846429377\n",
      "train loss:0.04604456504758342\n",
      "train loss:0.02083108439810341\n",
      "train loss:0.010545778542602469\n",
      "train loss:0.03844612667481292\n",
      "train loss:0.01938501083938399\n",
      "train loss:0.06747578144462087\n",
      "train loss:0.034092667423706854\n",
      "train loss:0.03189484421068287\n",
      "train loss:0.08210074281051702\n",
      "train loss:0.026640775534108766\n",
      "train loss:0.029184830878521657\n",
      "train loss:0.020622471569439707\n",
      "train loss:0.0598323621732058\n",
      "train loss:0.058002790455257316\n",
      "train loss:0.021177909045966184\n",
      "train loss:0.0434122959281025\n",
      "train loss:0.0245837258284628\n",
      "train loss:0.029222669884203106\n",
      "train loss:0.036736912932408335\n",
      "train loss:0.02377546929642072\n",
      "train loss:0.04477671555007982\n",
      "train loss:0.04824202062224648\n",
      "train loss:0.06772356685672666\n",
      "train loss:0.04320193128546949\n",
      "train loss:0.06530260997808572\n",
      "train loss:0.06838152498566248\n",
      "train loss:0.061362446163515605\n",
      "train loss:0.022911827200354912\n",
      "train loss:0.04987898182847537\n",
      "train loss:0.03059035923685249\n",
      "train loss:0.032828984247771274\n",
      "train loss:0.031475294871164385\n",
      "train loss:0.0356631450318821\n",
      "train loss:0.04667718470217769\n",
      "train loss:0.03446756494418633\n",
      "train loss:0.02219221502117946\n",
      "train loss:0.032067993611733944\n",
      "train loss:0.047899083650553766\n",
      "train loss:0.040706034593305115\n",
      "train loss:0.04483219979216629\n",
      "train loss:0.06275112127191758\n",
      "train loss:0.012905841628877946\n",
      "train loss:0.03467176626288524\n",
      "train loss:0.022186470869346508\n",
      "train loss:0.0368983339880934\n",
      "train loss:0.034429851674500786\n",
      "train loss:0.029877137364452543\n",
      "train loss:0.022964778471683548\n",
      "train loss:0.05560655036973544\n",
      "train loss:0.0540431605965563\n",
      "train loss:0.04043517921959855\n",
      "train loss:0.029281419430284287\n",
      "train loss:0.07450618580788426\n",
      "train loss:0.03254762099900623\n",
      "train loss:0.03130796210927967\n",
      "train loss:0.037071596353568353\n",
      "train loss:0.04432968367892884\n",
      "train loss:0.050455160900804145\n",
      "train loss:0.01760448267231402\n",
      "train loss:0.045698336053504394\n",
      "train loss:0.016901382117548956\n",
      "train loss:0.05912968663840089\n",
      "train loss:0.03031416616172033\n",
      "train loss:0.06355580467706141\n",
      "train loss:0.0501879882550276\n",
      "train loss:0.12431237263111333\n",
      "train loss:0.0639876072842922\n",
      "train loss:0.01760078327815949\n",
      "train loss:0.04021549179395418\n",
      "train loss:0.013583417761239384\n",
      "train loss:0.023749091971217006\n",
      "train loss:0.03421330288136514\n",
      "train loss:0.044468383102488185\n",
      "train loss:0.019729899941888427\n",
      "train loss:0.04173327944633298\n",
      "train loss:0.08428580128055099\n",
      "train loss:0.04128532248276232\n",
      "train loss:0.03359869654808746\n",
      "train loss:0.05331586518789335\n",
      "train loss:0.035191983048979324\n",
      "train loss:0.07134381897126588\n",
      "train loss:0.06089991358309813\n",
      "train loss:0.04959374198473828\n",
      "train loss:0.061152389402968764\n",
      "train loss:0.036426032924331546\n",
      "train loss:0.03909638677014479\n",
      "train loss:0.05412798230682518\n",
      "train loss:0.050555935475155606\n",
      "train loss:0.03799357588669097\n",
      "train loss:0.016681072556142807\n",
      "train loss:0.04773176805613738\n",
      "train loss:0.07546351735428415\n",
      "train loss:0.05946073848684686\n",
      "train loss:0.04206982870037386\n",
      "train loss:0.043744529752623856\n",
      "train loss:0.03125426892196475\n",
      "train loss:0.05063066529490147\n",
      "train loss:0.05031540918593309\n",
      "train loss:0.04286417316318593\n",
      "train loss:0.03816509177296097\n",
      "train loss:0.02249750809423713\n",
      "train loss:0.04132330738031094\n",
      "train loss:0.040352711438985035\n",
      "train loss:0.0159995453749305\n",
      "train loss:0.06284739634318413\n",
      "train loss:0.029615770748120204\n",
      "train loss:0.02490339857685093\n",
      "train loss:0.08045715532565151\n",
      "train loss:0.056067210526316955\n",
      "train loss:0.045332235314547456\n",
      "train loss:0.03510363600519271\n",
      "train loss:0.07500803009713422\n",
      "train loss:0.04392741197679057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.027086261823086235\n",
      "train loss:0.01789693632077347\n",
      "train loss:0.03516458577329298\n",
      "train loss:0.05890478125114127\n",
      "train loss:0.029948201563268453\n",
      "train loss:0.02870743599483099\n",
      "train loss:0.059769882955644726\n",
      "train loss:0.10051251502648137\n",
      "train loss:0.014766688300814157\n",
      "train loss:0.019525795625593294\n",
      "train loss:0.02487682450412984\n",
      "train loss:0.032464110263427055\n",
      "train loss:0.024285250678842293\n",
      "train loss:0.054110734003153714\n",
      "train loss:0.017300066112054827\n",
      "train loss:0.011087632088131816\n",
      "train loss:0.09377565201777749\n",
      "train loss:0.049916805666055525\n",
      "train loss:0.016683290585144554\n",
      "train loss:0.033452509607198394\n",
      "train loss:0.08516986656727589\n",
      "train loss:0.035939247302693635\n",
      "train loss:0.019762016874207\n",
      "train loss:0.024633893863453982\n",
      "train loss:0.031664177987275374\n",
      "train loss:0.021751402913617435\n",
      "train loss:0.04316721058279614\n",
      "train loss:0.022582286258744304\n",
      "train loss:0.03249169510680549\n",
      "train loss:0.041460006552404984\n",
      "train loss:0.029658471632762758\n",
      "train loss:0.05234114050955733\n",
      "train loss:0.025412707133988643\n",
      "train loss:0.018911680740235203\n",
      "train loss:0.06535948686219713\n",
      "train loss:0.04874946351435454\n",
      "train loss:0.01621408845398349\n",
      "train loss:0.026440615208070298\n",
      "train loss:0.10031100578833042\n",
      "train loss:0.040401564267662476\n",
      "train loss:0.028738725145843004\n",
      "train loss:0.03377413192075778\n",
      "train loss:0.06980944830121205\n",
      "train loss:0.0461146792726911\n",
      "train loss:0.025321840828373604\n",
      "train loss:0.05051547035771264\n",
      "train loss:0.02777867272648071\n",
      "train loss:0.031379236545076614\n",
      "train loss:0.04155820992523451\n",
      "train loss:0.029076077073846893\n",
      "train loss:0.026546361264457564\n",
      "train loss:0.018744985193390257\n",
      "train loss:0.012934322914895213\n",
      "train loss:0.101100695546167\n",
      "train loss:0.043376465922129126\n",
      "train loss:0.05494161793217898\n",
      "train loss:0.01801499545262861\n",
      "train loss:0.06677060420372577\n",
      "train loss:0.05109730134108873\n",
      "train loss:0.037439306260525766\n",
      "train loss:0.03337691159438566\n",
      "train loss:0.041110583706777976\n",
      "train loss:0.020217942737778903\n",
      "train loss:0.053187041093326164\n",
      "train loss:0.07453968021897095\n",
      "train loss:0.0343949217708625\n",
      "train loss:0.01811640168995838\n",
      "train loss:0.11425354202927313\n",
      "train loss:0.036960046887600406\n",
      "train loss:0.02813617845886416\n",
      "train loss:0.03682300632184206\n",
      "train loss:0.03363918256750308\n",
      "train loss:0.06093953701154349\n",
      "train loss:0.023821141363733474\n",
      "train loss:0.0441394014796564\n",
      "train loss:0.043706036080123196\n",
      "train loss:0.05416886439141569\n",
      "train loss:0.036182128635143605\n",
      "train loss:0.021077316158546102\n",
      "train loss:0.020151478405667923\n",
      "train loss:0.08948651402175692\n",
      "train loss:0.04743179491608699\n",
      "train loss:0.06540889718417493\n",
      "train loss:0.025537203980619972\n",
      "train loss:0.01684436611336692\n",
      "train loss:0.04156698016762211\n",
      "train loss:0.0530364424662744\n",
      "train loss:0.04286147844333338\n",
      "train loss:0.09704018128814605\n",
      "train loss:0.019555169645566615\n",
      "train loss:0.050383546290708486\n",
      "train loss:0.030542592475714288\n",
      "train loss:0.0165544281174664\n",
      "train loss:0.06577619087822685\n",
      "train loss:0.021868395785828186\n",
      "train loss:0.04921407825514553\n",
      "train loss:0.051753636876600846\n",
      "train loss:0.051535239879712626\n",
      "train loss:0.011291304632520338\n",
      "train loss:0.0963045658037575\n",
      "train loss:0.06474959950183284\n",
      "train loss:0.10294891311627667\n",
      "train loss:0.0437312732170237\n",
      "train loss:0.02170641962413795\n",
      "train loss:0.08210454067287898\n",
      "train loss:0.041951759283250796\n",
      "train loss:0.03050262769831569\n",
      "train loss:0.027810553871843266\n",
      "train loss:0.014820956500782762\n",
      "train loss:0.009902911700051625\n",
      "train loss:0.030453837408745014\n",
      "train loss:0.0341813793664319\n",
      "train loss:0.027358723826571545\n",
      "train loss:0.07125994909160799\n",
      "train loss:0.04719111936559069\n",
      "train loss:0.0663818450639446\n",
      "train loss:0.04233776817336647\n",
      "train loss:0.04751861524056\n",
      "train loss:0.030495162648699982\n",
      "train loss:0.07194868505267307\n",
      "train loss:0.03628973382767259\n",
      "train loss:0.035901923678722476\n",
      "train loss:0.07279872880298109\n",
      "train loss:0.024916827911855656\n",
      "train loss:0.06054310533848407\n",
      "train loss:0.05642248294516365\n",
      "train loss:0.033695597457398384\n",
      "train loss:0.023499319701720065\n",
      "train loss:0.015923900353531625\n",
      "train loss:0.019950436231156582\n",
      "train loss:0.024691229158432377\n",
      "train loss:0.010024607712419054\n",
      "train loss:0.06875426372422598\n",
      "train loss:0.03360551547773821\n",
      "train loss:0.025598274698964328\n",
      "train loss:0.021052341136046322\n",
      "train loss:0.0177843714886667\n",
      "train loss:0.044546607560226305\n",
      "train loss:0.05530194894906849\n",
      "train loss:0.07898999344030605\n",
      "train loss:0.05191523568772111\n",
      "train loss:0.08590150523727531\n",
      "train loss:0.02050486025540714\n",
      "train loss:0.01559166420845012\n",
      "train loss:0.010749072846259155\n",
      "train loss:0.02246512142822396\n",
      "train loss:0.023047115297233467\n",
      "train loss:0.06407877435077419\n",
      "train loss:0.02050145780780305\n",
      "train loss:0.029982760487086382\n",
      "train loss:0.04043566124388466\n",
      "train loss:0.043164671203717\n",
      "train loss:0.026716580998016343\n",
      "train loss:0.04081156231875472\n",
      "train loss:0.033395998547555664\n",
      "train loss:0.03553188139372412\n",
      "train loss:0.030248264391954615\n",
      "train loss:0.05637763332094166\n",
      "train loss:0.04559742236404167\n",
      "train loss:0.01350846858931161\n",
      "train loss:0.045193372624590424\n",
      "train loss:0.01911046849652778\n",
      "train loss:0.037346712887054136\n",
      "train loss:0.03704533007223648\n",
      "train loss:0.03939824939281172\n",
      "train loss:0.033252270218734614\n",
      "train loss:0.08006584585897034\n",
      "train loss:0.03692683143910278\n",
      "train loss:0.017304585730552994\n",
      "train loss:0.025957419017107575\n",
      "train loss:0.01380579844713553\n",
      "train loss:0.028601583494820098\n",
      "train loss:0.045937506620161085\n",
      "train loss:0.05765458190993785\n",
      "train loss:0.042340845785734806\n",
      "train loss:0.08766310511962697\n",
      "train loss:0.07429619486874423\n",
      "train loss:0.02749292470447893\n",
      "train loss:0.04557106103651168\n",
      "train loss:0.03448570051171786\n",
      "train loss:0.037036523908782495\n",
      "train loss:0.0479802102953023\n",
      "train loss:0.05256300926081974\n",
      "train loss:0.033907152213025225\n",
      "train loss:0.04040096723608873\n",
      "train loss:0.023783003594571448\n",
      "train loss:0.035013321347105955\n",
      "train loss:0.022839240436054474\n",
      "train loss:0.008601817111366133\n",
      "train loss:0.039155384322481446\n",
      "train loss:0.06343885251098748\n",
      "train loss:0.050207732524531895\n",
      "train loss:0.045544884770270785\n",
      "train loss:0.04902016948895788\n",
      "train loss:0.04104332491997258\n",
      "train loss:0.03288842641345998\n",
      "train loss:0.008419136438625477\n",
      "train loss:0.03654001191855513\n",
      "train loss:0.014488656384689809\n",
      "train loss:0.02353970933660706\n",
      "train loss:0.01279402275607732\n",
      "train loss:0.007017201038706292\n",
      "train loss:0.06443254090587512\n",
      "train loss:0.0387634384623844\n",
      "train loss:0.03561548939176925\n",
      "train loss:0.045182812469954155\n",
      "train loss:0.027315536870970235\n",
      "train loss:0.035758250117752646\n",
      "train loss:0.04602429936389833\n",
      "train loss:0.014292065282728837\n",
      "train loss:0.028691566628512848\n",
      "train loss:0.011958769489625216\n",
      "train loss:0.03214067972165684\n",
      "train loss:0.02527410164076479\n",
      "train loss:0.04810674079437082\n",
      "train loss:0.04682909002461992\n",
      "train loss:0.0908121094197793\n",
      "train loss:0.023030002398844042\n",
      "train loss:0.05393907791449107\n",
      "train loss:0.07149487976922185\n",
      "train loss:0.051770541398869864\n",
      "train loss:0.006422643836724335\n",
      "train loss:0.039913351687456806\n",
      "train loss:0.021390547932705825\n",
      "train loss:0.036317678881610256\n",
      "train loss:0.022369418740305888\n",
      "train loss:0.04019099293835829\n",
      "train loss:0.018393285617825755\n",
      "train loss:0.019981155693312116\n",
      "train loss:0.009139395436448282\n",
      "train loss:0.0498799376959259\n",
      "train loss:0.023262605398289643\n",
      "train loss:0.02288871190398829\n",
      "train loss:0.013516229429509858\n",
      "train loss:0.06650859751935632\n",
      "train loss:0.07208045246823706\n",
      "train loss:0.03493993924520001\n",
      "train loss:0.03940615324365673\n",
      "train loss:0.08887174836684159\n",
      "train loss:0.061311063174819935\n",
      "train loss:0.07612144749047028\n",
      "train loss:0.021387946536216895\n",
      "train loss:0.04812064562373011\n",
      "train loss:0.03033601689784511\n",
      "train loss:0.02721423801208205\n",
      "train loss:0.043589205959845195\n",
      "train loss:0.03489398942332902\n",
      "train loss:0.0063001828246394284\n",
      "train loss:0.03794916288157696\n",
      "train loss:0.05395521934758226\n",
      "train loss:0.029932275952146717\n",
      "train loss:0.06810104775957888\n",
      "train loss:0.07474807927306722\n",
      "train loss:0.025241003357086452\n",
      "train loss:0.048873907580921604\n",
      "train loss:0.03609884382193353\n",
      "train loss:0.06078504124125859\n",
      "train loss:0.051059333372153154\n",
      "train loss:0.06224997264902238\n",
      "train loss:0.04491564420180331\n",
      "train loss:0.04604226335206956\n",
      "train loss:0.030925950882601225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0714376021634574\n",
      "train loss:0.030373026699271985\n",
      "train loss:0.0434459332027724\n",
      "train loss:0.02555778926070902\n",
      "train loss:0.029621801061994905\n",
      "train loss:0.03584034859336644\n",
      "train loss:0.08113289022634664\n",
      "train loss:0.030231394597190483\n",
      "train loss:0.0365806646600196\n",
      "train loss:0.024075133732754214\n",
      "train loss:0.021883768896419346\n",
      "train loss:0.06261680108978947\n",
      "train loss:0.03467891206507765\n",
      "train loss:0.03149258617653489\n",
      "train loss:0.04483100477141023\n",
      "train loss:0.08626220074264722\n",
      "train loss:0.022677373419394176\n",
      "train loss:0.013817582111413276\n",
      "train loss:0.016607912771825512\n",
      "train loss:0.04647520825339353\n",
      "train loss:0.0337141788238435\n",
      "train loss:0.034660020832549904\n",
      "train loss:0.019804580885717564\n",
      "train loss:0.042611827694762155\n",
      "train loss:0.02065002685010823\n",
      "train loss:0.019549493044177624\n",
      "train loss:0.10910493029804456\n",
      "train loss:0.05479396922432809\n",
      "train loss:0.03628683434341613\n",
      "train loss:0.04456555204740419\n",
      "train loss:0.026585798426572906\n",
      "train loss:0.030968024442554462\n",
      "train loss:0.08837671476226702\n",
      "train loss:0.02770449039043245\n",
      "train loss:0.018604010787525087\n",
      "train loss:0.042050293436772294\n",
      "train loss:0.03172918729389931\n",
      "train loss:0.03670256636837494\n",
      "train loss:0.06186282795878184\n",
      "train loss:0.01859865618095786\n",
      "train loss:0.021114126948941013\n",
      "train loss:0.03243361067717751\n",
      "train loss:0.01433829780442406\n",
      "train loss:0.061363786602332125\n",
      "train loss:0.04639550041591996\n",
      "train loss:0.028121197747392107\n",
      "train loss:0.048959607029906066\n",
      "train loss:0.043129496848179426\n",
      "train loss:0.022159329782871367\n",
      "train loss:0.015666564761195167\n",
      "train loss:0.038486869440304335\n",
      "train loss:0.07653792824514241\n",
      "train loss:0.03878238271264686\n",
      "train loss:0.03958214460701277\n",
      "train loss:0.04113132900714515\n",
      "train loss:0.029400173946975472\n",
      "=== epoch:25, train acc:0.981, test acc:0.908 ===\n",
      "train loss:0.042336128142168555\n",
      "train loss:0.05027660763323729\n",
      "train loss:0.019335702794650796\n",
      "train loss:0.04262791226058095\n",
      "train loss:0.09148880579229793\n",
      "train loss:0.08828101604202114\n",
      "train loss:0.03997447527130384\n",
      "train loss:0.07735312413663699\n",
      "train loss:0.10035209632891258\n",
      "train loss:0.01380494338084947\n",
      "train loss:0.12029457355035156\n",
      "train loss:0.10571715878082061\n",
      "train loss:0.047946526350771734\n",
      "train loss:0.07977845058012566\n",
      "train loss:0.02451786794408999\n",
      "train loss:0.0122129869189157\n",
      "train loss:0.04493922622150127\n",
      "train loss:0.0493121697215389\n",
      "train loss:0.06915916910556154\n",
      "train loss:0.02751639774219968\n",
      "train loss:0.11149482724982286\n",
      "train loss:0.0390250418127394\n",
      "train loss:0.09237946499583252\n",
      "train loss:0.018913124246268037\n",
      "train loss:0.09539512223960088\n",
      "train loss:0.031619825160089474\n",
      "train loss:0.024109012177491475\n",
      "train loss:0.030291475854577657\n",
      "train loss:0.03030604460473399\n",
      "train loss:0.032696480724476173\n",
      "train loss:0.05131812860292656\n",
      "train loss:0.0336603123273802\n",
      "train loss:0.028357607218911337\n",
      "train loss:0.02376070122675146\n",
      "train loss:0.05396178291562651\n",
      "train loss:0.012929479454706206\n",
      "train loss:0.023153319970195037\n",
      "train loss:0.02640320287798388\n",
      "train loss:0.02587614561488441\n",
      "train loss:0.03042740350816577\n",
      "train loss:0.0240321046122069\n",
      "train loss:0.024872546522897124\n",
      "train loss:0.038237259367249164\n",
      "train loss:0.02009657659007352\n",
      "train loss:0.029909017914154408\n",
      "train loss:0.05733490787638645\n",
      "train loss:0.021158876002897915\n",
      "train loss:0.043010667904927836\n",
      "train loss:0.07254947496648591\n",
      "train loss:0.04114385965224402\n",
      "train loss:0.09496059019824168\n",
      "train loss:0.058638667628106524\n",
      "train loss:0.036264324050507266\n",
      "train loss:0.03404878704805944\n",
      "train loss:0.06977407401122664\n",
      "train loss:0.03476573949503455\n",
      "train loss:0.06325525040489242\n",
      "train loss:0.04449593245984129\n",
      "train loss:0.047997203694303596\n",
      "train loss:0.04373399995000177\n",
      "train loss:0.0617993966033467\n",
      "train loss:0.029696306101025166\n",
      "train loss:0.03948460445806508\n",
      "train loss:0.024763294348767152\n",
      "train loss:0.06256031810590695\n",
      "train loss:0.02855670751777071\n",
      "train loss:0.02180390290150261\n",
      "train loss:0.018506131035322296\n",
      "train loss:0.030089941329782016\n",
      "train loss:0.047332657147269586\n",
      "train loss:0.031087968993820474\n",
      "train loss:0.05917373712046426\n",
      "train loss:0.04779103908097339\n",
      "train loss:0.05375631502394317\n",
      "train loss:0.03575400930241399\n",
      "train loss:0.024760917977349806\n",
      "train loss:0.019354053423734988\n",
      "train loss:0.02778932436270042\n",
      "train loss:0.05044625472687837\n",
      "train loss:0.02683500178557079\n",
      "train loss:0.027190479709843517\n",
      "train loss:0.015521303013178165\n",
      "train loss:0.04313728579097675\n",
      "train loss:0.04836728553359628\n",
      "train loss:0.03205475282031422\n",
      "train loss:0.016748672971909337\n",
      "train loss:0.1378333035795097\n",
      "train loss:0.04691092394487299\n",
      "train loss:0.02559945669555739\n",
      "train loss:0.02301068413955643\n",
      "train loss:0.05798210071208366\n",
      "train loss:0.043506563653268424\n",
      "train loss:0.05235283533119031\n",
      "train loss:0.08784137657921205\n",
      "train loss:0.04888694371233765\n",
      "train loss:0.02034233222283829\n",
      "train loss:0.005586720264034961\n",
      "train loss:0.022799409533855598\n",
      "train loss:0.04169988256400689\n",
      "train loss:0.034532100100178445\n",
      "train loss:0.01542786116458625\n",
      "train loss:0.020297033148099067\n",
      "train loss:0.02368778462216909\n",
      "train loss:0.027918747843664153\n",
      "train loss:0.045678150998058775\n",
      "train loss:0.030859729357821594\n",
      "train loss:0.02069304799652955\n",
      "train loss:0.02771875490290865\n",
      "train loss:0.04001252850013813\n",
      "train loss:0.040467470070368355\n",
      "train loss:0.04947096158883065\n",
      "train loss:0.09356033939837984\n",
      "train loss:0.017072638901108984\n",
      "train loss:0.041023800341585294\n",
      "train loss:0.021538985761206397\n",
      "train loss:0.08459006282813966\n",
      "train loss:0.03485404136056071\n",
      "train loss:0.03395696084814852\n",
      "train loss:0.033048852258919584\n",
      "train loss:0.017409718232329993\n",
      "train loss:0.023247536803568777\n",
      "train loss:0.048774823877388816\n",
      "train loss:0.0635746684997693\n",
      "train loss:0.0183059861690384\n",
      "train loss:0.029012330504309562\n",
      "train loss:0.0393159839564119\n",
      "train loss:0.018237004181352108\n",
      "train loss:0.02540771046127667\n",
      "train loss:0.03594441065589388\n",
      "train loss:0.04101800108552716\n",
      "train loss:0.02945247887579499\n",
      "train loss:0.027787032423136005\n",
      "train loss:0.04723650924440914\n",
      "train loss:0.03353299689947423\n",
      "train loss:0.018086760677677324\n",
      "train loss:0.05368791769217216\n",
      "train loss:0.030348658306644825\n",
      "train loss:0.021471338297603015\n",
      "train loss:0.016882346355247227\n",
      "train loss:0.03673632140150343\n",
      "train loss:0.03285408459991596\n",
      "train loss:0.02559803510916654\n",
      "train loss:0.04218691386523726\n",
      "train loss:0.01119066983365286\n",
      "train loss:0.045687109006260024\n",
      "train loss:0.02553464998880098\n",
      "train loss:0.03335937387792903\n",
      "train loss:0.01817764677290965\n",
      "train loss:0.016864627150750468\n",
      "train loss:0.04867838951448604\n",
      "train loss:0.037834422742803964\n",
      "train loss:0.017885033843787212\n",
      "train loss:0.014628900911566782\n",
      "train loss:0.01325451454334319\n",
      "train loss:0.040132367711096996\n",
      "train loss:0.009554140908272718\n",
      "train loss:0.07455230100998024\n",
      "train loss:0.017893327067763178\n",
      "train loss:0.047635031943347735\n",
      "train loss:0.02686274403824696\n",
      "train loss:0.03080960628858888\n",
      "train loss:0.01855091319376877\n",
      "train loss:0.02079290422921057\n",
      "train loss:0.02560102784623706\n",
      "train loss:0.05649689005496893\n",
      "train loss:0.028674905627122202\n",
      "train loss:0.0180289840896561\n",
      "train loss:0.022559777289174382\n",
      "train loss:0.06519149860521951\n",
      "train loss:0.06750201809279403\n",
      "train loss:0.016204816364548923\n",
      "train loss:0.025513349716183357\n",
      "train loss:0.022792763941713347\n",
      "train loss:0.03818244971720599\n",
      "train loss:0.035274403193721\n",
      "train loss:0.020610272654001296\n",
      "train loss:0.023709079231379673\n",
      "train loss:0.023887196965216\n",
      "train loss:0.01782250653597925\n",
      "train loss:0.02040270171278718\n",
      "train loss:0.05342764750513763\n",
      "train loss:0.018307288181943496\n",
      "train loss:0.02687396500425305\n",
      "train loss:0.06652806516491587\n",
      "train loss:0.025626041584027925\n",
      "train loss:0.02475740164183105\n",
      "train loss:0.03652006047239831\n",
      "train loss:0.014180979906166005\n",
      "train loss:0.0459547680386337\n",
      "train loss:0.009875513472369216\n",
      "train loss:0.02813496795859204\n",
      "train loss:0.027286070159692293\n",
      "train loss:0.019891610475150458\n",
      "train loss:0.01765740626098031\n",
      "train loss:0.028824080405179385\n",
      "train loss:0.016126694450647044\n",
      "train loss:0.030037982063499936\n",
      "train loss:0.06204534709638671\n",
      "train loss:0.012654358016757423\n",
      "train loss:0.015231013552793429\n",
      "train loss:0.013447345101628531\n",
      "train loss:0.02848309572125082\n",
      "train loss:0.01966230024704889\n",
      "train loss:0.007947520383086326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.018900462909283308\n",
      "train loss:0.0305786808494374\n",
      "train loss:0.028571202009347655\n",
      "train loss:0.072846785106873\n",
      "train loss:0.0372055845702347\n",
      "train loss:0.03688878449627896\n",
      "train loss:0.03787105397095877\n",
      "train loss:0.023809636818319088\n",
      "train loss:0.03364220721340344\n",
      "train loss:0.041606941561435955\n",
      "train loss:0.01626409172808648\n",
      "train loss:0.014114802249111292\n",
      "train loss:0.0119414769631195\n",
      "train loss:0.01470630590956133\n",
      "train loss:0.07082726727360106\n",
      "train loss:0.07566469310448286\n",
      "train loss:0.01844439882083118\n",
      "train loss:0.029467904480193055\n",
      "train loss:0.01260994448820481\n",
      "train loss:0.03507081293040654\n",
      "train loss:0.02330009812407812\n",
      "train loss:0.04794513491033201\n",
      "train loss:0.029126425043650685\n",
      "train loss:0.01842563920093591\n",
      "train loss:0.026549172646862042\n",
      "train loss:0.004923597668828743\n",
      "train loss:0.02481857400378045\n",
      "train loss:0.03482286825379642\n",
      "train loss:0.07293339118790572\n",
      "train loss:0.07244910088473853\n",
      "train loss:0.06983241474509201\n",
      "train loss:0.017870201837873242\n",
      "train loss:0.03601478160342291\n",
      "train loss:0.019720033613647884\n",
      "train loss:0.028440584891243844\n",
      "train loss:0.04926170635752957\n",
      "train loss:0.027970225813418407\n",
      "train loss:0.14588604161235685\n",
      "train loss:0.05670610300760631\n",
      "train loss:0.03370852319002387\n",
      "train loss:0.027307714816272907\n",
      "train loss:0.014868862195042016\n",
      "train loss:0.017775385723065917\n",
      "train loss:0.04675928428778313\n",
      "train loss:0.034214512041820244\n",
      "train loss:0.01754033025081787\n",
      "train loss:0.047611943791016735\n",
      "train loss:0.05534846312237747\n",
      "train loss:0.017213772508793433\n",
      "train loss:0.02149032187412111\n",
      "train loss:0.07809801762598662\n",
      "train loss:0.03038695706611153\n",
      "train loss:0.02933858650671614\n",
      "train loss:0.06234552294555928\n",
      "train loss:0.07006632309932284\n",
      "train loss:0.023440230358466117\n",
      "train loss:0.043456505640853134\n",
      "train loss:0.013629131849689386\n",
      "train loss:0.011999163975596123\n",
      "train loss:0.035460220400017166\n",
      "train loss:0.024673174191387027\n",
      "train loss:0.05931469838359632\n",
      "train loss:0.024279411473799792\n",
      "train loss:0.03542909906560309\n",
      "train loss:0.024151505500074933\n",
      "train loss:0.05304764250420633\n",
      "train loss:0.025314659814072486\n",
      "train loss:0.02292867161692055\n",
      "train loss:0.04836842240941686\n",
      "train loss:0.05853333761294031\n",
      "train loss:0.01662878102170104\n",
      "train loss:0.053767822340464996\n",
      "train loss:0.058210357080994236\n",
      "train loss:0.05127775869005315\n",
      "train loss:0.025910734705829528\n",
      "train loss:0.10053798101766023\n",
      "train loss:0.029108644547299792\n",
      "train loss:0.04885362546452208\n",
      "train loss:0.05405827489408547\n",
      "train loss:0.0341810724163599\n",
      "train loss:0.03254116331682085\n",
      "train loss:0.05017955757993486\n",
      "train loss:0.031154240845542566\n",
      "train loss:0.023135665901567917\n",
      "train loss:0.03566744355865352\n",
      "train loss:0.010805121089645764\n",
      "train loss:0.050879374644380616\n",
      "train loss:0.046240735231350596\n",
      "train loss:0.04566804585368176\n",
      "train loss:0.020964760971308855\n",
      "train loss:0.01725218037264946\n",
      "train loss:0.03358714222246824\n",
      "train loss:0.01395345143910409\n",
      "train loss:0.013391983684001556\n",
      "train loss:0.0719008377072567\n",
      "train loss:0.12381367899992984\n",
      "train loss:0.03711653093672098\n",
      "train loss:0.02085661118725241\n",
      "train loss:0.04840025248275836\n",
      "train loss:0.0216500925514667\n",
      "train loss:0.013942843134717865\n",
      "train loss:0.019213026350229815\n",
      "train loss:0.07083562429275705\n",
      "train loss:0.03844200273553434\n",
      "train loss:0.05618002353842377\n",
      "train loss:0.0530844649051973\n",
      "train loss:0.019444513637199796\n",
      "train loss:0.05533796007100689\n",
      "train loss:0.02478885140534332\n",
      "train loss:0.04363699174170283\n",
      "train loss:0.05069269118702005\n",
      "train loss:0.032883492245371536\n",
      "train loss:0.026665692298665934\n",
      "train loss:0.024390879375280547\n",
      "train loss:0.09185933331754131\n",
      "train loss:0.007028817957898816\n",
      "train loss:0.0253081250635972\n",
      "train loss:0.09060285206332376\n",
      "train loss:0.06321478695877038\n",
      "train loss:0.02591630727171396\n",
      "train loss:0.011918768316657257\n",
      "train loss:0.027578315025145086\n",
      "train loss:0.04510135588448534\n",
      "train loss:0.0264930048494292\n",
      "train loss:0.10560933329292732\n",
      "train loss:0.026873351177462763\n",
      "train loss:0.029465305545490015\n",
      "train loss:0.044711646671612516\n",
      "train loss:0.012084262690968208\n",
      "train loss:0.01804490966367064\n",
      "train loss:0.011654822879598\n",
      "train loss:0.04227794431263528\n",
      "train loss:0.06173784116147736\n",
      "train loss:0.014892474109487715\n",
      "train loss:0.041968856825207415\n",
      "train loss:0.023543616094693576\n",
      "train loss:0.05519555734978873\n",
      "train loss:0.026210226242253696\n",
      "train loss:0.02357019747238493\n",
      "train loss:0.016897156541125363\n",
      "train loss:0.03673971505527784\n",
      "train loss:0.06354677290490227\n",
      "train loss:0.07426503305375473\n",
      "train loss:0.027473136300088706\n",
      "train loss:0.032320519291362856\n",
      "train loss:0.035852281704677476\n",
      "train loss:0.03162582899292406\n",
      "train loss:0.03401125994962543\n",
      "train loss:0.012345168559575738\n",
      "train loss:0.03980031258116662\n",
      "train loss:0.018966798284263314\n",
      "train loss:0.05996598847851519\n",
      "train loss:0.01983995484805223\n",
      "train loss:0.05530788143917311\n",
      "train loss:0.06149915594501076\n",
      "train loss:0.015023829116287994\n",
      "train loss:0.04708862416500815\n",
      "train loss:0.051525922118159595\n",
      "train loss:0.05890308367139459\n",
      "train loss:0.038439208662433694\n",
      "train loss:0.041874638142299615\n",
      "train loss:0.03972147049585752\n",
      "train loss:0.02701391126874369\n",
      "train loss:0.027201397327966212\n",
      "train loss:0.02925882696011191\n",
      "train loss:0.03132405358790004\n",
      "train loss:0.04132888879098214\n",
      "train loss:0.033140543430941485\n",
      "train loss:0.032544276049215656\n",
      "train loss:0.01794364824051139\n",
      "train loss:0.054444393819960475\n",
      "train loss:0.015191747988703869\n",
      "train loss:0.04162614573353804\n",
      "train loss:0.03299892693645684\n",
      "train loss:0.019359718523414712\n",
      "train loss:0.017323526789150844\n",
      "train loss:0.0324306956470344\n",
      "train loss:0.010177707695553184\n",
      "train loss:0.03224807040214021\n",
      "train loss:0.03992500360937104\n",
      "train loss:0.03660429386689276\n",
      "train loss:0.05595632179358009\n",
      "train loss:0.03988853260844338\n",
      "train loss:0.022609689013529267\n",
      "train loss:0.05576951304263528\n",
      "train loss:0.03119126629326248\n",
      "train loss:0.021463059345809457\n",
      "train loss:0.009260425174740454\n",
      "train loss:0.014425797502065359\n",
      "train loss:0.07084329731843267\n",
      "train loss:0.04964840332421168\n",
      "train loss:0.1378355769361529\n",
      "train loss:0.03041321382241102\n",
      "train loss:0.054868133108356136\n",
      "train loss:0.02637216065907122\n",
      "train loss:0.049328589978219435\n",
      "train loss:0.0281083026702033\n",
      "train loss:0.04610052072324588\n",
      "train loss:0.03565661725827615\n",
      "train loss:0.013405322590483335\n",
      "train loss:0.020870138548186958\n",
      "train loss:0.03559113203964192\n",
      "train loss:0.046598693300112785\n",
      "train loss:0.02450820584462416\n",
      "train loss:0.05349651073545744\n",
      "train loss:0.038661493223666944\n",
      "train loss:0.01945559118354728\n",
      "train loss:0.02355872881086169\n",
      "train loss:0.05096341529356921\n",
      "train loss:0.05051311600312809\n",
      "train loss:0.02821058038653546\n",
      "train loss:0.015495796036565625\n",
      "train loss:0.025105357093876485\n",
      "train loss:0.03797694261663556\n",
      "train loss:0.004754514789877024\n",
      "train loss:0.041013899851902416\n",
      "train loss:0.15468770915088972\n",
      "train loss:0.05194592699329355\n",
      "train loss:0.033611099366936216\n",
      "train loss:0.013802759871340617\n",
      "train loss:0.14556694040310728\n",
      "train loss:0.021863288393607943\n",
      "train loss:0.020956167733045802\n",
      "train loss:0.023854604780589136\n",
      "train loss:0.07245725935590328\n",
      "train loss:0.05233195745827562\n",
      "train loss:0.02671116606120892\n",
      "train loss:0.04562612436980357\n",
      "train loss:0.0536609663703188\n",
      "train loss:0.07032012508787422\n",
      "train loss:0.0323800661405352\n",
      "train loss:0.035320004085241094\n",
      "train loss:0.06197060894824604\n",
      "train loss:0.021813638048379425\n",
      "train loss:0.03546075149776317\n",
      "train loss:0.060227828498599034\n",
      "train loss:0.027902911744933832\n",
      "train loss:0.040127117714311676\n",
      "train loss:0.04790621287093685\n",
      "train loss:0.060450065011258616\n",
      "train loss:0.018201278413289657\n",
      "train loss:0.03340524897869653\n",
      "train loss:0.03377850937817089\n",
      "train loss:0.04568054681031932\n",
      "train loss:0.07397316743234189\n",
      "train loss:0.04217870326113633\n",
      "train loss:0.05706727053176242\n",
      "train loss:0.03882888404182925\n",
      "train loss:0.01629588104183435\n",
      "train loss:0.01416399203212028\n",
      "train loss:0.035178665680968814\n",
      "train loss:0.02866308088752286\n",
      "train loss:0.02243441714677132\n",
      "train loss:0.057507082003367585\n",
      "train loss:0.05465256289332442\n",
      "train loss:0.013662451755679834\n",
      "train loss:0.015535608708018624\n",
      "train loss:0.01802807488997219\n",
      "train loss:0.03280840795834892\n",
      "train loss:0.04256999757585007\n",
      "train loss:0.03448801852742884\n",
      "train loss:0.03937099751222291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.01747421644658847\n",
      "train loss:0.01713522842959351\n",
      "train loss:0.05750922330376287\n",
      "train loss:0.045760083638101155\n",
      "train loss:0.007683370170211767\n",
      "train loss:0.03406846856307037\n",
      "train loss:0.03150486233279811\n",
      "train loss:0.014417570033822586\n",
      "train loss:0.025798752771013005\n",
      "train loss:0.06392662974962991\n",
      "train loss:0.037663749015500445\n",
      "train loss:0.07402860763679268\n",
      "train loss:0.01211783870286594\n",
      "train loss:0.03455860066362201\n",
      "train loss:0.03619792213852079\n",
      "train loss:0.03944014252361747\n",
      "train loss:0.022950386262034998\n",
      "train loss:0.04390942854625185\n",
      "train loss:0.02679413822747905\n",
      "train loss:0.020775672495625844\n",
      "train loss:0.04183302178768183\n",
      "train loss:0.06113544155718704\n",
      "train loss:0.020003275187450043\n",
      "train loss:0.013522993298634324\n",
      "train loss:0.04868157051791391\n",
      "train loss:0.05042227028061383\n",
      "train loss:0.05217245282381205\n",
      "train loss:0.006990577926085065\n",
      "train loss:0.025831413369570715\n",
      "train loss:0.041850303638600775\n",
      "train loss:0.02790098530550742\n",
      "train loss:0.03589003786832137\n",
      "train loss:0.02267847099676114\n",
      "train loss:0.05593982384261573\n",
      "train loss:0.02966264269762398\n",
      "train loss:0.06409464372991962\n",
      "train loss:0.06421158176828982\n",
      "train loss:0.06733131505566506\n",
      "train loss:0.0677327052673601\n",
      "train loss:0.045874939431624344\n",
      "train loss:0.0411071201929766\n",
      "train loss:0.03183109329139849\n",
      "train loss:0.05775480803380889\n",
      "train loss:0.04554092796322364\n",
      "train loss:0.016716168287698216\n",
      "train loss:0.03717608820250068\n",
      "train loss:0.0993124672143259\n",
      "train loss:0.0341231734566397\n",
      "train loss:0.03552817024394282\n",
      "train loss:0.028657718423451276\n",
      "train loss:0.039855437317828576\n",
      "train loss:0.023284338478474834\n",
      "train loss:0.04319271596283028\n",
      "train loss:0.012819070309644652\n",
      "train loss:0.07940200619162034\n",
      "train loss:0.049221921952695286\n",
      "train loss:0.019668804626770495\n",
      "train loss:0.04593750997399445\n",
      "train loss:0.05315188988285669\n",
      "train loss:0.08580358533251378\n",
      "train loss:0.06241493475739145\n",
      "train loss:0.02157858353112485\n",
      "train loss:0.03838690715692369\n",
      "train loss:0.05081068030758263\n",
      "train loss:0.060330314686233795\n",
      "train loss:0.033540082541087576\n",
      "train loss:0.07423861678975603\n",
      "train loss:0.01889231098143504\n",
      "train loss:0.028089857525840436\n",
      "train loss:0.026043852373055638\n",
      "train loss:0.054783277289958375\n",
      "train loss:0.0599799037369213\n",
      "train loss:0.03765144936336136\n",
      "train loss:0.03327755242385331\n",
      "train loss:0.01745345460702693\n",
      "train loss:0.05287096950319717\n",
      "train loss:0.008421098211328084\n",
      "train loss:0.019277917911656516\n",
      "train loss:0.017810869792535974\n",
      "train loss:0.021047284379711963\n",
      "train loss:0.014777001029204788\n",
      "train loss:0.024356189891156902\n",
      "train loss:0.020549484412325528\n",
      "train loss:0.035717735415804704\n",
      "train loss:0.015039124868719752\n",
      "train loss:0.024370014931314105\n",
      "train loss:0.015912517505241267\n",
      "train loss:0.023097773037133788\n",
      "train loss:0.023979024014633084\n",
      "train loss:0.025091288975947562\n",
      "train loss:0.02573037990746458\n",
      "train loss:0.017268226485476303\n",
      "train loss:0.025933465598339277\n",
      "train loss:0.012910804437843553\n",
      "train loss:0.005117091408680943\n",
      "train loss:0.022431105703681647\n",
      "train loss:0.012405478083241963\n",
      "train loss:0.01826548663805341\n",
      "train loss:0.05670978834444786\n",
      "train loss:0.02810674962526659\n",
      "train loss:0.02636541623520272\n",
      "train loss:0.02350464324249019\n",
      "train loss:0.010297350606360561\n",
      "train loss:0.01676389359093136\n",
      "train loss:0.019828538782793483\n",
      "train loss:0.02510636985721369\n",
      "train loss:0.013836623178649789\n",
      "train loss:0.01631641085015397\n",
      "train loss:0.011952025407817006\n",
      "train loss:0.032142460736416203\n",
      "train loss:0.034799675297254404\n",
      "train loss:0.016362516512959092\n",
      "train loss:0.05286322321096952\n",
      "train loss:0.02541206245673168\n",
      "train loss:0.07959021083157153\n",
      "train loss:0.025867375426188225\n",
      "train loss:0.024558816159685453\n",
      "train loss:0.05035351364967948\n",
      "train loss:0.06151889705889455\n",
      "train loss:0.052477808432369766\n",
      "train loss:0.026218074349256257\n",
      "train loss:0.026647383483268082\n",
      "train loss:0.02541261944527238\n",
      "train loss:0.020255571577606265\n",
      "train loss:0.02697114975316664\n",
      "train loss:0.04820139180988015\n",
      "train loss:0.009476324482793383\n",
      "train loss:0.02938703104133014\n",
      "train loss:0.048726672314691355\n",
      "train loss:0.029270021397508946\n",
      "train loss:0.01986205160952489\n",
      "train loss:0.05273059774582741\n",
      "train loss:0.017975961617957767\n",
      "train loss:0.014328887633072673\n",
      "=== epoch:26, train acc:0.989, test acc:0.91 ===\n",
      "train loss:0.04514646859357577\n",
      "train loss:0.02936260938497026\n",
      "train loss:0.026178242218062298\n",
      "train loss:0.042176477965346085\n",
      "train loss:0.047169675440729926\n",
      "train loss:0.04741535251014778\n",
      "train loss:0.007999407918378592\n",
      "train loss:0.01606474628534587\n",
      "train loss:0.024410122099373016\n",
      "train loss:0.02197265402903242\n",
      "train loss:0.033121968686068044\n",
      "train loss:0.010591572306559233\n",
      "train loss:0.02525628905870076\n",
      "train loss:0.026822585414633792\n",
      "train loss:0.017305842131234844\n",
      "train loss:0.0272203692579493\n",
      "train loss:0.05564693050867191\n",
      "train loss:0.06067172822984456\n",
      "train loss:0.041650978859913826\n",
      "train loss:0.017454008402050046\n",
      "train loss:0.019581401535066573\n",
      "train loss:0.027987465934180906\n",
      "train loss:0.056461528681363775\n",
      "train loss:0.03564863198323922\n",
      "train loss:0.04133967119513278\n",
      "train loss:0.02831586678733682\n",
      "train loss:0.02757449609382756\n",
      "train loss:0.01616800716336267\n",
      "train loss:0.0690307033062613\n",
      "train loss:0.03907028713006378\n",
      "train loss:0.03790051192542325\n",
      "train loss:0.04211841446486468\n",
      "train loss:0.02018040705009705\n",
      "train loss:0.051738960800311457\n",
      "train loss:0.04122049333623832\n",
      "train loss:0.01942384474121823\n",
      "train loss:0.06714840285324222\n",
      "train loss:0.010472786010330384\n",
      "train loss:0.014785544280426605\n",
      "train loss:0.03077147723525877\n",
      "train loss:0.05890603652149339\n",
      "train loss:0.024684029459558516\n",
      "train loss:0.04614703752168741\n",
      "train loss:0.03739373204991148\n",
      "train loss:0.008477626918393617\n",
      "train loss:0.02501223684091139\n",
      "train loss:0.026838612907644794\n",
      "train loss:0.05412673549532429\n",
      "train loss:0.03316800909824917\n",
      "train loss:0.034247925783158564\n",
      "train loss:0.02576584189813734\n",
      "train loss:0.022002325817451412\n",
      "train loss:0.01215916427117234\n",
      "train loss:0.06555716823526445\n",
      "train loss:0.03486074557534531\n",
      "train loss:0.021483890104531094\n",
      "train loss:0.03858080131653583\n",
      "train loss:0.019511436609196946\n",
      "train loss:0.10027397136895172\n",
      "train loss:0.062391677110495335\n",
      "train loss:0.039809388598053524\n",
      "train loss:0.02243884746705335\n",
      "train loss:0.048916289937614224\n",
      "train loss:0.009127859798827074\n",
      "train loss:0.02131204879387584\n",
      "train loss:0.0873925598567637\n",
      "train loss:0.04142120767045267\n",
      "train loss:0.036798646682709386\n",
      "train loss:0.020369156876892894\n",
      "train loss:0.05746711081738426\n",
      "train loss:0.02239310966257254\n",
      "train loss:0.008118465618105013\n",
      "train loss:0.018882916893293637\n",
      "train loss:0.04193227048384617\n",
      "train loss:0.02808197879931475\n",
      "train loss:0.034017869816198074\n",
      "train loss:0.02252193813518222\n",
      "train loss:0.020212578810958767\n",
      "train loss:0.02259239146726998\n",
      "train loss:0.04289724833455981\n",
      "train loss:0.06014607375638002\n",
      "train loss:0.020114519841348374\n",
      "train loss:0.0328620226897243\n",
      "train loss:0.044836611385887445\n",
      "train loss:0.03841590720639995\n",
      "train loss:0.014285977212606642\n",
      "train loss:0.07196601596919705\n",
      "train loss:0.0408913123342219\n",
      "train loss:0.023500650733023685\n",
      "train loss:0.014274580553446891\n",
      "train loss:0.015659983719605298\n",
      "train loss:0.0089100056437959\n",
      "train loss:0.028876220472144446\n",
      "train loss:0.033093361397054086\n",
      "train loss:0.09786421648100144\n",
      "train loss:0.07080801101844669\n",
      "train loss:0.12409889361217578\n",
      "train loss:0.06556691135822097\n",
      "train loss:0.04803992363199729\n",
      "train loss:0.08970891715187332\n",
      "train loss:0.027877595804959205\n",
      "train loss:0.03191834183592468\n",
      "train loss:0.037397194784717244\n",
      "train loss:0.02190764774062976\n",
      "train loss:0.021715200152891925\n",
      "train loss:0.029037241394456747\n",
      "train loss:0.043818138006134884\n",
      "train loss:0.0851936335200996\n",
      "train loss:0.02183216793330483\n",
      "train loss:0.030537385929696396\n",
      "train loss:0.015027648706593516\n",
      "train loss:0.01690106160889015\n",
      "train loss:0.016812665294436716\n",
      "train loss:0.015952951849263722\n",
      "train loss:0.053494622361116774\n",
      "train loss:0.024486911603311737\n",
      "train loss:0.03792225956433132\n",
      "train loss:0.014577275219499655\n",
      "train loss:0.020073001390004907\n",
      "train loss:0.01284511191188207\n",
      "train loss:0.03512447513983353\n",
      "train loss:0.04074582251853121\n",
      "train loss:0.024303720826432902\n",
      "train loss:0.0491288465928274\n",
      "train loss:0.0921740969284429\n",
      "train loss:0.042663037713898753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.016742567635226593\n",
      "train loss:0.036326347227568154\n",
      "train loss:0.03858257072825591\n",
      "train loss:0.07735350033418419\n",
      "train loss:0.04826725782275723\n",
      "train loss:0.023713041980693177\n",
      "train loss:0.05769826656574514\n",
      "train loss:0.0455762184389506\n",
      "train loss:0.0753763898850196\n",
      "train loss:0.05575430838330054\n",
      "train loss:0.0885227815246216\n",
      "train loss:0.03405830295618562\n",
      "train loss:0.03148225368380054\n",
      "train loss:0.04549998600633321\n",
      "train loss:0.05448620758502394\n",
      "train loss:0.029072773611194716\n",
      "train loss:0.05690911603086943\n",
      "train loss:0.0633049976391125\n",
      "train loss:0.05348530081295067\n",
      "train loss:0.029358748813517795\n",
      "train loss:0.01440159814165517\n",
      "train loss:0.02301726177160306\n",
      "train loss:0.023010942165210095\n",
      "train loss:0.04496327591791896\n",
      "train loss:0.02340908456672717\n",
      "train loss:0.03209231411252044\n",
      "train loss:0.055821836299315704\n",
      "train loss:0.06901305740595955\n",
      "train loss:0.01625683710966545\n",
      "train loss:0.03559178831339677\n",
      "train loss:0.030616128747717034\n",
      "train loss:0.07248277974458509\n",
      "train loss:0.02871649754766418\n",
      "train loss:0.10137616212800121\n",
      "train loss:0.025477086086493746\n",
      "train loss:0.05182755751914318\n",
      "train loss:0.027318112164007802\n",
      "train loss:0.028429275797851025\n",
      "train loss:0.013069597771249974\n",
      "train loss:0.030371489743714956\n",
      "train loss:0.05978263401692175\n",
      "train loss:0.011327068747595932\n",
      "train loss:0.04367043856880433\n",
      "train loss:0.11587001820586523\n",
      "train loss:0.019285872178608228\n",
      "train loss:0.0586672295078568\n",
      "train loss:0.04397908958171878\n",
      "train loss:0.012847676198358263\n",
      "train loss:0.036474407950385285\n",
      "train loss:0.06044871945037993\n",
      "train loss:0.0270281674915973\n",
      "train loss:0.06476734486725536\n",
      "train loss:0.014836521826287837\n",
      "train loss:0.03734467751567112\n",
      "train loss:0.03606641119442731\n",
      "train loss:0.016661084026792408\n",
      "train loss:0.05941083930629616\n",
      "train loss:0.04796547916001212\n",
      "train loss:0.06894801791389225\n",
      "train loss:0.07979214078752565\n",
      "train loss:0.03796531474897968\n",
      "train loss:0.041626713297595215\n",
      "train loss:0.03704628972112069\n",
      "train loss:0.03818365711312232\n",
      "train loss:0.04615966153782261\n",
      "train loss:0.07033831950814379\n",
      "train loss:0.04055511045750241\n",
      "train loss:0.04317267503093695\n",
      "train loss:0.03719556960306461\n",
      "train loss:0.04321323540580047\n",
      "train loss:0.04574283887121799\n",
      "train loss:0.037263533879860075\n",
      "train loss:0.02676449982466884\n",
      "train loss:0.051977205385908734\n",
      "train loss:0.02335886192279121\n",
      "train loss:0.0335507409476909\n",
      "train loss:0.04797085352651993\n",
      "train loss:0.022721744800106865\n",
      "train loss:0.02518819646764311\n",
      "train loss:0.034463931517696354\n",
      "train loss:0.029734300533530923\n",
      "train loss:0.004246351801122029\n",
      "train loss:0.01842870236614489\n",
      "train loss:0.035566649760267105\n",
      "train loss:0.05068153416452706\n",
      "train loss:0.04228485045427309\n",
      "train loss:0.044517340385918605\n",
      "train loss:0.0656918308720092\n",
      "train loss:0.03296604989315943\n",
      "train loss:0.04462250937552328\n",
      "train loss:0.042984826471093696\n",
      "train loss:0.017778092203165386\n",
      "train loss:0.017898407176049354\n",
      "train loss:0.06581369216744273\n",
      "train loss:0.0366916632660228\n",
      "train loss:0.03240173232844784\n",
      "train loss:0.026180977536616523\n",
      "train loss:0.022597470397209198\n",
      "train loss:0.016091057810485112\n",
      "train loss:0.03941930450846408\n",
      "train loss:0.01243593214711681\n",
      "train loss:0.024545152727580965\n",
      "train loss:0.021469751936868123\n",
      "train loss:0.03389849202407835\n",
      "train loss:0.033383223108920376\n",
      "train loss:0.0393155817234963\n",
      "train loss:0.014139378992939829\n",
      "train loss:0.134660223340201\n",
      "train loss:0.1081043433743669\n",
      "train loss:0.012265087599397838\n",
      "train loss:0.03961970701660702\n",
      "train loss:0.05366179844069749\n",
      "train loss:0.0197433821995618\n",
      "train loss:0.015462845262479015\n",
      "train loss:0.03185244260781781\n",
      "train loss:0.03469604263144308\n",
      "train loss:0.07782803147907696\n",
      "train loss:0.05365036031101605\n",
      "train loss:0.03290074466017162\n",
      "train loss:0.037934720711344544\n",
      "train loss:0.035603976130902965\n",
      "train loss:0.03111909206435938\n",
      "train loss:0.1026654540400171\n",
      "train loss:0.028208002794462613\n",
      "train loss:0.07247881862982955\n",
      "train loss:0.013744466879317812\n",
      "train loss:0.08014386631596483\n",
      "train loss:0.03196776329637212\n",
      "train loss:0.024220180114107173\n",
      "train loss:0.01955379198997255\n",
      "train loss:0.021209646042101706\n",
      "train loss:0.05390904512421713\n",
      "train loss:0.09424219001400187\n",
      "train loss:0.01638366134742154\n",
      "train loss:0.03865470900672968\n",
      "train loss:0.06766511755724738\n",
      "train loss:0.030347708033800328\n",
      "train loss:0.056149001714037944\n",
      "train loss:0.09109924058069646\n",
      "train loss:0.10707298140961273\n",
      "train loss:0.010189022594318878\n",
      "train loss:0.031707590296339835\n",
      "train loss:0.027777083036653768\n",
      "train loss:0.03869457189596336\n",
      "train loss:0.050292861238011514\n",
      "train loss:0.04516498089826819\n",
      "train loss:0.05760826294847094\n",
      "train loss:0.08239317929930301\n",
      "train loss:0.0724929264734056\n",
      "train loss:0.034372923778666784\n",
      "train loss:0.04894817265280386\n",
      "train loss:0.018240781433718795\n",
      "train loss:0.015410629619463306\n",
      "train loss:0.01532303860170125\n",
      "train loss:0.06722603521749787\n",
      "train loss:0.051667720896232755\n",
      "train loss:0.018721225242365483\n",
      "train loss:0.0318160305944659\n",
      "train loss:0.02336054995385296\n",
      "train loss:0.03412555631640177\n",
      "train loss:0.017230189056009454\n",
      "train loss:0.048611795015325976\n",
      "train loss:0.03406315453724672\n",
      "train loss:0.056426094037860516\n",
      "train loss:0.10743321458143011\n",
      "train loss:0.03292687992454025\n",
      "train loss:0.027920547828170265\n",
      "train loss:0.06768199648886898\n",
      "train loss:0.04549246197344866\n",
      "train loss:0.04527683987941646\n",
      "train loss:0.0158094903794991\n",
      "train loss:0.0379215229147143\n",
      "train loss:0.027099269813147264\n",
      "train loss:0.034182895854587454\n",
      "train loss:0.03921381196930838\n",
      "train loss:0.019187552037153423\n",
      "train loss:0.01950652682006568\n",
      "train loss:0.03684305470674584\n",
      "train loss:0.018417232131061598\n",
      "train loss:0.04317216758977413\n",
      "train loss:0.019524384879503982\n",
      "train loss:0.023941992604335872\n",
      "train loss:0.047872599508640284\n",
      "train loss:0.024268545179949096\n",
      "train loss:0.028382635174412026\n",
      "train loss:0.029061854109842924\n",
      "train loss:0.05625626549878812\n",
      "train loss:0.03614616466284118\n",
      "train loss:0.010927984171607048\n",
      "train loss:0.018383072113077777\n",
      "train loss:0.024304333881114363\n",
      "train loss:0.037883325515224726\n",
      "train loss:0.016219216465354184\n",
      "train loss:0.027903247591243584\n",
      "train loss:0.03964398134048828\n",
      "train loss:0.11022936015833466\n",
      "train loss:0.039965789846726565\n",
      "train loss:0.04470696380721211\n",
      "train loss:0.02532337834271927\n",
      "train loss:0.055204504347445775\n",
      "train loss:0.01488223726106781\n",
      "train loss:0.030077157734045946\n",
      "train loss:0.04871816927759469\n",
      "train loss:0.015010076018907486\n",
      "train loss:0.008579321494142523\n",
      "train loss:0.03729357182274664\n",
      "train loss:0.03461708313134068\n",
      "train loss:0.017367256431714117\n",
      "train loss:0.02690128458753331\n",
      "train loss:0.035245775025183564\n",
      "train loss:0.01877555437081036\n",
      "train loss:0.027247936100487636\n",
      "train loss:0.09371610508530975\n",
      "train loss:0.08416064071482333\n",
      "train loss:0.029668660274930928\n",
      "train loss:0.024218026487633333\n",
      "train loss:0.03709709527287312\n",
      "train loss:0.02138153487117973\n",
      "train loss:0.025720212672894913\n",
      "train loss:0.02590522315274663\n",
      "train loss:0.015303497027850952\n",
      "train loss:0.0232089030121851\n",
      "train loss:0.03546425539698816\n",
      "train loss:0.03451056632413037\n",
      "train loss:0.029405059954866877\n",
      "train loss:0.013546956036145858\n",
      "train loss:0.053218348232670555\n",
      "train loss:0.057938821780302775\n",
      "train loss:0.030317292335825967\n",
      "train loss:0.0703159563717678\n",
      "train loss:0.014173388491039236\n",
      "train loss:0.02943094697402193\n",
      "train loss:0.0319184189633937\n",
      "train loss:0.02808695070952032\n",
      "train loss:0.016707999162415138\n",
      "train loss:0.04826587547104456\n",
      "train loss:0.023908834756950274\n",
      "train loss:0.015115001197057745\n",
      "train loss:0.054864020413934886\n",
      "train loss:0.03640551207406614\n",
      "train loss:0.01571838739294366\n",
      "train loss:0.02359168989738526\n",
      "train loss:0.014468217614808543\n",
      "train loss:0.021518242625219338\n",
      "train loss:0.016978522497526672\n",
      "train loss:0.03711985568958732\n",
      "train loss:0.014967507464219862\n",
      "train loss:0.007068089910443729\n",
      "train loss:0.03482750556653827\n",
      "train loss:0.036775702519717984\n",
      "train loss:0.028824091918537666\n",
      "train loss:0.04801354709068284\n",
      "train loss:0.04717850582165296\n",
      "train loss:0.049161104357396984\n",
      "train loss:0.030960668262628034\n",
      "train loss:0.02620642859440944\n",
      "train loss:0.02427767606670235\n",
      "train loss:0.02180529988307073\n",
      "train loss:0.03696432149582195\n",
      "train loss:0.049764729209375407\n",
      "train loss:0.02766659868245593\n",
      "train loss:0.02080597085769774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.03261249402243489\n",
      "train loss:0.009523227863832555\n",
      "train loss:0.01388014601989457\n",
      "train loss:0.026263775703738633\n",
      "train loss:0.058889041228510956\n",
      "train loss:0.05886590133708218\n",
      "train loss:0.02263595225372945\n",
      "train loss:0.05768208314864148\n",
      "train loss:0.01757410792989346\n",
      "train loss:0.015259498187653407\n",
      "train loss:0.05500811656320828\n",
      "train loss:0.01496227013313712\n",
      "train loss:0.03816057173132356\n",
      "train loss:0.016715580335957988\n",
      "train loss:0.021894229306955917\n",
      "train loss:0.005632615032161573\n",
      "train loss:0.01716809235165385\n",
      "train loss:0.09655391931066656\n",
      "train loss:0.03372614312133436\n",
      "train loss:0.01564698188026685\n",
      "train loss:0.0165636707686761\n",
      "train loss:0.025869343499733403\n",
      "train loss:0.016555962334837467\n",
      "train loss:0.038334520004328305\n",
      "train loss:0.02175532643323273\n",
      "train loss:0.034772563585815715\n",
      "train loss:0.03915753685282584\n",
      "train loss:0.03337561761517076\n",
      "train loss:0.024963211078914332\n",
      "train loss:0.031146546987834287\n",
      "train loss:0.009008029761739984\n",
      "train loss:0.054631847069308404\n",
      "train loss:0.034407468460655954\n",
      "train loss:0.06760206663200372\n",
      "train loss:0.030116888649128124\n",
      "train loss:0.03415035989565183\n",
      "train loss:0.0066689660812410834\n",
      "train loss:0.03896688364720732\n",
      "train loss:0.047811207671323575\n",
      "train loss:0.028663256881240638\n",
      "train loss:0.024137639082239776\n",
      "train loss:0.017829859043709068\n",
      "train loss:0.01738324840732099\n",
      "train loss:0.09923967355355283\n",
      "train loss:0.0198207325289675\n",
      "train loss:0.04875597740350573\n",
      "train loss:0.04856048756278008\n",
      "train loss:0.024080546180408516\n",
      "train loss:0.04925971034365457\n",
      "train loss:0.052460117633443486\n",
      "train loss:0.03415782349711834\n",
      "train loss:0.01536663539959025\n",
      "train loss:0.018544778809429827\n",
      "train loss:0.07710486574710716\n",
      "train loss:0.023207256035395477\n",
      "train loss:0.029465698713122733\n",
      "train loss:0.021323989887117447\n",
      "train loss:0.03903217537048051\n",
      "train loss:0.052354653593775995\n",
      "train loss:0.04320716278301935\n",
      "train loss:0.04293735802649708\n",
      "train loss:0.024243831378719206\n",
      "train loss:0.02666630957426773\n",
      "train loss:0.02836693048372207\n",
      "train loss:0.023874433453155156\n",
      "train loss:0.03228357418092663\n",
      "train loss:0.019522252997048333\n",
      "train loss:0.024538541865393414\n",
      "train loss:0.0714037707340716\n",
      "train loss:0.038871693215200585\n",
      "train loss:0.06553654152212379\n",
      "train loss:0.03301949032876995\n",
      "train loss:0.013703245584216135\n",
      "train loss:0.011305634945102207\n",
      "train loss:0.029167601722247895\n",
      "train loss:0.10403798336962279\n",
      "train loss:0.023770036075853155\n",
      "train loss:0.02041053978192149\n",
      "train loss:0.025280025756481438\n",
      "train loss:0.025978569545299715\n",
      "train loss:0.02207370707075327\n",
      "train loss:0.009824707269379817\n",
      "train loss:0.02296045912519772\n",
      "train loss:0.020645917027772315\n",
      "train loss:0.010987675139705132\n",
      "train loss:0.04377022468916587\n",
      "train loss:0.023596959504785037\n",
      "train loss:0.019229811694881357\n",
      "train loss:0.05523037018318246\n",
      "train loss:0.024817197388804425\n",
      "train loss:0.01720206640556663\n",
      "train loss:0.044835116634633625\n",
      "train loss:0.024194996634906915\n",
      "train loss:0.04523525784492573\n",
      "train loss:0.027068589514421783\n",
      "train loss:0.06322076466885666\n",
      "train loss:0.0267567187172906\n",
      "train loss:0.04343049388768776\n",
      "train loss:0.03685273896765333\n",
      "train loss:0.009039011607956083\n",
      "train loss:0.08051690753877094\n",
      "train loss:0.023638571709647404\n",
      "train loss:0.025076652230730773\n",
      "train loss:0.012881076833124692\n",
      "train loss:0.03015224957395126\n",
      "train loss:0.026570457054853037\n",
      "train loss:0.04499644469496933\n",
      "train loss:0.014857313258378059\n",
      "train loss:0.032913753947131356\n",
      "train loss:0.02544261001692782\n",
      "train loss:0.02497016206660867\n",
      "train loss:0.008671541644582545\n",
      "train loss:0.06532737146417615\n",
      "train loss:0.011432964009665335\n",
      "train loss:0.01626772891562174\n",
      "train loss:0.03048776744203549\n",
      "train loss:0.037277861823438826\n",
      "train loss:0.030446557041833883\n",
      "train loss:0.013656912231409156\n",
      "train loss:0.06280834520541671\n",
      "train loss:0.023210029416765234\n",
      "train loss:0.024253546959332812\n",
      "train loss:0.04282619204997891\n",
      "train loss:0.07071080972870175\n",
      "train loss:0.019402867226911327\n",
      "train loss:0.0343945846973181\n",
      "train loss:0.0727179021062506\n",
      "train loss:0.04485014546315308\n",
      "train loss:0.028272438850699844\n",
      "train loss:0.03474189841098019\n",
      "train loss:0.012520437205551231\n",
      "train loss:0.042391272040088766\n",
      "train loss:0.009317748126414754\n",
      "train loss:0.031687082351142\n",
      "train loss:0.020636687385784523\n",
      "train loss:0.02547906306557556\n",
      "train loss:0.01861299289850931\n",
      "train loss:0.051979597582556464\n",
      "train loss:0.016915082737914443\n",
      "train loss:0.043286068465969635\n",
      "train loss:0.028831749045012126\n",
      "train loss:0.012387933846114007\n",
      "train loss:0.04236469921518769\n",
      "train loss:0.027007906920875215\n",
      "train loss:0.045972659383312874\n",
      "train loss:0.060263111645327855\n",
      "train loss:0.02113271571243277\n",
      "train loss:0.02360811796472343\n",
      "train loss:0.02903201458322985\n",
      "train loss:0.029275361664076377\n",
      "train loss:0.03599944086837246\n",
      "train loss:0.016851064194708464\n",
      "train loss:0.006810291532294021\n",
      "train loss:0.051126192056015506\n",
      "train loss:0.02131673507854063\n",
      "train loss:0.021280363353962887\n",
      "train loss:0.010430346104325654\n",
      "train loss:0.017108464593009142\n",
      "train loss:0.01556664995638159\n",
      "train loss:0.018929576716691508\n",
      "train loss:0.03348040911255326\n",
      "train loss:0.009959061776163881\n",
      "train loss:0.032868223197366514\n",
      "train loss:0.04430041648022591\n",
      "train loss:0.01286449336514245\n",
      "train loss:0.011556121890451534\n",
      "train loss:0.09372153772323945\n",
      "train loss:0.03228438638987183\n",
      "train loss:0.012027410300572153\n",
      "train loss:0.010338105888556937\n",
      "train loss:0.035829102970341024\n",
      "train loss:0.01856339615329086\n",
      "train loss:0.06298080308454435\n",
      "train loss:0.023748519592766963\n",
      "train loss:0.018187670247178628\n",
      "train loss:0.030514854193991976\n",
      "train loss:0.014185361132516392\n",
      "train loss:0.01866990914183925\n",
      "train loss:0.016550145913715217\n",
      "train loss:0.01359496744779779\n",
      "train loss:0.012781559907867222\n",
      "train loss:0.09953229607501383\n",
      "train loss:0.036245470222836786\n",
      "train loss:0.041054881926027915\n",
      "train loss:0.03849717847564853\n",
      "train loss:0.03594737408052412\n",
      "train loss:0.029812353158041455\n",
      "train loss:0.051246538202260536\n",
      "train loss:0.08296930533931152\n",
      "train loss:0.03158866534070285\n",
      "train loss:0.027065618660958343\n",
      "train loss:0.02075258385805482\n",
      "train loss:0.006891475172319238\n",
      "train loss:0.033622925322200584\n",
      "train loss:0.01671294675381363\n",
      "train loss:0.027201550172238652\n",
      "train loss:0.017207681218558663\n",
      "train loss:0.0171669630282418\n",
      "train loss:0.010369735631475401\n",
      "train loss:0.029122853389968742\n",
      "train loss:0.025804267117071192\n",
      "train loss:0.010884862536872618\n",
      "train loss:0.03912109275097257\n",
      "train loss:0.013868869576843613\n",
      "train loss:0.05337237808297037\n",
      "train loss:0.011510994122014078\n",
      "train loss:0.01386854925105044\n",
      "train loss:0.028244131701915053\n",
      "train loss:0.03244413949802174\n",
      "train loss:0.05281742145210256\n",
      "train loss:0.009746759359170765\n",
      "train loss:0.06166247698747298\n",
      "=== epoch:27, train acc:0.991, test acc:0.921 ===\n",
      "train loss:0.05921217655502043\n",
      "train loss:0.014817610494288083\n",
      "train loss:0.017652669636177384\n",
      "train loss:0.03828623096161868\n",
      "train loss:0.018113088684373235\n",
      "train loss:0.01405977470857316\n",
      "train loss:0.06983054499189466\n",
      "train loss:0.0318179829348201\n",
      "train loss:0.04936900253247463\n",
      "train loss:0.015817633643178473\n",
      "train loss:0.03079617234016095\n",
      "train loss:0.03251861657099142\n",
      "train loss:0.025600680370764187\n",
      "train loss:0.022754439989765337\n",
      "train loss:0.058604234840703845\n",
      "train loss:0.01386333661256065\n",
      "train loss:0.047577001941989126\n",
      "train loss:0.04501611684661877\n",
      "train loss:0.014051191526641244\n",
      "train loss:0.01799310360725747\n",
      "train loss:0.03741015871903372\n",
      "train loss:0.021306300602257203\n",
      "train loss:0.025523034916568422\n",
      "train loss:0.05666188047384271\n",
      "train loss:0.022670332978069058\n",
      "train loss:0.021990190841187775\n",
      "train loss:0.035097734859903924\n",
      "train loss:0.03900253874066804\n",
      "train loss:0.05178541228828253\n",
      "train loss:0.0629947100638021\n",
      "train loss:0.05578759072230359\n",
      "train loss:0.023029471637438192\n",
      "train loss:0.04729899992567824\n",
      "train loss:0.022656854919121505\n",
      "train loss:0.07012433952348289\n",
      "train loss:0.015930157503113426\n",
      "train loss:0.02963494432752269\n",
      "train loss:0.029774550956488267\n",
      "train loss:0.032323251413110085\n",
      "train loss:0.04487639341667046\n",
      "train loss:0.04018104802649418\n",
      "train loss:0.026231131413515855\n",
      "train loss:0.014846179870165288\n",
      "train loss:0.050858366145797626\n",
      "train loss:0.008835048777609506\n",
      "train loss:0.061492168867099156\n",
      "train loss:0.03210345473708246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.02662436219138524\n",
      "train loss:0.027083712163606884\n",
      "train loss:0.05114281650372317\n",
      "train loss:0.04803045529457927\n",
      "train loss:0.025585671757496185\n",
      "train loss:0.06681817827770584\n",
      "train loss:0.017365054293494886\n",
      "train loss:0.011895613779313816\n",
      "train loss:0.047466070432464404\n",
      "train loss:0.03813758647189863\n",
      "train loss:0.020973623188916397\n",
      "train loss:0.021581725194252596\n",
      "train loss:0.018668813662842964\n",
      "train loss:0.02312748595510157\n",
      "train loss:0.034368601645727054\n",
      "train loss:0.026974036650658135\n",
      "train loss:0.015528803141575486\n",
      "train loss:0.04910033947352724\n",
      "train loss:0.017068875909270777\n",
      "train loss:0.08090344144759014\n",
      "train loss:0.02289616097951825\n",
      "train loss:0.015862331445683067\n",
      "train loss:0.025255995865648327\n",
      "train loss:0.02683631620201209\n",
      "train loss:0.041380815558749576\n",
      "train loss:0.037320758250200495\n",
      "train loss:0.08613497798384653\n",
      "train loss:0.01543500310948887\n",
      "train loss:0.0468545010223312\n",
      "train loss:0.01948299460552252\n",
      "train loss:0.08085877515310629\n",
      "train loss:0.028844866996992746\n",
      "train loss:0.020726390884136064\n",
      "train loss:0.03305760972900634\n",
      "train loss:0.033291962967518914\n",
      "train loss:0.022330829296855828\n",
      "train loss:0.032928294850601995\n",
      "train loss:0.03428656819073597\n",
      "train loss:0.01629098402093912\n",
      "train loss:0.008980152949274437\n",
      "train loss:0.018603829802057423\n",
      "train loss:0.048393759428755914\n",
      "train loss:0.034648973240586065\n",
      "train loss:0.06525755749415638\n",
      "train loss:0.020191635391958663\n",
      "train loss:0.02481783817144153\n",
      "train loss:0.015293418631925817\n",
      "train loss:0.046456030189781686\n",
      "train loss:0.020533992244950183\n",
      "train loss:0.0179596849605598\n",
      "train loss:0.05297937701942872\n",
      "train loss:0.04152815726843981\n",
      "train loss:0.017165880832772908\n",
      "train loss:0.04879166248421007\n",
      "train loss:0.016182403397874034\n",
      "train loss:0.08446253724424975\n",
      "train loss:0.04802844022656912\n",
      "train loss:0.018115440378888483\n",
      "train loss:0.0312933062288717\n",
      "train loss:0.023539976964066893\n",
      "train loss:0.03135090922997978\n",
      "train loss:0.035473471080078124\n",
      "train loss:0.029494206711859268\n",
      "train loss:0.07054007287112539\n",
      "train loss:0.035479296493624475\n",
      "train loss:0.03252157950351054\n",
      "train loss:0.01799221813896583\n",
      "train loss:0.05071333662670077\n",
      "train loss:0.02765609559026394\n",
      "train loss:0.0492477173345168\n",
      "train loss:0.04817605154063616\n",
      "train loss:0.012961333715773935\n",
      "train loss:0.013678578283197525\n",
      "train loss:0.03124188044413064\n",
      "train loss:0.04781697398434846\n",
      "train loss:0.004719436262163948\n",
      "train loss:0.05865086803142746\n",
      "train loss:0.07513489359941194\n",
      "train loss:0.038665101660335745\n",
      "train loss:0.0475341427045196\n",
      "train loss:0.005444901336147387\n",
      "train loss:0.0060366192171801\n",
      "train loss:0.022614409412246298\n",
      "train loss:0.023061613036102418\n",
      "train loss:0.011070081900053343\n",
      "train loss:0.026781060567059797\n",
      "train loss:0.038681111173857564\n",
      "train loss:0.027629786086153428\n",
      "train loss:0.029971011977051494\n",
      "train loss:0.04784391692891633\n",
      "train loss:0.02384659461184082\n",
      "train loss:0.023022597189602142\n",
      "train loss:0.023715566886825985\n",
      "train loss:0.018274612645884713\n",
      "train loss:0.030317224206809264\n",
      "train loss:0.06935361016959458\n",
      "train loss:0.03302549271583918\n",
      "train loss:0.020674677719329584\n",
      "train loss:0.010668700182934318\n",
      "train loss:0.056092048703344964\n",
      "train loss:0.020776179403795298\n",
      "train loss:0.012554196052796594\n",
      "train loss:0.01874212832143575\n",
      "train loss:0.04054267108025401\n",
      "train loss:0.018554756069841572\n",
      "train loss:0.06643824919424818\n",
      "train loss:0.011298571312174759\n",
      "train loss:0.03480089389385712\n",
      "train loss:0.0693806238477154\n",
      "train loss:0.015941791962794334\n",
      "train loss:0.03669931441503102\n",
      "train loss:0.03521301156926912\n",
      "train loss:0.04822070455929161\n",
      "train loss:0.029459087191887758\n",
      "train loss:0.04187236803686679\n",
      "train loss:0.03652581493602128\n",
      "train loss:0.02878118191728823\n",
      "train loss:0.023916376347467933\n",
      "train loss:0.059012825472869325\n",
      "train loss:0.0085887912835321\n",
      "train loss:0.01726668338832124\n",
      "train loss:0.02020212146678636\n",
      "train loss:0.06936505564964734\n",
      "train loss:0.1102415537557364\n",
      "train loss:0.035045936874926145\n",
      "train loss:0.015284282456984972\n",
      "train loss:0.03768624529051522\n",
      "train loss:0.02656635775602164\n",
      "train loss:0.022920050146836846\n",
      "train loss:0.037065871675550685\n",
      "train loss:0.03493413399524888\n",
      "train loss:0.02269097432960779\n",
      "train loss:0.029307370153518923\n",
      "train loss:0.014579019558825816\n",
      "train loss:0.0416857627009012\n",
      "train loss:0.023012536416376364\n",
      "train loss:0.07539398235686091\n",
      "train loss:0.024189590141077525\n",
      "train loss:0.045663775136699496\n",
      "train loss:0.05447359423904608\n",
      "train loss:0.025348813044931025\n",
      "train loss:0.012354373522823776\n",
      "train loss:0.07138410990512298\n",
      "train loss:0.025735975045271142\n",
      "train loss:0.029272495105155713\n",
      "train loss:0.04660564045410717\n",
      "train loss:0.038793897966836306\n",
      "train loss:0.07561610972259676\n",
      "train loss:0.04543848903820024\n",
      "train loss:0.02091958439827965\n",
      "train loss:0.03566640508180171\n",
      "train loss:0.04148066962732036\n",
      "train loss:0.0803941653968849\n",
      "train loss:0.05654721630166815\n",
      "train loss:0.050480725508941976\n",
      "train loss:0.014249240135794022\n",
      "train loss:0.0703902203083972\n",
      "train loss:0.03591159204293993\n",
      "train loss:0.03319682233865248\n",
      "train loss:0.010122316626607696\n",
      "train loss:0.03555218666545413\n",
      "train loss:0.038688113352005865\n",
      "train loss:0.04465811223763051\n",
      "train loss:0.028120274823743893\n",
      "train loss:0.01513536951748557\n",
      "train loss:0.06917689582221\n",
      "train loss:0.045964627767293244\n",
      "train loss:0.035981177948976435\n",
      "train loss:0.05478474495105021\n",
      "train loss:0.06978393649178953\n",
      "train loss:0.020628764483571604\n",
      "train loss:0.039223281918526955\n",
      "train loss:0.041987922681443024\n",
      "train loss:0.010089353834700858\n",
      "train loss:0.029210417495106982\n",
      "train loss:0.04600709196584159\n",
      "train loss:0.06478026856058505\n",
      "train loss:0.03764075484477516\n",
      "train loss:0.026808277959898517\n",
      "train loss:0.013477985010475197\n",
      "train loss:0.019255889687338747\n",
      "train loss:0.025046137123080712\n",
      "train loss:0.014381347355461087\n",
      "train loss:0.0222966311019107\n",
      "train loss:0.040853119561923175\n",
      "train loss:0.016115628837131392\n",
      "train loss:0.026126042409043832\n",
      "train loss:0.024092195628060562\n",
      "train loss:0.03296631947300323\n",
      "train loss:0.03833489923101114\n",
      "train loss:0.04090271465700989\n",
      "train loss:0.015236045067729204\n",
      "train loss:0.028462603281165556\n",
      "train loss:0.024697042824715413\n",
      "train loss:0.02452280130026733\n",
      "train loss:0.02054027074990383\n",
      "train loss:0.036762051949570565\n",
      "train loss:0.03175132808136178\n",
      "train loss:0.010244814551365899\n",
      "train loss:0.01906202612883923\n",
      "train loss:0.012160495180629137\n",
      "train loss:0.03477452489295004\n",
      "train loss:0.022897326099873536\n",
      "train loss:0.03704778002224448\n",
      "train loss:0.011586600453027633\n",
      "train loss:0.05054958564619099\n",
      "train loss:0.031531413022157465\n",
      "train loss:0.03452119427763681\n",
      "train loss:0.02503727853899442\n",
      "train loss:0.020963760894976948\n",
      "train loss:0.03796397647130891\n",
      "train loss:0.025099449563875224\n",
      "train loss:0.03989340638758995\n",
      "train loss:0.053098390280763255\n",
      "train loss:0.012611344288975337\n",
      "train loss:0.017145780402162077\n",
      "train loss:0.014210178670950844\n",
      "train loss:0.025193014065292497\n",
      "train loss:0.03356858201206296\n",
      "train loss:0.014462365319739162\n",
      "train loss:0.03221950541957722\n",
      "train loss:0.021342890694747107\n",
      "train loss:0.035509295037017934\n",
      "train loss:0.011605133538493795\n",
      "train loss:0.04123888477680194\n",
      "train loss:0.05568663254031913\n",
      "train loss:0.020922739513997785\n",
      "train loss:0.022452099077049054\n",
      "train loss:0.04505598250604215\n",
      "train loss:0.019878216576514417\n",
      "train loss:0.012088249474329588\n",
      "train loss:0.018545098061966258\n",
      "train loss:0.02483716310621671\n",
      "train loss:0.10260482607848352\n",
      "train loss:0.03599446403012402\n",
      "train loss:0.11638076931249691\n",
      "train loss:0.045353539773623816\n",
      "train loss:0.050258838022313394\n",
      "train loss:0.04475644035900245\n",
      "train loss:0.04430430764490644\n",
      "train loss:0.03352494651743649\n",
      "train loss:0.02110610197607591\n",
      "train loss:0.03655497661696428\n",
      "train loss:0.04177652199429842\n",
      "train loss:0.05606276793290074\n",
      "train loss:0.0229405774495441\n",
      "train loss:0.018797629167460753\n",
      "train loss:0.005155147932611958\n",
      "train loss:0.021548128815184312\n",
      "train loss:0.023220961485113954\n",
      "train loss:0.028231019559159666\n",
      "train loss:0.011471358045414649\n",
      "train loss:0.06280933774925451\n",
      "train loss:0.028917415864969372\n",
      "train loss:0.03131100904040533\n",
      "train loss:0.029662418340169628\n",
      "train loss:0.10033330941956342\n",
      "train loss:0.04066778901503522\n",
      "train loss:0.03551005666171493\n",
      "train loss:0.02680459003077755\n",
      "train loss:0.01330431500233933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.01944238363610383\n",
      "train loss:0.027540541071930057\n",
      "train loss:0.030987843063131754\n",
      "train loss:0.03368583990853833\n",
      "train loss:0.04572290087735754\n",
      "train loss:0.022079481923563953\n",
      "train loss:0.05653002601188157\n",
      "train loss:0.017482894670111417\n",
      "train loss:0.01077867593427134\n",
      "train loss:0.02052192712564631\n",
      "train loss:0.018626629431899282\n",
      "train loss:0.016040112981143426\n",
      "train loss:0.03725363811263296\n",
      "train loss:0.02799557006862755\n",
      "train loss:0.022262265766496914\n",
      "train loss:0.029168537803198776\n",
      "train loss:0.0172618953910621\n",
      "train loss:0.04082591271227518\n",
      "train loss:0.027642589720720475\n",
      "train loss:0.07448250220266305\n",
      "train loss:0.03608338563230255\n",
      "train loss:0.009820702986910769\n",
      "train loss:0.017567319899788724\n",
      "train loss:0.010126939625950727\n",
      "train loss:0.020966154061117195\n",
      "train loss:0.015464235667610262\n",
      "train loss:0.04814446807490626\n",
      "train loss:0.018763066745617608\n",
      "train loss:0.01941454079101622\n",
      "train loss:0.048688161820662774\n",
      "train loss:0.023591238623931955\n",
      "train loss:0.03359409745140543\n",
      "train loss:0.009409188720207013\n",
      "train loss:0.0030560926337142944\n",
      "train loss:0.04307254870217913\n",
      "train loss:0.01905154313963399\n",
      "train loss:0.017137913249639113\n",
      "train loss:0.04562648170207097\n",
      "train loss:0.05512835864996897\n",
      "train loss:0.03264864241329869\n",
      "train loss:0.055490171460988294\n",
      "train loss:0.04169587664652573\n",
      "train loss:0.03148979235050793\n",
      "train loss:0.029975322354633897\n",
      "train loss:0.010461006914435373\n",
      "train loss:0.011191166707374151\n",
      "train loss:0.0338776883330676\n",
      "train loss:0.03996440254649508\n",
      "train loss:0.01127511505663787\n",
      "train loss:0.012853947488977568\n",
      "train loss:0.03846058221894634\n",
      "train loss:0.028867337581009546\n",
      "train loss:0.029757879340919436\n",
      "train loss:0.03927841016412188\n",
      "train loss:0.02916656825091317\n",
      "train loss:0.027355197368134077\n",
      "train loss:0.014513467186732226\n",
      "train loss:0.006493641629115406\n",
      "train loss:0.020406841319354236\n",
      "train loss:0.020872465151398786\n",
      "train loss:0.017620851330211316\n",
      "train loss:0.03775828751353241\n",
      "train loss:0.015612862827175077\n",
      "train loss:0.018571498043467423\n",
      "train loss:0.02873282837435819\n",
      "train loss:0.01981726485368523\n",
      "train loss:0.05183586659735439\n",
      "train loss:0.03161329619486149\n",
      "train loss:0.015079632602626767\n",
      "train loss:0.026213641786871356\n",
      "train loss:0.02322203366078433\n",
      "train loss:0.007119035677013022\n",
      "train loss:0.0539493190892795\n",
      "train loss:0.10365202201022981\n",
      "train loss:0.017766030322384944\n",
      "train loss:0.01727033275419997\n",
      "train loss:0.013689210337440067\n",
      "train loss:0.08467777324707865\n",
      "train loss:0.04586820049270048\n",
      "train loss:0.05410249922062858\n",
      "train loss:0.01792635346635869\n",
      "train loss:0.04007817950570413\n",
      "train loss:0.03553817211713008\n",
      "train loss:0.01599552780894982\n",
      "train loss:0.004432040597790242\n",
      "train loss:0.04243475942577894\n",
      "train loss:0.05917227998112363\n",
      "train loss:0.05165674583814453\n",
      "train loss:0.014983369558954634\n",
      "train loss:0.030970051743766023\n",
      "train loss:0.02058326938629021\n",
      "train loss:0.01829460526249181\n",
      "train loss:0.021986490171912104\n",
      "train loss:0.025996160604779415\n",
      "train loss:0.019841816599055973\n",
      "train loss:0.030272811479430214\n",
      "train loss:0.03109173321318558\n",
      "train loss:0.02494513566336904\n",
      "train loss:0.03569932409571769\n",
      "train loss:0.06629195008132266\n",
      "train loss:0.016325750901435968\n",
      "train loss:0.010526910261214394\n",
      "train loss:0.06305601709489818\n",
      "train loss:0.01553676251727689\n",
      "train loss:0.02168317190845737\n",
      "train loss:0.03314219811713534\n",
      "train loss:0.026242169965240102\n",
      "train loss:0.03134146393396065\n",
      "train loss:0.03329781777857075\n",
      "train loss:0.0180464364477757\n",
      "train loss:0.014236397335974878\n",
      "train loss:0.02451632115768889\n",
      "train loss:0.015649651002570254\n",
      "train loss:0.010828984484602058\n",
      "train loss:0.048600233971250136\n",
      "train loss:0.01752567570385805\n",
      "train loss:0.05090447277083099\n",
      "train loss:0.026003562799003035\n",
      "train loss:0.02875265865880232\n",
      "train loss:0.03099266037236907\n",
      "train loss:0.04014189540477636\n",
      "train loss:0.015101750161669638\n",
      "train loss:0.009562959659840931\n",
      "train loss:0.038556047526003515\n",
      "train loss:0.0318704640244618\n",
      "train loss:0.023396733915664995\n",
      "train loss:0.01699760516550031\n",
      "train loss:0.04028756917077712\n",
      "train loss:0.0440682050207736\n",
      "train loss:0.012450787257600786\n",
      "train loss:0.029675353808957312\n",
      "train loss:0.018665768163050572\n",
      "train loss:0.032762651299443536\n",
      "train loss:0.02516630727597364\n",
      "train loss:0.03081574597096938\n",
      "train loss:0.01340623699063918\n",
      "train loss:0.02697807988371914\n",
      "train loss:0.021842497277259024\n",
      "train loss:0.022734172080970193\n",
      "train loss:0.014420755636504655\n",
      "train loss:0.05951900049040258\n",
      "train loss:0.03629868323110984\n",
      "train loss:0.02415957105475632\n",
      "train loss:0.010605189675793653\n",
      "train loss:0.04338874198782841\n",
      "train loss:0.027832087257319914\n",
      "train loss:0.00889369326703273\n",
      "train loss:0.00927524556416609\n",
      "train loss:0.019473874811484975\n",
      "train loss:0.010881461012422051\n",
      "train loss:0.02017660281307882\n",
      "train loss:0.04226046152263604\n",
      "train loss:0.019247316892871527\n",
      "train loss:0.023847965916300215\n",
      "train loss:0.027913320809373074\n",
      "train loss:0.04144375031353278\n",
      "train loss:0.008730034066576586\n",
      "train loss:0.027138813902367605\n",
      "train loss:0.024108898817410043\n",
      "train loss:0.02311887476666092\n",
      "train loss:0.053493542029396775\n",
      "train loss:0.00918174651159392\n",
      "train loss:0.017890838399628108\n",
      "train loss:0.05058642238625105\n",
      "train loss:0.010010756207921974\n",
      "train loss:0.05429894055559685\n",
      "train loss:0.017842609393025604\n",
      "train loss:0.03760852188446767\n",
      "train loss:0.03432393910059557\n",
      "train loss:0.07525515040643206\n",
      "train loss:0.047458467421852425\n",
      "train loss:0.013377643185107329\n",
      "train loss:0.03409680028824411\n",
      "train loss:0.01549528431069129\n",
      "train loss:0.016604160025656543\n",
      "train loss:0.02898834858796222\n",
      "train loss:0.024714361683440152\n",
      "train loss:0.03839098945405008\n",
      "train loss:0.01603697957080437\n",
      "train loss:0.009097562897151166\n",
      "train loss:0.02987904136997786\n",
      "train loss:0.028638709258795955\n",
      "train loss:0.028383855115935667\n",
      "train loss:0.014889183412060641\n",
      "train loss:0.052096133931507096\n",
      "train loss:0.015520128445725074\n",
      "train loss:0.04500307459591522\n",
      "train loss:0.035694354613792154\n",
      "train loss:0.0241556655682211\n",
      "train loss:0.025128503265668612\n",
      "train loss:0.08504655153626985\n",
      "train loss:0.025162859298407815\n",
      "train loss:0.08322051647429854\n",
      "train loss:0.02069477506382475\n",
      "train loss:0.03603807882751368\n",
      "train loss:0.02090288945741593\n",
      "train loss:0.04868036835810823\n",
      "train loss:0.030155087341748054\n",
      "train loss:0.0267722091571821\n",
      "train loss:0.02947597542191917\n",
      "train loss:0.03716174155875964\n",
      "train loss:0.036415900012474425\n",
      "train loss:0.02773729020683245\n",
      "train loss:0.03153498694870052\n",
      "train loss:0.015857697569155494\n",
      "train loss:0.04120177370129545\n",
      "train loss:0.006093677227701878\n",
      "train loss:0.03141418789152056\n",
      "train loss:0.006426234233750082\n",
      "train loss:0.06515633124145945\n",
      "train loss:0.013722541217448512\n",
      "train loss:0.0285007525012015\n",
      "train loss:0.005500375178179239\n",
      "train loss:0.015920909777022964\n",
      "train loss:0.003687292087545894\n",
      "train loss:0.05293239328486903\n",
      "train loss:0.05580331473440078\n",
      "train loss:0.009228868258679142\n",
      "train loss:0.006797150285739314\n",
      "train loss:0.034721720850781346\n",
      "train loss:0.026085882642320767\n",
      "train loss:0.018704631866698206\n",
      "train loss:0.016212230667198804\n",
      "train loss:0.023900180027496828\n",
      "train loss:0.006286081376737812\n",
      "train loss:0.01993815135529364\n",
      "train loss:0.02071781470545683\n",
      "train loss:0.021422712618584586\n",
      "train loss:0.01248544925822552\n",
      "train loss:0.02997426445413991\n",
      "train loss:0.014572434418044228\n",
      "train loss:0.02935266149529633\n",
      "train loss:0.021033054723944504\n",
      "train loss:0.017837310507941167\n",
      "train loss:0.01945519161920948\n",
      "train loss:0.011940770014377074\n",
      "train loss:0.021717379869725238\n",
      "train loss:0.026335466733362702\n",
      "train loss:0.022028427961778282\n",
      "train loss:0.010484367665750274\n",
      "train loss:0.007209911691504783\n",
      "train loss:0.024560164323552396\n",
      "train loss:0.05284703524166015\n",
      "train loss:0.0319680468688269\n",
      "train loss:0.0473969268294679\n",
      "train loss:0.05574639792355213\n",
      "train loss:0.04924616422862199\n",
      "train loss:0.025020775562003505\n",
      "train loss:0.0430237658521118\n",
      "train loss:0.041293706709180596\n",
      "train loss:0.01990441618041378\n",
      "train loss:0.013191683967825496\n",
      "train loss:0.04253834029022354\n",
      "train loss:0.037229197003664796\n",
      "train loss:0.07754598951512764\n",
      "train loss:0.018922309938749615\n",
      "train loss:0.034217558739622476\n",
      "train loss:0.010527279043402546\n",
      "train loss:0.012229545191322357\n",
      "train loss:0.017921637492209253\n",
      "train loss:0.013132839196677031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.044105566348134104\n",
      "train loss:0.0662894257878575\n",
      "train loss:0.06656585508865559\n",
      "train loss:0.03170202507913262\n",
      "train loss:0.028765550133205222\n",
      "train loss:0.02276936568668408\n",
      "train loss:0.03508557895730636\n",
      "train loss:0.042957372806408\n",
      "train loss:0.023429821938813\n",
      "train loss:0.037534465348567275\n",
      "train loss:0.049454106014762605\n",
      "train loss:0.05579801942099822\n",
      "train loss:0.03377262593679251\n",
      "train loss:0.012621874531410136\n",
      "train loss:0.027850581222789158\n",
      "train loss:0.016931832759009856\n",
      "train loss:0.027549081556036876\n",
      "train loss:0.024849796134939622\n",
      "train loss:0.017192450365638965\n",
      "train loss:0.019751557418555787\n",
      "train loss:0.02815449793296018\n",
      "train loss:0.03723627224487294\n",
      "train loss:0.04871011937407037\n",
      "train loss:0.034968139428356144\n",
      "train loss:0.010232089327654697\n",
      "train loss:0.03779528300801349\n",
      "train loss:0.15593911365311583\n",
      "train loss:0.04325499611221034\n",
      "train loss:0.02293416365203863\n",
      "train loss:0.013867847953909824\n",
      "train loss:0.02529035066892533\n",
      "=== epoch:28, train acc:0.991, test acc:0.91 ===\n",
      "train loss:0.04138672761445368\n",
      "train loss:0.017127984188011768\n",
      "train loss:0.051860253902325064\n",
      "train loss:0.044128671978000834\n",
      "train loss:0.0079020568720934\n",
      "train loss:0.007469904399034646\n",
      "train loss:0.018444434257182056\n",
      "train loss:0.021777226444895218\n",
      "train loss:0.015440353505595972\n",
      "train loss:0.013408372903759774\n",
      "train loss:0.02156847978873547\n",
      "train loss:0.03405789197991467\n",
      "train loss:0.021725278855934622\n",
      "train loss:0.028204141000657684\n",
      "train loss:0.023436027006471915\n",
      "train loss:0.02349523915647579\n",
      "train loss:0.017002114260111625\n",
      "train loss:0.0246568598624758\n",
      "train loss:0.025589185737082104\n",
      "train loss:0.032241148071926344\n",
      "train loss:0.00816542570496559\n",
      "train loss:0.016705822624483783\n",
      "train loss:0.013333940682748915\n",
      "train loss:0.03933506427625979\n",
      "train loss:0.029720815475215354\n",
      "train loss:0.025739399268230035\n",
      "train loss:0.033380380774981115\n",
      "train loss:0.03129972511920102\n",
      "train loss:0.02663617554315353\n",
      "train loss:0.018705850987386977\n",
      "train loss:0.02077565841549537\n",
      "train loss:0.032485440901596385\n",
      "train loss:0.015654909736589243\n",
      "train loss:0.02311250820591179\n",
      "train loss:0.015563303980806163\n",
      "train loss:0.009854278014882327\n",
      "train loss:0.031248276559071586\n",
      "train loss:0.03559858123263066\n",
      "train loss:0.06756190575013274\n",
      "train loss:0.019933823547557735\n",
      "train loss:0.00755918881594633\n",
      "train loss:0.03836288904117625\n",
      "train loss:0.04048359012943203\n",
      "train loss:0.015483738835851463\n",
      "train loss:0.018872112606255754\n",
      "train loss:0.025036534899226245\n",
      "train loss:0.03540784129693347\n",
      "train loss:0.008133701200055443\n",
      "train loss:0.08472568682220777\n",
      "train loss:0.04978077787677401\n",
      "train loss:0.011628718987111531\n",
      "train loss:0.016253766458209876\n",
      "train loss:0.026662696962279117\n",
      "train loss:0.03942768838049027\n",
      "train loss:0.06394997731674361\n",
      "train loss:0.024874100897238547\n",
      "train loss:0.017423043887611664\n",
      "train loss:0.018445675907808635\n",
      "train loss:0.05061285736863743\n",
      "train loss:0.06679743096796308\n",
      "train loss:0.02460267730798379\n",
      "train loss:0.0532079651510971\n",
      "train loss:0.050124948425853376\n",
      "train loss:0.011665971983737559\n",
      "train loss:0.020096727829664207\n",
      "train loss:0.018130105113456692\n",
      "train loss:0.008687168021293674\n",
      "train loss:0.020876609947745744\n",
      "train loss:0.06797575231431535\n",
      "train loss:0.015295157629647171\n",
      "train loss:0.014315899342131028\n",
      "train loss:0.030017150046472655\n",
      "train loss:0.01362756981762415\n",
      "train loss:0.02288654066720445\n",
      "train loss:0.023183646202326682\n",
      "train loss:0.02042646987357082\n",
      "train loss:0.028664812356694994\n",
      "train loss:0.020585817512051397\n",
      "train loss:0.04893501649151675\n",
      "train loss:0.02767347940112375\n",
      "train loss:0.0438189556887543\n",
      "train loss:0.017917895671474397\n",
      "train loss:0.034329428485591056\n",
      "train loss:0.034955850905009384\n",
      "train loss:0.04127199473409452\n",
      "train loss:0.05965852141682208\n",
      "train loss:0.0678250176729403\n",
      "train loss:0.016886329174977545\n",
      "train loss:0.04984225457946581\n",
      "train loss:0.015684125333942575\n",
      "train loss:0.016932533002745026\n",
      "train loss:0.05714714833387471\n",
      "train loss:0.016200222215376318\n",
      "train loss:0.01442501450785044\n",
      "train loss:0.043421283597855964\n",
      "train loss:0.03543291423300323\n",
      "train loss:0.020352577943041367\n",
      "train loss:0.04799970975696449\n",
      "train loss:0.03153303784768431\n",
      "train loss:0.031069478273471857\n",
      "train loss:0.006377499333036759\n",
      "train loss:0.014914370616365757\n",
      "train loss:0.027485841341788542\n",
      "train loss:0.03131042357644572\n",
      "train loss:0.026205577713581694\n",
      "train loss:0.018766274995420027\n",
      "train loss:0.054804734256463164\n",
      "train loss:0.024861699347786967\n",
      "train loss:0.013729898824239521\n",
      "train loss:0.037954743837237175\n",
      "train loss:0.01340148167896793\n",
      "train loss:0.010214731409811016\n",
      "train loss:0.050729163744757055\n",
      "train loss:0.019619635581036094\n",
      "train loss:0.04993646854058619\n",
      "train loss:0.06567804428694533\n",
      "train loss:0.007318173904396531\n",
      "train loss:0.018921015537847762\n",
      "train loss:0.02793960340932798\n",
      "train loss:0.0494623797531878\n",
      "train loss:0.07052314429808682\n",
      "train loss:0.06299509051456545\n",
      "train loss:0.009198687482616286\n",
      "train loss:0.03205967960511311\n",
      "train loss:0.028687190613715316\n",
      "train loss:0.022298183639871266\n",
      "train loss:0.033167557797770815\n",
      "train loss:0.02896500087650598\n",
      "train loss:0.01612709364552143\n",
      "train loss:0.026830410543456737\n",
      "train loss:0.06144716901754983\n",
      "train loss:0.036646657555493435\n",
      "train loss:0.04999381829895218\n",
      "train loss:0.010138307767337533\n",
      "train loss:0.027170852542513137\n",
      "train loss:0.01952682888918298\n",
      "train loss:0.04138766733143652\n",
      "train loss:0.02344295862683673\n",
      "train loss:0.03243304952743359\n",
      "train loss:0.027481568073071706\n",
      "train loss:0.018094489444033673\n",
      "train loss:0.01716224420314112\n",
      "train loss:0.044402283535817835\n",
      "train loss:0.04259715033397036\n",
      "train loss:0.027860137447478457\n",
      "train loss:0.012699731871424673\n",
      "train loss:0.033006749023265954\n",
      "train loss:0.03255809233987876\n",
      "train loss:0.02581142924733617\n",
      "train loss:0.0328611531758589\n",
      "train loss:0.023589769931226544\n",
      "train loss:0.032022442460705666\n",
      "train loss:0.03341406571701357\n",
      "train loss:0.04038036216499787\n",
      "train loss:0.032540130209413945\n",
      "train loss:0.04736860894867829\n",
      "train loss:0.030784731982122206\n",
      "train loss:0.011546592799692411\n",
      "train loss:0.022865666029249367\n",
      "train loss:0.0581650616352816\n",
      "train loss:0.04164783985105367\n",
      "train loss:0.059874031148233156\n",
      "train loss:0.031545308225986425\n",
      "train loss:0.02200543832449908\n",
      "train loss:0.005894297549371493\n",
      "train loss:0.019117459589907793\n",
      "train loss:0.09373435331698662\n",
      "train loss:0.017814450704928365\n",
      "train loss:0.040258865264625104\n",
      "train loss:0.023395768293575595\n",
      "train loss:0.028267347444449416\n",
      "train loss:0.04570589750651427\n",
      "train loss:0.01760543494422946\n",
      "train loss:0.014415898248270755\n",
      "train loss:0.018157286207988538\n",
      "train loss:0.026922012156421985\n",
      "train loss:0.013887398275031075\n",
      "train loss:0.022643133995968737\n",
      "train loss:0.01120119605693158\n",
      "train loss:0.03295100668900184\n",
      "train loss:0.012887154645668024\n",
      "train loss:0.02487443805185189\n",
      "train loss:0.034980232860549944\n",
      "train loss:0.02528192527441143\n",
      "train loss:0.01759928716613708\n",
      "train loss:0.028703942579614904\n",
      "train loss:0.07331043201335846\n",
      "train loss:0.016454118510018476\n",
      "train loss:0.03973195412185575\n",
      "train loss:0.025561281772115946\n",
      "train loss:0.018368619592478007\n",
      "train loss:0.020884338297359587\n",
      "train loss:0.01962253030126377\n",
      "train loss:0.016646917345252123\n",
      "train loss:0.007434325963966966\n",
      "train loss:0.03121401049362675\n",
      "train loss:0.022103920844533678\n",
      "train loss:0.023952982270978404\n",
      "train loss:0.012751377190887911\n",
      "train loss:0.040065069555249834\n",
      "train loss:0.04227620034931678\n",
      "train loss:0.026476043342747932\n",
      "train loss:0.050479047374386\n",
      "train loss:0.04648972271183241\n",
      "train loss:0.021980954872274472\n",
      "train loss:0.03927335391874009\n",
      "train loss:0.020516812399753826\n",
      "train loss:0.010774997175958428\n",
      "train loss:0.03256437481817624\n",
      "train loss:0.03151347687765621\n",
      "train loss:0.02655927788841486\n",
      "train loss:0.011694448832629935\n",
      "train loss:0.024916682617079827\n",
      "train loss:0.017226800812211014\n",
      "train loss:0.015953320718052215\n",
      "train loss:0.004766466086332374\n",
      "train loss:0.04109166677423084\n",
      "train loss:0.034394535495274894\n",
      "train loss:0.018268367016377532\n",
      "train loss:0.01908616137234095\n",
      "train loss:0.050215880116459395\n",
      "train loss:0.02901170300421474\n",
      "train loss:0.012600018368904363\n",
      "train loss:0.017370997501887236\n",
      "train loss:0.024009110993370015\n",
      "train loss:0.02412983086030418\n",
      "train loss:0.017072919190236912\n",
      "train loss:0.029956002303347908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.014060038164759328\n",
      "train loss:0.0075723636747551315\n",
      "train loss:0.05445264105761284\n",
      "train loss:0.019716632399917913\n",
      "train loss:0.035322319591490486\n",
      "train loss:0.03635787897787484\n",
      "train loss:0.022125362094477664\n",
      "train loss:0.011357891176143487\n",
      "train loss:0.017096506954223684\n",
      "train loss:0.011482001967708906\n",
      "train loss:0.00533177687265087\n",
      "train loss:0.018304181072236816\n",
      "train loss:0.02817314005311268\n",
      "train loss:0.013003840727074176\n",
      "train loss:0.06491582680651327\n",
      "train loss:0.047955425102754835\n",
      "train loss:0.02763285768411161\n",
      "train loss:0.029389402022819908\n",
      "train loss:0.05329778587328546\n",
      "train loss:0.022708172455575118\n",
      "train loss:0.049607255967257485\n",
      "train loss:0.02696305988260166\n",
      "train loss:0.01581292385103823\n",
      "train loss:0.03819693863661204\n",
      "train loss:0.005483600794826054\n",
      "train loss:0.017979519905122577\n",
      "train loss:0.03354228139266875\n",
      "train loss:0.03763495110537036\n",
      "train loss:0.010205223896699098\n",
      "train loss:0.026252064703276044\n",
      "train loss:0.012229002116098913\n",
      "train loss:0.07060220781801667\n",
      "train loss:0.007989928132364175\n",
      "train loss:0.0055500766755886026\n",
      "train loss:0.021332725446400958\n",
      "train loss:0.010613235400189684\n",
      "train loss:0.010053842777398559\n",
      "train loss:0.010805520272493848\n",
      "train loss:0.03516444005795102\n",
      "train loss:0.015110524688471278\n",
      "train loss:0.030293076706446806\n",
      "train loss:0.010375130500161258\n",
      "train loss:0.010564834050419213\n",
      "train loss:0.029065639882684322\n",
      "train loss:0.017018033370002256\n",
      "train loss:0.01324408875025223\n",
      "train loss:0.022603832281090194\n",
      "train loss:0.02441315091974451\n",
      "train loss:0.007592945759212102\n",
      "train loss:0.015040686140196055\n",
      "train loss:0.015444428630687165\n",
      "train loss:0.05224264966034273\n",
      "train loss:0.03576245887645386\n",
      "train loss:0.017396529313052744\n",
      "train loss:0.010903493861861131\n",
      "train loss:0.017214540795850233\n",
      "train loss:0.014632381965401649\n",
      "train loss:0.04542462676995612\n",
      "train loss:0.02640280133016887\n",
      "train loss:0.015865824860934748\n",
      "train loss:0.018964919970206818\n",
      "train loss:0.012181933606258482\n",
      "train loss:0.024334849931105393\n",
      "train loss:0.047322757939170484\n",
      "train loss:0.02070764580841116\n",
      "train loss:0.018390277495031596\n",
      "train loss:0.029144057208862678\n",
      "train loss:0.03295858058282666\n",
      "train loss:0.017047905382050633\n",
      "train loss:0.03262851104989484\n",
      "train loss:0.011518657519903336\n",
      "train loss:0.02424619878241793\n",
      "train loss:0.01984835525479721\n",
      "train loss:0.012921293057445288\n",
      "train loss:0.02417490015738649\n",
      "train loss:0.032241517120631884\n",
      "train loss:0.008571156256694464\n",
      "train loss:0.0068315300328117825\n",
      "train loss:0.023505697768867764\n",
      "train loss:0.041860237760044244\n",
      "train loss:0.019098733854371306\n",
      "train loss:0.014752386548332462\n",
      "train loss:0.04134266227162371\n",
      "train loss:0.01591875408274003\n",
      "train loss:0.05971578034023675\n",
      "train loss:0.032870356075046354\n",
      "train loss:0.012861490141457146\n",
      "train loss:0.03331478093591531\n",
      "train loss:0.048284894159862944\n",
      "train loss:0.020459646884885795\n",
      "train loss:0.020811786315034716\n",
      "train loss:0.01917940110543475\n",
      "train loss:0.01891125742535964\n",
      "train loss:0.04570486214480271\n",
      "train loss:0.030644642776249\n",
      "train loss:0.01592111680186827\n",
      "train loss:0.020270116228595706\n",
      "train loss:0.022893659988649076\n",
      "train loss:0.019236424225241792\n",
      "train loss:0.020623940172801215\n",
      "train loss:0.013115445062613923\n",
      "train loss:0.00309687969162431\n",
      "train loss:0.018640418924788144\n",
      "train loss:0.017106079956868175\n",
      "train loss:0.02334850229473893\n",
      "train loss:0.07679224668425774\n",
      "train loss:0.012939179453287984\n",
      "train loss:0.05971272277032447\n",
      "train loss:0.015085689617837534\n",
      "train loss:0.02169320520962055\n",
      "train loss:0.028013029615859303\n",
      "train loss:0.005030797172340474\n",
      "train loss:0.06626655740963036\n",
      "train loss:0.031910726871883045\n",
      "train loss:0.030978863160682373\n",
      "train loss:0.05720141316777062\n",
      "train loss:0.02896292994818726\n",
      "train loss:0.011310466445973534\n",
      "train loss:0.014841308635257774\n",
      "train loss:0.05865185123385789\n",
      "train loss:0.021101980725836102\n",
      "train loss:0.01678627795046858\n",
      "train loss:0.025613190931119533\n",
      "train loss:0.012830824397257743\n",
      "train loss:0.004396189841629254\n",
      "train loss:0.01729465496517215\n",
      "train loss:0.030580979650166058\n",
      "train loss:0.02327297900076205\n",
      "train loss:0.03358948657999448\n",
      "train loss:0.03330332539914539\n",
      "train loss:0.012436097703638823\n",
      "train loss:0.05840556042414379\n",
      "train loss:0.013049964650092147\n",
      "train loss:0.03830095164424793\n",
      "train loss:0.026191565972534372\n",
      "train loss:0.06460861481922599\n",
      "train loss:0.012549373221840087\n",
      "train loss:0.010604574957505906\n",
      "train loss:0.024734260528005633\n",
      "train loss:0.020869554674446907\n",
      "train loss:0.013610463139285251\n",
      "train loss:0.014713274342290594\n",
      "train loss:0.03616306745169276\n",
      "train loss:0.007545606843136824\n",
      "train loss:0.01888155823790765\n",
      "train loss:0.009616678138639471\n",
      "train loss:0.024956213479409538\n",
      "train loss:0.02504042375169819\n",
      "train loss:0.02890208038919591\n",
      "train loss:0.0997333635725835\n",
      "train loss:0.021321844104090538\n",
      "train loss:0.0281353162939783\n",
      "train loss:0.010982372151128636\n",
      "train loss:0.010490867266448317\n",
      "train loss:0.017931634785823616\n",
      "train loss:0.033177985282323845\n",
      "train loss:0.033172463309919756\n",
      "train loss:0.026558200824286546\n",
      "train loss:0.013379549324148097\n",
      "train loss:0.02471275936315455\n",
      "train loss:0.024569622297370138\n",
      "train loss:0.015184612383094069\n",
      "train loss:0.016734541620369626\n",
      "train loss:0.010997696841261976\n",
      "train loss:0.0047834770371714495\n",
      "train loss:0.00813882172193535\n",
      "train loss:0.03659158002789211\n",
      "train loss:0.02087620184012505\n",
      "train loss:0.010442870190232812\n",
      "train loss:0.051976949290299224\n",
      "train loss:0.022871536119052606\n",
      "train loss:0.01622366695161227\n",
      "train loss:0.023129425214975848\n",
      "train loss:0.01384498412581422\n",
      "train loss:0.018250612348034215\n",
      "train loss:0.08997627160753702\n",
      "train loss:0.016752022856495106\n",
      "train loss:0.020687340686144067\n",
      "train loss:0.010467300572904768\n",
      "train loss:0.01316874982245651\n",
      "train loss:0.015100979826229082\n",
      "train loss:0.008439608712700114\n",
      "train loss:0.020382464745761872\n",
      "train loss:0.07146014157518157\n",
      "train loss:0.016573204507660894\n",
      "train loss:0.03553634074207566\n",
      "train loss:0.012552638223561698\n",
      "train loss:0.00597456868772648\n",
      "train loss:0.034060423584331284\n",
      "train loss:0.0299515727269654\n",
      "train loss:0.008069151374711342\n",
      "train loss:0.005184526006704191\n",
      "train loss:0.02057507178534125\n",
      "train loss:0.016471253268252786\n",
      "train loss:0.037842892265590906\n",
      "train loss:0.01778750609599663\n",
      "train loss:0.01681187129504106\n",
      "train loss:0.02582037352592033\n",
      "train loss:0.030462924652873532\n",
      "train loss:0.005640926006655449\n",
      "train loss:0.020625695128836177\n",
      "train loss:0.027778355668537993\n",
      "train loss:0.022817407901639854\n",
      "train loss:0.02621570294374095\n",
      "train loss:0.07122663211038784\n",
      "train loss:0.028851037913407165\n",
      "train loss:0.0054434119980502505\n",
      "train loss:0.008128815797187298\n",
      "train loss:0.042809900962458604\n",
      "train loss:0.025853297574857756\n",
      "train loss:0.03433537138950779\n",
      "train loss:0.04748536105357183\n",
      "train loss:0.013328076065537932\n",
      "train loss:0.017032296998380686\n",
      "train loss:0.01525537013357016\n",
      "train loss:0.02326558853105857\n",
      "train loss:0.018843883794004958\n",
      "train loss:0.02884637904589288\n",
      "train loss:0.011998766149802196\n",
      "train loss:0.07962853829106224\n",
      "train loss:0.01461573365423953\n",
      "train loss:0.09066634044046472\n",
      "train loss:0.06727138576340706\n",
      "train loss:0.03556320216728647\n",
      "train loss:0.011735562935856269\n",
      "train loss:0.011517617182343369\n",
      "train loss:0.024970219350059265\n",
      "train loss:0.058474828559638724\n",
      "train loss:0.015364220808519893\n",
      "train loss:0.0778174730733877\n",
      "train loss:0.060743647848546925\n",
      "train loss:0.013811560956565652\n",
      "train loss:0.042773844485136575\n",
      "train loss:0.03215561658972515\n",
      "train loss:0.015977623159391934\n",
      "train loss:0.04155685612037804\n",
      "train loss:0.03596457271702799\n",
      "train loss:0.01899920484042605\n",
      "train loss:0.014267283194615916\n",
      "train loss:0.033038751214666796\n",
      "train loss:0.018073222883659742\n",
      "train loss:0.027350548685577524\n",
      "train loss:0.02233797783891143\n",
      "train loss:0.020951472469870534\n",
      "train loss:0.012037941480253554\n",
      "train loss:0.035667771320190916\n",
      "train loss:0.05461300721587704\n",
      "train loss:0.045970436886563056\n",
      "train loss:0.04450896418002779\n",
      "train loss:0.015138892560400862\n",
      "train loss:0.014650902688675936\n",
      "train loss:0.014691060988411185\n",
      "train loss:0.0312510896860084\n",
      "train loss:0.03431799344644011\n",
      "train loss:0.03696775067163623\n",
      "train loss:0.02308980333497864\n",
      "train loss:0.030311717639842337\n",
      "train loss:0.027529508816413664\n",
      "train loss:0.015650324812582536\n",
      "train loss:0.02944726256958822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.05968011588010392\n",
      "train loss:0.03653623779272645\n",
      "train loss:0.030797893004567083\n",
      "train loss:0.043686386419534845\n",
      "train loss:0.028810122357909616\n",
      "train loss:0.02514025033685898\n",
      "train loss:0.02190922553967801\n",
      "train loss:0.03212167235358005\n",
      "train loss:0.015291699820622354\n",
      "train loss:0.024245774256464223\n",
      "train loss:0.021013830932068718\n",
      "train loss:0.018022457877894825\n",
      "train loss:0.02855540025917861\n",
      "train loss:0.009613309758705266\n",
      "train loss:0.06193835790846065\n",
      "train loss:0.006671658767596688\n",
      "train loss:0.024970711276379003\n",
      "train loss:0.017933342457527254\n",
      "train loss:0.033211324594205394\n",
      "train loss:0.022883403754258073\n",
      "train loss:0.04048097440095245\n",
      "train loss:0.019470738382140015\n",
      "train loss:0.02637225607185003\n",
      "train loss:0.029259681872756328\n",
      "train loss:0.032404584922449894\n",
      "train loss:0.012042475718933871\n",
      "train loss:0.0063808190106589705\n",
      "train loss:0.013929018478735946\n",
      "train loss:0.021239937524310314\n",
      "train loss:0.061308011739937315\n",
      "train loss:0.010697442614312859\n",
      "train loss:0.024859896158461896\n",
      "train loss:0.01988818274286267\n",
      "train loss:0.041943367211548795\n",
      "train loss:0.016350347352567164\n",
      "train loss:0.02179094203402007\n",
      "train loss:0.026742306731783298\n",
      "train loss:0.024859154337571063\n",
      "train loss:0.005851482718180509\n",
      "train loss:0.012984370692911678\n",
      "train loss:0.05368265078697938\n",
      "train loss:0.023166724494903618\n",
      "train loss:0.015621319348230278\n",
      "train loss:0.014499540599378023\n",
      "train loss:0.011159472670720197\n",
      "train loss:0.009570112078688586\n",
      "train loss:0.02384968633367609\n",
      "train loss:0.02730094529482536\n",
      "train loss:0.019931681540722397\n",
      "train loss:0.014686450150326411\n",
      "train loss:0.00925438584908733\n",
      "train loss:0.02074549871973264\n",
      "train loss:0.008328049854839658\n",
      "train loss:0.03182272630831143\n",
      "train loss:0.06924365720655844\n",
      "train loss:0.01204823444281642\n",
      "train loss:0.05865995025967223\n",
      "train loss:0.010604385773728233\n",
      "train loss:0.020601594109822537\n",
      "train loss:0.009089081428126764\n",
      "train loss:0.05163443355176952\n",
      "train loss:0.027376661704331152\n",
      "train loss:0.01539903145078677\n",
      "train loss:0.019972039514470442\n",
      "train loss:0.005918546086404646\n",
      "train loss:0.011206936108224753\n",
      "train loss:0.01648564770697342\n",
      "train loss:0.0641444220343506\n",
      "train loss:0.007928200621582383\n",
      "train loss:0.03591418651334185\n",
      "train loss:0.024582970183769273\n",
      "train loss:0.023505136946011043\n",
      "train loss:0.029528895052943392\n",
      "train loss:0.02531570133036605\n",
      "train loss:0.015644075736244475\n",
      "train loss:0.03336509113169136\n",
      "train loss:0.005475269426899727\n",
      "train loss:0.03460806352684587\n",
      "train loss:0.016399291088819764\n",
      "train loss:0.03847657613227858\n",
      "train loss:0.011552438408774915\n",
      "train loss:0.04174330235991319\n",
      "train loss:0.03862893434861641\n",
      "train loss:0.012427072292018388\n",
      "train loss:0.04922264689934442\n",
      "train loss:0.01502988558139888\n",
      "train loss:0.04818315551457432\n",
      "train loss:0.011767128201718385\n",
      "train loss:0.040679948918170325\n",
      "train loss:0.06305165131655344\n",
      "train loss:0.021441124616076515\n",
      "train loss:0.020673608771074856\n",
      "train loss:0.010926164817563224\n",
      "train loss:0.05367484151853911\n",
      "train loss:0.019603524070755076\n",
      "train loss:0.013320056853438537\n",
      "train loss:0.007813021968769833\n",
      "train loss:0.012471853925489296\n",
      "train loss:0.007633543618280535\n",
      "train loss:0.007711350052241855\n",
      "train loss:0.016267164934707052\n",
      "train loss:0.008492162643891915\n",
      "train loss:0.015018303119552759\n",
      "train loss:0.03237702413306416\n",
      "train loss:0.007835425833176828\n",
      "train loss:0.008906726979407054\n",
      "train loss:0.023912074421332412\n",
      "train loss:0.009046361195945611\n",
      "train loss:0.030333196395677935\n",
      "train loss:0.05371820975567749\n",
      "train loss:0.026186447238668063\n",
      "train loss:0.0259436262287028\n",
      "=== epoch:29, train acc:0.992, test acc:0.916 ===\n",
      "train loss:0.025104905243189354\n",
      "train loss:0.014332505022824\n",
      "train loss:0.05060837686054264\n",
      "train loss:0.01769094560756618\n",
      "train loss:0.015756452422821428\n",
      "train loss:0.026331159458440265\n",
      "train loss:0.016002274166991494\n",
      "train loss:0.009755652896397933\n",
      "train loss:0.06553153639211962\n",
      "train loss:0.044357249484424204\n",
      "train loss:0.03993210303642004\n",
      "train loss:0.03197924237503992\n",
      "train loss:0.011562212496000337\n",
      "train loss:0.008288388560145755\n",
      "train loss:0.020262300853634833\n",
      "train loss:0.03832316743838401\n",
      "train loss:0.04780178144774813\n",
      "train loss:0.019180137282668156\n",
      "train loss:0.009123462085820799\n",
      "train loss:0.007833739470021141\n",
      "train loss:0.032737347391666984\n",
      "train loss:0.05166806464668799\n",
      "train loss:0.006941231918392122\n",
      "train loss:0.014134999120550605\n",
      "train loss:0.009236055990082781\n",
      "train loss:0.01254230663798582\n",
      "train loss:0.09427590568679405\n",
      "train loss:0.01892921693748026\n",
      "train loss:0.01044672145640998\n",
      "train loss:0.02415162968850086\n",
      "train loss:0.040697840608286684\n",
      "train loss:0.03319809579888162\n",
      "train loss:0.024138770655112184\n",
      "train loss:0.010607214996451791\n",
      "train loss:0.029819157818800384\n",
      "train loss:0.0026369099871819046\n",
      "train loss:0.014793048691236859\n",
      "train loss:0.021355620183249043\n",
      "train loss:0.028602786536380854\n",
      "train loss:0.0172936798202335\n",
      "train loss:0.01740861132833473\n",
      "train loss:0.012025089495899342\n",
      "train loss:0.01854754883767753\n",
      "train loss:0.020457974659041502\n",
      "train loss:0.10525130837244992\n",
      "train loss:0.10258010523296714\n",
      "train loss:0.010984955013693978\n",
      "train loss:0.033928797375849154\n",
      "train loss:0.010677475898884998\n",
      "train loss:0.021383363164587048\n",
      "train loss:0.014867023765785787\n",
      "train loss:0.02367889566471842\n",
      "train loss:0.03295965392570314\n",
      "train loss:0.014514071803456605\n",
      "train loss:0.031969483075255885\n",
      "train loss:0.021163797911980118\n",
      "train loss:0.0824680284360544\n",
      "train loss:0.022610620492144917\n",
      "train loss:0.011089603033942477\n",
      "train loss:0.045477626939439346\n",
      "train loss:0.010501295198391951\n",
      "train loss:0.014668738381787344\n",
      "train loss:0.029428168472816662\n",
      "train loss:0.016926977333793634\n",
      "train loss:0.06936614924675906\n",
      "train loss:0.036680024213321685\n",
      "train loss:0.09329927445854969\n",
      "train loss:0.02924114003775989\n",
      "train loss:0.026561054120075284\n",
      "train loss:0.009289811907817776\n",
      "train loss:0.010199256493704099\n",
      "train loss:0.008555355439808156\n",
      "train loss:0.05137339344029229\n",
      "train loss:0.02572370646625386\n",
      "train loss:0.010716191105710591\n",
      "train loss:0.012620525516830428\n",
      "train loss:0.051415480257226726\n",
      "train loss:0.06681327406404083\n",
      "train loss:0.013864010949190623\n",
      "train loss:0.023657210917009137\n",
      "train loss:0.052959161737553204\n",
      "train loss:0.006626059836412319\n",
      "train loss:0.018460913585366973\n",
      "train loss:0.02214969338175884\n",
      "train loss:0.07040159632677383\n",
      "train loss:0.025814819080229263\n",
      "train loss:0.01584995190930316\n",
      "train loss:0.016473964723225678\n",
      "train loss:0.004553987809332668\n",
      "train loss:0.027121773266145007\n",
      "train loss:0.011528946632679457\n",
      "train loss:0.022486060338345576\n",
      "train loss:0.06345795872378698\n",
      "train loss:0.01998167416282851\n",
      "train loss:0.01575838760798218\n",
      "train loss:0.008116303039644559\n",
      "train loss:0.015537480019373339\n",
      "train loss:0.009448128590842484\n",
      "train loss:0.025222441144783163\n",
      "train loss:0.01382155243272622\n",
      "train loss:0.011849213850344651\n",
      "train loss:0.025699870633367206\n",
      "train loss:0.013837511829417094\n",
      "train loss:0.021968716476910625\n",
      "train loss:0.028997885034634473\n",
      "train loss:0.010632387195587886\n",
      "train loss:0.023520006992201848\n",
      "train loss:0.018662118525654123\n",
      "train loss:0.03315102354475521\n",
      "train loss:0.031391934254324405\n",
      "train loss:0.02478059183775032\n",
      "train loss:0.04723157570352134\n",
      "train loss:0.006740807622140885\n",
      "train loss:0.023884467825056165\n",
      "train loss:0.043597879959729885\n",
      "train loss:0.07527684380195651\n",
      "train loss:0.00942858932481971\n",
      "train loss:0.024354624238097325\n",
      "train loss:0.015598343250289432\n",
      "train loss:0.038551950921620864\n",
      "train loss:0.0304741921861125\n",
      "train loss:0.008784683104731213\n",
      "train loss:0.06339146123086442\n",
      "train loss:0.009819105234357252\n",
      "train loss:0.03239247670868465\n",
      "train loss:0.007286735867289976\n",
      "train loss:0.014112252961421268\n",
      "train loss:0.048093495304107406\n",
      "train loss:0.06423553886813839\n",
      "train loss:0.017655257787008244\n",
      "train loss:0.021011261947216413\n",
      "train loss:0.012596780402655222\n",
      "train loss:0.01290401864615567\n",
      "train loss:0.011057660057700359\n",
      "train loss:0.014380949270522733\n",
      "train loss:0.008823040949215849\n",
      "train loss:0.017666573147361034\n",
      "train loss:0.0061481424382511226\n",
      "train loss:0.011912370657571354\n",
      "train loss:0.01492389074492139\n",
      "train loss:0.02337151141377799\n",
      "train loss:0.026324742793840186\n",
      "train loss:0.008396780827651114\n",
      "train loss:0.014184525301835884\n",
      "train loss:0.020626483817943186\n",
      "train loss:0.011632845846567312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0336785906066352\n",
      "train loss:0.014165356462672939\n",
      "train loss:0.018155322110483204\n",
      "train loss:0.0372487067712585\n",
      "train loss:0.019167924982726906\n",
      "train loss:0.038080908222316856\n",
      "train loss:0.007351296851759484\n",
      "train loss:0.05285609863423997\n",
      "train loss:0.015125515482532383\n",
      "train loss:0.012712928135369091\n",
      "train loss:0.07223003840247542\n",
      "train loss:0.011501263333052758\n",
      "train loss:0.007475002731320739\n",
      "train loss:0.0524220063043635\n",
      "train loss:0.015254719820921154\n",
      "train loss:0.02998487133240451\n",
      "train loss:0.005236630828794544\n",
      "train loss:0.00877425773002363\n",
      "train loss:0.05210444849293945\n",
      "train loss:0.01458499430946699\n",
      "train loss:0.01784408775805459\n",
      "train loss:0.02794303398402463\n",
      "train loss:0.03457486206650402\n",
      "train loss:0.029756235864355406\n",
      "train loss:0.04283575294779565\n",
      "train loss:0.02479309102659975\n",
      "train loss:0.03435039398453688\n",
      "train loss:0.04197004986903957\n",
      "train loss:0.028605872003345807\n",
      "train loss:0.020041314929471702\n",
      "train loss:0.04539324029172846\n",
      "train loss:0.015481975073815048\n",
      "train loss:0.04593771742596724\n",
      "train loss:0.031262159036471206\n",
      "train loss:0.03139970596416557\n",
      "train loss:0.028226615856156892\n",
      "train loss:0.023620420844589818\n",
      "train loss:0.01723966324966262\n",
      "train loss:0.019162297094997328\n",
      "train loss:0.01692598520223565\n",
      "train loss:0.056594278769051716\n",
      "train loss:0.06498389042954326\n",
      "train loss:0.0123984394654987\n",
      "train loss:0.08203965222355057\n",
      "train loss:0.022330124174388823\n",
      "train loss:0.036968563960639564\n",
      "train loss:0.013861689291750256\n",
      "train loss:0.017935032269917394\n",
      "train loss:0.006475729921210485\n",
      "train loss:0.007399417715231115\n",
      "train loss:0.012548881913227228\n",
      "train loss:0.011330419592047012\n",
      "train loss:0.021728344659824966\n",
      "train loss:0.01866686517409939\n",
      "train loss:0.009152697208020887\n",
      "train loss:0.02845625371274942\n",
      "train loss:0.02582090375011078\n",
      "train loss:0.008840699094568928\n",
      "train loss:0.041245925183092697\n",
      "train loss:0.024496877334945703\n",
      "train loss:0.021770466754065288\n",
      "train loss:0.029573722996963606\n",
      "train loss:0.005898707216492254\n",
      "train loss:0.03159394253623664\n",
      "train loss:0.048565579548977646\n",
      "train loss:0.019988447372842052\n",
      "train loss:0.02413169870182933\n",
      "train loss:0.007294583789812969\n",
      "train loss:0.01867160631308632\n",
      "train loss:0.016103582941104363\n",
      "train loss:0.0315862906817601\n",
      "train loss:0.03631232283096452\n",
      "train loss:0.019572065001022987\n",
      "train loss:0.006494030767540212\n",
      "train loss:0.02430266843109971\n",
      "train loss:0.027284955829467186\n",
      "train loss:0.008081632548417069\n",
      "train loss:0.010700739246163174\n",
      "train loss:0.053378804279888815\n",
      "train loss:0.0062664711769229095\n",
      "train loss:0.029853711211198317\n",
      "train loss:0.022821048849836597\n",
      "train loss:0.0161877059822593\n",
      "train loss:0.02154398720338939\n",
      "train loss:0.04521759342183871\n",
      "train loss:0.020792721717465795\n",
      "train loss:0.03386104351578061\n",
      "train loss:0.015407440210797825\n",
      "train loss:0.013999116455845648\n",
      "train loss:0.01038884327444213\n",
      "train loss:0.022666231374329816\n",
      "train loss:0.009832733444494103\n",
      "train loss:0.030477809541067755\n",
      "train loss:0.012559777149585625\n",
      "train loss:0.04916183185553816\n",
      "train loss:0.026699332227448584\n",
      "train loss:0.014818898713309594\n",
      "train loss:0.020021546846451438\n",
      "train loss:0.06345050838887319\n",
      "train loss:0.012696009935055834\n",
      "train loss:0.027189594431714995\n",
      "train loss:0.007983604675643205\n",
      "train loss:0.01998230308057199\n",
      "train loss:0.04055461094582822\n",
      "train loss:0.012311759036450175\n",
      "train loss:0.022771624075814033\n",
      "train loss:0.014405853398873535\n",
      "train loss:0.03369360967950976\n",
      "train loss:0.02754072502909444\n",
      "train loss:0.012700785417657227\n",
      "train loss:0.12281241202221391\n",
      "train loss:0.0137064139629662\n",
      "train loss:0.014125427908898485\n",
      "train loss:0.06339555270844302\n",
      "train loss:0.013853885971605447\n",
      "train loss:0.01196977493363101\n",
      "train loss:0.0254809636841791\n",
      "train loss:0.011682506243762053\n",
      "train loss:0.038038457221916754\n",
      "train loss:0.01012680141113942\n",
      "train loss:0.03126714692854158\n",
      "train loss:0.013238219149771637\n",
      "train loss:0.016174051822838032\n",
      "train loss:0.055257325361352215\n",
      "train loss:0.021992636962297668\n",
      "train loss:0.024507142203710502\n",
      "train loss:0.020705480767338736\n",
      "train loss:0.015362087406628063\n",
      "train loss:0.010235317157669788\n",
      "train loss:0.02165572712463165\n",
      "train loss:0.015524831003557732\n",
      "train loss:0.00815466545729856\n",
      "train loss:0.02212036735906429\n",
      "train loss:0.026104454443696367\n",
      "train loss:0.021681894155462712\n",
      "train loss:0.015308121921317738\n",
      "train loss:0.02237911633809478\n",
      "train loss:0.01878037408028529\n",
      "train loss:0.022063531867477764\n",
      "train loss:0.011864580238807411\n",
      "train loss:0.016656784396346623\n",
      "train loss:0.007012609370995476\n",
      "train loss:0.046559589575457964\n",
      "train loss:0.023850836124407054\n",
      "train loss:0.025697047180287102\n",
      "train loss:0.04584462231490834\n",
      "train loss:0.024915309605370646\n",
      "train loss:0.007156315216695297\n",
      "train loss:0.022585066211630467\n",
      "train loss:0.019785118627806627\n",
      "train loss:0.026505993461034872\n",
      "train loss:0.019622012777779772\n",
      "train loss:0.02035256903224381\n",
      "train loss:0.019643837071428524\n",
      "train loss:0.025965180464554993\n",
      "train loss:0.016027366248814123\n",
      "train loss:0.026475215635493755\n",
      "train loss:0.059903939334070344\n",
      "train loss:0.025730683609323898\n",
      "train loss:0.024452136284624754\n",
      "train loss:0.020395183831841884\n",
      "train loss:0.02167287128990902\n",
      "train loss:0.011607751725391788\n",
      "train loss:0.010730004237879953\n",
      "train loss:0.028739566900177597\n",
      "train loss:0.015309384876769385\n",
      "train loss:0.017415576810488723\n",
      "train loss:0.06849165022896558\n",
      "train loss:0.007141614187113836\n",
      "train loss:0.02311423359004928\n",
      "train loss:0.014732495332842464\n",
      "train loss:0.04721688858371034\n",
      "train loss:0.020354888291749317\n",
      "train loss:0.01973556480003619\n",
      "train loss:0.027253058834677536\n",
      "train loss:0.03637971772480714\n",
      "train loss:0.01873754147896671\n",
      "train loss:0.03608814536862551\n",
      "train loss:0.01880976646984535\n",
      "train loss:0.04146015410106652\n",
      "train loss:0.02286643830181141\n",
      "train loss:0.04414250711482363\n",
      "train loss:0.033543861742699625\n",
      "train loss:0.012588920733367742\n",
      "train loss:0.04010994786189398\n",
      "train loss:0.018506784585073186\n",
      "train loss:0.03349323847607025\n",
      "train loss:0.014623512092487613\n",
      "train loss:0.04382984769162905\n",
      "train loss:0.027397437827016063\n",
      "train loss:0.016849792527571742\n",
      "train loss:0.005212875330891608\n",
      "train loss:0.011494874091082572\n",
      "train loss:0.033910941544374025\n",
      "train loss:0.008673579405486772\n",
      "train loss:0.015304181836675318\n",
      "train loss:0.016817357126541598\n",
      "train loss:0.01981729318871068\n",
      "train loss:0.05098065163627004\n",
      "train loss:0.03174635734631423\n",
      "train loss:0.025606578152280037\n",
      "train loss:0.02353796025328271\n",
      "train loss:0.015382336731707486\n",
      "train loss:0.009867448713338077\n",
      "train loss:0.014408963550324717\n",
      "train loss:0.01923932596490196\n",
      "train loss:0.007221372735947498\n",
      "train loss:0.002826379394088682\n",
      "train loss:0.03915772730286354\n",
      "train loss:0.011818765341213722\n",
      "train loss:0.042196521972087966\n",
      "train loss:0.008738060618308228\n",
      "train loss:0.05961204011248235\n",
      "train loss:0.030242794866151456\n",
      "train loss:0.027883845297078942\n",
      "train loss:0.027337020899971524\n",
      "train loss:0.015419074795425052\n",
      "train loss:0.016141071847965337\n",
      "train loss:0.03688898317737936\n",
      "train loss:0.015706995030217084\n",
      "train loss:0.06831894698353093\n",
      "train loss:0.01338100240744642\n",
      "train loss:0.006739988081177174\n",
      "train loss:0.04329605913455395\n",
      "train loss:0.009048254855893629\n",
      "train loss:0.016096881496391116\n",
      "train loss:0.019154718999316353\n",
      "train loss:0.007924021737290654\n",
      "train loss:0.009050434943237502\n",
      "train loss:0.02743968148298785\n",
      "train loss:0.017669593424429853\n",
      "train loss:0.023179296639863737\n",
      "train loss:0.01193570755471261\n",
      "train loss:0.0201193735329784\n",
      "train loss:0.009481239453983542\n",
      "train loss:0.01972173830851434\n",
      "train loss:0.026771564429485792\n",
      "train loss:0.008401869130225482\n",
      "train loss:0.01207807712732344\n",
      "train loss:0.011262048199571157\n",
      "train loss:0.027140920626309763\n",
      "train loss:0.025629182794392677\n",
      "train loss:0.018407407123732324\n",
      "train loss:0.036403174368491054\n",
      "train loss:0.012858657364227971\n",
      "train loss:0.01693283020271558\n",
      "train loss:0.022679356220139727\n",
      "train loss:0.02249846637270316\n",
      "train loss:0.009776947176829205\n",
      "train loss:0.011726774839955923\n",
      "train loss:0.01740303640437778\n",
      "train loss:0.025188318496994606\n",
      "train loss:0.016580427658806626\n",
      "train loss:0.016261863887986103\n",
      "train loss:0.00709700273664918\n",
      "train loss:0.031669588586342216\n",
      "train loss:0.01107531925795908\n",
      "train loss:0.02939784543168094\n",
      "train loss:0.027448067914841365\n",
      "train loss:0.02335703329889199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.03000033540531806\n",
      "train loss:0.04388719346368368\n",
      "train loss:0.02282282102585244\n",
      "train loss:0.013911230475709182\n",
      "train loss:0.014969914072792611\n",
      "train loss:0.011427870190929284\n",
      "train loss:0.026554306293711475\n",
      "train loss:0.05066033265359938\n",
      "train loss:0.019484107249087154\n",
      "train loss:0.015052481702492968\n",
      "train loss:0.015344992797242536\n",
      "train loss:0.022967815682986396\n",
      "train loss:0.045297974066752775\n",
      "train loss:0.024071962602570864\n",
      "train loss:0.02390200953322492\n",
      "train loss:0.031936189693890914\n",
      "train loss:0.013089908021264635\n",
      "train loss:0.013930976804412689\n",
      "train loss:0.019031301809630266\n",
      "train loss:0.016642504473129933\n",
      "train loss:0.05348790317045635\n",
      "train loss:0.02479892086211993\n",
      "train loss:0.016015530286496046\n",
      "train loss:0.020658502479986594\n",
      "train loss:0.017286530564572727\n",
      "train loss:0.01631697026878963\n",
      "train loss:0.01594375983079499\n",
      "train loss:0.017304236714478526\n",
      "train loss:0.008253439635224137\n",
      "train loss:0.010416592310148631\n",
      "train loss:0.01721765342361916\n",
      "train loss:0.03799875477717707\n",
      "train loss:0.010648022298381823\n",
      "train loss:0.027792268110663838\n",
      "train loss:0.014052804229953723\n",
      "train loss:0.019027083161281932\n",
      "train loss:0.008724756592709739\n",
      "train loss:0.022691359430499904\n",
      "train loss:0.015137780219907802\n",
      "train loss:0.05467990763627809\n",
      "train loss:0.028160885957731936\n",
      "train loss:0.010943020931580227\n",
      "train loss:0.010870946955458009\n",
      "train loss:0.02348839758925266\n",
      "train loss:0.01816215301754077\n",
      "train loss:0.01866393321590984\n",
      "train loss:0.022889704628260878\n",
      "train loss:0.014776110684078192\n",
      "train loss:0.029937440882534742\n",
      "train loss:0.04250862374463045\n",
      "train loss:0.007409358998498769\n",
      "train loss:0.013132760363425332\n",
      "train loss:0.025600357678998948\n",
      "train loss:0.017094805441749933\n",
      "train loss:0.008445911629712376\n",
      "train loss:0.019463839502861555\n",
      "train loss:0.0539033978846878\n",
      "train loss:0.007451202114201636\n",
      "train loss:0.021470334245356874\n",
      "train loss:0.014286445743876032\n",
      "train loss:0.011872061347558884\n",
      "train loss:0.01696110549000903\n",
      "train loss:0.011377304386150453\n",
      "train loss:0.02165705598292893\n",
      "train loss:0.03223226128318022\n",
      "train loss:0.020109140858934334\n",
      "train loss:0.007482719300318668\n",
      "train loss:0.06026621041762155\n",
      "train loss:0.009736042550452155\n",
      "train loss:0.024669989633863354\n",
      "train loss:0.020961161424414777\n",
      "train loss:0.023932291012234045\n",
      "train loss:0.030321220976075484\n",
      "train loss:0.012614149399902106\n",
      "train loss:0.030018627594278525\n",
      "train loss:0.009545850162912331\n",
      "train loss:0.016026302805563865\n",
      "train loss:0.017543628595018776\n",
      "train loss:0.02164045776798408\n",
      "train loss:0.010020714768984244\n",
      "train loss:0.015857759669894136\n",
      "train loss:0.026789354077109587\n",
      "train loss:0.04627335708588532\n",
      "train loss:0.005724515335725595\n",
      "train loss:0.047322941249483774\n",
      "train loss:0.026446046331567597\n",
      "train loss:0.022551978017958482\n",
      "train loss:0.023844169346433942\n",
      "train loss:0.014381099029672611\n",
      "train loss:0.03837158996523236\n",
      "train loss:0.05021468544256604\n",
      "train loss:0.01078659982788296\n",
      "train loss:0.026670355485487903\n",
      "train loss:0.046624851772133186\n",
      "train loss:0.009645514102454407\n",
      "train loss:0.020154390863757463\n",
      "train loss:0.029491154552416497\n",
      "train loss:0.056560387193209556\n",
      "train loss:0.008732462260422801\n",
      "train loss:0.03488844252298975\n",
      "train loss:0.01153797657708392\n",
      "train loss:0.012532142265096202\n",
      "train loss:0.02510736690470695\n",
      "train loss:0.011318946156673481\n",
      "train loss:0.06308330723310292\n",
      "train loss:0.013477489757444516\n",
      "train loss:0.01740511928465749\n",
      "train loss:0.027245363430942467\n",
      "train loss:0.0190381607815545\n",
      "train loss:0.03157423079628783\n",
      "train loss:0.0243772146215899\n",
      "train loss:0.02030407416072419\n",
      "train loss:0.018177426943152622\n",
      "train loss:0.00786427807282142\n",
      "train loss:0.015351285434598919\n",
      "train loss:0.013269267274586384\n",
      "train loss:0.018494864568456938\n",
      "train loss:0.027258036570359717\n",
      "train loss:0.02167515268107672\n",
      "train loss:0.04201598990000492\n",
      "train loss:0.0038685844977208615\n",
      "train loss:0.019370881666429307\n",
      "train loss:0.010807886974276792\n",
      "train loss:0.03910600518049925\n",
      "train loss:0.024345651998353323\n",
      "train loss:0.01177553469062263\n",
      "train loss:0.02623311600722375\n",
      "train loss:0.025949930185733123\n",
      "train loss:0.009022332149136187\n",
      "train loss:0.037998901188786904\n",
      "train loss:0.01145765820108887\n",
      "train loss:0.07589612290667397\n",
      "train loss:0.02238643746045517\n",
      "train loss:0.02262817915607415\n",
      "train loss:0.027962653948886085\n",
      "train loss:0.002549932803143623\n",
      "train loss:0.030668729507670748\n",
      "train loss:0.020236623184694533\n",
      "train loss:0.01085946201929238\n",
      "train loss:0.013062212045316046\n",
      "train loss:0.02820457124815046\n",
      "train loss:0.013879953254885837\n",
      "train loss:0.020536153835279968\n",
      "train loss:0.009878774975542825\n",
      "train loss:0.041322006639009444\n",
      "train loss:0.0358195330241806\n",
      "train loss:0.09831758522569325\n",
      "train loss:0.006130788139209486\n",
      "train loss:0.02349648438911258\n",
      "train loss:0.03513534665963649\n",
      "train loss:0.024113010581034957\n",
      "train loss:0.01889346360689355\n",
      "train loss:0.023997180387082012\n",
      "train loss:0.010944986186365776\n",
      "train loss:0.02954091142783145\n",
      "train loss:0.012949634656907287\n",
      "train loss:0.040900061231764394\n",
      "train loss:0.009794775850310354\n",
      "train loss:0.01764518702341599\n",
      "train loss:0.059528530743441326\n",
      "train loss:0.0246787047108642\n",
      "train loss:0.02665713814425649\n",
      "train loss:0.013567463299681679\n",
      "train loss:0.00697046713033092\n",
      "train loss:0.038323235916699054\n",
      "train loss:0.04489057986022631\n",
      "train loss:0.028969446153258138\n",
      "train loss:0.05496299580642217\n",
      "train loss:0.051983246128640664\n",
      "train loss:0.048096575149296834\n",
      "train loss:0.05855765056030541\n",
      "train loss:0.02898025141074342\n",
      "train loss:0.019441046922317722\n",
      "train loss:0.0695737085989198\n",
      "train loss:0.031148930682598122\n",
      "train loss:0.06459150138848054\n",
      "train loss:0.01701342272590731\n",
      "train loss:0.06942941135821623\n",
      "train loss:0.017076467375493513\n",
      "train loss:0.04259912647931147\n",
      "train loss:0.023254027520716952\n",
      "train loss:0.021002947261775377\n",
      "train loss:0.06607513986212708\n",
      "train loss:0.04330639485613237\n",
      "train loss:0.010683902070050209\n",
      "train loss:0.02091491825515966\n",
      "train loss:0.04490476549114741\n",
      "train loss:0.013003344496406761\n",
      "train loss:0.0604575282888761\n",
      "train loss:0.039577580809102036\n",
      "train loss:0.017161231994905757\n",
      "train loss:0.009246703279912028\n",
      "train loss:0.02486864801455775\n",
      "train loss:0.01421289497535435\n",
      "=== epoch:30, train acc:0.989, test acc:0.912 ===\n",
      "train loss:0.020342653718296248\n",
      "train loss:0.008236895925144164\n",
      "train loss:0.03855714470992149\n",
      "train loss:0.023164779441290192\n",
      "train loss:0.022909913591924465\n",
      "train loss:0.008645131173191184\n",
      "train loss:0.02123924943246034\n",
      "train loss:0.01579811255535572\n",
      "train loss:0.016024753014214816\n",
      "train loss:0.04584687806859379\n",
      "train loss:0.014537774447070582\n",
      "train loss:0.00889010567946925\n",
      "train loss:0.018852015917804135\n",
      "train loss:0.024698721348378486\n",
      "train loss:0.03072433102918748\n",
      "train loss:0.01089819473651198\n",
      "train loss:0.008521991404205996\n",
      "train loss:0.016587014464038558\n",
      "train loss:0.012725325261657941\n",
      "train loss:0.02934035694106107\n",
      "train loss:0.023393421547229506\n",
      "train loss:0.03276676002169979\n",
      "train loss:0.017010597636574563\n",
      "train loss:0.007301162762650551\n",
      "train loss:0.04346971553147347\n",
      "train loss:0.01855751189181975\n",
      "train loss:0.02627530584834728\n",
      "train loss:0.013903025564654678\n",
      "train loss:0.017583833032105308\n",
      "train loss:0.08237126783386761\n",
      "train loss:0.008946144527669914\n",
      "train loss:0.01618455696562128\n",
      "train loss:0.020120801716924\n",
      "train loss:0.025391585783968443\n",
      "train loss:0.024366335067028816\n",
      "train loss:0.012527788453043026\n",
      "train loss:0.04638029544152392\n",
      "train loss:0.020949756548965647\n",
      "train loss:0.030094407737447187\n",
      "train loss:0.0172549748208555\n",
      "train loss:0.007605489874034837\n",
      "train loss:0.026687231566559107\n",
      "train loss:0.010180766282202047\n",
      "train loss:0.058392915631056995\n",
      "train loss:0.011000964019578972\n",
      "train loss:0.05049428392943225\n",
      "train loss:0.05114839332781683\n",
      "train loss:0.0043615973532560495\n",
      "train loss:0.022771289600121692\n",
      "train loss:0.07903385816234551\n",
      "train loss:0.024844009242881687\n",
      "train loss:0.018386356926329152\n",
      "train loss:0.0496546433470906\n",
      "train loss:0.01497568872745152\n",
      "train loss:0.024359106816764925\n",
      "train loss:0.038988768456210604\n",
      "train loss:0.008021095475108972\n",
      "train loss:0.11268677474088984\n",
      "train loss:0.017071670888555598\n",
      "train loss:0.031155540472696572\n",
      "train loss:0.006278110000201525\n",
      "train loss:0.023036269862549016\n",
      "train loss:0.011620351717054788\n",
      "train loss:0.06611626397269116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.010651017570914996\n",
      "train loss:0.008524775709681173\n",
      "train loss:0.03539358679085393\n",
      "train loss:0.0051774490053002565\n",
      "train loss:0.025674168962455626\n",
      "train loss:0.015512942113714933\n",
      "train loss:0.034747819528554345\n",
      "train loss:0.005097591356226262\n",
      "train loss:0.024965029779992362\n",
      "train loss:0.022468391632753656\n",
      "train loss:0.019754703780123554\n",
      "train loss:0.04074513892097803\n",
      "train loss:0.018105863154891627\n",
      "train loss:0.01519945858358893\n",
      "train loss:0.05826752679014856\n",
      "train loss:0.024444945264268898\n",
      "train loss:0.012131114260147974\n",
      "train loss:0.01697986476112467\n",
      "train loss:0.03959200659582345\n",
      "train loss:0.027427930250876035\n",
      "train loss:0.00936704779583822\n",
      "train loss:0.018444027004355216\n",
      "train loss:0.006813319476742837\n",
      "train loss:0.023526038085419372\n",
      "train loss:0.018503107189631586\n",
      "train loss:0.028835292822447615\n",
      "train loss:0.03348552538742129\n",
      "train loss:0.011739041437683133\n",
      "train loss:0.03644261917880417\n",
      "train loss:0.018011755380133786\n",
      "train loss:0.05910871458180813\n",
      "train loss:0.010518778308625153\n",
      "train loss:0.08391120290395654\n",
      "train loss:0.010087997083410469\n",
      "train loss:0.006692015403427307\n",
      "train loss:0.01350849256366464\n",
      "train loss:0.006107240638491689\n",
      "train loss:0.03216486972873375\n",
      "train loss:0.016339199881073862\n",
      "train loss:0.06930668618501877\n",
      "train loss:0.016511196481233056\n",
      "train loss:0.009806433007285174\n",
      "train loss:0.022743118890178916\n",
      "train loss:0.03168725216052345\n",
      "train loss:0.016832122447365747\n",
      "train loss:0.02079669534624112\n",
      "train loss:0.02917952517531636\n",
      "train loss:0.03669425016061388\n",
      "train loss:0.033891840921916036\n",
      "train loss:0.01816945711496103\n",
      "train loss:0.004084383282212709\n",
      "train loss:0.045532865698290924\n",
      "train loss:0.03971591893683407\n",
      "train loss:0.004550647605593774\n",
      "train loss:0.009779388648914812\n",
      "train loss:0.01598384405884059\n",
      "train loss:0.018580647504623488\n",
      "train loss:0.008117197935101407\n",
      "train loss:0.009266611182431427\n",
      "train loss:0.006429616015693226\n",
      "train loss:0.042217357896670096\n",
      "train loss:0.01563997866714757\n",
      "train loss:0.035795997738119596\n",
      "train loss:0.031727105939013865\n",
      "train loss:0.015146692673249447\n",
      "train loss:0.00907300219448683\n",
      "train loss:0.021538012927735314\n",
      "train loss:0.025556008553339917\n",
      "train loss:0.007115384410608613\n",
      "train loss:0.035706852374406496\n",
      "train loss:0.008107295591360445\n",
      "train loss:0.022228000098070737\n",
      "train loss:0.012314508502449396\n",
      "train loss:0.028641695269913385\n",
      "train loss:0.016999271133339558\n",
      "train loss:0.013182171021875513\n",
      "train loss:0.023542628535451256\n",
      "train loss:0.005806605287092769\n",
      "train loss:0.014823800542378095\n",
      "train loss:0.010922005637503104\n",
      "train loss:0.026157294710011502\n",
      "train loss:0.02210707283379655\n",
      "train loss:0.008247265625329863\n",
      "train loss:0.011403806104223736\n",
      "train loss:0.015332264339431197\n",
      "train loss:0.012308022227237203\n",
      "train loss:0.010217802124901688\n",
      "train loss:0.0625757545921604\n",
      "train loss:0.010959058747577119\n",
      "train loss:0.00829994706451336\n",
      "train loss:0.005494322056220567\n",
      "train loss:0.018429350056681035\n",
      "train loss:0.010519879691799485\n",
      "train loss:0.009285707508212108\n",
      "train loss:0.00935916524094698\n",
      "train loss:0.019323990181584615\n",
      "train loss:0.04833033854270239\n",
      "train loss:0.011599099772988553\n",
      "train loss:0.004441151727595918\n",
      "train loss:0.017446230321693068\n",
      "train loss:0.014082998280149186\n",
      "train loss:0.05917342303106677\n",
      "train loss:0.011573938643472415\n",
      "train loss:0.02270019137244014\n",
      "train loss:0.025073612712592803\n",
      "train loss:0.004636255788816293\n",
      "train loss:0.009083394486163942\n",
      "train loss:0.03741156912370518\n",
      "train loss:0.02470971816726009\n",
      "train loss:0.01132703410700442\n",
      "train loss:0.025753326050828352\n",
      "train loss:0.010923335361989119\n",
      "train loss:0.007830140948839437\n",
      "train loss:0.01365788345216167\n",
      "train loss:0.05344649451198384\n",
      "train loss:0.03116644378664855\n",
      "train loss:0.07904014016143175\n",
      "train loss:0.011772505050996746\n",
      "train loss:0.02010502729800506\n",
      "train loss:0.03688670672415842\n",
      "train loss:0.03559364011381739\n",
      "train loss:0.014138229485234728\n",
      "train loss:0.036012711329374704\n",
      "train loss:0.006890849242729747\n",
      "train loss:0.008831208694768522\n",
      "train loss:0.026514823779458786\n",
      "train loss:0.024514313146197595\n",
      "train loss:0.017833457260286994\n",
      "train loss:0.029701518217516463\n",
      "train loss:0.03646146088499087\n",
      "train loss:0.0343643232134615\n",
      "train loss:0.007613152760844252\n",
      "train loss:0.012867413478534772\n",
      "train loss:0.012272288419521804\n",
      "train loss:0.019901708678320147\n",
      "train loss:0.00834372415461559\n",
      "train loss:0.013263923833430941\n",
      "train loss:0.011998018283544389\n",
      "train loss:0.023865101235615704\n",
      "train loss:0.009378897623880306\n",
      "train loss:0.015303273945983173\n",
      "train loss:0.017258615787860664\n",
      "train loss:0.008094404173269048\n",
      "train loss:0.015955557964079707\n",
      "train loss:0.007251674932406403\n",
      "train loss:0.010164915112801353\n",
      "train loss:0.04899974412321706\n",
      "train loss:0.03510459824046604\n",
      "train loss:0.028639094158335404\n",
      "train loss:0.0034601661180040637\n",
      "train loss:0.012737419572426682\n",
      "train loss:0.009696329410440806\n",
      "train loss:0.008848612018605395\n",
      "train loss:0.013938464948936205\n",
      "train loss:0.023173862856768104\n",
      "train loss:0.04132438965142357\n",
      "train loss:0.012308316029112323\n",
      "train loss:0.05139350278481771\n",
      "train loss:0.006544418645270573\n",
      "train loss:0.057645838923357166\n",
      "train loss:0.013247975411358052\n",
      "train loss:0.019088967567421497\n",
      "train loss:0.02812910245043942\n",
      "train loss:0.014803155550013478\n",
      "train loss:0.02906823495611925\n",
      "train loss:0.013364368937503817\n",
      "train loss:0.005763877707861886\n",
      "train loss:0.02122895291350131\n",
      "train loss:0.013315517111983201\n",
      "train loss:0.051922285530459744\n",
      "train loss:0.006666273758445615\n",
      "train loss:0.022516423234883277\n",
      "train loss:0.02655058021868206\n",
      "train loss:0.04205992265940242\n",
      "train loss:0.01320422599614345\n",
      "train loss:0.027791787558573207\n",
      "train loss:0.06518064374837544\n",
      "train loss:0.016313947728825814\n",
      "train loss:0.032765090466718924\n",
      "train loss:0.02151709394097361\n",
      "train loss:0.013731483513252336\n",
      "train loss:0.013600838478652465\n",
      "train loss:0.02343915239467595\n",
      "train loss:0.028042426112546922\n",
      "train loss:0.03735292174574964\n",
      "train loss:0.03442667247877088\n",
      "train loss:0.035121095893017464\n",
      "train loss:0.05752931535292973\n",
      "train loss:0.013651862898326617\n",
      "train loss:0.02385032256899541\n",
      "train loss:0.008302339746461352\n",
      "train loss:0.021533673047009518\n",
      "train loss:0.049433929104693755\n",
      "train loss:0.018694729949218246\n",
      "train loss:0.016551101443795554\n",
      "train loss:0.029737798528130476\n",
      "train loss:0.017005860855702437\n",
      "train loss:0.010854437893921643\n",
      "train loss:0.012223875745158437\n",
      "train loss:0.02301520120482268\n",
      "train loss:0.023692232527501016\n",
      "train loss:0.04520179617043011\n",
      "train loss:0.010770589214090666\n",
      "train loss:0.011907414929512073\n",
      "train loss:0.026034731929893504\n",
      "train loss:0.0086481809128573\n",
      "train loss:0.018839122743932672\n",
      "train loss:0.03382180784379221\n",
      "train loss:0.03839069767318511\n",
      "train loss:0.012443912935816653\n",
      "train loss:0.011206017263783771\n",
      "train loss:0.02749545996941229\n",
      "train loss:0.019378863094197295\n",
      "train loss:0.017139413501319967\n",
      "train loss:0.016254750323029813\n",
      "train loss:0.008629600432650663\n",
      "train loss:0.04731993543194183\n",
      "train loss:0.024541707992862313\n",
      "train loss:0.05691217145857985\n",
      "train loss:0.04387344323769631\n",
      "train loss:0.056030355786668117\n",
      "train loss:0.030991736938032338\n",
      "train loss:0.02047484467747675\n",
      "train loss:0.022856995899043622\n",
      "train loss:0.021252047206504074\n",
      "train loss:0.02637068929471782\n",
      "train loss:0.021260615680175426\n",
      "train loss:0.017077740155129573\n",
      "train loss:0.021751377372786776\n",
      "train loss:0.02344016282655795\n",
      "train loss:0.007354665570083557\n",
      "train loss:0.023900104027678566\n",
      "train loss:0.02161145716393601\n",
      "train loss:0.009070739282894614\n",
      "train loss:0.009510913192557625\n",
      "train loss:0.05959235322721347\n",
      "train loss:0.01036999478267901\n",
      "train loss:0.024222709187492916\n",
      "train loss:0.019446776446629635\n",
      "train loss:0.015354042057899513\n",
      "train loss:0.021978878745086132\n",
      "train loss:0.009013664859845642\n",
      "train loss:0.02250691344447009\n",
      "train loss:0.013832285783921936\n",
      "train loss:0.029734700660892264\n",
      "train loss:0.032034039800689994\n",
      "train loss:0.01323357471457854\n",
      "train loss:0.05452963956470258\n",
      "train loss:0.010759839036321517\n",
      "train loss:0.028123884815704124\n",
      "train loss:0.02171270427637996\n",
      "train loss:0.029388345190870416\n",
      "train loss:0.0234250169211645\n",
      "train loss:0.03177369344828294\n",
      "train loss:0.015990393655107113\n",
      "train loss:0.0501437980627741\n",
      "train loss:0.02983512225014043\n",
      "train loss:0.01940461426293805\n",
      "train loss:0.03842607676521107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.020748609378153978\n",
      "train loss:0.02635966408741015\n",
      "train loss:0.047499104355462514\n",
      "train loss:0.006363578019612353\n",
      "train loss:0.05858480877794348\n",
      "train loss:0.04821992454276236\n",
      "train loss:0.030775186207456166\n",
      "train loss:0.039113268629697835\n",
      "train loss:0.011277147313895232\n",
      "train loss:0.028893033064921556\n",
      "train loss:0.009390846737269648\n",
      "train loss:0.051053697126185786\n",
      "train loss:0.018547894747432334\n",
      "train loss:0.026012826632769662\n",
      "train loss:0.01937024279654841\n",
      "train loss:0.04890358087371724\n",
      "train loss:0.017194893231079967\n",
      "train loss:0.00840270883158042\n",
      "train loss:0.0417402268803062\n",
      "train loss:0.011798869593055745\n",
      "train loss:0.06802903456512652\n",
      "train loss:0.05602785829639293\n",
      "train loss:0.021677212405352076\n",
      "train loss:0.022784002382267583\n",
      "train loss:0.03485767549692889\n",
      "train loss:0.04037025012636808\n",
      "train loss:0.020928698388135394\n",
      "train loss:0.018247630196346388\n",
      "train loss:0.011147044964895679\n",
      "train loss:0.022249010426389063\n",
      "train loss:0.012829012397733305\n",
      "train loss:0.01966409594048753\n",
      "train loss:0.022819358841465992\n",
      "train loss:0.008953097027826769\n",
      "train loss:0.028275378204337242\n",
      "train loss:0.05674705848233933\n",
      "train loss:0.029270626846847402\n",
      "train loss:0.03555944824958577\n",
      "train loss:0.017838688003056012\n",
      "train loss:0.011006181984779942\n",
      "train loss:0.01557857349844739\n",
      "train loss:0.010952713207226784\n",
      "train loss:0.010457647299392265\n",
      "train loss:0.01999965550583528\n",
      "train loss:0.08783671881708868\n",
      "train loss:0.020119285620014398\n",
      "train loss:0.011561135896728508\n",
      "train loss:0.02881889962565459\n",
      "train loss:0.0212418195719901\n",
      "train loss:0.03779630714368405\n",
      "train loss:0.025385422263367666\n",
      "train loss:0.036329219870346076\n",
      "train loss:0.0218560355792413\n",
      "train loss:0.058281788434381455\n",
      "train loss:0.008716264123542424\n",
      "train loss:0.03046881825706617\n",
      "train loss:0.03643031134822208\n",
      "train loss:0.04060752683526668\n",
      "train loss:0.015051463134917599\n",
      "train loss:0.02225810297144068\n",
      "train loss:0.013395045908669183\n",
      "train loss:0.014223850388140996\n",
      "train loss:0.020396960551348795\n",
      "train loss:0.010237203956823515\n",
      "train loss:0.028594928823880594\n",
      "train loss:0.03594428114981715\n",
      "train loss:0.011502891162185518\n",
      "train loss:0.023525573443011313\n",
      "train loss:0.005665680104450149\n",
      "train loss:0.03327078546542658\n",
      "train loss:0.04949472906455872\n",
      "train loss:0.013256737290943408\n",
      "train loss:0.02940265750584069\n",
      "train loss:0.014296350020582495\n",
      "train loss:0.022674328523961562\n",
      "train loss:0.01024999662024396\n",
      "train loss:0.03630563396332941\n",
      "train loss:0.010208999218430583\n",
      "train loss:0.043623295918176784\n",
      "train loss:0.010873971404150222\n",
      "train loss:0.03924940294520773\n",
      "train loss:0.0038789642330088457\n",
      "train loss:0.033417097147967166\n",
      "train loss:0.016940479000272353\n",
      "train loss:0.025712836301953493\n",
      "train loss:0.025940215936960057\n",
      "train loss:0.019996003562732102\n",
      "train loss:0.014050868880226434\n",
      "train loss:0.01709274403063693\n",
      "train loss:0.04584165534763408\n",
      "train loss:0.009888712226277739\n",
      "train loss:0.01547164261854919\n",
      "train loss:0.016232383833476003\n",
      "train loss:0.018435085425167773\n",
      "train loss:0.03107804371154455\n",
      "train loss:0.02340149656500012\n",
      "train loss:0.011778038364938537\n",
      "train loss:0.03327043811221627\n",
      "train loss:0.024366354175869152\n",
      "train loss:0.008716599493945725\n",
      "train loss:0.03415625238600915\n",
      "train loss:0.013406487765940986\n",
      "train loss:0.04341965889213727\n",
      "train loss:0.0052385096340652046\n",
      "train loss:0.0366524162774296\n",
      "train loss:0.034470345929922805\n",
      "train loss:0.011636874321582526\n",
      "train loss:0.02072608148403192\n",
      "train loss:0.014117678789042909\n",
      "train loss:0.029502443937250666\n",
      "train loss:0.018954020966844908\n",
      "train loss:0.06987312298059929\n",
      "train loss:0.00965457027828614\n",
      "train loss:0.01634689197034846\n",
      "train loss:0.08219628060206013\n",
      "train loss:0.03263664031816657\n",
      "train loss:0.03280428693864495\n",
      "train loss:0.011915552935552633\n",
      "train loss:0.007139907995871393\n",
      "train loss:0.017205085692463\n",
      "train loss:0.014722801591872215\n",
      "train loss:0.020483389169460443\n",
      "train loss:0.012467982324227196\n",
      "train loss:0.016028337565101212\n",
      "train loss:0.017305210419556082\n",
      "train loss:0.019095494181470565\n",
      "train loss:0.02837430397010642\n",
      "train loss:0.015554485115842431\n",
      "train loss:0.01798092888853005\n",
      "train loss:0.03160822786430207\n",
      "train loss:0.007944715860655458\n",
      "train loss:0.040064346759789225\n",
      "train loss:0.028876120960443043\n",
      "train loss:0.013822585622120766\n",
      "train loss:0.017398584950962758\n",
      "train loss:0.0301341278243557\n",
      "train loss:0.022650146814063993\n",
      "train loss:0.026403122976250793\n",
      "train loss:0.034756738594154055\n",
      "train loss:0.020464775759790433\n",
      "train loss:0.005992125063365058\n",
      "train loss:0.017713192151365485\n",
      "train loss:0.007252284908257149\n",
      "train loss:0.008795799687951439\n",
      "train loss:0.028495633906473784\n",
      "train loss:0.0429458358296993\n",
      "train loss:0.03052668961789054\n",
      "train loss:0.02620911074201593\n",
      "train loss:0.012782156384801693\n",
      "train loss:0.00861434282898776\n",
      "train loss:0.04667321107684419\n",
      "train loss:0.045368722515859605\n",
      "train loss:0.025663423296501713\n",
      "train loss:0.012891927849137216\n",
      "train loss:0.020860897975868774\n",
      "train loss:0.017482607059496304\n",
      "train loss:0.02098772820418839\n",
      "train loss:0.01644358874281402\n",
      "train loss:0.02552661427665678\n",
      "train loss:0.050601498565437934\n",
      "train loss:0.03173053971911174\n",
      "train loss:0.04845291942357711\n",
      "train loss:0.012725328764513228\n",
      "train loss:0.030159376487628488\n",
      "train loss:0.009790983683109059\n",
      "train loss:0.016812670162275875\n",
      "train loss:0.009222992271781033\n",
      "train loss:0.011788724480951219\n",
      "train loss:0.02590579130921749\n",
      "train loss:0.022147067265026757\n",
      "train loss:0.006514048230904382\n",
      "train loss:0.037517952317928344\n",
      "train loss:0.011640082256061135\n",
      "train loss:0.015606666707392261\n",
      "train loss:0.06155994306628667\n",
      "train loss:0.022350862929644954\n",
      "train loss:0.022191516456138073\n",
      "train loss:0.011287689974228214\n",
      "train loss:0.012644683328023702\n",
      "train loss:0.0032781227631956465\n",
      "train loss:0.02823428135067667\n",
      "train loss:0.032755091255454526\n",
      "train loss:0.012858489072061502\n",
      "train loss:0.01905924686411835\n",
      "train loss:0.02024915178391435\n",
      "train loss:0.020746027583538728\n",
      "train loss:0.016774847583797832\n",
      "train loss:0.058739750495287665\n",
      "train loss:0.044536149685530005\n",
      "train loss:0.026261784876861503\n",
      "train loss:0.02707560918257811\n",
      "train loss:0.03023368826748286\n",
      "train loss:0.01918513557852634\n",
      "train loss:0.0253158962083153\n",
      "train loss:0.02838374271209894\n",
      "train loss:0.03936765308688197\n",
      "train loss:0.04345568675727944\n",
      "train loss:0.01058155667375867\n",
      "train loss:0.0071274581855028775\n",
      "train loss:0.016966902260359108\n",
      "train loss:0.008787766373036118\n",
      "train loss:0.026143095818909133\n",
      "train loss:0.020705670669452125\n",
      "train loss:0.0178029955114409\n",
      "train loss:0.006049282688996555\n",
      "train loss:0.006039942501367273\n",
      "train loss:0.03062016691589134\n",
      "train loss:0.016565531827761815\n",
      "train loss:0.021183966588238467\n",
      "train loss:0.009598863708734036\n",
      "train loss:0.01451674046928074\n",
      "train loss:0.011721609505860575\n",
      "train loss:0.019360287437702867\n",
      "train loss:0.022498985939075903\n",
      "train loss:0.0255920456537464\n",
      "train loss:0.05469935621702526\n",
      "train loss:0.021589474155283662\n",
      "train loss:0.026401965779475532\n",
      "train loss:0.01769614442694368\n",
      "train loss:0.0258518379994909\n",
      "train loss:0.027235987246228128\n",
      "train loss:0.028650557049016662\n",
      "train loss:0.020882731402329012\n",
      "train loss:0.061402458056137366\n",
      "train loss:0.006639299038544057\n",
      "train loss:0.01697218006252471\n",
      "train loss:0.035288867746136196\n",
      "train loss:0.0462594087018266\n",
      "train loss:0.009113841129478526\n",
      "train loss:0.0241650035492363\n",
      "train loss:0.006441799285255943\n",
      "train loss:0.009672447851845708\n",
      "train loss:0.058374034854737536\n",
      "train loss:0.023767747936572773\n",
      "train loss:0.022136917712526377\n",
      "train loss:0.01242620959613388\n",
      "train loss:0.015577612967146555\n",
      "train loss:0.025497290866109593\n",
      "train loss:0.03575586791127614\n",
      "train loss:0.022445251857198686\n",
      "train loss:0.02884456551152424\n",
      "train loss:0.006363903749788084\n",
      "train loss:0.015122864922685317\n",
      "train loss:0.02615804518699844\n",
      "train loss:0.027719974913457682\n",
      "train loss:0.018092112938264654\n",
      "train loss:0.06230653164751995\n",
      "train loss:0.011539882960096857\n",
      "train loss:0.006322165662943693\n",
      "train loss:0.045068957218888824\n",
      "train loss:0.009472838963066076\n",
      "train loss:0.028640133344858053\n",
      "train loss:0.03143498633129574\n",
      "train loss:0.005292842505842942\n",
      "train loss:0.01624998854339425\n",
      "train loss:0.011785779485978745\n",
      "train loss:0.03720671558861308\n",
      "train loss:0.023883917866603706\n",
      "train loss:0.04441049492777713\n",
      "train loss:0.01760503491697372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.05910841303291555\n",
      "train loss:0.01977336980460844\n",
      "train loss:0.011077213349288535\n",
      "train loss:0.005053192613951982\n",
      "train loss:0.008815772157278334\n",
      "train loss:0.03872481595006618\n",
      "train loss:0.014120907924855517\n",
      "train loss:0.03436184628598015\n",
      "train loss:0.015411335160718733\n",
      "train loss:0.01455109780454521\n",
      "train loss:0.003701544533718941\n",
      "train loss:0.021262346246113624\n",
      "train loss:0.0047053591001658375\n",
      "train loss:0.01725826801411986\n",
      "train loss:0.017943019873282295\n",
      "train loss:0.024618421376137657\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.9116train acc :0.9891166666666666\n",
      "Saved Network Parameters!\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "from common.trainer import Trainer\n",
    "\n",
    "# 데이터 읽기\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "# 시간이 오래 걸릴 경우 데이터를 줄인다.\n",
    "#x_train, t_train = x_train[:5000], t_train[:5000]\n",
    "#x_test, t_test = x_test[:1000], t_test[:1000]\n",
    "\n",
    "max_epochs = 30\n",
    "\n",
    "network = SimpleConvNet(input_dim=(1,28,28), \n",
    "                        conv_param = {'filter_num': 30, 'filter_size': 5, 'pad': 0, 'stride': 1},\n",
    "                        hidden_size=100, output_size=10, weight_init_std=0.01)\n",
    "                        \n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=max_epochs, mini_batch_size=100,\n",
    "                  optimizer='Adam', optimizer_param={'lr': 0.001},\n",
    "                  evaluate_sample_num_per_epoch=1000)\n",
    "trainer.train()\n",
    "\n",
    "# 매개변수 보존\n",
    "network.save_params(\"params.pkl\")\n",
    "print(\"Saved Network Parameters!\")\n",
    "\n",
    "# 그래프 그리기\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(max_epochs)\n",
    "plt.plot(x, trainer.train_acc_list, marker='o', label='train', markevery=2)\n",
    "plt.plot(x, trainer.test_acc_list, marker='s', label='test', markevery=2)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087b4a9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
