{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40ea6e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import pickle\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from common.layers import *\n",
    "from common.gradient import numerical_gradient\n",
    "\n",
    "\n",
    "class SimpleConvNet:\n",
    "    \n",
    "    def __init__(self, input_dim=(1, 28, 28), \n",
    "                 conv_param={'filter_num':30, 'filter_size':5, 'pad':0, 'stride':1},\n",
    "                 hidden_size=100, output_size=10, weight_init_std=0.01):\n",
    "        filter_num = conv_param['filter_num']\n",
    "        filter_size = conv_param['filter_size']\n",
    "        filter_pad = conv_param['pad']\n",
    "        filter_stride = conv_param['stride']\n",
    "        input_size = input_dim[1]\n",
    "        conv_output_size = (input_size - filter_size + 2*filter_pad) / filter_stride + 1\n",
    "        pool_output_size = int(filter_num * (conv_output_size/2) * (conv_output_size/2))\n",
    "\n",
    "        # 가중치 초기화\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * \\\n",
    "                            np.random.randn(filter_num, input_dim[0], filter_size, filter_size)\n",
    "        self.params['b1'] = np.zeros(filter_num)\n",
    "        self.params['W2'] = weight_init_std * \\\n",
    "                            np.random.randn(pool_output_size, hidden_size)\n",
    "        self.params['b2'] = np.zeros(hidden_size)\n",
    "        self.params['W3'] = weight_init_std * \\\n",
    "                            np.random.randn(hidden_size, output_size)\n",
    "        self.params['b3'] = np.zeros(output_size)\n",
    "\n",
    "        # 계층 생성\n",
    "        self.layers = OrderedDict()\n",
    "        self.layers['Conv1'] = Convolution(self.params['W1'], self.params['b1'],\n",
    "                                           conv_param['stride'], conv_param['pad'])\n",
    "        self.layers['Relu1'] = Relu()\n",
    "        self.layers['Pool1'] = Pooling(pool_h=2, pool_w=2, stride=2)\n",
    "        self.layers['Affine1'] = Affine(self.params['W2'], self.params['b2'])\n",
    "        self.layers['Relu2'] = Relu()\n",
    "        self.layers['Affine2'] = Affine(self.params['W3'], self.params['b3'])\n",
    "\n",
    "        self.last_layer = SoftmaxWithLoss()\n",
    "\n",
    "    def predict(self, x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def loss(self, x, t):\n",
    "         \n",
    "         \n",
    "        y = self.predict(x)\n",
    "        return self.last_layer.forward(y, t)\n",
    "\n",
    "    def accuracy(self, x, t, batch_size=100):\n",
    "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
    "        \n",
    "        acc = 0.0\n",
    "        \n",
    "        for i in range(int(x.shape[0] / batch_size)):\n",
    "            tx = x[i*batch_size:(i+1)*batch_size]\n",
    "            tt = t[i*batch_size:(i+1)*batch_size]\n",
    "            y = self.predict(tx)\n",
    "            y = np.argmax(y, axis=1)\n",
    "            acc += np.sum(y == tt) \n",
    "        \n",
    "        return acc / x.shape[0]\n",
    "\n",
    "    def numerical_gradient(self, x, t):\n",
    "         \n",
    "        loss_w = lambda w: self.loss(x, t)\n",
    "\n",
    "        grads = {}\n",
    "        for idx in (1, 2, 3):\n",
    "            grads['W' + str(idx)] = numerical_gradient(loss_w, self.params['W' + str(idx)])\n",
    "            grads['b' + str(idx)] = numerical_gradient(loss_w, self.params['b' + str(idx)])\n",
    "\n",
    "        return grads\n",
    "\n",
    "    def gradient(self, x, t):\n",
    "        \n",
    "        # forward\n",
    "        self.loss(x, t)\n",
    "\n",
    "        # backward\n",
    "        dout = 1\n",
    "        dout = self.last_layer.backward(dout)\n",
    "\n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "\n",
    "        # 결과 저장\n",
    "        grads = {}\n",
    "        grads['W1'], grads['b1'] = self.layers['Conv1'].dW, self.layers['Conv1'].db\n",
    "        grads['W2'], grads['b2'] = self.layers['Affine1'].dW, self.layers['Affine1'].db\n",
    "        grads['W3'], grads['b3'] = self.layers['Affine2'].dW, self.layers['Affine2'].db\n",
    "\n",
    "        return grads\n",
    "        \n",
    "    def save_params(self, file_name=\"params.pkl\"):\n",
    "        params = {}\n",
    "        for key, val in self.params.items():\n",
    "            params[key] = val\n",
    "        with open(file_name, 'wb') as f:\n",
    "            pickle.dump(params, f)\n",
    "\n",
    "    def load_params(self, file_name=\"params.pkl\"):\n",
    "        with open(file_name, 'rb') as f:\n",
    "            params = pickle.load(f)\n",
    "        for key, val in params.items():\n",
    "            self.params[key] = val\n",
    "\n",
    "        for i, key in enumerate(['Conv1', 'Affine1', 'Affine2']):\n",
    "            self.layers[key].W = self.params['W' + str(i+1)]\n",
    "            self.layers[key].b = self.params['b' + str(i+1)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45d98e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.2993359634467354\n",
      "=== epoch:1, train acc:0.202, test acc:0.194 ===\n",
      "train loss:2.2950504059080816\n",
      "train loss:2.2879452929391944\n",
      "train loss:2.2834175573728275\n",
      "train loss:2.2702740068591147\n",
      "train loss:2.249655412002217\n",
      "train loss:2.2209535626797794\n",
      "train loss:2.2082028993977945\n",
      "train loss:2.1742078551285626\n",
      "train loss:2.1004660202016168\n",
      "train loss:2.069632017459008\n",
      "train loss:2.005400775405022\n",
      "train loss:1.934300550120697\n",
      "train loss:1.860894357302292\n",
      "train loss:1.818035449852388\n",
      "train loss:1.712880255971796\n",
      "train loss:1.6453798729510782\n",
      "train loss:1.4918764459411835\n",
      "train loss:1.4477165601338595\n",
      "train loss:1.3585683611098338\n",
      "train loss:1.3712254869578784\n",
      "train loss:1.3859787506354582\n",
      "train loss:1.2792802627006212\n",
      "train loss:1.1904202286961465\n",
      "train loss:1.0400064403583453\n",
      "train loss:1.1727172512255823\n",
      "train loss:1.1692851964087014\n",
      "train loss:0.9917471578733053\n",
      "train loss:1.1670310265145425\n",
      "train loss:1.2141866489255884\n",
      "train loss:1.1875560268094594\n",
      "train loss:0.931308174292541\n",
      "train loss:1.1129014368592578\n",
      "train loss:1.1025008671347256\n",
      "train loss:0.908567943231078\n",
      "train loss:0.7896566549119002\n",
      "train loss:0.8582038371086397\n",
      "train loss:0.9760721468828659\n",
      "train loss:1.090517986620386\n",
      "train loss:0.9358464061064201\n",
      "train loss:1.028777249852592\n",
      "train loss:0.9038726551280887\n",
      "train loss:1.0224847032125433\n",
      "train loss:0.7859865533145942\n",
      "train loss:0.777390492222157\n",
      "train loss:0.7605813078611612\n",
      "train loss:1.0900156550303142\n",
      "train loss:0.8082991479768685\n",
      "train loss:0.8263286611880518\n",
      "train loss:0.84763039796574\n",
      "train loss:0.7816529827155726\n",
      "train loss:0.8062231290226886\n",
      "train loss:0.9898182704192032\n",
      "train loss:0.9021427626184387\n",
      "train loss:0.7706832876095052\n",
      "train loss:0.7190486281734462\n",
      "train loss:0.9109898269292803\n",
      "train loss:0.8332034257803401\n",
      "train loss:0.9089628967510567\n",
      "train loss:0.8298788041761633\n",
      "train loss:0.9132319467117085\n",
      "train loss:0.8600469982430314\n",
      "train loss:0.8392877599537869\n",
      "train loss:0.7718516879927705\n",
      "train loss:0.8794800735095116\n",
      "train loss:0.8543964793833924\n",
      "train loss:0.8845199845553973\n",
      "train loss:0.8717761624394764\n",
      "train loss:0.7193522564676885\n",
      "train loss:0.9507539790814384\n",
      "train loss:0.743694045363672\n",
      "train loss:0.743177525102034\n",
      "train loss:0.70786979070205\n",
      "train loss:0.7051800362710833\n",
      "train loss:0.5977938113965139\n",
      "train loss:0.8468391070887945\n",
      "train loss:0.7120224386883198\n",
      "train loss:0.8437492240882973\n",
      "train loss:0.6534252656789598\n",
      "train loss:0.5479927429881322\n",
      "train loss:0.8709818944867459\n",
      "train loss:0.7463358282942774\n",
      "train loss:0.7319851659122775\n",
      "train loss:0.8404010563678297\n",
      "train loss:0.7738912399691306\n",
      "train loss:0.7268616884812091\n",
      "train loss:0.7500085968779507\n",
      "train loss:0.6311204225107953\n",
      "train loss:0.6688385664197152\n",
      "train loss:0.6732928061747326\n",
      "train loss:0.7394713466755105\n",
      "train loss:0.7568220122199675\n",
      "train loss:0.7392448547611356\n",
      "train loss:0.5656685688837687\n",
      "train loss:0.8507699254698291\n",
      "train loss:0.7762181197650706\n",
      "train loss:0.6586620707322958\n",
      "train loss:0.6880141109316723\n",
      "train loss:0.913285068111469\n",
      "train loss:0.7697080955179557\n",
      "train loss:0.7676717118027824\n",
      "train loss:0.9344253855250583\n",
      "train loss:0.7465727676010342\n",
      "train loss:0.706675038054471\n",
      "train loss:0.6451519495755039\n",
      "train loss:0.7362754184822518\n",
      "train loss:0.6423129184816699\n",
      "train loss:0.6814831638488154\n",
      "train loss:0.8365663486664944\n",
      "train loss:0.6289641230906386\n",
      "train loss:0.8454489071193108\n",
      "train loss:0.6238109950233123\n",
      "train loss:0.691265826069607\n",
      "train loss:0.6631588797560677\n",
      "train loss:0.6483836999489913\n",
      "train loss:0.7440008525825571\n",
      "train loss:0.6241459350356495\n",
      "train loss:0.7386098240655942\n",
      "train loss:0.7340683714377505\n",
      "train loss:0.687301651160538\n",
      "train loss:0.6567658351601772\n",
      "train loss:0.5864679249891226\n",
      "train loss:0.7138880388376996\n",
      "train loss:0.6714458180415218\n",
      "train loss:0.5908323881229066\n",
      "train loss:0.5596575118972312\n",
      "train loss:0.6724042043900238\n",
      "train loss:0.591301471785086\n",
      "train loss:0.7445874234828156\n",
      "train loss:0.879861351694537\n",
      "train loss:0.6833124330103051\n",
      "train loss:0.7062854888791504\n",
      "train loss:0.8116391578327518\n",
      "train loss:0.671112992384129\n",
      "train loss:0.6674741472546823\n",
      "train loss:0.7444495130745886\n",
      "train loss:0.7870693644979057\n",
      "train loss:0.6084953908798362\n",
      "train loss:0.7689935142202445\n",
      "train loss:0.7167341557841904\n",
      "train loss:0.4843955943407816\n",
      "train loss:0.969991422236561\n",
      "train loss:0.5984195118777381\n",
      "train loss:0.5737008944809205\n",
      "train loss:0.7045213763370485\n",
      "train loss:0.6037632732579545\n",
      "train loss:0.6974408825749352\n",
      "train loss:0.7561692232190712\n",
      "train loss:0.6457030052393107\n",
      "train loss:0.7181171112971587\n",
      "train loss:0.6471863149240399\n",
      "train loss:0.6393969641415561\n",
      "train loss:0.5734323245978533\n",
      "train loss:0.7296757964842324\n",
      "train loss:0.9127690267979741\n",
      "train loss:0.6040096674645817\n",
      "train loss:0.54985946930756\n",
      "train loss:0.6122873085563991\n",
      "train loss:0.6293153216305927\n",
      "train loss:0.6046226925276925\n",
      "train loss:0.6345039676167181\n",
      "train loss:0.71278182385531\n",
      "train loss:0.8004994041404777\n",
      "train loss:0.5601879416900944\n",
      "train loss:0.6590336332008023\n",
      "train loss:0.6404022602605823\n",
      "train loss:0.6535179911513227\n",
      "train loss:0.538783671560637\n",
      "train loss:0.6203730461830507\n",
      "train loss:0.6478838044888753\n",
      "train loss:0.6594129239111635\n",
      "train loss:0.5509603101265357\n",
      "train loss:0.6426765888461611\n",
      "train loss:0.5291025070973696\n",
      "train loss:0.5503306287705829\n",
      "train loss:0.5662116022890857\n",
      "train loss:0.6032342631071471\n",
      "train loss:0.5806555833517468\n",
      "train loss:0.6944968182753304\n",
      "train loss:0.7608301996779716\n",
      "train loss:0.66995696378155\n",
      "train loss:0.5603076780114319\n",
      "train loss:0.8113412572248717\n",
      "train loss:0.6216563739476197\n",
      "train loss:0.5938077278554051\n",
      "train loss:0.5053328961129006\n",
      "train loss:0.6170840449132023\n",
      "train loss:0.4818968225543189\n",
      "train loss:0.608694221983693\n",
      "train loss:0.6022236523008808\n",
      "train loss:0.5543159640450411\n",
      "train loss:0.4885947771314169\n",
      "train loss:0.5366764304212494\n",
      "train loss:0.6909232379790059\n",
      "train loss:0.5503021754661023\n",
      "train loss:0.6185662627633128\n",
      "train loss:0.6976276658606753\n",
      "train loss:0.6181814471669017\n",
      "train loss:0.5116440278902604\n",
      "train loss:0.4759140395296548\n",
      "train loss:0.5940642924949961\n",
      "train loss:0.5936388103684918\n",
      "train loss:0.5939373790024651\n",
      "train loss:0.6417071854875376\n",
      "train loss:0.6787310203433075\n",
      "train loss:0.7352624417869431\n",
      "train loss:0.5253605638637595\n",
      "train loss:0.6447147852823698\n",
      "train loss:0.46819318700238166\n",
      "train loss:0.6181522894544621\n",
      "train loss:0.5365707018441088\n",
      "train loss:0.5149481002867974\n",
      "train loss:0.7016264575115011\n",
      "train loss:0.6872910521139284\n",
      "train loss:0.6292804795772932\n",
      "train loss:0.5689841231562675\n",
      "train loss:0.4754793079501504\n",
      "train loss:0.6350448607171956\n",
      "train loss:0.5194463619394192\n",
      "train loss:0.5183833334768378\n",
      "train loss:0.6782596736639742\n",
      "train loss:0.679100629043642\n",
      "train loss:0.7332916263153858\n",
      "train loss:0.5925036521234752\n",
      "train loss:0.5768158885160746\n",
      "train loss:0.6025990954050429\n",
      "train loss:0.5846095311893456\n",
      "train loss:0.5516323586834131\n",
      "train loss:0.45755736316429735\n",
      "train loss:0.49755043721696396\n",
      "train loss:0.5207620407524423\n",
      "train loss:0.6167989500683537\n",
      "train loss:0.5588186823417671\n",
      "train loss:0.6050599184235912\n",
      "train loss:0.43365544298892045\n",
      "train loss:0.6451066521084959\n",
      "train loss:0.5206431808419572\n",
      "train loss:0.4931381703477862\n",
      "train loss:0.6339824052336452\n",
      "train loss:0.6000677947747723\n",
      "train loss:0.7059725558287028\n",
      "train loss:0.8080777707668305\n",
      "train loss:0.5258963776546226\n",
      "train loss:0.5274099359702431\n",
      "train loss:0.6631323509821765\n",
      "train loss:0.4582429090218956\n",
      "train loss:0.5279321880569366\n",
      "train loss:0.671049165653511\n",
      "train loss:0.4541954080307295\n",
      "train loss:0.6352570216641397\n",
      "train loss:0.604601255189538\n",
      "train loss:0.4959750662992748\n",
      "train loss:0.6146618195515337\n",
      "train loss:0.4621148492500789\n",
      "train loss:0.5743261520487961\n",
      "train loss:0.6616326804930174\n",
      "train loss:0.538064436381493\n",
      "train loss:0.6678363823971644\n",
      "train loss:0.5380826852174665\n",
      "train loss:0.46413420249274373\n",
      "train loss:0.6069066321489465\n",
      "train loss:0.5559161253626523\n",
      "train loss:0.5039934104886182\n",
      "train loss:0.4919084018976571\n",
      "train loss:0.490842114178908\n",
      "train loss:0.732566144465099\n",
      "train loss:0.5446875286523185\n",
      "train loss:0.6734015172609311\n",
      "train loss:0.48474459889602545\n",
      "train loss:0.41609528697913656\n",
      "train loss:0.4627279014934189\n",
      "train loss:0.4731897933240865\n",
      "train loss:0.4461092695695285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.5585525982005123\n",
      "train loss:0.5846426486074757\n",
      "train loss:0.43820486750375404\n",
      "train loss:0.5069162903100313\n",
      "train loss:0.5115737790426078\n",
      "train loss:0.5430714391598594\n",
      "train loss:0.5441318428395828\n",
      "train loss:0.5853591942729107\n",
      "train loss:0.4929968799407859\n",
      "train loss:0.5621129190089769\n",
      "train loss:0.5741323379411291\n",
      "train loss:0.6586594213773523\n",
      "train loss:0.7702723577595992\n",
      "train loss:0.4599755989876638\n",
      "train loss:0.667903324063819\n",
      "train loss:0.5359254321392293\n",
      "train loss:0.5831858085105622\n",
      "train loss:0.49378422287560286\n",
      "train loss:0.6929133279178472\n",
      "train loss:0.627920242506236\n",
      "train loss:0.6521005687441795\n",
      "train loss:0.5904361482092836\n",
      "train loss:0.48645832899718755\n",
      "train loss:0.5139277348121473\n",
      "train loss:0.5710296130922038\n",
      "train loss:0.3824813948107446\n",
      "train loss:0.5761442295201266\n",
      "train loss:0.6370330517810487\n",
      "train loss:0.5747399471126071\n",
      "train loss:0.5924457835991409\n",
      "train loss:0.4559863906720332\n",
      "train loss:0.6570121035286701\n",
      "train loss:0.45566828936064496\n",
      "train loss:0.6093225436478482\n",
      "train loss:0.5835299897262505\n",
      "train loss:0.5214124277381716\n",
      "train loss:0.4295634913784601\n",
      "train loss:0.46625853532957073\n",
      "train loss:0.37449998874706003\n",
      "train loss:0.4474629161090432\n",
      "train loss:0.6365503667866467\n",
      "train loss:0.46838966180528613\n",
      "train loss:0.6024353934153285\n",
      "train loss:0.4880477389304594\n",
      "train loss:0.36434325798396794\n",
      "train loss:0.48957029892020365\n",
      "train loss:0.41398685545934916\n",
      "train loss:0.3676980969072023\n",
      "train loss:0.4064169034391573\n",
      "train loss:0.5627248682418526\n",
      "train loss:0.49968679864350096\n",
      "train loss:0.49804075250854524\n",
      "train loss:0.47898473877072717\n",
      "train loss:0.5128669626620639\n",
      "train loss:0.5673724139718742\n",
      "train loss:0.6325542208686552\n",
      "train loss:0.5284680704940175\n",
      "train loss:0.4387983492180183\n",
      "train loss:0.49973895577488675\n",
      "train loss:0.354975421617581\n",
      "train loss:0.47669731435204477\n",
      "train loss:0.4813424918226945\n",
      "train loss:0.4713060874847458\n",
      "train loss:0.4191990822863791\n",
      "train loss:0.4805598347825039\n",
      "train loss:0.5205618604490666\n",
      "train loss:0.5527533784515747\n",
      "train loss:0.6624532441272479\n",
      "train loss:0.6412379454520102\n",
      "train loss:0.5087272771535427\n",
      "train loss:0.4015603833506681\n",
      "train loss:0.3844430605440617\n",
      "train loss:0.5583917763585663\n",
      "train loss:0.5287128064861379\n",
      "train loss:0.5458076084767477\n",
      "train loss:0.468636130375473\n",
      "train loss:0.5372826591575117\n",
      "train loss:0.5843672403909481\n",
      "train loss:0.5367090568201253\n",
      "train loss:0.42689230141594037\n",
      "train loss:0.4137736524771565\n",
      "train loss:0.3679828603906165\n",
      "train loss:0.6613990150825084\n",
      "train loss:0.5641945469620405\n",
      "train loss:0.5974642823466209\n",
      "train loss:0.382229969787068\n",
      "train loss:0.5505646550377065\n",
      "train loss:0.42849087848712325\n",
      "train loss:0.4152574462816687\n",
      "train loss:0.41710743335677314\n",
      "train loss:0.5444750776715327\n",
      "train loss:0.4227413981319696\n",
      "train loss:0.5365804462574653\n",
      "train loss:0.5902454793795622\n",
      "train loss:0.39342319132364145\n",
      "train loss:0.5532121095775833\n",
      "train loss:0.4922479715376381\n",
      "train loss:0.5241970571793033\n",
      "train loss:0.5197520142756836\n",
      "train loss:0.4937130450927101\n",
      "train loss:0.38627525225058307\n",
      "train loss:0.5671624457995168\n",
      "train loss:0.6304202401227865\n",
      "train loss:0.4806298691613259\n",
      "train loss:0.6621974688570275\n",
      "train loss:0.518166354660244\n",
      "train loss:0.6808253382482209\n",
      "train loss:0.3918867086934709\n",
      "train loss:0.4132127338417513\n",
      "train loss:0.539350143479958\n",
      "train loss:0.574387208467241\n",
      "train loss:0.5215713545661778\n",
      "train loss:0.5524979890177256\n",
      "train loss:0.5518227320779563\n",
      "train loss:0.5205555751778733\n",
      "train loss:0.434279402091268\n",
      "train loss:0.41291809607161767\n",
      "train loss:0.6550422425866645\n",
      "train loss:0.4692258069842712\n",
      "train loss:0.4254701307013435\n",
      "train loss:0.6016520376209604\n",
      "train loss:0.4873624792922947\n",
      "train loss:0.4855680318242787\n",
      "train loss:0.46048216228424205\n",
      "train loss:0.5660827681789452\n",
      "train loss:0.47441286638040286\n",
      "train loss:0.5320836564661144\n",
      "train loss:0.42138784415093483\n",
      "train loss:0.6077520175977782\n",
      "train loss:0.4276233156505617\n",
      "train loss:0.5814436230099583\n",
      "train loss:0.6702146115324772\n",
      "train loss:0.4489517075592594\n",
      "train loss:0.5582409836528242\n",
      "train loss:0.43652030097252137\n",
      "train loss:0.4365512631205427\n",
      "train loss:0.3464143944940731\n",
      "train loss:0.4522239784834602\n",
      "train loss:0.5266070308501694\n",
      "train loss:0.6572714906273229\n",
      "train loss:0.698989293245727\n",
      "train loss:0.4443668644072346\n",
      "train loss:0.4720895353631146\n",
      "train loss:0.5830700600056496\n",
      "train loss:0.6288328216573609\n",
      "train loss:0.5463210947728533\n",
      "train loss:0.5135988397557693\n",
      "train loss:0.4692966340904326\n",
      "train loss:0.576224688063684\n",
      "train loss:0.3952506698564558\n",
      "train loss:0.5367844284617224\n",
      "train loss:0.4744092971253165\n",
      "train loss:0.4986944287389276\n",
      "train loss:0.4907965961102921\n",
      "train loss:0.5133872863146303\n",
      "train loss:0.44277805208957305\n",
      "train loss:0.37082446139299824\n",
      "train loss:0.5437588740300225\n",
      "train loss:0.38512845034684096\n",
      "train loss:0.4458518306127759\n",
      "train loss:0.48031347960637283\n",
      "train loss:0.4699989364583505\n",
      "train loss:0.420204904031274\n",
      "train loss:0.46275257175542217\n",
      "train loss:0.5544886578842582\n",
      "train loss:0.4143517906045403\n",
      "train loss:0.7179859507728061\n",
      "train loss:0.502075302261356\n",
      "train loss:0.6259300896969182\n",
      "train loss:0.37540879556092593\n",
      "train loss:0.4686146168023083\n",
      "train loss:0.4917375353377731\n",
      "train loss:0.45400424516389115\n",
      "train loss:0.3892033831496369\n",
      "train loss:0.48509690628520347\n",
      "train loss:0.5544978860746603\n",
      "train loss:0.5259950961085553\n",
      "train loss:0.396293831909879\n",
      "train loss:0.3785121758625102\n",
      "train loss:0.41830555506172185\n",
      "train loss:0.39748422453180593\n",
      "train loss:0.38258173590244154\n",
      "train loss:0.5448533060822456\n",
      "train loss:0.4001034078083356\n",
      "train loss:0.5220900933810633\n",
      "train loss:0.3376565398228287\n",
      "train loss:0.3873961781489267\n",
      "train loss:0.4530421520322627\n",
      "train loss:0.5109473882865688\n",
      "train loss:0.2996632613527195\n",
      "train loss:0.3594027585495889\n",
      "train loss:0.409528949079933\n",
      "train loss:0.5445421627895551\n",
      "train loss:0.43999012666326953\n",
      "train loss:0.43813087015758206\n",
      "train loss:0.37248505283686667\n",
      "train loss:0.5834024750699279\n",
      "train loss:0.6396651694847266\n",
      "train loss:0.45248824512931873\n",
      "train loss:0.32934940309822763\n",
      "train loss:0.5048608603363545\n",
      "train loss:0.3351609244708744\n",
      "train loss:0.4809469632668221\n",
      "train loss:0.4500057955978584\n",
      "train loss:0.5638769302303751\n",
      "train loss:0.4472991142604224\n",
      "train loss:0.4916381721507945\n",
      "train loss:0.5987829668120163\n",
      "train loss:0.5062994830443382\n",
      "train loss:0.669262951172188\n",
      "train loss:0.48847044235182535\n",
      "train loss:0.6263526253147973\n",
      "train loss:0.5029287800988727\n",
      "train loss:0.482260491544639\n",
      "train loss:0.5351650730693955\n",
      "train loss:0.4590697173144075\n",
      "train loss:0.5170077872564787\n",
      "train loss:0.4301534953218143\n",
      "train loss:0.45328131224276397\n",
      "train loss:0.34595093093103435\n",
      "train loss:0.4459360055367438\n",
      "train loss:0.5491859231522654\n",
      "train loss:0.6575030142011827\n",
      "train loss:0.5468124771157062\n",
      "train loss:0.35765665529300067\n",
      "train loss:0.48345558664633265\n",
      "train loss:0.46124300060659584\n",
      "train loss:0.5643265690334472\n",
      "train loss:0.5133033070255167\n",
      "train loss:0.4715063373105112\n",
      "train loss:0.6440488533079716\n",
      "train loss:0.4942452652080002\n",
      "train loss:0.4943910144304436\n",
      "train loss:0.3937136145064695\n",
      "train loss:0.4578661474640036\n",
      "train loss:0.5874734782775684\n",
      "train loss:0.5569260691485699\n",
      "train loss:0.5154333760930068\n",
      "train loss:0.43809640467254773\n",
      "train loss:0.34153314561993875\n",
      "train loss:0.5213640303319739\n",
      "train loss:0.5026996135737354\n",
      "train loss:0.5296758320376832\n",
      "train loss:0.48432909063989804\n",
      "train loss:0.46197853080661694\n",
      "train loss:0.5097228468811045\n",
      "train loss:0.5405035331276045\n",
      "train loss:0.4833064201211765\n",
      "train loss:0.47622462990887593\n",
      "train loss:0.5059909338842866\n",
      "train loss:0.3838533700485878\n",
      "train loss:0.32911176087246075\n",
      "train loss:0.4404378993143868\n",
      "train loss:0.39397047852679223\n",
      "train loss:0.3566918006066115\n",
      "train loss:0.3489079707967649\n",
      "train loss:0.6471889439866187\n",
      "train loss:0.4484900274154418\n",
      "train loss:0.5740431224129229\n",
      "train loss:0.3934987057221038\n",
      "train loss:0.3500403340419376\n",
      "train loss:0.4989904336822822\n",
      "train loss:0.33616832123773527\n",
      "train loss:0.5578297004097337\n",
      "train loss:0.38941814869916624\n",
      "train loss:0.5600015869805798\n",
      "train loss:0.5434023662850841\n",
      "train loss:0.6276068055445161\n",
      "train loss:0.3397175405098211\n",
      "train loss:0.41264788297226085\n",
      "train loss:0.5079185027792973\n",
      "train loss:0.4521097591717292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.44969839451189925\n",
      "train loss:0.4304951319740738\n",
      "train loss:0.545154249686439\n",
      "train loss:0.5027108433123705\n",
      "train loss:0.5267267019728429\n",
      "train loss:0.3884621356004392\n",
      "train loss:0.4149200819012531\n",
      "train loss:0.3896974968418421\n",
      "train loss:0.43058684695506527\n",
      "train loss:0.592056921942127\n",
      "train loss:0.4188499407463151\n",
      "train loss:0.47299435522647676\n",
      "train loss:0.4166104214561121\n",
      "train loss:0.40658868974910023\n",
      "train loss:0.40617522282621715\n",
      "train loss:0.4872895389807102\n",
      "train loss:0.6293926242356231\n",
      "train loss:0.3733683385343591\n",
      "train loss:0.49529265930914923\n",
      "train loss:0.5815514897060612\n",
      "train loss:0.40866128683930825\n",
      "train loss:0.5835147954593652\n",
      "train loss:0.3933135621108885\n",
      "train loss:0.4377386459529611\n",
      "train loss:0.46206334921658054\n",
      "train loss:0.45545866622937553\n",
      "train loss:0.58533171498751\n",
      "train loss:0.4648995059740069\n",
      "train loss:0.5643448899847259\n",
      "train loss:0.5159925156302694\n",
      "train loss:0.5628094129907595\n",
      "train loss:0.4342346214577232\n",
      "train loss:0.5583204399164586\n",
      "train loss:0.32609514308340076\n",
      "train loss:0.3335755155077\n",
      "train loss:0.3930511510084297\n",
      "train loss:0.37229033576760223\n",
      "train loss:0.3903940687954756\n",
      "train loss:0.507713761894414\n",
      "train loss:0.4181146460714207\n",
      "train loss:0.5034685889222623\n",
      "train loss:0.4254457408410399\n",
      "train loss:0.3695656211675511\n",
      "train loss:0.4169237084670273\n",
      "train loss:0.4257025508156216\n",
      "train loss:0.44661432508348203\n",
      "train loss:0.49214159875670055\n",
      "train loss:0.47204381096049397\n",
      "train loss:0.31579051954117904\n",
      "train loss:0.38264060424069696\n",
      "train loss:0.3868078995193891\n",
      "train loss:0.3152737426036721\n",
      "train loss:0.4357038091847485\n",
      "train loss:0.49506073499759845\n",
      "train loss:0.4690449930988955\n",
      "train loss:0.5239216281656536\n",
      "=== epoch:2, train acc:0.868, test acc:0.845 ===\n",
      "train loss:0.5186770010841856\n",
      "train loss:0.3247718278856695\n",
      "train loss:0.3192363406085794\n",
      "train loss:0.3844748075337268\n",
      "train loss:0.48685394053447484\n",
      "train loss:0.4040718750270092\n",
      "train loss:0.43904330807466\n",
      "train loss:0.32900743334398214\n",
      "train loss:0.3952156149339149\n",
      "train loss:0.39357218240977315\n",
      "train loss:0.39748136084749014\n",
      "train loss:0.43480690235573816\n",
      "train loss:0.35673021680479294\n",
      "train loss:0.4417306286677687\n",
      "train loss:0.41766162568596393\n",
      "train loss:0.49404654804885856\n",
      "train loss:0.3545244481124701\n",
      "train loss:0.3917602296858306\n",
      "train loss:0.3969134043410109\n",
      "train loss:0.4758802711237788\n",
      "train loss:0.46104479364939543\n",
      "train loss:0.513512899051014\n",
      "train loss:0.6619187456639116\n",
      "train loss:0.4685984131742892\n",
      "train loss:0.4370516880846461\n",
      "train loss:0.41129047745569436\n",
      "train loss:0.2998052708886533\n",
      "train loss:0.5097137754822636\n",
      "train loss:0.3917397019294734\n",
      "train loss:0.34830339704325297\n",
      "train loss:0.4164208604224923\n",
      "train loss:0.3968774644878299\n",
      "train loss:0.389466605673892\n",
      "train loss:0.462904832486024\n",
      "train loss:0.4694538605486981\n",
      "train loss:0.4650704398021567\n",
      "train loss:0.5165535386233078\n",
      "train loss:0.3638707922839361\n",
      "train loss:0.49915476317289015\n",
      "train loss:0.4606898749600656\n",
      "train loss:0.5167700309003769\n",
      "train loss:0.48050639239733434\n",
      "train loss:0.41250177111303876\n",
      "train loss:0.48603437830544166\n",
      "train loss:0.33700242643039596\n",
      "train loss:0.36128446505697814\n",
      "train loss:0.34836252384669353\n",
      "train loss:0.50015412672238\n",
      "train loss:0.36219825934452365\n",
      "train loss:0.29019316727357775\n",
      "train loss:0.4494268903772276\n",
      "train loss:0.4278954594102957\n",
      "train loss:0.3570765250668773\n",
      "train loss:0.2728671339409845\n",
      "train loss:0.4029197602134919\n",
      "train loss:0.3220671631083308\n",
      "train loss:0.37086286096761184\n",
      "train loss:0.4589554801101795\n",
      "train loss:0.3418298687132924\n",
      "train loss:0.270071943352462\n",
      "train loss:0.4996007120712928\n",
      "train loss:0.35348567978234446\n",
      "train loss:0.3988075108562709\n",
      "train loss:0.36552348165871656\n",
      "train loss:0.4153486696613905\n",
      "train loss:0.44974351759755093\n",
      "train loss:0.3978136497199152\n",
      "train loss:0.4787922252070883\n",
      "train loss:0.3458446095270913\n",
      "train loss:0.34785435499274003\n",
      "train loss:0.4099190213621954\n",
      "train loss:0.4241366559131377\n",
      "train loss:0.31292036038635135\n",
      "train loss:0.4054803843040342\n",
      "train loss:0.4978904343100053\n",
      "train loss:0.44092798753677565\n",
      "train loss:0.3929185350685798\n",
      "train loss:0.44174311543776945\n",
      "train loss:0.4998701843128991\n",
      "train loss:0.4039839336836615\n",
      "train loss:0.6356668838243577\n",
      "train loss:0.4484715364904798\n",
      "train loss:0.41449323455794035\n",
      "train loss:0.44622900984568176\n",
      "train loss:0.29020351743310985\n",
      "train loss:0.33091731619622794\n",
      "train loss:0.37128816176545215\n",
      "train loss:0.2669193428706071\n",
      "train loss:0.5077624959557396\n",
      "train loss:0.5667574499327113\n",
      "train loss:0.28566814056512946\n",
      "train loss:0.3561626853933369\n",
      "train loss:0.5450099100976569\n",
      "train loss:0.3350759335225264\n",
      "train loss:0.38001714831092726\n",
      "train loss:0.32695908334662865\n",
      "train loss:0.39286895308072206\n",
      "train loss:0.323350930363217\n",
      "train loss:0.46219521899654514\n",
      "train loss:0.5448068407553165\n",
      "train loss:0.40511602235614946\n",
      "train loss:0.46653619862300294\n",
      "train loss:0.5669699558387816\n",
      "train loss:0.3487593327132832\n",
      "train loss:0.2560886534134156\n",
      "train loss:0.3934017651557668\n",
      "train loss:0.44361510493661\n",
      "train loss:0.5023078541122704\n",
      "train loss:0.5897636302910984\n",
      "train loss:0.43163831003241954\n",
      "train loss:0.39410076562170476\n",
      "train loss:0.45621924278904125\n",
      "train loss:0.5516889422690902\n",
      "train loss:0.3178285820208482\n",
      "train loss:0.4130970013532504\n",
      "train loss:0.3244260507688508\n",
      "train loss:0.41832640044964264\n",
      "train loss:0.47366367832695405\n",
      "train loss:0.33470203056497366\n",
      "train loss:0.4087502345950776\n",
      "train loss:0.4348492369642127\n",
      "train loss:0.48205850687992585\n",
      "train loss:0.41841859030951123\n",
      "train loss:0.4234416024318899\n",
      "train loss:0.3361792524898039\n",
      "train loss:0.3326474330538253\n",
      "train loss:0.5022477360911418\n",
      "train loss:0.44075786486054036\n",
      "train loss:0.4485656835806359\n",
      "train loss:0.45304059631929233\n",
      "train loss:0.44430336303501755\n",
      "train loss:0.4037093088321199\n",
      "train loss:0.390030939546216\n",
      "train loss:0.5192236235778577\n",
      "train loss:0.3493897350431906\n",
      "train loss:0.41601870139733976\n",
      "train loss:0.3365466192752272\n",
      "train loss:0.33122985038768343\n",
      "train loss:0.38299945013138037\n",
      "train loss:0.5614101259240664\n",
      "train loss:0.4590643931010303\n",
      "train loss:0.42380420294566484\n",
      "train loss:0.3688531340444887\n",
      "train loss:0.47924474717266563\n",
      "train loss:0.40057239222207214\n",
      "train loss:0.4323024437493162\n",
      "train loss:0.41282549058470247\n",
      "train loss:0.3527490551320597\n",
      "train loss:0.35590812138361116\n",
      "train loss:0.295412596373392\n",
      "train loss:0.32069181784524575\n",
      "train loss:0.30598241331673126\n",
      "train loss:0.2255983209498645\n",
      "train loss:0.6755359865716595\n",
      "train loss:0.45406581232542104\n",
      "train loss:0.4810329747203983\n",
      "train loss:0.4854494389597819\n",
      "train loss:0.6216692022748083\n",
      "train loss:0.34591959608921163\n",
      "train loss:0.45210836291259354\n",
      "train loss:0.396434287441001\n",
      "train loss:0.4113537484001901\n",
      "train loss:0.37964697467983116\n",
      "train loss:0.4912489941905826\n",
      "train loss:0.4811908393557493\n",
      "train loss:0.3338617862806836\n",
      "train loss:0.35044068391456756\n",
      "train loss:0.3326475689436172\n",
      "train loss:0.5051314613936329\n",
      "train loss:0.3795551085128742\n",
      "train loss:0.3299027259277789\n",
      "train loss:0.41306717686563227\n",
      "train loss:0.5965590579279233\n",
      "train loss:0.4470636142535816\n",
      "train loss:0.530651959657141\n",
      "train loss:0.29545863630262664\n",
      "train loss:0.418608827335129\n",
      "train loss:0.4253382662696066\n",
      "train loss:0.5289113717718381\n",
      "train loss:0.3298277021850326\n",
      "train loss:0.4472078463161182\n",
      "train loss:0.28439829777613623\n",
      "train loss:0.5747031775729717\n",
      "train loss:0.33301580883227216\n",
      "train loss:0.3870055168646945\n",
      "train loss:0.3644997654762942\n",
      "train loss:0.31261499042991464\n",
      "train loss:0.43388722588324674\n",
      "train loss:0.29512008104453336\n",
      "train loss:0.6420910995887107\n",
      "train loss:0.40410584130930877\n",
      "train loss:0.3811832091356015\n",
      "train loss:0.3090419954195838\n",
      "train loss:0.4954386941710583\n",
      "train loss:0.34374456205984744\n",
      "train loss:0.4121506136294946\n",
      "train loss:0.2659578983836779\n",
      "train loss:0.3944470938994579\n",
      "train loss:0.5013119189361598\n",
      "train loss:0.4670500258066216\n",
      "train loss:0.36581881581636927\n",
      "train loss:0.39737697076962986\n",
      "train loss:0.3390629999437724\n",
      "train loss:0.4575257111046873\n",
      "train loss:0.42167230296051683\n",
      "train loss:0.3247071867753526\n",
      "train loss:0.5096786019577074\n",
      "train loss:0.4818772487522607\n",
      "train loss:0.37818887566827974\n",
      "train loss:0.4371334225775028\n",
      "train loss:0.3408497064427655\n",
      "train loss:0.45119705702042545\n",
      "train loss:0.4059824017125986\n",
      "train loss:0.42791414422442864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.35204793757357544\n",
      "train loss:0.528580948863545\n",
      "train loss:0.4431698084813744\n",
      "train loss:0.3091853584777351\n",
      "train loss:0.2996505170179917\n",
      "train loss:0.43099529436458417\n",
      "train loss:0.36988663001361693\n",
      "train loss:0.4370715476339972\n",
      "train loss:0.40568204887863213\n",
      "train loss:0.45259580164572805\n",
      "train loss:0.3693961174167372\n",
      "train loss:0.37406107771958186\n",
      "train loss:0.4075691426291965\n",
      "train loss:0.3188489296239809\n",
      "train loss:0.40561976953904305\n",
      "train loss:0.4636008316845859\n",
      "train loss:0.4825891760884348\n",
      "train loss:0.31332695421342704\n",
      "train loss:0.3600780350425211\n",
      "train loss:0.348064547082449\n",
      "train loss:0.3139278606319805\n",
      "train loss:0.45368398043825836\n",
      "train loss:0.37983753394278486\n",
      "train loss:0.4290192846056987\n",
      "train loss:0.5602668745496739\n",
      "train loss:0.3152853219304243\n",
      "train loss:0.43915805312058276\n",
      "train loss:0.44136321751882973\n",
      "train loss:0.35118748449878323\n",
      "train loss:0.3104693266144791\n",
      "train loss:0.4023564305243593\n",
      "train loss:0.36004804003945895\n",
      "train loss:0.44114554172833714\n",
      "train loss:0.3640764154998616\n",
      "train loss:0.3776593055564468\n",
      "train loss:0.3531342413718391\n",
      "train loss:0.39274996308306653\n",
      "train loss:0.46863522477117203\n",
      "train loss:0.46359896684518875\n",
      "train loss:0.26193467235906953\n",
      "train loss:0.3481751222958575\n",
      "train loss:0.3741566403450329\n",
      "train loss:0.36278513244389365\n",
      "train loss:0.39399473669865726\n",
      "train loss:0.4722751513294094\n",
      "train loss:0.3459715202714254\n",
      "train loss:0.3438431454850141\n",
      "train loss:0.3094423412013851\n",
      "train loss:0.29657279015495175\n",
      "train loss:0.3930057630990707\n",
      "train loss:0.31863914613231836\n",
      "train loss:0.3353907651027106\n",
      "train loss:0.5295524558309173\n",
      "train loss:0.31530852861777675\n",
      "train loss:0.319925680201094\n",
      "train loss:0.36910572514387924\n",
      "train loss:0.41808591068290224\n",
      "train loss:0.27867000471185877\n",
      "train loss:0.3782947512625284\n",
      "train loss:0.4462631029879982\n",
      "train loss:0.4595236457737704\n",
      "train loss:0.17768023103612027\n",
      "train loss:0.4072191937007765\n",
      "train loss:0.41076132868245646\n",
      "train loss:0.45302379549805133\n",
      "train loss:0.5078943151301697\n",
      "train loss:0.38509921647841777\n",
      "train loss:0.5411589452415823\n",
      "train loss:0.29196777939174934\n",
      "train loss:0.3355211375827396\n",
      "train loss:0.4910926478339783\n",
      "train loss:0.4517379184835511\n",
      "train loss:0.4347269326144738\n",
      "train loss:0.3866532416553135\n",
      "train loss:0.371084253466224\n",
      "train loss:0.4983252157265885\n",
      "train loss:0.43097491472719307\n",
      "train loss:0.4367284571406554\n",
      "train loss:0.3931113238728636\n",
      "train loss:0.63461139243876\n",
      "train loss:0.26810497399107425\n",
      "train loss:0.3521656520115173\n",
      "train loss:0.30748802398716035\n",
      "train loss:0.33481210630668584\n",
      "train loss:0.31111745423955733\n",
      "train loss:0.3844329798514783\n",
      "train loss:0.4109514043465749\n",
      "train loss:0.4100880995971407\n",
      "train loss:0.29090142820152215\n",
      "train loss:0.26027385603031\n",
      "train loss:0.4088404275866078\n",
      "train loss:0.42112509087280015\n",
      "train loss:0.3622822976276978\n",
      "train loss:0.3276368450085767\n",
      "train loss:0.3277872709023654\n",
      "train loss:0.29498962619102537\n",
      "train loss:0.39713477765860683\n",
      "train loss:0.45260785629161815\n",
      "train loss:0.3186705805389839\n",
      "train loss:0.2833577395752054\n",
      "train loss:0.3563044533458597\n",
      "train loss:0.4831272098091751\n",
      "train loss:0.42363782126082633\n",
      "train loss:0.4666083107806304\n",
      "train loss:0.40213895651528403\n",
      "train loss:0.2992397503987046\n",
      "train loss:0.4152169251428298\n",
      "train loss:0.48622770601011955\n",
      "train loss:0.2704682806570102\n",
      "train loss:0.3576600282034377\n",
      "train loss:0.4447289801106807\n",
      "train loss:0.39268923929467603\n",
      "train loss:0.36454679364248677\n",
      "train loss:0.30124891111240104\n",
      "train loss:0.3512575940625944\n",
      "train loss:0.32426709016535676\n",
      "train loss:0.24268021230899084\n",
      "train loss:0.36839271372692445\n",
      "train loss:0.3141267909178375\n",
      "train loss:0.21572600556127192\n",
      "train loss:0.5112915706035138\n",
      "train loss:0.2530160501957571\n",
      "train loss:0.44338758286962265\n",
      "train loss:0.3957419784660247\n",
      "train loss:0.3713392091630199\n",
      "train loss:0.36479781639364284\n",
      "train loss:0.3473457390326376\n",
      "train loss:0.3469611270864526\n",
      "train loss:0.26571336298592607\n",
      "train loss:0.348222495575792\n",
      "train loss:0.5916922728362175\n",
      "train loss:0.4066472399799719\n",
      "train loss:0.5536349758160756\n",
      "train loss:0.3516153899576505\n",
      "train loss:0.44491618525306775\n",
      "train loss:0.3638887002958539\n",
      "train loss:0.2670311680653504\n",
      "train loss:0.3036592460404463\n",
      "train loss:0.35008794475457883\n",
      "train loss:0.4804069554601213\n",
      "train loss:0.3553067890257332\n",
      "train loss:0.3602067689566226\n",
      "train loss:0.4129749559362971\n",
      "train loss:0.3321200893854116\n",
      "train loss:0.48844777846391835\n",
      "train loss:0.4179450866609027\n",
      "train loss:0.5060911376695215\n",
      "train loss:0.4246961942258655\n",
      "train loss:0.324491110798742\n",
      "train loss:0.39843964109187047\n",
      "train loss:0.36148548748420034\n",
      "train loss:0.4159727746292131\n",
      "train loss:0.32855539053015953\n",
      "train loss:0.33821784438458935\n",
      "train loss:0.3215368334444988\n",
      "train loss:0.29114398024319416\n",
      "train loss:0.3383760952612232\n",
      "train loss:0.19518873402305906\n",
      "train loss:0.2824273959568507\n",
      "train loss:0.43643885488058565\n",
      "train loss:0.32032939687189665\n",
      "train loss:0.28749258548731715\n",
      "train loss:0.36657403098884633\n",
      "train loss:0.29636071374366857\n",
      "train loss:0.2515612661117181\n",
      "train loss:0.34738949179149203\n",
      "train loss:0.32887746418632013\n",
      "train loss:0.40498781566996855\n",
      "train loss:0.3820406556291593\n",
      "train loss:0.2725610257178113\n",
      "train loss:0.3091647867132464\n",
      "train loss:0.522817262311888\n",
      "train loss:0.3159502467324634\n",
      "train loss:0.3053364782506771\n",
      "train loss:0.34978692252098653\n",
      "train loss:0.44365165336229195\n",
      "train loss:0.4977877489800759\n",
      "train loss:0.28415291075549737\n",
      "train loss:0.39262482710287794\n",
      "train loss:0.3957687861107682\n",
      "train loss:0.2964725381323824\n",
      "train loss:0.3969064192179585\n",
      "train loss:0.3871219566337308\n",
      "train loss:0.47572069006553064\n",
      "train loss:0.2481017340899086\n",
      "train loss:0.4509140991227376\n",
      "train loss:0.4337396547906161\n",
      "train loss:0.32994640083173365\n",
      "train loss:0.40959461240603695\n",
      "train loss:0.3049904029486385\n",
      "train loss:0.3305867462239364\n",
      "train loss:0.2763478498675422\n",
      "train loss:0.316704666316993\n",
      "train loss:0.4296536940573173\n",
      "train loss:0.2699349347996787\n",
      "train loss:0.42922279651177775\n",
      "train loss:0.417426288429674\n",
      "train loss:0.4452986197915023\n",
      "train loss:0.3430516964362485\n",
      "train loss:0.37364602653222806\n",
      "train loss:0.39998225556320777\n",
      "train loss:0.3122944476693699\n",
      "train loss:0.5338232823238439\n",
      "train loss:0.42667170938266763\n",
      "train loss:0.4364307559470493\n",
      "train loss:0.40755383626723524\n",
      "train loss:0.44990883709118173\n",
      "train loss:0.3644231577425036\n",
      "train loss:0.31429569763621856\n",
      "train loss:0.37333804745958404\n",
      "train loss:0.24685936184919574\n",
      "train loss:0.21576642705511767\n",
      "train loss:0.33449857098311925\n",
      "train loss:0.3952319357380387\n",
      "train loss:0.380782817014256\n",
      "train loss:0.4115778072866299\n",
      "train loss:0.30517515245073623\n",
      "train loss:0.3670318389659245\n",
      "train loss:0.36602622474427954\n",
      "train loss:0.34896987904397325\n",
      "train loss:0.4775059143987112\n",
      "train loss:0.2909588360194402\n",
      "train loss:0.33928294598203956\n",
      "train loss:0.32409378477310696\n",
      "train loss:0.2930726869799748\n",
      "train loss:0.41338197238935975\n",
      "train loss:0.40172467784883137\n",
      "train loss:0.42199480652304167\n",
      "train loss:0.2729157490123452\n",
      "train loss:0.3429216598768726\n",
      "train loss:0.33404889737308585\n",
      "train loss:0.328191149716574\n",
      "train loss:0.4293501380543704\n",
      "train loss:0.27761641924147407\n",
      "train loss:0.3711658188714154\n",
      "train loss:0.4254103225734465\n",
      "train loss:0.332851817172849\n",
      "train loss:0.4942002342391477\n",
      "train loss:0.32102424104763827\n",
      "train loss:0.3420443516888597\n",
      "train loss:0.2780135776475794\n",
      "train loss:0.4154885247898222\n",
      "train loss:0.4518738830195578\n",
      "train loss:0.3212793096597821\n",
      "train loss:0.28345144735272876\n",
      "train loss:0.47371537372379185\n",
      "train loss:0.26004913562508286\n",
      "train loss:0.37979105880529673\n",
      "train loss:0.32183146699183596\n",
      "train loss:0.4379562224088982\n",
      "train loss:0.34038164381584446\n",
      "train loss:0.20474156363427742\n",
      "train loss:0.39852228378870913\n",
      "train loss:0.511921903966638\n",
      "train loss:0.37170952000306556\n",
      "train loss:0.42213645459577703\n",
      "train loss:0.30499056805045877\n",
      "train loss:0.41474473121203737\n",
      "train loss:0.36128757391433486\n",
      "train loss:0.6242861712921507\n",
      "train loss:0.3081779586282464\n",
      "train loss:0.2875796979765811\n",
      "train loss:0.4487726681293393\n",
      "train loss:0.4159667065878031\n",
      "train loss:0.3625531494108875\n",
      "train loss:0.33564689077203547\n",
      "train loss:0.2720529260721738\n",
      "train loss:0.3620643396988178\n",
      "train loss:0.35296820641967636\n",
      "train loss:0.3353088191467428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.38674805627765707\n",
      "train loss:0.3802393552923804\n",
      "train loss:0.3131919881669591\n",
      "train loss:0.3665934895743982\n",
      "train loss:0.34025045488713096\n",
      "train loss:0.2760221770599667\n",
      "train loss:0.42873097263347726\n",
      "train loss:0.24136998908820717\n",
      "train loss:0.37127646215401255\n",
      "train loss:0.36585164711595985\n",
      "train loss:0.3282893906523323\n",
      "train loss:0.497852356003069\n",
      "train loss:0.3290868521120548\n",
      "train loss:0.29656805531431035\n",
      "train loss:0.35240172672485803\n",
      "train loss:0.3905015704291038\n",
      "train loss:0.30786231854409435\n",
      "train loss:0.3735545926202124\n",
      "train loss:0.41258086994867654\n",
      "train loss:0.23589850804750032\n",
      "train loss:0.4377514735180262\n",
      "train loss:0.4321184455489051\n",
      "train loss:0.31905183332595605\n",
      "train loss:0.3680984493473457\n",
      "train loss:0.35906183839180356\n",
      "train loss:0.41669851156418247\n",
      "train loss:0.3389275710759543\n",
      "train loss:0.36399187665533417\n",
      "train loss:0.3888166940375576\n",
      "train loss:0.343260267326047\n",
      "train loss:0.25808867886202985\n",
      "train loss:0.29202791878211004\n",
      "train loss:0.3433507716895992\n",
      "train loss:0.3830160802430834\n",
      "train loss:0.2753593205813452\n",
      "train loss:0.3100862540031857\n",
      "train loss:0.4218222585255978\n",
      "train loss:0.2835370756129055\n",
      "train loss:0.2946904261020023\n",
      "train loss:0.3237836764842486\n",
      "train loss:0.31110721441473355\n",
      "train loss:0.33351016432435154\n",
      "train loss:0.33809783987017694\n",
      "train loss:0.24638036166480093\n",
      "train loss:0.2911229802864975\n",
      "train loss:0.31235125453087154\n",
      "train loss:0.2807066815990281\n",
      "train loss:0.2859294869408339\n",
      "train loss:0.36938543939088947\n",
      "train loss:0.24236626838583789\n",
      "train loss:0.507282074160933\n",
      "train loss:0.38803937859598775\n",
      "train loss:0.37652247757259133\n",
      "train loss:0.5526998986872702\n",
      "train loss:0.3034335941893345\n",
      "train loss:0.3394234407579415\n",
      "train loss:0.3513627248746098\n",
      "train loss:0.4178029054865988\n",
      "train loss:0.4627724674028439\n",
      "train loss:0.37097807651006065\n",
      "train loss:0.3565284877065665\n",
      "train loss:0.3671040625577063\n",
      "train loss:0.4270024468040713\n",
      "train loss:0.38931770980144703\n",
      "train loss:0.4344970936998791\n",
      "train loss:0.41855696076316135\n",
      "train loss:0.2798079896583977\n",
      "train loss:0.3419669707664073\n",
      "train loss:0.34700934979845294\n",
      "train loss:0.4050670097742614\n",
      "train loss:0.4736509287248419\n",
      "train loss:0.34319607178490846\n",
      "train loss:0.36399969765944656\n",
      "train loss:0.2527450801789545\n",
      "train loss:0.44183052398672645\n",
      "train loss:0.33982158265635576\n",
      "train loss:0.3283089757297997\n",
      "train loss:0.3829175298219255\n",
      "train loss:0.2756874852413618\n",
      "train loss:0.4974244914658441\n",
      "train loss:0.41316263950868404\n",
      "train loss:0.32817430763588346\n",
      "train loss:0.3990114607967957\n",
      "train loss:0.38776083964468094\n",
      "train loss:0.3813076729474606\n",
      "train loss:0.45719478349545634\n",
      "train loss:0.27103378064146605\n",
      "train loss:0.2986271655196772\n",
      "train loss:0.41506142293832665\n",
      "train loss:0.5630184270719203\n",
      "train loss:0.43118890729006354\n",
      "train loss:0.3828335143220395\n",
      "train loss:0.3303971825474124\n",
      "train loss:0.2754364735652215\n",
      "train loss:0.22480535598832002\n",
      "train loss:0.3275504430300471\n",
      "train loss:0.44856264113771843\n",
      "train loss:0.4221369051251857\n",
      "train loss:0.31082092347815216\n",
      "train loss:0.33420329418432715\n",
      "train loss:0.3212987688749493\n",
      "train loss:0.344637472380745\n",
      "train loss:0.3762460893127622\n",
      "train loss:0.2790616004480769\n",
      "train loss:0.32875814274762055\n",
      "train loss:0.35887617995465226\n",
      "train loss:0.26165604770703765\n",
      "train loss:0.600756285785944\n",
      "train loss:0.30903067226874326\n",
      "train loss:0.34580792357843576\n",
      "train loss:0.34855117272136893\n",
      "train loss:0.46482450415088045\n",
      "train loss:0.41198021377872507\n",
      "train loss:0.37199772761084093\n",
      "train loss:0.31039255302226654\n",
      "train loss:0.306655127227086\n",
      "=== epoch:3, train acc:0.895, test acc:0.861 ===\n",
      "train loss:0.28837330922927473\n",
      "train loss:0.3711128107193084\n",
      "train loss:0.37610479355706716\n",
      "train loss:0.37493436262488217\n",
      "train loss:0.1942439171267268\n",
      "train loss:0.3257903708158089\n",
      "train loss:0.33809232039065484\n",
      "train loss:0.28198023025102525\n",
      "train loss:0.2934084403416532\n",
      "train loss:0.5069363645678233\n",
      "train loss:0.25527793030839907\n",
      "train loss:0.43230915057163144\n",
      "train loss:0.18693296457683545\n",
      "train loss:0.349903670425436\n",
      "train loss:0.30422199551791257\n",
      "train loss:0.28970083790043727\n",
      "train loss:0.3058695494246505\n",
      "train loss:0.35787113456832026\n",
      "train loss:0.24422535560506936\n",
      "train loss:0.3904045080075943\n",
      "train loss:0.22940163293824178\n",
      "train loss:0.31075408073508737\n",
      "train loss:0.3533041337409791\n",
      "train loss:0.3216059644216951\n",
      "train loss:0.3759047151213934\n",
      "train loss:0.4680037750318766\n",
      "train loss:0.22848504792164273\n",
      "train loss:0.22194971324063562\n",
      "train loss:0.27750983095453674\n",
      "train loss:0.2207290539148963\n",
      "train loss:0.385538489729757\n",
      "train loss:0.266486390723073\n",
      "train loss:0.26894512549909977\n",
      "train loss:0.246097604857524\n",
      "train loss:0.29084797758433895\n",
      "train loss:0.3388513833117198\n",
      "train loss:0.25951074408274005\n",
      "train loss:0.2388545560994938\n",
      "train loss:0.44480857464822215\n",
      "train loss:0.23638829647133416\n",
      "train loss:0.2917090480775698\n",
      "train loss:0.26982031937935635\n",
      "train loss:0.24915289377153033\n",
      "train loss:0.3744691075339885\n",
      "train loss:0.23369628724387792\n",
      "train loss:0.3970314581739503\n",
      "train loss:0.5703685737191022\n",
      "train loss:0.3390920124673427\n",
      "train loss:0.3258317844646877\n",
      "train loss:0.3469310231626174\n",
      "train loss:0.28794398894771217\n",
      "train loss:0.2911376689559451\n",
      "train loss:0.2256959404593694\n",
      "train loss:0.4074009722652528\n",
      "train loss:0.17847231106061343\n",
      "train loss:0.44761573442049346\n",
      "train loss:0.3207993533307721\n",
      "train loss:0.35508992264466954\n",
      "train loss:0.3381465251575446\n",
      "train loss:0.32259610107665276\n",
      "train loss:0.28525865943641404\n",
      "train loss:0.25944279053325486\n",
      "train loss:0.3567917345099195\n",
      "train loss:0.3499493961087905\n",
      "train loss:0.3165821870390687\n",
      "train loss:0.3490067325750077\n",
      "train loss:0.3206015481104501\n",
      "train loss:0.31915902603897456\n",
      "train loss:0.37809619065209893\n",
      "train loss:0.21733595746297749\n",
      "train loss:0.43573966868789554\n",
      "train loss:0.3790444349860595\n",
      "train loss:0.3833708490220124\n",
      "train loss:0.30071842134739\n",
      "train loss:0.29151281778594346\n",
      "train loss:0.28250850092722285\n",
      "train loss:0.5337199193619057\n",
      "train loss:0.31114468265136486\n",
      "train loss:0.3015188348054016\n",
      "train loss:0.3778363281885025\n",
      "train loss:0.39685378630637574\n",
      "train loss:0.2977217206714908\n",
      "train loss:0.39373209669858716\n",
      "train loss:0.3437886612812971\n",
      "train loss:0.25844602876334305\n",
      "train loss:0.3119277711683414\n",
      "train loss:0.407775159252771\n",
      "train loss:0.319197636050869\n",
      "train loss:0.29766947051907816\n",
      "train loss:0.38579255015247815\n",
      "train loss:0.2546682797696818\n",
      "train loss:0.3208432597966274\n",
      "train loss:0.331820984269419\n",
      "train loss:0.3466939839159696\n",
      "train loss:0.33787789135568064\n",
      "train loss:0.34415098080191453\n",
      "train loss:0.29951424473849037\n",
      "train loss:0.37679964883334705\n",
      "train loss:0.3325955965945082\n",
      "train loss:0.30675195933986277\n",
      "train loss:0.3288850235267873\n",
      "train loss:0.43699552795656443\n",
      "train loss:0.3363538916422653\n",
      "train loss:0.4668847848060556\n",
      "train loss:0.3090263521467741\n",
      "train loss:0.2831111244134228\n",
      "train loss:0.31250282175217575\n",
      "train loss:0.5177283300718419\n",
      "train loss:0.294166447046232\n",
      "train loss:0.44767537730470525\n",
      "train loss:0.33487308301481805\n",
      "train loss:0.46596258508346267\n",
      "train loss:0.3963724916226997\n",
      "train loss:0.22740196165746254\n",
      "train loss:0.36202718178702775\n",
      "train loss:0.36359313030515045\n",
      "train loss:0.3886690546267601\n",
      "train loss:0.4037939721050916\n",
      "train loss:0.35675420410824527\n",
      "train loss:0.33722531389629545\n",
      "train loss:0.4122679197775523\n",
      "train loss:0.40050071045795854\n",
      "train loss:0.3151161807892554\n",
      "train loss:0.3329525286999392\n",
      "train loss:0.36302585212565625\n",
      "train loss:0.4107546374107149\n",
      "train loss:0.3196632900008716\n",
      "train loss:0.3468910044209361\n",
      "train loss:0.35145596862649164\n",
      "train loss:0.2930698120185694\n",
      "train loss:0.2886267270658854\n",
      "train loss:0.42323276830613255\n",
      "train loss:0.31442402306795314\n",
      "train loss:0.3526551104034303\n",
      "train loss:0.23736464307511584\n",
      "train loss:0.27211728465371765\n",
      "train loss:0.3920395939980246\n",
      "train loss:0.3550598641761477\n",
      "train loss:0.3558896253593311\n",
      "train loss:0.4628095544489094\n",
      "train loss:0.3913974275057594\n",
      "train loss:0.3465267612159646\n",
      "train loss:0.27206391358997317\n",
      "train loss:0.3997798757918642\n",
      "train loss:0.37599271431762815\n",
      "train loss:0.3529257838185834\n",
      "train loss:0.36013095138571793\n",
      "train loss:0.3504403289043518\n",
      "train loss:0.37198797007599604\n",
      "train loss:0.37840596176429137\n",
      "train loss:0.2908195336757276\n",
      "train loss:0.2971495819077316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.3857759233839962\n",
      "train loss:0.24820246230250423\n",
      "train loss:0.43975394971279563\n",
      "train loss:0.43097775594419624\n",
      "train loss:0.1755656522863924\n",
      "train loss:0.27907983407306824\n",
      "train loss:0.26208145079907663\n",
      "train loss:0.34172628262610666\n",
      "train loss:0.26956629463718984\n",
      "train loss:0.5820911692668287\n",
      "train loss:0.3234654276411713\n",
      "train loss:0.34289202817292475\n",
      "train loss:0.3274240508472033\n",
      "train loss:0.2696496617004193\n",
      "train loss:0.35870987752807887\n",
      "train loss:0.30920510759221953\n",
      "train loss:0.45159480024941856\n",
      "train loss:0.3716218477958181\n",
      "train loss:0.3705090111578205\n",
      "train loss:0.25431207771261005\n",
      "train loss:0.38186914092571195\n",
      "train loss:0.2955323727568422\n",
      "train loss:0.27114115077779505\n",
      "train loss:0.2280629517706555\n",
      "train loss:0.39744373300002356\n",
      "train loss:0.37387200849989577\n",
      "train loss:0.4114386650171646\n",
      "train loss:0.39953932667494485\n",
      "train loss:0.21065720037771765\n",
      "train loss:0.2568927604842105\n",
      "train loss:0.39362496982237494\n",
      "train loss:0.2921468459560867\n",
      "train loss:0.3309069675123525\n",
      "train loss:0.25422041281684504\n",
      "train loss:0.36018963073468263\n",
      "train loss:0.2843972959344485\n",
      "train loss:0.27845815435894716\n",
      "train loss:0.5478771333678293\n",
      "train loss:0.38762278010615325\n",
      "train loss:0.3927606210244873\n",
      "train loss:0.2600075227629421\n",
      "train loss:0.3163482294795371\n",
      "train loss:0.432964772152512\n",
      "train loss:0.22629766126193576\n",
      "train loss:0.2289455257172159\n",
      "train loss:0.37049562720158385\n",
      "train loss:0.17287374916164325\n",
      "train loss:0.28476255517894755\n",
      "train loss:0.3376178197238701\n",
      "train loss:0.258936019229197\n",
      "train loss:0.509895994946476\n",
      "train loss:0.3305685670340887\n",
      "train loss:0.23417063413461278\n",
      "train loss:0.3598586501721318\n",
      "train loss:0.4251423473448767\n",
      "train loss:0.3022272035904899\n",
      "train loss:0.40982477798907857\n",
      "train loss:0.4232778713266904\n",
      "train loss:0.329855928966642\n",
      "train loss:0.2574047379109199\n",
      "train loss:0.3909319371515142\n",
      "train loss:0.28774443976825786\n",
      "train loss:0.3374450958286179\n",
      "train loss:0.24177044331793918\n",
      "train loss:0.3014331013435244\n",
      "train loss:0.28387294004318125\n",
      "train loss:0.31826151744715786\n",
      "train loss:0.3591437618990782\n",
      "train loss:0.2513147055112019\n",
      "train loss:0.41247129428468504\n",
      "train loss:0.28562473968005053\n",
      "train loss:0.2865257417670754\n",
      "train loss:0.22128222583079665\n",
      "train loss:0.3528599099239984\n",
      "train loss:0.7279244370716672\n",
      "train loss:0.28736394515486013\n",
      "train loss:0.2544770214354424\n",
      "train loss:0.4118146541698141\n",
      "train loss:0.3051675356088825\n",
      "train loss:0.4425296670807836\n",
      "train loss:0.28222096734494906\n",
      "train loss:0.31426678726295737\n",
      "train loss:0.2966571670945971\n",
      "train loss:0.2572449283386505\n",
      "train loss:0.3617212142169158\n",
      "train loss:0.3346684456139954\n",
      "train loss:0.2571383150832773\n",
      "train loss:0.2921153842365261\n",
      "train loss:0.3094131004117909\n",
      "train loss:0.36640000954858154\n",
      "train loss:0.3943341944116966\n",
      "train loss:0.3207370088388022\n",
      "train loss:0.3393070682007405\n",
      "train loss:0.35113769192971445\n",
      "train loss:0.2949264904911874\n",
      "train loss:0.33952580806154325\n",
      "train loss:0.3739930444588536\n",
      "train loss:0.3137022174614894\n",
      "train loss:0.30491921453567467\n",
      "train loss:0.3739781278794677\n",
      "train loss:0.2343712008219013\n",
      "train loss:0.25787544317981487\n",
      "train loss:0.2761161608600759\n",
      "train loss:0.2863881956691261\n",
      "train loss:0.4150117827104925\n",
      "train loss:0.4002634858932418\n",
      "train loss:0.2732170567465598\n",
      "train loss:0.4646712471083113\n",
      "train loss:0.31347160906647314\n",
      "train loss:0.41792846462405886\n",
      "train loss:0.27651184954861013\n",
      "train loss:0.30147976175170393\n",
      "train loss:0.34336539948119343\n",
      "train loss:0.3290394136539151\n",
      "train loss:0.23674525708441863\n",
      "train loss:0.449955695006979\n",
      "train loss:0.2337012350168996\n",
      "train loss:0.38921413979487646\n",
      "train loss:0.288019333934818\n",
      "train loss:0.3761506067209677\n",
      "train loss:0.376173154048347\n",
      "train loss:0.3969667797552103\n",
      "train loss:0.32180755329328775\n",
      "train loss:0.3477376017822682\n",
      "train loss:0.23536571549160434\n",
      "train loss:0.20293767702486634\n",
      "train loss:0.30275584740215294\n",
      "train loss:0.4389217703950067\n",
      "train loss:0.352650363567803\n",
      "train loss:0.26004424981046187\n",
      "train loss:0.3831988899224313\n",
      "train loss:0.3688187340240431\n",
      "train loss:0.22015478676282535\n",
      "train loss:0.3593684818296727\n",
      "train loss:0.26589460084362204\n",
      "train loss:0.2074869616290412\n",
      "train loss:0.31462203336015454\n",
      "train loss:0.1864883942895147\n",
      "train loss:0.33050321640383423\n",
      "train loss:0.3276088438017824\n",
      "train loss:0.32782947902229814\n",
      "train loss:0.31256737725218375\n",
      "train loss:0.2813499045412676\n",
      "train loss:0.5698343089161073\n",
      "train loss:0.4416670187131973\n",
      "train loss:0.28879537256683735\n",
      "train loss:0.23516278307986035\n",
      "train loss:0.2714403287837378\n",
      "train loss:0.30978718868486116\n",
      "train loss:0.23735766059605268\n",
      "train loss:0.36555218819937374\n",
      "train loss:0.4441886125920076\n",
      "train loss:0.19832606215426313\n",
      "train loss:0.40100938480372506\n",
      "train loss:0.3686099138679781\n",
      "train loss:0.2760260610481482\n",
      "train loss:0.26102361600713075\n",
      "train loss:0.3033914561114611\n",
      "train loss:0.3589118841077907\n",
      "train loss:0.3212472393539493\n",
      "train loss:0.27924544272505064\n",
      "train loss:0.2287448796614749\n",
      "train loss:0.4496541894982479\n",
      "train loss:0.3400912663476592\n",
      "train loss:0.30989686396391536\n",
      "train loss:0.2581397479619299\n",
      "train loss:0.2615037858052662\n",
      "train loss:0.37547204316508576\n",
      "train loss:0.28467242982379615\n",
      "train loss:0.3530200754801771\n",
      "train loss:0.18908201682601944\n",
      "train loss:0.47111152195595385\n",
      "train loss:0.32597324787929133\n",
      "train loss:0.25880804726590007\n",
      "train loss:0.31870867394585733\n",
      "train loss:0.326301600751786\n",
      "train loss:0.345863206717529\n",
      "train loss:0.19021460102170226\n",
      "train loss:0.18019162678055367\n",
      "train loss:0.39272869880649075\n",
      "train loss:0.5062221966340803\n",
      "train loss:0.48731039997133574\n",
      "train loss:0.39521640072236763\n",
      "train loss:0.48160915745780514\n",
      "train loss:0.2612016768626507\n",
      "train loss:0.36576892135600425\n",
      "train loss:0.3418397933405273\n",
      "train loss:0.45036743191754625\n",
      "train loss:0.28238598355779476\n",
      "train loss:0.31049092296028336\n",
      "train loss:0.30136482213549687\n",
      "train loss:0.3997892487423907\n",
      "train loss:0.34626151038647285\n",
      "train loss:0.26740138542451924\n",
      "train loss:0.27282021419711733\n",
      "train loss:0.33856521874571227\n",
      "train loss:0.2929393226098526\n",
      "train loss:0.33018680683940216\n",
      "train loss:0.36812185689019217\n",
      "train loss:0.37853140196469537\n",
      "train loss:0.32545648184893217\n",
      "train loss:0.18912123712632206\n",
      "train loss:0.3558698052392779\n",
      "train loss:0.42408951988845445\n",
      "train loss:0.2797358456964065\n",
      "train loss:0.3074528077042686\n",
      "train loss:0.3737291095693041\n",
      "train loss:0.36961044688914385\n",
      "train loss:0.32121200895218954\n",
      "train loss:0.3770839814253293\n",
      "train loss:0.2894595052298271\n",
      "train loss:0.2398232656517159\n",
      "train loss:0.377929830368821\n",
      "train loss:0.39571825433928604\n",
      "train loss:0.2225827613531205\n",
      "train loss:0.31045369291704294\n",
      "train loss:0.2990148565125146\n",
      "train loss:0.34671648820854045\n",
      "train loss:0.4406626993402821\n",
      "train loss:0.3073291058406642\n",
      "train loss:0.49267483896766673\n",
      "train loss:0.3680013146663091\n",
      "train loss:0.40929353211654784\n",
      "train loss:0.21849439683693575\n",
      "train loss:0.3679170435503583\n",
      "train loss:0.3899348276404232\n",
      "train loss:0.3728338664717755\n",
      "train loss:0.3313417512567176\n",
      "train loss:0.291603774828383\n",
      "train loss:0.3327972512912818\n",
      "train loss:0.43649505741958733\n",
      "train loss:0.3645861988573216\n",
      "train loss:0.2789158831443709\n",
      "train loss:0.3896845784481045\n",
      "train loss:0.4014584926316908\n",
      "train loss:0.28117368920138\n",
      "train loss:0.2670948594920864\n",
      "train loss:0.24567968220246952\n",
      "train loss:0.28917893008566875\n",
      "train loss:0.40569360743471683\n",
      "train loss:0.290520867103325\n",
      "train loss:0.22897469843634685\n",
      "train loss:0.2967796982695563\n",
      "train loss:0.2793435736388787\n",
      "train loss:0.4249162049442742\n",
      "train loss:0.24170971652003412\n",
      "train loss:0.3347478767015314\n",
      "train loss:0.35295686327180725\n",
      "train loss:0.251461738783755\n",
      "train loss:0.2988585515192067\n",
      "train loss:0.3414601569919412\n",
      "train loss:0.32902790689328043\n",
      "train loss:0.30355379452201503\n",
      "train loss:0.2648319881849667\n",
      "train loss:0.30368587870730307\n",
      "train loss:0.3731670104803241\n",
      "train loss:0.2733781725314011\n",
      "train loss:0.32717678532151806\n",
      "train loss:0.3666959324585139\n",
      "train loss:0.40649825082381985\n",
      "train loss:0.21119071511799306\n",
      "train loss:0.35271301530822297\n",
      "train loss:0.17473351965680586\n",
      "train loss:0.2858498517677593\n",
      "train loss:0.2741052234514021\n",
      "train loss:0.3498652571195366\n",
      "train loss:0.2861599729313776\n",
      "train loss:0.33722464658549706\n",
      "train loss:0.28715372865795535\n",
      "train loss:0.29284368624505275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.49768665912144044\n",
      "train loss:0.2689931018219006\n",
      "train loss:0.2168777885400035\n",
      "train loss:0.19266956891021994\n",
      "train loss:0.23067382054300303\n",
      "train loss:0.3598702457295237\n",
      "train loss:0.28711066607499564\n",
      "train loss:0.23931100976856573\n",
      "train loss:0.23700306645852906\n",
      "train loss:0.2532867934547711\n",
      "train loss:0.39171986154524385\n",
      "train loss:0.22636987797592684\n",
      "train loss:0.42084777758872655\n",
      "train loss:0.2693662475407827\n",
      "train loss:0.3180703981488973\n",
      "train loss:0.41152434147227096\n",
      "train loss:0.23560997912634232\n",
      "train loss:0.17113215044168512\n",
      "train loss:0.3705300663812877\n",
      "train loss:0.34263800013788415\n",
      "train loss:0.25408186160961893\n",
      "train loss:0.40183750709366406\n",
      "train loss:0.17917257263939138\n",
      "train loss:0.37560389984300036\n",
      "train loss:0.38574634140478553\n",
      "train loss:0.31644486316670734\n",
      "train loss:0.27934074716629986\n",
      "train loss:0.361075423285134\n",
      "train loss:0.4107878695200574\n",
      "train loss:0.22830491814823875\n",
      "train loss:0.16976586255379705\n",
      "train loss:0.36792325947143845\n",
      "train loss:0.20744926458539883\n",
      "train loss:0.2369873069514082\n",
      "train loss:0.34430039289480197\n",
      "train loss:0.26049145921083033\n",
      "train loss:0.19700378423360898\n",
      "train loss:0.35522055054875823\n",
      "train loss:0.25457461621805827\n",
      "train loss:0.2661109463366932\n",
      "train loss:0.41125769212226787\n",
      "train loss:0.3725574215023714\n",
      "train loss:0.3501851702824246\n",
      "train loss:0.3237360509415187\n",
      "train loss:0.24723673251240266\n",
      "train loss:0.18183071142241988\n",
      "train loss:0.1991455684196559\n",
      "train loss:0.4777004811791982\n",
      "train loss:0.303684806043678\n",
      "train loss:0.31055750704244767\n",
      "train loss:0.23363724750363013\n",
      "train loss:0.28638676892794984\n",
      "train loss:0.21253595117380988\n",
      "train loss:0.41949229602210025\n",
      "train loss:0.31935664819122905\n",
      "train loss:0.34508449589672247\n",
      "train loss:0.2258968733703767\n",
      "train loss:0.1982209147784369\n",
      "train loss:0.23965918322713858\n",
      "train loss:0.18866846914227017\n",
      "train loss:0.24494921649584753\n",
      "train loss:0.3017467588772383\n",
      "train loss:0.15816716973855746\n",
      "train loss:0.2481882144351947\n",
      "train loss:0.264087372887505\n",
      "train loss:0.3526296396009363\n",
      "train loss:0.251166846560465\n",
      "train loss:0.2008154837888741\n",
      "train loss:0.3472517136242419\n",
      "train loss:0.24415573602861723\n",
      "train loss:0.24396959764583542\n",
      "train loss:0.335519433332559\n",
      "train loss:0.33037543401189745\n",
      "train loss:0.43302368377786415\n",
      "train loss:0.3327577887564661\n",
      "train loss:0.3103502452983348\n",
      "train loss:0.2906106549143603\n",
      "train loss:0.315638835614161\n",
      "train loss:0.22468745249081454\n",
      "train loss:0.2687760348048349\n",
      "train loss:0.20896946920393483\n",
      "train loss:0.31566090550871\n",
      "train loss:0.25876007190780914\n",
      "train loss:0.4535143131712248\n",
      "train loss:0.4516544346256003\n",
      "train loss:0.2587245463830152\n",
      "train loss:0.2848988731180711\n",
      "train loss:0.3236077684054494\n",
      "train loss:0.23281897988910458\n",
      "train loss:0.31291542223745955\n",
      "train loss:0.3614509587554028\n",
      "train loss:0.33610945314598645\n",
      "train loss:0.43960966772541915\n",
      "train loss:0.245172220334816\n",
      "train loss:0.3611749373105622\n",
      "train loss:0.3453590911243802\n",
      "train loss:0.44761384406510324\n",
      "train loss:0.23290849085824905\n",
      "train loss:0.2806415039569423\n",
      "train loss:0.3794849931898485\n",
      "train loss:0.26768266230204185\n",
      "train loss:0.2739993394601616\n",
      "train loss:0.2020644365964995\n",
      "train loss:0.3327330150057724\n",
      "train loss:0.3061452558701058\n",
      "train loss:0.3133540473108764\n",
      "train loss:0.22795425494441315\n",
      "train loss:0.25497120382080174\n",
      "train loss:0.30034663788071886\n",
      "train loss:0.40991592628522766\n",
      "train loss:0.33083501051072217\n",
      "train loss:0.404996369884581\n",
      "train loss:0.34705429684141204\n",
      "train loss:0.327681257945886\n",
      "train loss:0.32126623419659883\n",
      "train loss:0.32869978324513965\n",
      "train loss:0.23143367975863705\n",
      "train loss:0.2503210603044456\n",
      "train loss:0.14727177135235728\n",
      "train loss:0.31514075150377185\n",
      "train loss:0.29386903223446853\n",
      "train loss:0.29492306354305575\n",
      "train loss:0.19203681535612468\n",
      "train loss:0.4241930730980957\n",
      "train loss:0.2820269272728913\n",
      "train loss:0.2630576439814703\n",
      "train loss:0.19060286951855449\n",
      "train loss:0.3229939570990429\n",
      "train loss:0.1842922341683014\n",
      "train loss:0.4230025107868678\n",
      "train loss:0.45171028143419645\n",
      "train loss:0.24778708583229478\n",
      "train loss:0.3187273762704573\n",
      "train loss:0.17433533047462263\n",
      "train loss:0.22951503676775611\n",
      "train loss:0.2794054060253621\n",
      "train loss:0.4130330073835941\n",
      "train loss:0.35080462163774223\n",
      "train loss:0.2506017337412367\n",
      "train loss:0.376709757704224\n",
      "train loss:0.31301415652437287\n",
      "train loss:0.25945160516230603\n",
      "train loss:0.35468389317177434\n",
      "train loss:0.262672044382659\n",
      "train loss:0.3857106263797976\n",
      "train loss:0.19883321510241472\n",
      "train loss:0.3368198254778174\n",
      "train loss:0.4213075619881985\n",
      "train loss:0.26548636511506785\n",
      "train loss:0.2686157667058662\n",
      "train loss:0.3833549761365523\n",
      "train loss:0.3054748808152514\n",
      "train loss:0.32176147410511874\n",
      "train loss:0.3122227456663401\n",
      "train loss:0.37988837354907523\n",
      "train loss:0.2630022777268176\n",
      "train loss:0.2612462033501827\n",
      "train loss:0.3218502424965706\n",
      "train loss:0.37924084424363946\n",
      "train loss:0.5261498201589586\n",
      "train loss:0.33141312422128144\n",
      "train loss:0.35071023679237534\n",
      "train loss:0.19793006779725597\n",
      "train loss:0.34547905507831994\n",
      "train loss:0.5398557731873624\n",
      "train loss:0.3695604130769293\n",
      "train loss:0.36438532872748797\n",
      "train loss:0.2350988341539656\n",
      "train loss:0.19382590142752001\n",
      "train loss:0.2892764472111262\n",
      "train loss:0.23952861839843695\n",
      "train loss:0.16803579540507363\n",
      "train loss:0.36583431654873066\n",
      "train loss:0.29715357677070886\n",
      "train loss:0.2903974101507234\n",
      "train loss:0.4435611867254438\n",
      "train loss:0.27423759214758653\n",
      "train loss:0.5348217662870967\n",
      "=== epoch:4, train acc:0.905, test acc:0.88 ===\n",
      "train loss:0.28662358670449806\n",
      "train loss:0.3827897369928755\n",
      "train loss:0.27792588211869806\n",
      "train loss:0.2985219476303913\n",
      "train loss:0.2883072161252285\n",
      "train loss:0.25457755589455117\n",
      "train loss:0.3607455678547006\n",
      "train loss:0.38281291078277696\n",
      "train loss:0.3006701408372877\n",
      "train loss:0.3676199547016863\n",
      "train loss:0.2596353773015671\n",
      "train loss:0.33524536863782844\n",
      "train loss:0.36981788512465175\n",
      "train loss:0.3150017257678487\n",
      "train loss:0.23757395920192717\n",
      "train loss:0.31407104345472553\n",
      "train loss:0.3374114366334466\n",
      "train loss:0.2433075644727981\n",
      "train loss:0.30002459463904946\n",
      "train loss:0.30130399420860354\n",
      "train loss:0.3107281057734289\n",
      "train loss:0.34704570388132644\n",
      "train loss:0.25187134420311225\n",
      "train loss:0.16660478639813817\n",
      "train loss:0.16570221923241946\n",
      "train loss:0.3368000028389821\n",
      "train loss:0.32429570236127886\n",
      "train loss:0.2669029068656843\n",
      "train loss:0.2042167036625262\n",
      "train loss:0.24116264266903772\n",
      "train loss:0.3671212338958042\n",
      "train loss:0.2941186111867273\n",
      "train loss:0.28050180127412316\n",
      "train loss:0.36927108775733797\n",
      "train loss:0.2274669736342535\n",
      "train loss:0.19794971603912345\n",
      "train loss:0.45459535759460296\n",
      "train loss:0.29771763959882425\n",
      "train loss:0.31858134986302206\n",
      "train loss:0.31867801480446073\n",
      "train loss:0.3062041168539567\n",
      "train loss:0.25199116115274056\n",
      "train loss:0.365578032551831\n",
      "train loss:0.28778235435567295\n",
      "train loss:0.4519933235975931\n",
      "train loss:0.29572721804453755\n",
      "train loss:0.3054728560021338\n",
      "train loss:0.3001950778446653\n",
      "train loss:0.24783416407887057\n",
      "train loss:0.22839452253502493\n",
      "train loss:0.32169876631671607\n",
      "train loss:0.1921818923290691\n",
      "train loss:0.4112532736847692\n",
      "train loss:0.2582175929500782\n",
      "train loss:0.3275800672090499\n",
      "train loss:0.3506160909385813\n",
      "train loss:0.3531454250226173\n",
      "train loss:0.271250515893804\n",
      "train loss:0.44326322343152363\n",
      "train loss:0.31961205520241864\n",
      "train loss:0.2347638158294616\n",
      "train loss:0.21828752865732443\n",
      "train loss:0.21302387592983696\n",
      "train loss:0.24256643406347242\n",
      "train loss:0.2689444097362969\n",
      "train loss:0.3344755308822044\n",
      "train loss:0.2644932518075407\n",
      "train loss:0.24015912281338586\n",
      "train loss:0.24196297733123145\n",
      "train loss:0.22160518154406994\n",
      "train loss:0.3617373009429346\n",
      "train loss:0.1785611639955966\n",
      "train loss:0.24494263672496916\n",
      "train loss:0.2297368043961388\n",
      "train loss:0.2526648041495131\n",
      "train loss:0.29238850224141494\n",
      "train loss:0.3434354967866751\n",
      "train loss:0.32757582937709345\n",
      "train loss:0.34069433421686723\n",
      "train loss:0.44786777657551574\n",
      "train loss:0.22201956023106362\n",
      "train loss:0.2623812838665426\n",
      "train loss:0.3097191058344797\n",
      "train loss:0.3046093312372465\n",
      "train loss:0.44336167610925165\n",
      "train loss:0.2928792703400976\n",
      "train loss:0.2861857146277978\n",
      "train loss:0.3216388919952032\n",
      "train loss:0.24528027477112466\n",
      "train loss:0.23131442927641901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.2918199127165719\n",
      "train loss:0.35581538039003396\n",
      "train loss:0.31739470209140974\n",
      "train loss:0.28818797794447865\n",
      "train loss:0.3445000350614088\n",
      "train loss:0.29896756012816333\n",
      "train loss:0.25548029033663366\n",
      "train loss:0.33051179114780543\n",
      "train loss:0.316140994954458\n",
      "train loss:0.29854143576395864\n",
      "train loss:0.293650034737651\n",
      "train loss:0.260030152433629\n",
      "train loss:0.21554071090947546\n",
      "train loss:0.3540366506084122\n",
      "train loss:0.20839805858343496\n",
      "train loss:0.3611779253527424\n",
      "train loss:0.27586434120151637\n",
      "train loss:0.2504354181332929\n",
      "train loss:0.24288020296776414\n",
      "train loss:0.30020605024990465\n",
      "train loss:0.38603444840768586\n",
      "train loss:0.38679184236540737\n",
      "train loss:0.3417995023483032\n",
      "train loss:0.2822547762515619\n",
      "train loss:0.2979685577259958\n",
      "train loss:0.23989166993393532\n",
      "train loss:0.4803671464809892\n",
      "train loss:0.2763486267688763\n",
      "train loss:0.24046852076849706\n",
      "train loss:0.4246964959939345\n",
      "train loss:0.322814175096952\n",
      "train loss:0.22716842529066242\n",
      "train loss:0.2908549617625389\n",
      "train loss:0.3134269666140318\n",
      "train loss:0.40507517409071986\n",
      "train loss:0.2929395648641374\n",
      "train loss:0.3356994150497464\n",
      "train loss:0.24348377371435068\n",
      "train loss:0.2965484092225364\n",
      "train loss:0.20277497584037088\n",
      "train loss:0.25260040621804514\n",
      "train loss:0.34080235451896806\n",
      "train loss:0.28099590074746944\n",
      "train loss:0.2675920928290683\n",
      "train loss:0.34414303720469214\n",
      "train loss:0.31739680172989526\n",
      "train loss:0.15644062816011595\n",
      "train loss:0.2742570480361599\n",
      "train loss:0.40419650398052576\n",
      "train loss:0.30163684015171943\n",
      "train loss:0.2366139453154199\n",
      "train loss:0.29492011954355263\n",
      "train loss:0.20044095023843841\n",
      "train loss:0.27222187027183753\n",
      "train loss:0.3143203774644868\n",
      "train loss:0.3147676602774847\n",
      "train loss:0.32858042936352555\n",
      "train loss:0.26244498339759836\n",
      "train loss:0.27691325935019223\n",
      "train loss:0.2696236877962394\n",
      "train loss:0.3744417780358251\n",
      "train loss:0.1697759378985508\n",
      "train loss:0.25556279748219674\n",
      "train loss:0.31064235654561656\n",
      "train loss:0.4264019010969081\n",
      "train loss:0.33941252740810407\n",
      "train loss:0.1945218244699867\n",
      "train loss:0.23747925074505571\n",
      "train loss:0.24023540896549334\n",
      "train loss:0.283951261054912\n",
      "train loss:0.3900707002549037\n",
      "train loss:0.4103506405017868\n",
      "train loss:0.4047728271022048\n",
      "train loss:0.22098769747912356\n",
      "train loss:0.38616410842883364\n",
      "train loss:0.29687102505945423\n",
      "train loss:0.3098024609005854\n",
      "train loss:0.2878815446101611\n",
      "train loss:0.2711184236280162\n",
      "train loss:0.32249339211208744\n",
      "train loss:0.22083060521852108\n",
      "train loss:0.2586861798814789\n",
      "train loss:0.20420862171616758\n",
      "train loss:0.29840101119103474\n",
      "train loss:0.37730464708602723\n",
      "train loss:0.2676458945718638\n",
      "train loss:0.27735864983566866\n",
      "train loss:0.15549907683281983\n",
      "train loss:0.2058187662090261\n",
      "train loss:0.3842426599688753\n",
      "train loss:0.30023076331917464\n",
      "train loss:0.38295713976307044\n",
      "train loss:0.2683571291959997\n",
      "train loss:0.3341106988677861\n",
      "train loss:0.203668731022155\n",
      "train loss:0.39194617789031655\n",
      "train loss:0.27276851262091645\n",
      "train loss:0.2686645196984471\n",
      "train loss:0.29951616207538256\n",
      "train loss:0.3137907958447342\n",
      "train loss:0.2748086014858725\n",
      "train loss:0.3739774770382708\n",
      "train loss:0.37970824644967843\n",
      "train loss:0.45805865005015134\n",
      "train loss:0.31026471745537365\n",
      "train loss:0.2976401761383277\n",
      "train loss:0.342713859058389\n",
      "train loss:0.30870870170717696\n",
      "train loss:0.25952803335378954\n",
      "train loss:0.2791508239680239\n",
      "train loss:0.29733549147807947\n",
      "train loss:0.3105441166783609\n",
      "train loss:0.5606783735314737\n",
      "train loss:0.23607957733353982\n",
      "train loss:0.23964822498506444\n",
      "train loss:0.21834432107878105\n",
      "train loss:0.372559663896231\n",
      "train loss:0.30398644196859076\n",
      "train loss:0.3222873765429698\n",
      "train loss:0.30831186238277114\n",
      "train loss:0.193190474993548\n",
      "train loss:0.2795447236422687\n",
      "train loss:0.21753839410839032\n",
      "train loss:0.19465114423484423\n",
      "train loss:0.41592746951727094\n",
      "train loss:0.30884372837165514\n",
      "train loss:0.303814891590893\n",
      "train loss:0.32550193918273296\n",
      "train loss:0.27250429546072213\n",
      "train loss:0.37808995525048517\n",
      "train loss:0.3366459097784639\n",
      "train loss:0.151197272959527\n",
      "train loss:0.27846803453362184\n",
      "train loss:0.32412032326504536\n",
      "train loss:0.31422543475987913\n",
      "train loss:0.14433397235851364\n",
      "train loss:0.24773961697053384\n",
      "train loss:0.16514631843970654\n",
      "train loss:0.412480212567105\n",
      "train loss:0.2556662191642655\n",
      "train loss:0.3350535508424199\n",
      "train loss:0.2320994315916133\n",
      "train loss:0.26482088755070043\n",
      "train loss:0.3391442113354069\n",
      "train loss:0.4642180480741167\n",
      "train loss:0.21282438915506682\n",
      "train loss:0.22277690490102364\n",
      "train loss:0.2159783634995472\n",
      "train loss:0.3282708691137065\n",
      "train loss:0.2728914711118016\n",
      "train loss:0.2543577950265637\n",
      "train loss:0.32939114332160474\n",
      "train loss:0.267248073306483\n",
      "train loss:0.3009658623301792\n",
      "train loss:0.36862626966241335\n",
      "train loss:0.32387557980365367\n",
      "train loss:0.2556765976355565\n",
      "train loss:0.23443602035959402\n",
      "train loss:0.414231539082594\n",
      "train loss:0.3304605292530154\n",
      "train loss:0.29436577636028877\n",
      "train loss:0.34673976805763884\n",
      "train loss:0.42504358934148817\n",
      "train loss:0.17281436200363362\n",
      "train loss:0.3317475686872208\n",
      "train loss:0.35241191244279496\n",
      "train loss:0.24768955440096138\n",
      "train loss:0.2834591030066818\n",
      "train loss:0.19855622481390134\n",
      "train loss:0.28115099381211067\n",
      "train loss:0.41890512146346653\n",
      "train loss:0.3081206562965703\n",
      "train loss:0.23994512417280814\n",
      "train loss:0.2911506774308286\n",
      "train loss:0.3000126526375269\n",
      "train loss:0.36174234989073456\n",
      "train loss:0.262471452563862\n",
      "train loss:0.23528447363051402\n",
      "train loss:0.21614566642771624\n",
      "train loss:0.2035080930008942\n",
      "train loss:0.29296489240953066\n",
      "train loss:0.20996469637238754\n",
      "train loss:0.32464534029144154\n",
      "train loss:0.33498771395154575\n",
      "train loss:0.3007312528984292\n",
      "train loss:0.2886294307578254\n",
      "train loss:0.23320608378528124\n",
      "train loss:0.2639741238145812\n",
      "train loss:0.2687055255137422\n",
      "train loss:0.18692742617077995\n",
      "train loss:0.3011110042014283\n",
      "train loss:0.21447087750721447\n",
      "train loss:0.24778624806999286\n",
      "train loss:0.2617532369777727\n",
      "train loss:0.3057178204938671\n",
      "train loss:0.31955561332723664\n",
      "train loss:0.3386186994892789\n",
      "train loss:0.35684839872233254\n",
      "train loss:0.1582197094879144\n",
      "train loss:0.27915481061213787\n",
      "train loss:0.2774012650987536\n",
      "train loss:0.19238578664511258\n",
      "train loss:0.2514579442387659\n",
      "train loss:0.24955332886960932\n",
      "train loss:0.28962726990370136\n",
      "train loss:0.19714085777608673\n",
      "train loss:0.38286675433316913\n",
      "train loss:0.14246966951334744\n",
      "train loss:0.3087441691105662\n",
      "train loss:0.15288346157532065\n",
      "train loss:0.30988658356563986\n",
      "train loss:0.30637363037193394\n",
      "train loss:0.29557439537125324\n",
      "train loss:0.2072501710730099\n",
      "train loss:0.23770429603048845\n",
      "train loss:0.18284886661613858\n",
      "train loss:0.28982287577736654\n",
      "train loss:0.31476204061390956\n",
      "train loss:0.2536031639406852\n",
      "train loss:0.27536589486229646\n",
      "train loss:0.1625890668129135\n",
      "train loss:0.3432450714499373\n",
      "train loss:0.34263958599153765\n",
      "train loss:0.328768238953029\n",
      "train loss:0.25114511861780103\n",
      "train loss:0.28210474967012705\n",
      "train loss:0.322503271505674\n",
      "train loss:0.2619699166319249\n",
      "train loss:0.36956083045051696\n",
      "train loss:0.2417446792894072\n",
      "train loss:0.3000230514041332\n",
      "train loss:0.3369316349773237\n",
      "train loss:0.3395320189540655\n",
      "train loss:0.16218676527579373\n",
      "train loss:0.4358599779344993\n",
      "train loss:0.25039727818128665\n",
      "train loss:0.3025492053777781\n",
      "train loss:0.12956366572092634\n",
      "train loss:0.15666965977121827\n",
      "train loss:0.2468403278590732\n",
      "train loss:0.32286767886380136\n",
      "train loss:0.21179038773743222\n",
      "train loss:0.2017530638276207\n",
      "train loss:0.4205444415893631\n",
      "train loss:0.21315518190930846\n",
      "train loss:0.31613530688491087\n",
      "train loss:0.35182605319657206\n",
      "train loss:0.20156951704195047\n",
      "train loss:0.189347587005111\n",
      "train loss:0.14390496392833468\n",
      "train loss:0.22894811473082874\n",
      "train loss:0.4157055255621775\n",
      "train loss:0.2756897069022516\n",
      "train loss:0.17195099973395678\n",
      "train loss:0.18367162175157553\n",
      "train loss:0.24347902133477323\n",
      "train loss:0.17376779809988768\n",
      "train loss:0.3281777007392232\n",
      "train loss:0.3060385601516655\n",
      "train loss:0.34416893978014085\n",
      "train loss:0.2265372911669515\n",
      "train loss:0.30509711169224724\n",
      "train loss:0.3257585152675207\n",
      "train loss:0.27246793767757954\n",
      "train loss:0.3401688997046744\n",
      "train loss:0.23811020001729644\n",
      "train loss:0.344613108539579\n",
      "train loss:0.2191411166329599\n",
      "train loss:0.25097756029943624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.23448417980467487\n",
      "train loss:0.38384022527201195\n",
      "train loss:0.24828589846610735\n",
      "train loss:0.30476905921976766\n",
      "train loss:0.2615042003419854\n",
      "train loss:0.37107205372573027\n",
      "train loss:0.25794486988417886\n",
      "train loss:0.22521130972076983\n",
      "train loss:0.34571078026272345\n",
      "train loss:0.21203578025409964\n",
      "train loss:0.28665426068248673\n",
      "train loss:0.2835664196749564\n",
      "train loss:0.2593556354261284\n",
      "train loss:0.3055201844826403\n",
      "train loss:0.25318197558053074\n",
      "train loss:0.35237633052236367\n",
      "train loss:0.2981292600659861\n",
      "train loss:0.3254597691312091\n",
      "train loss:0.3956622708766335\n",
      "train loss:0.33198277756156697\n",
      "train loss:0.34946010249110304\n",
      "train loss:0.24034671823121515\n",
      "train loss:0.21549073736935917\n",
      "train loss:0.2289990130247388\n",
      "train loss:0.3160916366475484\n",
      "train loss:0.3113861224948771\n",
      "train loss:0.24464352248591317\n",
      "train loss:0.2734490495396244\n",
      "train loss:0.2513972776440095\n",
      "train loss:0.3019209816902766\n",
      "train loss:0.2910575705087861\n",
      "train loss:0.3373861292706547\n",
      "train loss:0.3317157140401488\n",
      "train loss:0.23302051390758116\n",
      "train loss:0.26676673065307727\n",
      "train loss:0.18086643838130834\n",
      "train loss:0.22092000096467893\n",
      "train loss:0.3793286660471456\n",
      "train loss:0.23844258794874057\n",
      "train loss:0.2923508963047908\n",
      "train loss:0.3026977372672386\n",
      "train loss:0.2547554271029163\n",
      "train loss:0.17486913168201432\n",
      "train loss:0.20846669772349874\n",
      "train loss:0.1645662520866336\n",
      "train loss:0.4327406050442459\n",
      "train loss:0.20058267864332768\n",
      "train loss:0.2560284568365974\n",
      "train loss:0.30875115491007976\n",
      "train loss:0.32144595963698364\n",
      "train loss:0.292176751095541\n",
      "train loss:0.26146531588458666\n",
      "train loss:0.3021659733077121\n",
      "train loss:0.4072847647224896\n",
      "train loss:0.34678285752699145\n",
      "train loss:0.21125652957796232\n",
      "train loss:0.23507848630238765\n",
      "train loss:0.35956775801212515\n",
      "train loss:0.28912192256217606\n",
      "train loss:0.29415240943227944\n",
      "train loss:0.3072498751073712\n",
      "train loss:0.18623331113679684\n",
      "train loss:0.2747024080854158\n",
      "train loss:0.2556889063960622\n",
      "train loss:0.23971946528915222\n",
      "train loss:0.34289805715653165\n",
      "train loss:0.30397988528194625\n",
      "train loss:0.22735320985518556\n",
      "train loss:0.2842020058901826\n",
      "train loss:0.32752868631155396\n",
      "train loss:0.15342823419860027\n",
      "train loss:0.2872122783588764\n",
      "train loss:0.3020326288988536\n",
      "train loss:0.27320935822065723\n",
      "train loss:0.39878122923626025\n",
      "train loss:0.20085740840323638\n",
      "train loss:0.265897212423976\n",
      "train loss:0.24590413672171263\n",
      "train loss:0.3433992254271715\n",
      "train loss:0.3062597472264326\n",
      "train loss:0.21184818868416877\n",
      "train loss:0.28567214921832185\n",
      "train loss:0.34170403184539966\n",
      "train loss:0.21701753308795677\n",
      "train loss:0.23479975814790324\n",
      "train loss:0.2270919905287419\n",
      "train loss:0.2951814469555603\n",
      "train loss:0.3496555735528015\n",
      "train loss:0.245129124072344\n",
      "train loss:0.2313733101036518\n",
      "train loss:0.3173112253089387\n",
      "train loss:0.3399723079461336\n",
      "train loss:0.19457981760250057\n",
      "train loss:0.30864531467428363\n",
      "train loss:0.3199709004551138\n",
      "train loss:0.32028782885496887\n",
      "train loss:0.3402778908755485\n",
      "train loss:0.29863307916380344\n",
      "train loss:0.22674457385184155\n",
      "train loss:0.28365563041940783\n",
      "train loss:0.23741086901040875\n",
      "train loss:0.3932425293656621\n",
      "train loss:0.229809773708606\n",
      "train loss:0.18978105908528892\n",
      "train loss:0.30510890423062914\n",
      "train loss:0.2634812537261192\n",
      "train loss:0.26938980672514334\n",
      "train loss:0.25659193870729147\n",
      "train loss:0.26542410938265093\n",
      "train loss:0.22817237716215863\n",
      "train loss:0.257911818396811\n",
      "train loss:0.2462343550464224\n",
      "train loss:0.2775233520241197\n",
      "train loss:0.27529258763701514\n",
      "train loss:0.3828315578937083\n",
      "train loss:0.42860146414339867\n",
      "train loss:0.35693856692622705\n",
      "train loss:0.1362981258347127\n",
      "train loss:0.2720251314071007\n",
      "train loss:0.3399154579531956\n",
      "train loss:0.29045880606553376\n",
      "train loss:0.30155898090349326\n",
      "train loss:0.19584875575265975\n",
      "train loss:0.24324677735089142\n",
      "train loss:0.19717257195367754\n",
      "train loss:0.49459904457948967\n",
      "train loss:0.38066126954992024\n",
      "train loss:0.16471317336405952\n",
      "train loss:0.30430889251031995\n",
      "train loss:0.22111526657660427\n",
      "train loss:0.3460175922691566\n",
      "train loss:0.29211272023531426\n",
      "train loss:0.25060734857388584\n",
      "train loss:0.29699848957114444\n",
      "train loss:0.23862707150051585\n",
      "train loss:0.26069614002557806\n",
      "train loss:0.17255057460557577\n",
      "train loss:0.2526902242186554\n",
      "train loss:0.21547047579183012\n",
      "train loss:0.32172363856132624\n",
      "train loss:0.2723562623878218\n",
      "train loss:0.2413325551728518\n",
      "train loss:0.21798443817927032\n",
      "train loss:0.2229000976589501\n",
      "train loss:0.2784715512008116\n",
      "train loss:0.1826109228416939\n",
      "train loss:0.2720752366558663\n",
      "train loss:0.2551822922083748\n",
      "train loss:0.27201240987762865\n",
      "train loss:0.4588807572363298\n",
      "train loss:0.20161059196964135\n",
      "train loss:0.24104444068218642\n",
      "train loss:0.3559408126300052\n",
      "train loss:0.23363001688753862\n",
      "train loss:0.3473747293612487\n",
      "train loss:0.2886705767184148\n",
      "train loss:0.27556015275268964\n",
      "train loss:0.26296413251668815\n",
      "train loss:0.21657309023094282\n",
      "train loss:0.2757678912442965\n",
      "train loss:0.2203220304210394\n",
      "train loss:0.1908063092940058\n",
      "train loss:0.18667874220766575\n",
      "train loss:0.31182580984419717\n",
      "train loss:0.37042674906190615\n",
      "train loss:0.19991411819256552\n",
      "train loss:0.18101171294769572\n",
      "train loss:0.27153619350212777\n",
      "train loss:0.23297313698030198\n",
      "train loss:0.24961627636341313\n",
      "train loss:0.19997692843744239\n",
      "train loss:0.28981408974749284\n",
      "train loss:0.29568598884121816\n",
      "train loss:0.19980253982772866\n",
      "train loss:0.2805315193848802\n",
      "train loss:0.26552021092630523\n",
      "train loss:0.2905659207836592\n",
      "train loss:0.2856669860811392\n",
      "train loss:0.2437991968637489\n",
      "train loss:0.2539216401611932\n",
      "train loss:0.30568470165906175\n",
      "train loss:0.21871166894045652\n",
      "train loss:0.15397333884833553\n",
      "train loss:0.20128606529785564\n",
      "train loss:0.263517837769873\n",
      "train loss:0.2525527846115911\n",
      "train loss:0.33911758000362147\n",
      "train loss:0.20933915714961845\n",
      "train loss:0.20632529337267547\n",
      "train loss:0.23139305459317597\n",
      "train loss:0.16047067920942593\n",
      "train loss:0.3527685347628651\n",
      "train loss:0.31605171128154735\n",
      "train loss:0.43202274574246374\n",
      "train loss:0.2860119134741901\n",
      "train loss:0.21090433007770237\n",
      "train loss:0.28449215708614217\n",
      "train loss:0.27625796177694995\n",
      "train loss:0.25469855292793664\n",
      "train loss:0.20970632370199102\n",
      "train loss:0.27545617735119765\n",
      "train loss:0.3219603323502627\n",
      "train loss:0.3365617868709675\n",
      "train loss:0.2536229575665875\n",
      "train loss:0.3147126829772007\n",
      "train loss:0.3481030737298854\n",
      "train loss:0.209891893821826\n",
      "train loss:0.3981252305708283\n",
      "train loss:0.11267644238856335\n",
      "train loss:0.1650944690038248\n",
      "train loss:0.40310754736189275\n",
      "train loss:0.18350084610440817\n",
      "train loss:0.21652451460278574\n",
      "train loss:0.36029615840895846\n",
      "train loss:0.3673366214476226\n",
      "train loss:0.2754251048661128\n",
      "train loss:0.3612345760342325\n",
      "train loss:0.2981944876258274\n",
      "train loss:0.24806775327696934\n",
      "train loss:0.25236103859241643\n",
      "train loss:0.41916763453057515\n",
      "train loss:0.41244318636677585\n",
      "train loss:0.4530531123467615\n",
      "train loss:0.2620785155811489\n",
      "train loss:0.3284044212905857\n",
      "train loss:0.3045948399655941\n",
      "train loss:0.21756536342444974\n",
      "train loss:0.21691632092641114\n",
      "train loss:0.33167670048792003\n",
      "train loss:0.19080908933766977\n",
      "train loss:0.3115241105793155\n",
      "train loss:0.3238550077516839\n",
      "train loss:0.27032598413888953\n",
      "train loss:0.2558555095436448\n",
      "train loss:0.3103482664891743\n",
      "train loss:0.2902635982706147\n",
      "train loss:0.2118914732701607\n",
      "train loss:0.2710980422970951\n",
      "train loss:0.30439028521871553\n",
      "train loss:0.24766429022951614\n",
      "train loss:0.32662855819940595\n",
      "=== epoch:5, train acc:0.908, test acc:0.894 ===\n",
      "train loss:0.3165242935312297\n",
      "train loss:0.3412046695231815\n",
      "train loss:0.17042520467493172\n",
      "train loss:0.32123034304615056\n",
      "train loss:0.16610031190571375\n",
      "train loss:0.17402484904068738\n",
      "train loss:0.29001885142381784\n",
      "train loss:0.26368793517694267\n",
      "train loss:0.23426328999162507\n",
      "train loss:0.20955305843351543\n",
      "train loss:0.32316555545557357\n",
      "train loss:0.20453740608806367\n",
      "train loss:0.3042557175093855\n",
      "train loss:0.2936644248237609\n",
      "train loss:0.29829695849744087\n",
      "train loss:0.30792531336911666\n",
      "train loss:0.2073236369014354\n",
      "train loss:0.19942835323862906\n",
      "train loss:0.30819335493133954\n",
      "train loss:0.3846273602761012\n",
      "train loss:0.269828388821987\n",
      "train loss:0.26605482839820066\n",
      "train loss:0.2871575192681393\n",
      "train loss:0.33141192255269414\n",
      "train loss:0.32085240993707076\n",
      "train loss:0.28784382816229703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.24351226481134322\n",
      "train loss:0.2113175677086013\n",
      "train loss:0.27100629813123794\n",
      "train loss:0.4568039342703764\n",
      "train loss:0.15509123287256849\n",
      "train loss:0.2064569611157299\n",
      "train loss:0.22668431647668427\n",
      "train loss:0.2957777799668232\n",
      "train loss:0.2622883547999066\n",
      "train loss:0.21635738498603443\n",
      "train loss:0.20768208388481293\n",
      "train loss:0.2436264245769657\n",
      "train loss:0.23630253285090463\n",
      "train loss:0.2465138161240791\n",
      "train loss:0.176665031803785\n",
      "train loss:0.2163088109287618\n",
      "train loss:0.3591484165122264\n",
      "train loss:0.27511553450635723\n",
      "train loss:0.37008771827015907\n",
      "train loss:0.35029812637982716\n",
      "train loss:0.2886983009897873\n",
      "train loss:0.11679185894737755\n",
      "train loss:0.24191201902440126\n",
      "train loss:0.3205316434454626\n",
      "train loss:0.2385983996428186\n",
      "train loss:0.29753389153112003\n",
      "train loss:0.3195092273777436\n",
      "train loss:0.1691213408596284\n",
      "train loss:0.2890360451618517\n",
      "train loss:0.3080846447004266\n",
      "train loss:0.22738782494845805\n",
      "train loss:0.3184988679500806\n",
      "train loss:0.2751063014169142\n",
      "train loss:0.254246968881401\n",
      "train loss:0.28016843544154396\n",
      "train loss:0.23266127377352208\n",
      "train loss:0.3138584701064299\n",
      "train loss:0.2839070815442244\n",
      "train loss:0.23421520045553507\n",
      "train loss:0.23974705095577944\n",
      "train loss:0.4031234483189438\n",
      "train loss:0.30516215214167725\n",
      "train loss:0.24852015065371214\n",
      "train loss:0.23983338574788415\n",
      "train loss:0.2516226570748646\n",
      "train loss:0.2340826099243687\n",
      "train loss:0.2686611941142401\n",
      "train loss:0.3633012259271069\n",
      "train loss:0.2669778342146964\n",
      "train loss:0.2500838636518436\n",
      "train loss:0.31078813653382126\n",
      "train loss:0.3964502848803014\n",
      "train loss:0.2587858923514428\n",
      "train loss:0.2281352367908159\n",
      "train loss:0.17625342768803084\n",
      "train loss:0.21450230658386593\n",
      "train loss:0.18346838567339238\n",
      "train loss:0.19724620255635636\n",
      "train loss:0.3003612700806757\n",
      "train loss:0.2866290981115929\n",
      "train loss:0.31023929614211887\n",
      "train loss:0.2983855679937281\n",
      "train loss:0.2530155533001499\n",
      "train loss:0.1910331816207584\n",
      "train loss:0.24081651364102627\n",
      "train loss:0.1425066208591774\n",
      "train loss:0.3076105210593311\n",
      "train loss:0.2586038753377026\n",
      "train loss:0.3700233128800521\n",
      "train loss:0.30486783238415793\n",
      "train loss:0.28916971443121864\n",
      "train loss:0.27466769013930264\n",
      "train loss:0.27658786167821336\n",
      "train loss:0.215072209766484\n",
      "train loss:0.2558234068811549\n",
      "train loss:0.3199417921109144\n",
      "train loss:0.2815019956083767\n",
      "train loss:0.2572308960964697\n",
      "train loss:0.2626731141960761\n",
      "train loss:0.20446327708366333\n",
      "train loss:0.4007832108261236\n",
      "train loss:0.25701644198864654\n",
      "train loss:0.26194539027278535\n",
      "train loss:0.21157507731110634\n",
      "train loss:0.233001559187456\n",
      "train loss:0.3052466257799355\n",
      "train loss:0.2874393897394842\n",
      "train loss:0.24707122204133486\n",
      "train loss:0.22908637409056634\n",
      "train loss:0.18534352197235335\n",
      "train loss:0.13603050531238498\n",
      "train loss:0.13392917607684646\n",
      "train loss:0.2979120949628853\n",
      "train loss:0.17341502614245918\n",
      "train loss:0.3452274922939922\n",
      "train loss:0.23352540013298406\n",
      "train loss:0.2657954492151443\n",
      "train loss:0.2612579869113843\n",
      "train loss:0.291241896818623\n",
      "train loss:0.11519151396357355\n",
      "train loss:0.2516828378920218\n",
      "train loss:0.25678240903024724\n",
      "train loss:0.3343916407336765\n",
      "train loss:0.3737795823102721\n",
      "train loss:0.2857779065012231\n",
      "train loss:0.15852036430354532\n",
      "train loss:0.19401145156849453\n",
      "train loss:0.21606540464606938\n",
      "train loss:0.16042117929311228\n",
      "train loss:0.21670045093237897\n",
      "train loss:0.35647552668566157\n",
      "train loss:0.33735690717917083\n",
      "train loss:0.22613039393682566\n",
      "train loss:0.12500326388588406\n",
      "train loss:0.20500400650503958\n",
      "train loss:0.19854087283891989\n",
      "train loss:0.3318772896075594\n",
      "train loss:0.17960922204948004\n",
      "train loss:0.2929857988870685\n",
      "train loss:0.3638461023727109\n",
      "train loss:0.30534186162620036\n",
      "train loss:0.17870332621378826\n",
      "train loss:0.1715085021140974\n",
      "train loss:0.25282401069504873\n",
      "train loss:0.1787047436957875\n",
      "train loss:0.21666599205815099\n",
      "train loss:0.1820752829981516\n",
      "train loss:0.28632314303849155\n",
      "train loss:0.28522232549294346\n",
      "train loss:0.23254429536124413\n",
      "train loss:0.22787514565381695\n",
      "train loss:0.2477633465598981\n",
      "train loss:0.15999558974898218\n",
      "train loss:0.27595348889160154\n",
      "train loss:0.1833517388242029\n",
      "train loss:0.2022820898482953\n",
      "train loss:0.24268500617787797\n",
      "train loss:0.21491804187492733\n",
      "train loss:0.2208224423405164\n",
      "train loss:0.21354270143453158\n",
      "train loss:0.3183960028566566\n",
      "train loss:0.23688914692360316\n",
      "train loss:0.31074845717761007\n",
      "train loss:0.21897264480981185\n",
      "train loss:0.2214031882697327\n",
      "train loss:0.29236248384259955\n",
      "train loss:0.3521815910826718\n",
      "train loss:0.32132057817456344\n",
      "train loss:0.2739283337567355\n",
      "train loss:0.23845806854805637\n",
      "train loss:0.242015090019416\n",
      "train loss:0.2945485921820716\n",
      "train loss:0.3047774935730186\n",
      "train loss:0.20311919213449883\n",
      "train loss:0.18901029121471719\n",
      "train loss:0.14987019385201944\n",
      "train loss:0.3127669449944849\n",
      "train loss:0.22894516250551358\n",
      "train loss:0.35918427181260687\n",
      "train loss:0.2227261355366858\n",
      "train loss:0.31290981386202477\n",
      "train loss:0.16166104454412533\n",
      "train loss:0.2484888203032788\n",
      "train loss:0.27548538008494544\n",
      "train loss:0.28948025265746635\n",
      "train loss:0.20460671666287716\n",
      "train loss:0.1906617366418864\n",
      "train loss:0.2339566063221897\n",
      "train loss:0.2769876990179823\n",
      "train loss:0.20365735511448166\n",
      "train loss:0.3553337499714456\n",
      "train loss:0.24637802010787166\n",
      "train loss:0.33529243048662477\n",
      "train loss:0.24342650333010674\n",
      "train loss:0.4085849796666446\n",
      "train loss:0.28722479332484996\n",
      "train loss:0.19529757274326556\n",
      "train loss:0.3491998037669981\n",
      "train loss:0.23353422503679902\n",
      "train loss:0.170079956308306\n",
      "train loss:0.29830038802603853\n",
      "train loss:0.3267179270913483\n",
      "train loss:0.13150097030887595\n",
      "train loss:0.19833489337668567\n",
      "train loss:0.3033773311611032\n",
      "train loss:0.182237555380151\n",
      "train loss:0.2640658412365535\n",
      "train loss:0.4351038814991025\n",
      "train loss:0.26728164828526996\n",
      "train loss:0.306430881514558\n",
      "train loss:0.23746565196074773\n",
      "train loss:0.16670769697909216\n",
      "train loss:0.3347187009436919\n",
      "train loss:0.15528085305802744\n",
      "train loss:0.23259863784740178\n",
      "train loss:0.36351907718765775\n",
      "train loss:0.2764131562606481\n",
      "train loss:0.25804466002763066\n",
      "train loss:0.22922067704034926\n",
      "train loss:0.27523213146627074\n",
      "train loss:0.22610277622993977\n",
      "train loss:0.2930931356747006\n",
      "train loss:0.28550463782147895\n",
      "train loss:0.2095622886208769\n",
      "train loss:0.17487073517969745\n",
      "train loss:0.3004434196651022\n",
      "train loss:0.2671848392470253\n",
      "train loss:0.27844870648505965\n",
      "train loss:0.3129967190453089\n",
      "train loss:0.4041340898230578\n",
      "train loss:0.19581854607737978\n",
      "train loss:0.13447333981908266\n",
      "train loss:0.19977135365702797\n",
      "train loss:0.2765887369051842\n",
      "train loss:0.17913615791290755\n",
      "train loss:0.30139957708443055\n",
      "train loss:0.2688034734338101\n",
      "train loss:0.2007662753818074\n",
      "train loss:0.19419627548324478\n",
      "train loss:0.24386803014157188\n",
      "train loss:0.25017128817813217\n",
      "train loss:0.24930312792459078\n",
      "train loss:0.1468944495359658\n",
      "train loss:0.32640214260635125\n",
      "train loss:0.17489352838579347\n",
      "train loss:0.3161138809760027\n",
      "train loss:0.1229856234261875\n",
      "train loss:0.25707553125963856\n",
      "train loss:0.2669623310842737\n",
      "train loss:0.2901742452042977\n",
      "train loss:0.23035563511143656\n",
      "train loss:0.36289604097722433\n",
      "train loss:0.2511071689251218\n",
      "train loss:0.5029523308940046\n",
      "train loss:0.3224910105115358\n",
      "train loss:0.30934936984426625\n",
      "train loss:0.25712421046459877\n",
      "train loss:0.3060956155924302\n",
      "train loss:0.19863530793575748\n",
      "train loss:0.29704652219393196\n",
      "train loss:0.14186822622006043\n",
      "train loss:0.22544128206219757\n",
      "train loss:0.2846889992509608\n",
      "train loss:0.2134163328288235\n",
      "train loss:0.2571920089428463\n",
      "train loss:0.22320778806492034\n",
      "train loss:0.26604369291911373\n",
      "train loss:0.23512511739817757\n",
      "train loss:0.18624525148167437\n",
      "train loss:0.34498465149233376\n",
      "train loss:0.17265623942916136\n",
      "train loss:0.2002273452804939\n",
      "train loss:0.24675719238782395\n",
      "train loss:0.24913386050861186\n",
      "train loss:0.2675850545164123\n",
      "train loss:0.1255539561879639\n",
      "train loss:0.22823637275679057\n",
      "train loss:0.26405159570982606\n",
      "train loss:0.20198523751582279\n",
      "train loss:0.2617359152173515\n",
      "train loss:0.196321285243088\n",
      "train loss:0.24728214093929124\n",
      "train loss:0.2892061387441881\n",
      "train loss:0.2528487174886048\n",
      "train loss:0.2745980266930675\n",
      "train loss:0.2603836389478481\n",
      "train loss:0.20591053725315941\n",
      "train loss:0.25030361255552386\n",
      "train loss:0.26285549598164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.2521531526698368\n",
      "train loss:0.15142173693778022\n",
      "train loss:0.3018058807396121\n",
      "train loss:0.22914305809438307\n",
      "train loss:0.26377914287333065\n",
      "train loss:0.24573215093529033\n",
      "train loss:0.1712500483774022\n",
      "train loss:0.28272710182223315\n",
      "train loss:0.25611313169744365\n",
      "train loss:0.25916530984680086\n",
      "train loss:0.3173056437744471\n",
      "train loss:0.23875454631333426\n",
      "train loss:0.17269537067306867\n",
      "train loss:0.30686037462159904\n",
      "train loss:0.29765696911031503\n",
      "train loss:0.2318856127221505\n",
      "train loss:0.20770913771607277\n",
      "train loss:0.1797961383980487\n",
      "train loss:0.23852077475904374\n",
      "train loss:0.26786432914701197\n",
      "train loss:0.1459022628877779\n",
      "train loss:0.16826786257856605\n",
      "train loss:0.3819835231909597\n",
      "train loss:0.2749413518137854\n",
      "train loss:0.3857071995186515\n",
      "train loss:0.16169215368318632\n",
      "train loss:0.18636604246442448\n",
      "train loss:0.3175156270926085\n",
      "train loss:0.2253738231443888\n",
      "train loss:0.23166576850741583\n",
      "train loss:0.22348219757793486\n",
      "train loss:0.20177652596328494\n",
      "train loss:0.219146285546005\n",
      "train loss:0.26623416859406307\n",
      "train loss:0.2601712452113312\n",
      "train loss:0.2991816834845421\n",
      "train loss:0.2848516949828745\n",
      "train loss:0.3476487915659819\n",
      "train loss:0.29520930320410826\n",
      "train loss:0.22311627628845726\n",
      "train loss:0.2715457073216415\n",
      "train loss:0.23600081436357098\n",
      "train loss:0.22201042593309675\n",
      "train loss:0.2666173001493656\n",
      "train loss:0.16756363544623482\n",
      "train loss:0.142689854617682\n",
      "train loss:0.2601417370966023\n",
      "train loss:0.329218228120014\n",
      "train loss:0.4337040800254831\n",
      "train loss:0.22123101628141043\n",
      "train loss:0.19850637874592497\n",
      "train loss:0.2198407867171819\n",
      "train loss:0.15292273570129453\n",
      "train loss:0.43548813851347085\n",
      "train loss:0.15971044058447267\n",
      "train loss:0.2087575962372401\n",
      "train loss:0.3543658055501836\n",
      "train loss:0.27088494873241165\n",
      "train loss:0.38400718690407687\n",
      "train loss:0.3381509651268514\n",
      "train loss:0.23511655897568823\n",
      "train loss:0.1475342537767158\n",
      "train loss:0.3400461464014834\n",
      "train loss:0.3850830310590309\n",
      "train loss:0.3762804814906163\n",
      "train loss:0.29562342649366047\n",
      "train loss:0.27801973607406083\n",
      "train loss:0.26547260622184476\n",
      "train loss:0.262266794754262\n",
      "train loss:0.23720411791053386\n",
      "train loss:0.2533017155806914\n",
      "train loss:0.387477487807459\n",
      "train loss:0.17416736878924471\n",
      "train loss:0.3368203361493315\n",
      "train loss:0.3753373156914213\n",
      "train loss:0.3100272731371437\n",
      "train loss:0.3231764513478377\n",
      "train loss:0.14110374109919938\n",
      "train loss:0.20293900537197573\n",
      "train loss:0.2779410132331996\n",
      "train loss:0.1795948018075992\n",
      "train loss:0.26426754921596207\n",
      "train loss:0.29852643083605407\n",
      "train loss:0.29599121916807386\n",
      "train loss:0.28361584476571733\n",
      "train loss:0.4211685887533319\n",
      "train loss:0.18994634909767238\n",
      "train loss:0.27864140885610306\n",
      "train loss:0.2639457614728869\n",
      "train loss:0.2919774290313601\n",
      "train loss:0.21955284065229705\n",
      "train loss:0.19307279925948362\n",
      "train loss:0.13822995803650165\n",
      "train loss:0.2858694617481105\n",
      "train loss:0.3409516388377979\n",
      "train loss:0.19246701251025172\n",
      "train loss:0.24382963771268307\n",
      "train loss:0.3008060908412417\n",
      "train loss:0.2199051155312867\n",
      "train loss:0.18120399870755552\n",
      "train loss:0.15482558118130219\n",
      "train loss:0.27901632560890266\n",
      "train loss:0.21017969868922814\n",
      "train loss:0.2615916422929465\n",
      "train loss:0.21690339658974195\n",
      "train loss:0.23272621972367483\n",
      "train loss:0.270350676914442\n",
      "train loss:0.30077730433903294\n",
      "train loss:0.2389571609490063\n",
      "train loss:0.17429328724224402\n",
      "train loss:0.21756625538991636\n",
      "train loss:0.31523231493925075\n",
      "train loss:0.2269804260979971\n",
      "train loss:0.21576640188939267\n",
      "train loss:0.22694087963253703\n",
      "train loss:0.25931219413091633\n",
      "train loss:0.25174357812676074\n",
      "train loss:0.30215455733713786\n",
      "train loss:0.28960675902566657\n",
      "train loss:0.22916112009964387\n",
      "train loss:0.23658128204967457\n",
      "train loss:0.18766615476316142\n",
      "train loss:0.21358152633365615\n",
      "train loss:0.3319651612006499\n",
      "train loss:0.22287263425924755\n",
      "train loss:0.1804744362038011\n",
      "train loss:0.24107894046730746\n",
      "train loss:0.16913252369919307\n",
      "train loss:0.2992304258460345\n",
      "train loss:0.2710364159747071\n",
      "train loss:0.2681733253144564\n",
      "train loss:0.3016309883491202\n",
      "train loss:0.21480445801540188\n",
      "train loss:0.15320325448816433\n",
      "train loss:0.1595226520288659\n",
      "train loss:0.24164848176367681\n",
      "train loss:0.1326925836282966\n",
      "train loss:0.24070944555550733\n",
      "train loss:0.2566427106427682\n",
      "train loss:0.3764112828240889\n",
      "train loss:0.23355835816297893\n",
      "train loss:0.3092857757774841\n",
      "train loss:0.1663366372429608\n",
      "train loss:0.2912045132146568\n",
      "train loss:0.34278956833664653\n",
      "train loss:0.1717271802566967\n",
      "train loss:0.2593499035727994\n",
      "train loss:0.15783658149900923\n",
      "train loss:0.20470091368411425\n",
      "train loss:0.3538759507608158\n",
      "train loss:0.30009022693294396\n",
      "train loss:0.24776317871265516\n",
      "train loss:0.29983570911113583\n",
      "train loss:0.23508255656428464\n",
      "train loss:0.2809698789740908\n",
      "train loss:0.30930542837070146\n",
      "train loss:0.33472573802168454\n",
      "train loss:0.21969508257995693\n",
      "train loss:0.27319328412141813\n",
      "train loss:0.20646847016729084\n",
      "train loss:0.2691130884071688\n",
      "train loss:0.35741452480442454\n",
      "train loss:0.2716511130541051\n",
      "train loss:0.3371163916893648\n",
      "train loss:0.22519821227091338\n",
      "train loss:0.20300228699135295\n",
      "train loss:0.19985275451574044\n",
      "train loss:0.2007559646748726\n",
      "train loss:0.28088261530222886\n",
      "train loss:0.20160690614023888\n",
      "train loss:0.32102597295673746\n",
      "train loss:0.2807320735013073\n",
      "train loss:0.26457287889723685\n",
      "train loss:0.24389693680716132\n",
      "train loss:0.2176210531608719\n",
      "train loss:0.3356630821596397\n",
      "train loss:0.24139184999438182\n",
      "train loss:0.24493038124218885\n",
      "train loss:0.10548959467925906\n",
      "train loss:0.17008237949311816\n",
      "train loss:0.1678214419340449\n",
      "train loss:0.24633776904720833\n",
      "train loss:0.3328743357954413\n",
      "train loss:0.24523255338236033\n",
      "train loss:0.28610389918971185\n",
      "train loss:0.2748844996570836\n",
      "train loss:0.2795199724043849\n",
      "train loss:0.2773578856787478\n",
      "train loss:0.32905629708624473\n",
      "train loss:0.19175616836400117\n",
      "train loss:0.14439255865642317\n",
      "train loss:0.21450140776761212\n",
      "train loss:0.3356682787666315\n",
      "train loss:0.20926461867514898\n",
      "train loss:0.23400581165896964\n",
      "train loss:0.3530725226366203\n",
      "train loss:0.17013998736271232\n",
      "train loss:0.5441950884786627\n",
      "train loss:0.19811068015901806\n",
      "train loss:0.2279730295557532\n",
      "train loss:0.1846996633816048\n",
      "train loss:0.2234075489410198\n",
      "train loss:0.24036860222437526\n",
      "train loss:0.23479635028635643\n",
      "train loss:0.19270020191881707\n",
      "train loss:0.25154561272713544\n",
      "train loss:0.2469118129346591\n",
      "train loss:0.27123298771147786\n",
      "train loss:0.278930441293726\n",
      "train loss:0.31330806060147287\n",
      "train loss:0.22551392578328916\n",
      "train loss:0.2042822931216517\n",
      "train loss:0.21808069176920458\n",
      "train loss:0.18833102345133465\n",
      "train loss:0.22348926056312549\n",
      "train loss:0.1890567781965283\n",
      "train loss:0.23034620991975843\n",
      "train loss:0.2840570535423197\n",
      "train loss:0.24745771422970655\n",
      "train loss:0.22813412809179592\n",
      "train loss:0.2313890050111695\n",
      "train loss:0.24234961886526854\n",
      "train loss:0.2308097064182043\n",
      "train loss:0.20472513613087742\n",
      "train loss:0.2035620404339346\n",
      "train loss:0.21316897499085144\n",
      "train loss:0.25983093564935106\n",
      "train loss:0.2766731454361785\n",
      "train loss:0.2004675250890998\n",
      "train loss:0.21710020359843\n",
      "train loss:0.40448408193158925\n",
      "train loss:0.2888612899338597\n",
      "train loss:0.31355129781338303\n",
      "train loss:0.23489245731096223\n",
      "train loss:0.21372046313318496\n",
      "train loss:0.3267858478823331\n",
      "train loss:0.1592124988118908\n",
      "train loss:0.281078044936896\n",
      "train loss:0.29203271596752606\n",
      "train loss:0.23297206443080473\n",
      "train loss:0.2441069620204782\n",
      "train loss:0.2800162497896627\n",
      "train loss:0.2766159726535281\n",
      "train loss:0.27275161989429636\n",
      "train loss:0.26143197001973295\n",
      "train loss:0.28203555668284375\n",
      "train loss:0.2936176529856474\n",
      "train loss:0.143570137982704\n",
      "train loss:0.29589214743900155\n",
      "train loss:0.27939682267779753\n",
      "train loss:0.1825246440198159\n",
      "train loss:0.30658964570810016\n",
      "train loss:0.2525027084324509\n",
      "train loss:0.2161274233969169\n",
      "train loss:0.28055421995877133\n",
      "train loss:0.15282010961618678\n",
      "train loss:0.12830186028923632\n",
      "train loss:0.15476639918988183\n",
      "train loss:0.21107972390035062\n",
      "train loss:0.22354850506252938\n",
      "train loss:0.2987060468976674\n",
      "train loss:0.19721477119142633\n",
      "train loss:0.24998648354295913\n",
      "train loss:0.1936020563812777\n",
      "train loss:0.24198915811697655\n",
      "train loss:0.15767270823666027\n",
      "train loss:0.2854000458459074\n",
      "train loss:0.16146026283206308\n",
      "train loss:0.1928828486838951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.2876857849331526\n",
      "train loss:0.2211401285972012\n",
      "train loss:0.24352373887922604\n",
      "train loss:0.22600490036505433\n",
      "train loss:0.2525014381322121\n",
      "train loss:0.299886963241573\n",
      "train loss:0.2150763412110498\n",
      "train loss:0.2908923970745176\n",
      "train loss:0.1620709926769036\n",
      "train loss:0.25803383350850057\n",
      "train loss:0.2582491509504279\n",
      "train loss:0.19057470760447118\n",
      "train loss:0.15306678458779302\n",
      "train loss:0.2242189883291512\n",
      "train loss:0.2839346946813631\n",
      "train loss:0.29286510968083485\n",
      "train loss:0.27698178775982674\n",
      "train loss:0.35310497725605083\n",
      "train loss:0.18101137291984437\n",
      "train loss:0.2871863368938666\n",
      "train loss:0.2399979928041783\n",
      "train loss:0.34656689706986116\n",
      "train loss:0.25431960088868366\n",
      "train loss:0.21287349129619915\n",
      "train loss:0.17532252498395806\n",
      "train loss:0.18781211708049994\n",
      "train loss:0.3016044702943018\n",
      "train loss:0.22754396012113673\n",
      "train loss:0.15731163115914512\n",
      "train loss:0.20199628643096088\n",
      "train loss:0.30991028271989607\n",
      "train loss:0.2810772290949442\n",
      "train loss:0.22217577677395348\n",
      "train loss:0.22216489499901454\n",
      "train loss:0.21271239588557303\n",
      "train loss:0.31617392379535547\n",
      "=== epoch:6, train acc:0.914, test acc:0.896 ===\n",
      "train loss:0.21216479431301793\n",
      "train loss:0.20910581914424245\n",
      "train loss:0.2723962225667723\n",
      "train loss:0.23231981726341094\n",
      "train loss:0.18611247809693915\n",
      "train loss:0.23015840524521747\n",
      "train loss:0.27653604589661435\n",
      "train loss:0.15950386378840278\n",
      "train loss:0.325708782294839\n",
      "train loss:0.23352927818095495\n",
      "train loss:0.4056408876862376\n",
      "train loss:0.381480604260151\n",
      "train loss:0.24860960528936588\n",
      "train loss:0.16770253574787078\n",
      "train loss:0.2540692698238236\n",
      "train loss:0.23254871277727485\n",
      "train loss:0.19911266319472049\n",
      "train loss:0.20076094281256474\n",
      "train loss:0.2510677437458684\n",
      "train loss:0.28205336075093823\n",
      "train loss:0.24193359099884812\n",
      "train loss:0.2946621966113774\n",
      "train loss:0.15115095205297063\n",
      "train loss:0.17574070705564676\n",
      "train loss:0.4478133259336187\n",
      "train loss:0.15594792100630342\n",
      "train loss:0.26656095441981426\n",
      "train loss:0.27687008843989647\n",
      "train loss:0.2437911369552686\n",
      "train loss:0.211369827579777\n",
      "train loss:0.22733037896296074\n",
      "train loss:0.1890466381137834\n",
      "train loss:0.20235410354411545\n",
      "train loss:0.27750502138682037\n",
      "train loss:0.18563384694785587\n",
      "train loss:0.3164346401989216\n",
      "train loss:0.09888387730636802\n",
      "train loss:0.270734029872324\n",
      "train loss:0.2897741679821444\n",
      "train loss:0.2194050104046594\n",
      "train loss:0.23584499805324846\n",
      "train loss:0.23550454902698476\n",
      "train loss:0.32497525991040715\n",
      "train loss:0.25609554247702426\n",
      "train loss:0.3846144809968361\n",
      "train loss:0.23368675633765934\n",
      "train loss:0.2879065239245092\n",
      "train loss:0.21064454988670359\n",
      "train loss:0.4223283707984751\n",
      "train loss:0.22404657966901342\n",
      "train loss:0.33536895392395044\n",
      "train loss:0.26159989819445023\n",
      "train loss:0.31063538760381854\n",
      "train loss:0.22427852810230628\n",
      "train loss:0.2150669213414205\n",
      "train loss:0.1900755608263246\n",
      "train loss:0.2365318280100636\n",
      "train loss:0.2672652314051816\n",
      "train loss:0.17638367561244941\n",
      "train loss:0.20889197716683378\n",
      "train loss:0.24928416933479697\n",
      "train loss:0.20791272193110066\n",
      "train loss:0.19830232505425463\n",
      "train loss:0.2363129908345001\n",
      "train loss:0.2374421197533902\n",
      "train loss:0.30036841220651644\n",
      "train loss:0.34185757527802546\n",
      "train loss:0.21257002626763669\n",
      "train loss:0.2696429444593393\n",
      "train loss:0.22516648729484198\n",
      "train loss:0.1679439978142036\n",
      "train loss:0.4172366868925033\n",
      "train loss:0.22671787995116\n",
      "train loss:0.26953577390221534\n",
      "train loss:0.3859614273014752\n",
      "train loss:0.205435566971611\n",
      "train loss:0.2177293667743685\n",
      "train loss:0.1760476462282422\n",
      "train loss:0.2127534711457697\n",
      "train loss:0.1669166578476997\n",
      "train loss:0.38471018912062405\n",
      "train loss:0.21415470857646743\n",
      "train loss:0.24191722630180315\n",
      "train loss:0.2775975865924675\n",
      "train loss:0.3441290487724383\n",
      "train loss:0.3659777237946987\n",
      "train loss:0.30986739825781023\n",
      "train loss:0.22553070020949012\n",
      "train loss:0.27485550466549635\n",
      "train loss:0.21709484536404663\n",
      "train loss:0.2560037002994789\n",
      "train loss:0.23026962043885987\n",
      "train loss:0.19637528066912824\n",
      "train loss:0.2220732424005718\n",
      "train loss:0.20253714943569853\n",
      "train loss:0.23631111336219643\n",
      "train loss:0.29702882550826215\n",
      "train loss:0.2191667885111046\n",
      "train loss:0.34998240699995664\n",
      "train loss:0.24185807460428413\n",
      "train loss:0.37420019511175456\n",
      "train loss:0.23306897910325047\n",
      "train loss:0.2267649569904497\n",
      "train loss:0.3651726386029425\n",
      "train loss:0.37482425044752365\n",
      "train loss:0.24308066769197814\n",
      "train loss:0.2522066561547768\n",
      "train loss:0.2075421342169152\n",
      "train loss:0.2862308953176383\n",
      "train loss:0.3407385307175658\n",
      "train loss:0.19707545226476347\n",
      "train loss:0.38952501593674704\n",
      "train loss:0.2155450553815145\n",
      "train loss:0.3012045596155599\n",
      "train loss:0.19394189233915715\n",
      "train loss:0.2929135212189741\n",
      "train loss:0.3979706042544246\n",
      "train loss:0.25315000323520087\n",
      "train loss:0.19348288399904182\n",
      "train loss:0.30106283796982297\n",
      "train loss:0.4330640129505398\n",
      "train loss:0.15715234412043924\n",
      "train loss:0.37617070256396984\n",
      "train loss:0.277945103980943\n",
      "train loss:0.12820364629356962\n",
      "train loss:0.33198552839871553\n",
      "train loss:0.311872166422445\n",
      "train loss:0.22644133331769845\n",
      "train loss:0.20483577879438095\n",
      "train loss:0.2666019884370209\n",
      "train loss:0.19893303913306248\n",
      "train loss:0.18387789299719148\n",
      "train loss:0.20122714372932538\n",
      "train loss:0.24249475231075657\n",
      "train loss:0.24462710207005844\n",
      "train loss:0.20756931099168324\n",
      "train loss:0.28233336483597715\n",
      "train loss:0.2856208216050206\n",
      "train loss:0.2171441964064672\n",
      "train loss:0.17994349877587612\n",
      "train loss:0.25314023286281756\n",
      "train loss:0.16655970559285727\n",
      "train loss:0.2792616480676837\n",
      "train loss:0.13677783610278418\n",
      "train loss:0.3456440253697528\n",
      "train loss:0.2651982177914115\n",
      "train loss:0.21011277346018747\n",
      "train loss:0.316434586267988\n",
      "train loss:0.26568294692485606\n",
      "train loss:0.19928252506004224\n",
      "train loss:0.15304665558646674\n",
      "train loss:0.20466200898772055\n",
      "train loss:0.2630679825010304\n",
      "train loss:0.26837879120015573\n",
      "train loss:0.25103835900729193\n",
      "train loss:0.27203705293767966\n",
      "train loss:0.27320514216827246\n",
      "train loss:0.280012898039172\n",
      "train loss:0.22788754974207218\n",
      "train loss:0.28701003611940556\n",
      "train loss:0.1936760129166771\n",
      "train loss:0.13814767768006733\n",
      "train loss:0.3481990394202076\n",
      "train loss:0.3188741689463873\n",
      "train loss:0.23139103493574442\n",
      "train loss:0.2485370004956252\n",
      "train loss:0.20289302223969283\n",
      "train loss:0.23628966229492657\n",
      "train loss:0.2689781348571891\n",
      "train loss:0.26757875352758115\n",
      "train loss:0.16666498177417743\n",
      "train loss:0.17422060676770187\n",
      "train loss:0.26743039632331284\n",
      "train loss:0.22213126283680598\n",
      "train loss:0.404900910087887\n",
      "train loss:0.30642126669898795\n",
      "train loss:0.21978267952806893\n",
      "train loss:0.23958189073373293\n",
      "train loss:0.20481259971055063\n",
      "train loss:0.20055176713910083\n",
      "train loss:0.2186759341904269\n",
      "train loss:0.14003664709658245\n",
      "train loss:0.22579768060962813\n",
      "train loss:0.21907124559539398\n",
      "train loss:0.22025381824194024\n",
      "train loss:0.3184190923228474\n",
      "train loss:0.24455018073815085\n",
      "train loss:0.1927192864571774\n",
      "train loss:0.18783760995986956\n",
      "train loss:0.2435596457356793\n",
      "train loss:0.20863293329845095\n",
      "train loss:0.14212189708991\n",
      "train loss:0.236436573006561\n",
      "train loss:0.28036886530308214\n",
      "train loss:0.10816745948585524\n",
      "train loss:0.21109281897699614\n",
      "train loss:0.24392293414708643\n",
      "train loss:0.2038824675083273\n",
      "train loss:0.17828408135630017\n",
      "train loss:0.28488573235068587\n",
      "train loss:0.31758086180149175\n",
      "train loss:0.2202971656795317\n",
      "train loss:0.16742207731648462\n",
      "train loss:0.20534579460149285\n",
      "train loss:0.22418337593082122\n",
      "train loss:0.1788853765455306\n",
      "train loss:0.2346743085741269\n",
      "train loss:0.23999423659605001\n",
      "train loss:0.17976341217802588\n",
      "train loss:0.2904137758304235\n",
      "train loss:0.21312878465764626\n",
      "train loss:0.2024276784876941\n",
      "train loss:0.31410971517169956\n",
      "train loss:0.15465388348947473\n",
      "train loss:0.14478390373878347\n",
      "train loss:0.2911436612250435\n",
      "train loss:0.32572410362999465\n",
      "train loss:0.24149548769152687\n",
      "train loss:0.19655846170959973\n",
      "train loss:0.24031449943802624\n",
      "train loss:0.1877432880986627\n",
      "train loss:0.27317250370286034\n",
      "train loss:0.1660897352503065\n",
      "train loss:0.1775665636506085\n",
      "train loss:0.1829152927160621\n",
      "train loss:0.3523944418948679\n",
      "train loss:0.18644759047757797\n",
      "train loss:0.23827779643285718\n",
      "train loss:0.12379422242746502\n",
      "train loss:0.3165689935178258\n",
      "train loss:0.3113800573819375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.19439384145666733\n",
      "train loss:0.32324813916774736\n",
      "train loss:0.17856940667278226\n",
      "train loss:0.22474085317885126\n",
      "train loss:0.2288425029686891\n",
      "train loss:0.2402623769812838\n",
      "train loss:0.197710430640449\n",
      "train loss:0.35450777104708264\n",
      "train loss:0.18241360197507045\n",
      "train loss:0.2400586687558209\n",
      "train loss:0.15671560053031744\n",
      "train loss:0.22668926816455814\n",
      "train loss:0.29835334074164005\n",
      "train loss:0.2890750170281433\n",
      "train loss:0.11637356026458928\n",
      "train loss:0.2478453642231885\n",
      "train loss:0.3282373827890772\n",
      "train loss:0.2449578631930434\n",
      "train loss:0.19653436207695585\n",
      "train loss:0.25654976486910225\n",
      "train loss:0.15249124085130383\n",
      "train loss:0.3138285780905923\n",
      "train loss:0.24095874777813575\n",
      "train loss:0.215331152385973\n",
      "train loss:0.27398364599063785\n",
      "train loss:0.29892274414794584\n",
      "train loss:0.2278241679861884\n",
      "train loss:0.23192272823131344\n",
      "train loss:0.19981306635065177\n",
      "train loss:0.21002966366051584\n",
      "train loss:0.12073217601602669\n",
      "train loss:0.19668687756419992\n",
      "train loss:0.303234698627884\n",
      "train loss:0.24854267276369602\n",
      "train loss:0.2965104133774484\n",
      "train loss:0.26632089127036024\n",
      "train loss:0.27880326004016853\n",
      "train loss:0.18333097487226233\n",
      "train loss:0.24546403083076382\n",
      "train loss:0.23013055636892024\n",
      "train loss:0.27040598914692315\n",
      "train loss:0.24016945384309588\n",
      "train loss:0.32906471897226275\n",
      "train loss:0.2554737016916237\n",
      "train loss:0.28382195901525487\n",
      "train loss:0.3424380019182715\n",
      "train loss:0.16602163877223947\n",
      "train loss:0.3680569019262922\n",
      "train loss:0.3376277652233988\n",
      "train loss:0.22021993349286453\n",
      "train loss:0.25554692206972085\n",
      "train loss:0.16417111378350888\n",
      "train loss:0.28272681930478155\n",
      "train loss:0.1786513804688669\n",
      "train loss:0.20503913451902167\n",
      "train loss:0.23867756188090294\n",
      "train loss:0.1438160360388489\n",
      "train loss:0.21233185821210948\n",
      "train loss:0.2762629522015228\n",
      "train loss:0.21886551136587648\n",
      "train loss:0.1863415665777087\n",
      "train loss:0.2625693101177079\n",
      "train loss:0.20810870892854821\n",
      "train loss:0.21116043469210172\n",
      "train loss:0.270054746339108\n",
      "train loss:0.3009341745221239\n",
      "train loss:0.21123628498644223\n",
      "train loss:0.14218438894665003\n",
      "train loss:0.14361743364919632\n",
      "train loss:0.3913592083310661\n",
      "train loss:0.27216830273008796\n",
      "train loss:0.24185150857660104\n",
      "train loss:0.24906626879362512\n",
      "train loss:0.20313210575156798\n",
      "train loss:0.23717590189887067\n",
      "train loss:0.3073731539749131\n",
      "train loss:0.19274800819258917\n",
      "train loss:0.19734960210905272\n",
      "train loss:0.2919776437985974\n",
      "train loss:0.20739868953816176\n",
      "train loss:0.3749921574675868\n",
      "train loss:0.16847185197992093\n",
      "train loss:0.2921180053174\n",
      "train loss:0.21440492443439715\n",
      "train loss:0.19034288596009774\n",
      "train loss:0.276340670697223\n",
      "train loss:0.22552454847346418\n",
      "train loss:0.17397668280102457\n",
      "train loss:0.21000048757022313\n",
      "train loss:0.32412217804107746\n",
      "train loss:0.3098640426226472\n",
      "train loss:0.20470726794982216\n",
      "train loss:0.1687021140894578\n",
      "train loss:0.19339800279988995\n",
      "train loss:0.18411166618229138\n",
      "train loss:0.1561989290682856\n",
      "train loss:0.19487053083391345\n",
      "train loss:0.20342936683541066\n",
      "train loss:0.2206160835132056\n",
      "train loss:0.2810513858883768\n",
      "train loss:0.3494581233499309\n",
      "train loss:0.18905075688599168\n",
      "train loss:0.26676846317248154\n",
      "train loss:0.14631300524992155\n",
      "train loss:0.24425490814270834\n",
      "train loss:0.17252802300532288\n",
      "train loss:0.33333361782139\n",
      "train loss:0.16966611144416383\n",
      "train loss:0.24670805864306555\n",
      "train loss:0.20422796836316096\n",
      "train loss:0.23938447484578745\n",
      "train loss:0.2099494042693134\n",
      "train loss:0.2618470071100032\n",
      "train loss:0.3419971068472178\n",
      "train loss:0.25281659447553534\n",
      "train loss:0.19773101598960643\n",
      "train loss:0.18455119779102905\n",
      "train loss:0.25518435849309606\n",
      "train loss:0.280482042163705\n",
      "train loss:0.31876037055554146\n",
      "train loss:0.21825739849129946\n",
      "train loss:0.17926676664036342\n",
      "train loss:0.2260979390525218\n",
      "train loss:0.2802129108694203\n",
      "train loss:0.21056705823607738\n",
      "train loss:0.25992248673867274\n",
      "train loss:0.24606079806127268\n",
      "train loss:0.21692725560604223\n",
      "train loss:0.18028906113658139\n",
      "train loss:0.20116694873327617\n",
      "train loss:0.3885667819916636\n",
      "train loss:0.3265379932250548\n",
      "train loss:0.1711202582362389\n",
      "train loss:0.1952915354645501\n",
      "train loss:0.19458014122078895\n",
      "train loss:0.20553477194963313\n",
      "train loss:0.14287918935498928\n",
      "train loss:0.17258087432330277\n",
      "train loss:0.2385586354260587\n",
      "train loss:0.18219917452374465\n",
      "train loss:0.15971604113740498\n",
      "train loss:0.2153311169456468\n",
      "train loss:0.19649714930889003\n",
      "train loss:0.1962165885834263\n",
      "train loss:0.15368930422177057\n",
      "train loss:0.31371659140572644\n",
      "train loss:0.15462818702155273\n",
      "train loss:0.29110616522723864\n",
      "train loss:0.280873872608619\n",
      "train loss:0.17982144747748685\n",
      "train loss:0.2672502166835601\n",
      "train loss:0.27239052896756216\n",
      "train loss:0.25265330695969834\n",
      "train loss:0.20983591952584957\n",
      "train loss:0.17071086258440446\n",
      "train loss:0.24116666902928277\n",
      "train loss:0.17873874204660567\n",
      "train loss:0.2302831399943308\n",
      "train loss:0.23529581438883482\n",
      "train loss:0.23880440793982172\n",
      "train loss:0.20855417109663477\n",
      "train loss:0.28908576275455206\n",
      "train loss:0.30168134430663085\n",
      "train loss:0.23320525457086333\n",
      "train loss:0.2612376043546742\n",
      "train loss:0.21821687821620983\n",
      "train loss:0.25013206125205645\n",
      "train loss:0.10863420684700166\n",
      "train loss:0.24708481834917648\n",
      "train loss:0.30831711520902383\n",
      "train loss:0.3111267444828906\n",
      "train loss:0.3245312589399528\n",
      "train loss:0.1945507599633469\n",
      "train loss:0.18413282249026305\n",
      "train loss:0.26810130768243484\n",
      "train loss:0.2658535874133868\n",
      "train loss:0.27659168335951223\n",
      "train loss:0.1105067101390523\n",
      "train loss:0.1426501940637293\n",
      "train loss:0.18252735293099284\n",
      "train loss:0.327206305595704\n",
      "train loss:0.23722742402145144\n",
      "train loss:0.30721083476913935\n",
      "train loss:0.22354014601921945\n",
      "train loss:0.2363185688153391\n",
      "train loss:0.21875462535366252\n",
      "train loss:0.2272974191800552\n",
      "train loss:0.18218957358554172\n",
      "train loss:0.17674369857402936\n",
      "train loss:0.21260974766186283\n",
      "train loss:0.18436949491483698\n",
      "train loss:0.17815868666930462\n",
      "train loss:0.32163134724668496\n",
      "train loss:0.21570551471907554\n",
      "train loss:0.31349155128923867\n",
      "train loss:0.20004245400100074\n",
      "train loss:0.21543446776972908\n",
      "train loss:0.23287900724858843\n",
      "train loss:0.16999949332069955\n",
      "train loss:0.18141872000346207\n",
      "train loss:0.14935555048591923\n",
      "train loss:0.1777323144563824\n",
      "train loss:0.29868865085856244\n",
      "train loss:0.3109736466767128\n",
      "train loss:0.14111411970755247\n",
      "train loss:0.16952095600709569\n",
      "train loss:0.23381084863457027\n",
      "train loss:0.09889044362005636\n",
      "train loss:0.2665060709689786\n",
      "train loss:0.20884796888559123\n",
      "train loss:0.3386095083425111\n",
      "train loss:0.205269840333466\n",
      "train loss:0.23794804836570146\n",
      "train loss:0.17708128276218837\n",
      "train loss:0.25413512344583833\n",
      "train loss:0.3212934879144154\n",
      "train loss:0.2679380523986637\n",
      "train loss:0.21190126347051497\n",
      "train loss:0.23732669573240095\n",
      "train loss:0.1886489835145452\n",
      "train loss:0.20791438145143157\n",
      "train loss:0.25840729582829636\n",
      "train loss:0.25298776848861093\n",
      "train loss:0.15709635562870272\n",
      "train loss:0.23870696580486922\n",
      "train loss:0.3165699555283416\n",
      "train loss:0.14987813700085323\n",
      "train loss:0.2569265537089659\n",
      "train loss:0.2242397072845456\n",
      "train loss:0.23778091075021593\n",
      "train loss:0.2960945193791074\n",
      "train loss:0.12106089290906284\n",
      "train loss:0.20266172418771408\n",
      "train loss:0.24748551764490695\n",
      "train loss:0.1726161690160727\n",
      "train loss:0.20236085866518053\n",
      "train loss:0.28080106459948584\n",
      "train loss:0.3961995706319153\n",
      "train loss:0.18395035139254287\n",
      "train loss:0.23024491894064802\n",
      "train loss:0.28761399982936664\n",
      "train loss:0.17617941592716233\n",
      "train loss:0.27166435628532065\n",
      "train loss:0.1826824920124447\n",
      "train loss:0.24246177881309466\n",
      "train loss:0.3581100215647359\n",
      "train loss:0.2474896878140121\n",
      "train loss:0.2670003041347512\n",
      "train loss:0.1623698127411573\n",
      "train loss:0.19583871616985157\n",
      "train loss:0.34706767255297655\n",
      "train loss:0.24879067945085187\n",
      "train loss:0.23365103456689623\n",
      "train loss:0.1863400434630945\n",
      "train loss:0.22013951775329485\n",
      "train loss:0.19296925532280532\n",
      "train loss:0.2699713911842134\n",
      "train loss:0.23595077457390412\n",
      "train loss:0.28458568148634994\n",
      "train loss:0.30392230968834594\n",
      "train loss:0.24214802317058287\n",
      "train loss:0.1922749498873628\n",
      "train loss:0.17502202105327544\n",
      "train loss:0.2639617424810816\n",
      "train loss:0.2398197156046584\n",
      "train loss:0.2312678985764831\n",
      "train loss:0.18813467504454046\n",
      "train loss:0.30071656500015714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.2607296464304096\n",
      "train loss:0.2440959038142682\n",
      "train loss:0.36976200778221746\n",
      "train loss:0.2182874640258565\n",
      "train loss:0.18032697961747715\n",
      "train loss:0.21016895909689295\n",
      "train loss:0.21698036088398687\n",
      "train loss:0.1372184733748181\n",
      "train loss:0.15218278963236426\n",
      "train loss:0.2921393438841859\n",
      "train loss:0.2321119369746707\n",
      "train loss:0.21347068085132903\n",
      "train loss:0.2517415719989103\n",
      "train loss:0.15746682755665217\n",
      "train loss:0.20999003187476353\n",
      "train loss:0.2767577074628961\n",
      "train loss:0.17134743535657307\n",
      "train loss:0.19400032913155937\n",
      "train loss:0.20061183690442\n",
      "train loss:0.3109562496932983\n",
      "train loss:0.21684366610946604\n",
      "train loss:0.2629723708375684\n",
      "train loss:0.3160631850974176\n",
      "train loss:0.1648340181220419\n",
      "train loss:0.27678610780018287\n",
      "train loss:0.20726304760742895\n",
      "train loss:0.28810670226802537\n",
      "train loss:0.18658275053426931\n",
      "train loss:0.1790190734922123\n",
      "train loss:0.21636895790286195\n",
      "train loss:0.22319291090222693\n",
      "train loss:0.15328090746710626\n",
      "train loss:0.2544965322807702\n",
      "train loss:0.24160264966270995\n",
      "train loss:0.2595308101387587\n",
      "train loss:0.3248585953283882\n",
      "train loss:0.24585715148608306\n",
      "train loss:0.25845814766118613\n",
      "train loss:0.20466143435156983\n",
      "train loss:0.3425076523776825\n",
      "train loss:0.09877965394208425\n",
      "train loss:0.2050766531754005\n",
      "train loss:0.32545428660136017\n",
      "train loss:0.20553660348949887\n",
      "train loss:0.2210349897808423\n",
      "train loss:0.22663688681224334\n",
      "train loss:0.17736311719229314\n",
      "train loss:0.17583251991566018\n",
      "train loss:0.34589406477567913\n",
      "train loss:0.1734053918482719\n",
      "train loss:0.14831415947336157\n",
      "train loss:0.23807464939171308\n",
      "train loss:0.19887896507586714\n",
      "train loss:0.28071116858139106\n",
      "train loss:0.17773531855645217\n",
      "train loss:0.19415171430115868\n",
      "train loss:0.24579450339700656\n",
      "train loss:0.17107992089835627\n",
      "train loss:0.1573333197347171\n",
      "train loss:0.23908650274730966\n",
      "train loss:0.255326431634353\n",
      "train loss:0.2992970156206922\n",
      "train loss:0.20915903130168398\n",
      "train loss:0.25645013541554335\n",
      "train loss:0.22777588488413472\n",
      "train loss:0.18407712216141234\n",
      "train loss:0.15300361006104668\n",
      "train loss:0.15990204613014397\n",
      "train loss:0.18811597533515456\n",
      "train loss:0.1747572949996927\n",
      "train loss:0.15200797019119158\n",
      "train loss:0.1307158659954126\n",
      "train loss:0.15136495325766972\n",
      "train loss:0.1760379656358059\n",
      "train loss:0.2450474912798191\n",
      "train loss:0.3239966830439646\n",
      "train loss:0.14042860583730912\n",
      "train loss:0.18471149573652068\n",
      "train loss:0.23327685167544818\n",
      "train loss:0.33696358341625193\n",
      "train loss:0.12773474297096254\n",
      "train loss:0.2015400649030504\n",
      "train loss:0.26208330199826174\n",
      "train loss:0.149336184926769\n",
      "train loss:0.256718778401835\n",
      "train loss:0.23634427263464186\n",
      "train loss:0.29151955846197786\n",
      "train loss:0.13222296726774643\n",
      "train loss:0.2150427835626639\n",
      "train loss:0.27874594505173217\n",
      "train loss:0.12256568520054217\n",
      "train loss:0.22228734246281184\n",
      "train loss:0.15332912857952502\n",
      "train loss:0.2196573136793186\n",
      "train loss:0.20308979104902516\n",
      "train loss:0.24437514343259178\n",
      "train loss:0.26214625021830834\n",
      "train loss:0.2188251064804822\n",
      "train loss:0.40492514463896806\n",
      "train loss:0.23813925932381308\n",
      "train loss:0.17449499809317273\n",
      "=== epoch:7, train acc:0.926, test acc:0.895 ===\n",
      "train loss:0.1632824615937097\n",
      "train loss:0.13257826473615325\n",
      "train loss:0.2306613404620309\n",
      "train loss:0.24622125606727438\n",
      "train loss:0.28038919404080315\n",
      "train loss:0.14802822452735734\n",
      "train loss:0.2700688838263028\n",
      "train loss:0.2920266188502808\n",
      "train loss:0.17901753297302947\n",
      "train loss:0.3239716497237446\n",
      "train loss:0.11965189012182682\n",
      "train loss:0.1887949032179877\n",
      "train loss:0.1612822009982284\n",
      "train loss:0.1775519343834582\n",
      "train loss:0.11671294170859127\n",
      "train loss:0.26888284144057356\n",
      "train loss:0.2259715673390208\n",
      "train loss:0.17703279201723082\n",
      "train loss:0.24076495365288506\n",
      "train loss:0.22836010613337288\n",
      "train loss:0.20613574237522733\n",
      "train loss:0.23209671720248137\n",
      "train loss:0.23610644723691654\n",
      "train loss:0.12271123274108224\n",
      "train loss:0.24464467605697254\n",
      "train loss:0.16595333573385468\n",
      "train loss:0.29266490558661723\n",
      "train loss:0.1278348931740635\n",
      "train loss:0.1524519052021546\n",
      "train loss:0.16847982953721907\n",
      "train loss:0.22067465240293832\n",
      "train loss:0.23660983007943692\n",
      "train loss:0.18499213864969022\n",
      "train loss:0.26498143879510444\n",
      "train loss:0.17554659104571488\n",
      "train loss:0.10451051122383548\n",
      "train loss:0.1599337195763341\n",
      "train loss:0.18856150048277026\n",
      "train loss:0.23543758204352855\n",
      "train loss:0.2166133501787076\n",
      "train loss:0.10973585176201862\n",
      "train loss:0.21566395376300482\n",
      "train loss:0.15804937488563053\n",
      "train loss:0.18846080007264274\n",
      "train loss:0.3287818940366961\n",
      "train loss:0.14190179713489273\n",
      "train loss:0.17878020360143207\n",
      "train loss:0.18408286928255282\n",
      "train loss:0.23459366843597335\n",
      "train loss:0.18418702555497857\n",
      "train loss:0.1995856887796974\n",
      "train loss:0.26588602073803896\n",
      "train loss:0.21484298197768936\n",
      "train loss:0.20660873228499063\n",
      "train loss:0.1720869527131482\n",
      "train loss:0.19867996722192185\n",
      "train loss:0.2760842700383615\n",
      "train loss:0.17066608358648314\n",
      "train loss:0.1983081020001755\n",
      "train loss:0.18693548660331616\n",
      "train loss:0.20562829281264874\n",
      "train loss:0.19716401534352246\n",
      "train loss:0.27549045750589934\n",
      "train loss:0.23198484667344627\n",
      "train loss:0.20307851314761322\n",
      "train loss:0.23417693635118503\n",
      "train loss:0.2000928572127458\n",
      "train loss:0.11384093575399444\n",
      "train loss:0.10470614237248382\n",
      "train loss:0.27029393123960893\n",
      "train loss:0.15454270474175047\n",
      "train loss:0.22020284044459384\n",
      "train loss:0.322226865578859\n",
      "train loss:0.17562364999232002\n",
      "train loss:0.21424208755807733\n",
      "train loss:0.2678718051053305\n",
      "train loss:0.16722416576189378\n",
      "train loss:0.3252613417014328\n",
      "train loss:0.15740150277763504\n",
      "train loss:0.2749005988672241\n",
      "train loss:0.24381890558371985\n",
      "train loss:0.16544194988650715\n",
      "train loss:0.17609972525699122\n",
      "train loss:0.16957157698407538\n",
      "train loss:0.1704841161297464\n",
      "train loss:0.2976204607821808\n",
      "train loss:0.2648468978917492\n",
      "train loss:0.2824588393157405\n",
      "train loss:0.21205732394100732\n",
      "train loss:0.20430613397109354\n",
      "train loss:0.20318747346412394\n",
      "train loss:0.31385311937991106\n",
      "train loss:0.22976462784278703\n",
      "train loss:0.22311100211094362\n",
      "train loss:0.12393376411823166\n",
      "train loss:0.2126529615893561\n",
      "train loss:0.18291994990983781\n",
      "train loss:0.2077453663567178\n",
      "train loss:0.24411615362642702\n",
      "train loss:0.16919488741351696\n",
      "train loss:0.2603661178688261\n",
      "train loss:0.22916041231526696\n",
      "train loss:0.1644835370134526\n",
      "train loss:0.14455716471151298\n",
      "train loss:0.1849655154415526\n",
      "train loss:0.12979069232849544\n",
      "train loss:0.26424054854076107\n",
      "train loss:0.32484639203178944\n",
      "train loss:0.18235651225581972\n",
      "train loss:0.14398300935284136\n",
      "train loss:0.13488840900258858\n",
      "train loss:0.1461809706626138\n",
      "train loss:0.11650647216584596\n",
      "train loss:0.14084122375201377\n",
      "train loss:0.1977630071961836\n",
      "train loss:0.06267967573646567\n",
      "train loss:0.19250721791326397\n",
      "train loss:0.252433327668195\n",
      "train loss:0.2365460196566666\n",
      "train loss:0.18996828401217639\n",
      "train loss:0.30718230562110743\n",
      "train loss:0.16825254350876345\n",
      "train loss:0.17080891334362366\n",
      "train loss:0.21846679967822388\n",
      "train loss:0.261746131378526\n",
      "train loss:0.2308980148142928\n",
      "train loss:0.2808789069140646\n",
      "train loss:0.203291632509877\n",
      "train loss:0.1313051467076708\n",
      "train loss:0.29212381695802186\n",
      "train loss:0.31771533900805976\n",
      "train loss:0.20299592069346503\n",
      "train loss:0.13953394102702274\n",
      "train loss:0.19821333173826347\n",
      "train loss:0.2666075341094039\n",
      "train loss:0.22345457336683236\n",
      "train loss:0.2875708187902799\n",
      "train loss:0.3815719564849063\n",
      "train loss:0.2498262674234621\n",
      "train loss:0.2198623616267378\n",
      "train loss:0.15427837886465487\n",
      "train loss:0.18949458302423744\n",
      "train loss:0.15021654528986045\n",
      "train loss:0.1536749211084397\n",
      "train loss:0.2916269395884614\n",
      "train loss:0.2446347996278365\n",
      "train loss:0.2110704397895765\n",
      "train loss:0.1624509204831041\n",
      "train loss:0.17285047235924927\n",
      "train loss:0.26549996318349944\n",
      "train loss:0.21445844678655338\n",
      "train loss:0.27840138549278526\n",
      "train loss:0.1634174033974432\n",
      "train loss:0.3176457779284237\n",
      "train loss:0.1889534493145581\n",
      "train loss:0.21499553374013303\n",
      "train loss:0.17918440193486687\n",
      "train loss:0.25707514468250797\n",
      "train loss:0.1413190853376242\n",
      "train loss:0.2551836712165718\n",
      "train loss:0.24031460767260016\n",
      "train loss:0.16503882838019168\n",
      "train loss:0.3052577676042527\n",
      "train loss:0.3501035784486461\n",
      "train loss:0.1424329282645293\n",
      "train loss:0.16804503562408615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.23053267214306422\n",
      "train loss:0.2707523307347929\n",
      "train loss:0.28540789711285275\n",
      "train loss:0.1519048549544108\n",
      "train loss:0.2737705337362676\n",
      "train loss:0.24395151210653976\n",
      "train loss:0.15656210460597936\n",
      "train loss:0.21454089498144474\n",
      "train loss:0.17470537089581076\n",
      "train loss:0.2691966332330759\n",
      "train loss:0.14791139032329095\n",
      "train loss:0.0982948591838776\n",
      "train loss:0.23239850645618915\n",
      "train loss:0.1284303045704906\n",
      "train loss:0.23619588424368235\n",
      "train loss:0.22001750082026533\n",
      "train loss:0.15778601603049883\n",
      "train loss:0.21846679708103603\n",
      "train loss:0.34443279003834576\n",
      "train loss:0.1765562805675718\n",
      "train loss:0.18918931328259872\n",
      "train loss:0.2088636177243438\n",
      "train loss:0.20698580275405487\n",
      "train loss:0.24322042183960194\n",
      "train loss:0.27572343062175547\n",
      "train loss:0.34881897697944697\n",
      "train loss:0.28424503772294163\n",
      "train loss:0.19666226775565993\n",
      "train loss:0.2116246573583413\n",
      "train loss:0.16283805929174683\n",
      "train loss:0.23219981945736926\n",
      "train loss:0.2516381397563898\n",
      "train loss:0.12259642401315977\n",
      "train loss:0.22059841674529182\n",
      "train loss:0.2497478858432228\n",
      "train loss:0.12469395171078239\n",
      "train loss:0.21956751525742124\n",
      "train loss:0.27558712607183256\n",
      "train loss:0.16548632945846556\n",
      "train loss:0.21158935095896653\n",
      "train loss:0.1423563369728759\n",
      "train loss:0.2514549076071213\n",
      "train loss:0.12626005865245282\n",
      "train loss:0.22446162240649722\n",
      "train loss:0.17492098512966542\n",
      "train loss:0.2823586071211037\n",
      "train loss:0.18207714463133512\n",
      "train loss:0.16932940637894794\n",
      "train loss:0.16944123340870937\n",
      "train loss:0.16641976744409628\n",
      "train loss:0.1460487934650535\n",
      "train loss:0.25402610966566647\n",
      "train loss:0.2480446587285173\n",
      "train loss:0.240407385482464\n",
      "train loss:0.2734475252784337\n",
      "train loss:0.3506538177912845\n",
      "train loss:0.23423508271629945\n",
      "train loss:0.1896953216997429\n",
      "train loss:0.20356960596306603\n",
      "train loss:0.2913607925404806\n",
      "train loss:0.1412565265898028\n",
      "train loss:0.2868599086617364\n",
      "train loss:0.21095512523507115\n",
      "train loss:0.3326555491830097\n",
      "train loss:0.2331439827853987\n",
      "train loss:0.1971095383499361\n",
      "train loss:0.22324180370450297\n",
      "train loss:0.33858646676341264\n",
      "train loss:0.29997880239170693\n",
      "train loss:0.1838022123230843\n",
      "train loss:0.1789301498345492\n",
      "train loss:0.17605619034355993\n",
      "train loss:0.2291379747829796\n",
      "train loss:0.1977664400744822\n",
      "train loss:0.23941805347955267\n",
      "train loss:0.22947642057277043\n",
      "train loss:0.23145236700018224\n",
      "train loss:0.2684872701596074\n",
      "train loss:0.2110235216203258\n",
      "train loss:0.2605866555929099\n",
      "train loss:0.2536588298930432\n",
      "train loss:0.2158019176628706\n",
      "train loss:0.18012036062260806\n",
      "train loss:0.21896261693735283\n",
      "train loss:0.22457477540055704\n",
      "train loss:0.2662480854730804\n",
      "train loss:0.2801253710119431\n",
      "train loss:0.1906960886522484\n",
      "train loss:0.33796778458316884\n",
      "train loss:0.1959150291053382\n",
      "train loss:0.354952926103446\n",
      "train loss:0.16161246192534912\n",
      "train loss:0.2176738510075327\n",
      "train loss:0.20068992463815274\n",
      "train loss:0.21930636422635616\n",
      "train loss:0.2068481405452535\n",
      "train loss:0.26173941004847234\n",
      "train loss:0.23210671268559022\n",
      "train loss:0.40134306386544516\n",
      "train loss:0.1271170054775004\n",
      "train loss:0.2743736005385303\n",
      "train loss:0.19760012061906182\n",
      "train loss:0.3595996551830152\n",
      "train loss:0.18099374507955257\n",
      "train loss:0.19812422021233625\n",
      "train loss:0.18531877083360526\n",
      "train loss:0.1367691501334526\n",
      "train loss:0.14256020427407556\n",
      "train loss:0.2165872084419368\n",
      "train loss:0.14593885750022642\n",
      "train loss:0.17268234424131135\n",
      "train loss:0.13838977714446501\n",
      "train loss:0.21383901537293964\n",
      "train loss:0.17993335805324745\n",
      "train loss:0.16291286181072934\n",
      "train loss:0.23659766303047394\n",
      "train loss:0.1767938969001251\n",
      "train loss:0.274128561453727\n",
      "train loss:0.1890576038027828\n",
      "train loss:0.23745959377044276\n",
      "train loss:0.2769231131602794\n",
      "train loss:0.4101924416571234\n",
      "train loss:0.19799735990855258\n",
      "train loss:0.27152415117100664\n",
      "train loss:0.2051127612822166\n",
      "train loss:0.32757487403887\n",
      "train loss:0.19007724331164122\n",
      "train loss:0.17237378653567748\n",
      "train loss:0.27498439178756207\n",
      "train loss:0.4095394284259787\n",
      "train loss:0.19929522605853187\n",
      "train loss:0.19733151561870316\n",
      "train loss:0.12005869140897098\n",
      "train loss:0.15050017919935232\n",
      "train loss:0.16070246841484573\n",
      "train loss:0.23158137737345416\n",
      "train loss:0.14475563211192816\n",
      "train loss:0.34798367127553737\n",
      "train loss:0.14830789199664182\n",
      "train loss:0.1815911038533894\n",
      "train loss:0.18926800833824708\n",
      "train loss:0.09694257557567719\n",
      "train loss:0.2100877335963897\n",
      "train loss:0.255525595826449\n",
      "train loss:0.13862390997917534\n",
      "train loss:0.26641835618230997\n",
      "train loss:0.19174282141649657\n",
      "train loss:0.2942731142610541\n",
      "train loss:0.11140624025053393\n",
      "train loss:0.21458494642310977\n",
      "train loss:0.18040035079510616\n",
      "train loss:0.32075336266253224\n",
      "train loss:0.23057476271723437\n",
      "train loss:0.10891297210189389\n",
      "train loss:0.1407500469564548\n",
      "train loss:0.16648659550412026\n",
      "train loss:0.14704787952311277\n",
      "train loss:0.27557362289703613\n",
      "train loss:0.12719018261272855\n",
      "train loss:0.18551691080104557\n",
      "train loss:0.1789984570768138\n",
      "train loss:0.15960054168646903\n",
      "train loss:0.20095920508388962\n",
      "train loss:0.15809628001082632\n",
      "train loss:0.27401551913011796\n",
      "train loss:0.23874686410443058\n",
      "train loss:0.24613714003596104\n",
      "train loss:0.1454182977126389\n",
      "train loss:0.1292241556528709\n",
      "train loss:0.16292976447067833\n",
      "train loss:0.15283495679105025\n",
      "train loss:0.16834927177338124\n",
      "train loss:0.20093440826840417\n",
      "train loss:0.2377969124103739\n",
      "train loss:0.2355167568214904\n",
      "train loss:0.16750948697367124\n",
      "train loss:0.20931113382318783\n",
      "train loss:0.34112244147547577\n",
      "train loss:0.21686583288584033\n",
      "train loss:0.23968157253376834\n",
      "train loss:0.1856635952875822\n",
      "train loss:0.1149892755435998\n",
      "train loss:0.18932938390946322\n",
      "train loss:0.1446697978202403\n",
      "train loss:0.30038245655068296\n",
      "train loss:0.32239480496727163\n",
      "train loss:0.35566939485210725\n",
      "train loss:0.19844181290403115\n",
      "train loss:0.32063859980993525\n",
      "train loss:0.20679852134362656\n",
      "train loss:0.17234445465371617\n",
      "train loss:0.17017921117870724\n",
      "train loss:0.15747063765571886\n",
      "train loss:0.18536902810323025\n",
      "train loss:0.27656471482009926\n",
      "train loss:0.13175576727836347\n",
      "train loss:0.1960978195307915\n",
      "train loss:0.1850721653809189\n",
      "train loss:0.2236250909468025\n",
      "train loss:0.26760643176558363\n",
      "train loss:0.2542925548467795\n",
      "train loss:0.15717558255991773\n",
      "train loss:0.23813885815875388\n",
      "train loss:0.2258380194003774\n",
      "train loss:0.20880626647172737\n",
      "train loss:0.1537828790973087\n",
      "train loss:0.21698846946963488\n",
      "train loss:0.19523425382306178\n",
      "train loss:0.2422644612608029\n",
      "train loss:0.29341242928055977\n",
      "train loss:0.20539799334349176\n",
      "train loss:0.08149056174017275\n",
      "train loss:0.24761934816850484\n",
      "train loss:0.18600810273119406\n",
      "train loss:0.31044221888391665\n",
      "train loss:0.20851311368093167\n",
      "train loss:0.16606529091376146\n",
      "train loss:0.15797864144842463\n",
      "train loss:0.25278571437589387\n",
      "train loss:0.1985536035759897\n",
      "train loss:0.2387873086763372\n",
      "train loss:0.20088924787869722\n",
      "train loss:0.21485080292103192\n",
      "train loss:0.3286423239003785\n",
      "train loss:0.10501070530778703\n",
      "train loss:0.18702489531354677\n",
      "train loss:0.15838264600414254\n",
      "train loss:0.2509195561450365\n",
      "train loss:0.1456333512736405\n",
      "train loss:0.22462372426481061\n",
      "train loss:0.24212206104340045\n",
      "train loss:0.3165081247830811\n",
      "train loss:0.22201263721514358\n",
      "train loss:0.15449910057278704\n",
      "train loss:0.13439136595075415\n",
      "train loss:0.18870755560568284\n",
      "train loss:0.16722380834699585\n",
      "train loss:0.2513761914837193\n",
      "train loss:0.21928954844686885\n",
      "train loss:0.26851709645626554\n",
      "train loss:0.21666803028650392\n",
      "train loss:0.1974656118088009\n",
      "train loss:0.1903158689500601\n",
      "train loss:0.17240888556823517\n",
      "train loss:0.24247696383250336\n",
      "train loss:0.2021003224698986\n",
      "train loss:0.16841285580157514\n",
      "train loss:0.2961339850451267\n",
      "train loss:0.2230855577557755\n",
      "train loss:0.20030307883825998\n",
      "train loss:0.14859800606559262\n",
      "train loss:0.32927480446571467\n",
      "train loss:0.21171520670207739\n",
      "train loss:0.16296849563744542\n",
      "train loss:0.1728797877472061\n",
      "train loss:0.09615081103271315\n",
      "train loss:0.20475766143773597\n",
      "train loss:0.23544436556898596\n",
      "train loss:0.18234916638831603\n",
      "train loss:0.18479594009070285\n",
      "train loss:0.1877753813581267\n",
      "train loss:0.2517460455768897\n",
      "train loss:0.19942928923000786\n",
      "train loss:0.2516011810101125\n",
      "train loss:0.19980656827736545\n",
      "train loss:0.2832471542859122\n",
      "train loss:0.128568581169336\n",
      "train loss:0.25943726141702766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.2358043540920296\n",
      "train loss:0.13597842211102085\n",
      "train loss:0.17187655084944048\n",
      "train loss:0.20528561110328408\n",
      "train loss:0.1571767843767018\n",
      "train loss:0.16389850847517326\n",
      "train loss:0.24789126943353168\n",
      "train loss:0.16201108457346866\n",
      "train loss:0.19667796670002755\n",
      "train loss:0.12114365402830385\n",
      "train loss:0.1764152007076375\n",
      "train loss:0.2000606466689199\n",
      "train loss:0.3263975003903765\n",
      "train loss:0.17505032127075507\n",
      "train loss:0.23477601356878758\n",
      "train loss:0.18532319716592885\n",
      "train loss:0.18132959946127086\n",
      "train loss:0.13619088385403702\n",
      "train loss:0.1957910902060238\n",
      "train loss:0.08775675980714814\n",
      "train loss:0.2560226106204395\n",
      "train loss:0.24658679388349114\n",
      "train loss:0.19386295702966794\n",
      "train loss:0.19509595537614208\n",
      "train loss:0.16503459510279073\n",
      "train loss:0.18881266047198225\n",
      "train loss:0.2146278465242903\n",
      "train loss:0.19197948878817023\n",
      "train loss:0.12793858500509117\n",
      "train loss:0.165693554985966\n",
      "train loss:0.17763056606800143\n",
      "train loss:0.14614619897114056\n",
      "train loss:0.21118198147951198\n",
      "train loss:0.1784753581940486\n",
      "train loss:0.17750252543872963\n",
      "train loss:0.12324454136379864\n",
      "train loss:0.2560502961978266\n",
      "train loss:0.19055022434367286\n",
      "train loss:0.3117642198558456\n",
      "train loss:0.16519580616305773\n",
      "train loss:0.3178678788413731\n",
      "train loss:0.1360604434680599\n",
      "train loss:0.14498911076267948\n",
      "train loss:0.26176930956176675\n",
      "train loss:0.19275301542974688\n",
      "train loss:0.21546492643386825\n",
      "train loss:0.15399628133674692\n",
      "train loss:0.12108334163353464\n",
      "train loss:0.22513244518868042\n",
      "train loss:0.2677815929943968\n",
      "train loss:0.24690939612917423\n",
      "train loss:0.19146339907853815\n",
      "train loss:0.1413832749091107\n",
      "train loss:0.23266741988711742\n",
      "train loss:0.22578758687397493\n",
      "train loss:0.12226084011725381\n",
      "train loss:0.19221161626927383\n",
      "train loss:0.18332174391620085\n",
      "train loss:0.2580485692704937\n",
      "train loss:0.3802415694902999\n",
      "train loss:0.19112418015598087\n",
      "train loss:0.14142052232438113\n",
      "train loss:0.18325215764296673\n",
      "train loss:0.21241102708862986\n",
      "train loss:0.1637067912654393\n",
      "train loss:0.20134065773856094\n",
      "train loss:0.1820227478750244\n",
      "train loss:0.16303230769216573\n",
      "train loss:0.201594779425426\n",
      "train loss:0.17410378752683323\n",
      "train loss:0.1680221079861274\n",
      "train loss:0.07883288709488662\n",
      "train loss:0.14397795925556886\n",
      "train loss:0.35753880417476647\n",
      "train loss:0.2752790220119054\n",
      "train loss:0.1432488997828802\n",
      "train loss:0.2979246396138229\n",
      "train loss:0.18832319759699095\n",
      "train loss:0.24530298926786742\n",
      "train loss:0.26473278672389405\n",
      "train loss:0.17471217080254853\n",
      "train loss:0.20226177188393663\n",
      "train loss:0.251873092984831\n",
      "train loss:0.21214400021585006\n",
      "train loss:0.16097886638798606\n",
      "train loss:0.14766195303814678\n",
      "train loss:0.25267679430398976\n",
      "train loss:0.12646868951671877\n",
      "train loss:0.18805747438523024\n",
      "train loss:0.19563501329072658\n",
      "train loss:0.2418510707979786\n",
      "train loss:0.12174555282125006\n",
      "train loss:0.2268637217506612\n",
      "train loss:0.1475124337674354\n",
      "train loss:0.26418968951190874\n",
      "train loss:0.1340257985248512\n",
      "train loss:0.2152358514206542\n",
      "train loss:0.13565865079306771\n",
      "train loss:0.21335320372475589\n",
      "train loss:0.21545402760565005\n",
      "train loss:0.14718903143292988\n",
      "train loss:0.1945882849633808\n",
      "train loss:0.24151958642539054\n",
      "train loss:0.27453737695347463\n",
      "train loss:0.1545917236065066\n",
      "train loss:0.1145087347299798\n",
      "train loss:0.2309466392322751\n",
      "train loss:0.21958006196904503\n",
      "train loss:0.2860199333548984\n",
      "train loss:0.2917004255188892\n",
      "train loss:0.16725016192595565\n",
      "train loss:0.2229292243525955\n",
      "train loss:0.18868080762696343\n",
      "train loss:0.2255423012656602\n",
      "train loss:0.14286789844175676\n",
      "train loss:0.22723215728437246\n",
      "train loss:0.17565902542871228\n",
      "train loss:0.12080669398464705\n",
      "train loss:0.20482981913846462\n",
      "train loss:0.236044863063105\n",
      "train loss:0.18832536888138254\n",
      "train loss:0.250638129333064\n",
      "train loss:0.1681151421005613\n",
      "train loss:0.22370777870359043\n",
      "train loss:0.30870133415246603\n",
      "train loss:0.21585914872688797\n",
      "train loss:0.21445204999156584\n",
      "train loss:0.13156951339767547\n",
      "train loss:0.2090148713242168\n",
      "train loss:0.2870061679555989\n",
      "train loss:0.20732295608397208\n",
      "train loss:0.2804246732528478\n",
      "train loss:0.18832173400128466\n",
      "train loss:0.35062872307949505\n",
      "train loss:0.16886594245276068\n",
      "train loss:0.21497623753566\n",
      "train loss:0.2759178251965182\n",
      "train loss:0.24005623811554444\n",
      "train loss:0.2595155178525259\n",
      "train loss:0.19781237484878716\n",
      "train loss:0.2618656234274763\n",
      "train loss:0.23006498741516598\n",
      "train loss:0.2476944300534734\n",
      "train loss:0.3195072584162187\n",
      "train loss:0.26500116928186856\n",
      "train loss:0.14447897181159366\n",
      "train loss:0.21602341098732442\n",
      "train loss:0.19242088453438122\n",
      "train loss:0.27702692877452156\n",
      "train loss:0.23559136637980477\n",
      "train loss:0.24674315759097717\n",
      "train loss:0.23151199513882936\n",
      "train loss:0.270283829332195\n",
      "train loss:0.17954671120981489\n",
      "train loss:0.2067978822428847\n",
      "train loss:0.15628790285948654\n",
      "train loss:0.3652907904213197\n",
      "train loss:0.20084188902950995\n",
      "train loss:0.23797873136577008\n",
      "train loss:0.17273736174238202\n",
      "train loss:0.21931432704882048\n",
      "train loss:0.22125172288430947\n",
      "train loss:0.168623267771769\n",
      "train loss:0.24032992870277303\n",
      "train loss:0.17193946486200315\n",
      "train loss:0.18147070895129747\n",
      "=== epoch:8, train acc:0.932, test acc:0.892 ===\n",
      "train loss:0.1323430581613936\n",
      "train loss:0.17507398945751274\n",
      "train loss:0.1919279718650071\n",
      "train loss:0.16819287810990657\n",
      "train loss:0.16740131371293876\n",
      "train loss:0.12665330923845214\n",
      "train loss:0.12623881638153495\n",
      "train loss:0.2949399172911371\n",
      "train loss:0.2890736784761968\n",
      "train loss:0.17556953385029422\n",
      "train loss:0.3887200152809601\n",
      "train loss:0.22916408568579175\n",
      "train loss:0.1234604157128773\n",
      "train loss:0.12906191663387234\n",
      "train loss:0.20422058565775544\n",
      "train loss:0.19364960162614456\n",
      "train loss:0.1696290933448257\n",
      "train loss:0.2371127198796538\n",
      "train loss:0.20709815539919305\n",
      "train loss:0.1709231441401632\n",
      "train loss:0.15311602335256874\n",
      "train loss:0.19492877088354438\n",
      "train loss:0.2191899001061135\n",
      "train loss:0.12629044956460792\n",
      "train loss:0.17231672550459648\n",
      "train loss:0.2988267407791786\n",
      "train loss:0.18216551477527684\n",
      "train loss:0.2500502995429879\n",
      "train loss:0.1342959392633797\n",
      "train loss:0.2971059021763408\n",
      "train loss:0.20725235557488272\n",
      "train loss:0.16635149886653067\n",
      "train loss:0.15483045925617428\n",
      "train loss:0.09644736347293331\n",
      "train loss:0.28849976918372205\n",
      "train loss:0.27600785959947866\n",
      "train loss:0.21186569653821322\n",
      "train loss:0.24411706803196329\n",
      "train loss:0.13009786034129492\n",
      "train loss:0.1477618482695399\n",
      "train loss:0.15897739597713167\n",
      "train loss:0.25308862844380464\n",
      "train loss:0.23495974252298274\n",
      "train loss:0.26464630571779735\n",
      "train loss:0.21250909534617057\n",
      "train loss:0.16221561063938147\n",
      "train loss:0.1904759187125367\n",
      "train loss:0.2139974913329079\n",
      "train loss:0.23691503418000606\n",
      "train loss:0.18300707743256872\n",
      "train loss:0.2640809727094724\n",
      "train loss:0.22255419469013812\n",
      "train loss:0.2146498228134077\n",
      "train loss:0.2802757456398813\n",
      "train loss:0.2773749056946237\n",
      "train loss:0.15182511005498914\n",
      "train loss:0.17142254218273417\n",
      "train loss:0.32286904883361234\n",
      "train loss:0.15759400974388377\n",
      "train loss:0.20539340932316338\n",
      "train loss:0.1795863177669884\n",
      "train loss:0.11589201334436627\n",
      "train loss:0.23120423002095897\n",
      "train loss:0.15637691876344748\n",
      "train loss:0.13765332661378138\n",
      "train loss:0.1643973025539221\n",
      "train loss:0.1492098571358169\n",
      "train loss:0.18665878005842004\n",
      "train loss:0.22922783412158165\n",
      "train loss:0.15072277801827386\n",
      "train loss:0.2748983342898513\n",
      "train loss:0.2764733106482199\n",
      "train loss:0.08570966591469446\n",
      "train loss:0.14331440385604088\n",
      "train loss:0.1956700718621806\n",
      "train loss:0.18450324384486647\n",
      "train loss:0.1551555554091642\n",
      "train loss:0.24310957859090152\n",
      "train loss:0.3507456496832591\n",
      "train loss:0.21414074962983826\n",
      "train loss:0.1938426383103818\n",
      "train loss:0.12704067005469427\n",
      "train loss:0.19668861017536365\n",
      "train loss:0.11448856579207878\n",
      "train loss:0.17364671975688778\n",
      "train loss:0.13181833285045502\n",
      "train loss:0.13594457814917135\n",
      "train loss:0.16762644585933067\n",
      "train loss:0.21616524460037922\n",
      "train loss:0.1503604176777269\n",
      "train loss:0.14246129691465131\n",
      "train loss:0.23847002545905485\n",
      "train loss:0.1707014885401053\n",
      "train loss:0.2793545517131946\n",
      "train loss:0.21357562993204612\n",
      "train loss:0.20242926869136071\n",
      "train loss:0.15261409740713894\n",
      "train loss:0.17229767240424476\n",
      "train loss:0.16499272075633598\n",
      "train loss:0.12973367238538006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.12474646611927996\n",
      "train loss:0.19289421731579154\n",
      "train loss:0.29497415091169166\n",
      "train loss:0.12861985098788725\n",
      "train loss:0.21164183444406975\n",
      "train loss:0.2148634121667036\n",
      "train loss:0.19623629443082766\n",
      "train loss:0.13733033788248825\n",
      "train loss:0.1581499589565429\n",
      "train loss:0.1336649376675946\n",
      "train loss:0.2561538031736713\n",
      "train loss:0.27586084014563567\n",
      "train loss:0.29348747207133674\n",
      "train loss:0.2273520069104433\n",
      "train loss:0.1384938727759359\n",
      "train loss:0.2813770446687755\n",
      "train loss:0.26516952280698725\n",
      "train loss:0.27431519876498567\n",
      "train loss:0.2656963461204327\n",
      "train loss:0.1403528045198729\n",
      "train loss:0.2122469715727574\n",
      "train loss:0.12213803922189177\n",
      "train loss:0.16079533482632996\n",
      "train loss:0.2280474890532465\n",
      "train loss:0.1754599772706092\n",
      "train loss:0.12069287531263864\n",
      "train loss:0.3009138828627959\n",
      "train loss:0.08460954776404113\n",
      "train loss:0.25258460863763266\n",
      "train loss:0.1622090227929579\n",
      "train loss:0.15583372961373024\n",
      "train loss:0.2577843014137578\n",
      "train loss:0.08665431761695153\n",
      "train loss:0.2732096028993341\n",
      "train loss:0.25741600890904764\n",
      "train loss:0.18730910028444758\n",
      "train loss:0.13476776224392087\n",
      "train loss:0.2868404806696129\n",
      "train loss:0.2450652435279785\n",
      "train loss:0.20897715908571815\n",
      "train loss:0.15271815230590366\n",
      "train loss:0.18083679206201478\n",
      "train loss:0.1413171327668647\n",
      "train loss:0.1925418382901307\n",
      "train loss:0.27491396014388403\n",
      "train loss:0.19829898379573607\n",
      "train loss:0.09925227686151997\n",
      "train loss:0.21714336608807427\n",
      "train loss:0.2371124386391985\n",
      "train loss:0.14870082829343587\n",
      "train loss:0.1626784643485551\n",
      "train loss:0.3223479050305834\n",
      "train loss:0.13112372438980863\n",
      "train loss:0.10284519291947086\n",
      "train loss:0.17823633820525697\n",
      "train loss:0.1998505274495583\n",
      "train loss:0.20712598016050737\n",
      "train loss:0.1327673522280035\n",
      "train loss:0.2572438822621759\n",
      "train loss:0.12733775216833682\n",
      "train loss:0.1117766639207872\n",
      "train loss:0.28672307531747476\n",
      "train loss:0.2049514815196978\n",
      "train loss:0.20704882799244806\n",
      "train loss:0.1927524968765152\n",
      "train loss:0.26032291366923554\n",
      "train loss:0.2830800128591626\n",
      "train loss:0.19167995795500772\n",
      "train loss:0.23472884892280074\n",
      "train loss:0.20368545550541772\n",
      "train loss:0.18750689733656242\n",
      "train loss:0.25429105542374714\n",
      "train loss:0.18199485854882597\n",
      "train loss:0.16613087094833645\n",
      "train loss:0.15872220353183497\n",
      "train loss:0.1724748004934347\n",
      "train loss:0.21414310756475496\n",
      "train loss:0.24222832796700142\n",
      "train loss:0.20282915206249652\n",
      "train loss:0.1631395769134507\n",
      "train loss:0.22840918971435542\n",
      "train loss:0.17822039380323407\n",
      "train loss:0.07237374646888733\n",
      "train loss:0.19944061348973968\n",
      "train loss:0.12917772545527414\n",
      "train loss:0.2556117577067731\n",
      "train loss:0.15875207517262546\n",
      "train loss:0.20877911796553542\n",
      "train loss:0.22194380928904608\n",
      "train loss:0.12775707680077963\n",
      "train loss:0.09467358594953196\n",
      "train loss:0.1973043834660546\n",
      "train loss:0.2414485976529269\n",
      "train loss:0.13857073727938907\n",
      "train loss:0.22497965292565134\n",
      "train loss:0.1884146805464277\n",
      "train loss:0.16976513020489367\n",
      "train loss:0.15264710728461284\n",
      "train loss:0.1779021212555001\n",
      "train loss:0.1538793995972488\n",
      "train loss:0.23622601205953753\n",
      "train loss:0.10837058513355656\n",
      "train loss:0.2303975525306339\n",
      "train loss:0.2528126949019679\n",
      "train loss:0.08918280444691694\n",
      "train loss:0.17685842258476886\n",
      "train loss:0.1929575792901128\n",
      "train loss:0.11973010990131144\n",
      "train loss:0.20851592362985638\n",
      "train loss:0.29498974298408437\n",
      "train loss:0.2025180616212271\n",
      "train loss:0.10322291681609883\n",
      "train loss:0.19616361663143536\n",
      "train loss:0.11854552748615549\n",
      "train loss:0.22109653365447396\n",
      "train loss:0.18178094931694166\n",
      "train loss:0.2484782284306012\n",
      "train loss:0.13306306506639393\n",
      "train loss:0.18776506382977576\n",
      "train loss:0.13306766282811353\n",
      "train loss:0.14877091865248634\n",
      "train loss:0.10704317902390167\n",
      "train loss:0.2967426613840858\n",
      "train loss:0.29958971087456004\n",
      "train loss:0.16744593562182464\n",
      "train loss:0.10776739782024816\n",
      "train loss:0.2197671984298708\n",
      "train loss:0.12573875128037218\n",
      "train loss:0.22551061517224444\n",
      "train loss:0.2531419631766199\n",
      "train loss:0.20405287472962172\n",
      "train loss:0.20292340609675438\n",
      "train loss:0.17855489745408548\n",
      "train loss:0.21280146056617086\n",
      "train loss:0.1993769648167489\n",
      "train loss:0.13516685156066754\n",
      "train loss:0.2583561668567727\n",
      "train loss:0.18650720201843293\n",
      "train loss:0.10128422193001738\n",
      "train loss:0.17456051259270067\n",
      "train loss:0.13421890707424006\n",
      "train loss:0.16040358628043944\n",
      "train loss:0.30708170557096376\n",
      "train loss:0.2751202176393748\n",
      "train loss:0.20168977633886498\n",
      "train loss:0.19618546430494763\n",
      "train loss:0.2774760193480541\n",
      "train loss:0.21635526289285675\n",
      "train loss:0.21337036704719825\n",
      "train loss:0.13271804685942773\n",
      "train loss:0.15213583298192795\n",
      "train loss:0.30855071195100203\n",
      "train loss:0.1928135656310265\n",
      "train loss:0.20731787430194726\n",
      "train loss:0.15842756186427123\n",
      "train loss:0.2111525770543263\n",
      "train loss:0.10588589314013169\n",
      "train loss:0.15155643016844933\n",
      "train loss:0.19612289437793756\n",
      "train loss:0.22247822001847112\n",
      "train loss:0.17009594875841827\n",
      "train loss:0.07221148005536618\n",
      "train loss:0.12253797356842132\n",
      "train loss:0.33313718270525006\n",
      "train loss:0.1736960646973038\n",
      "train loss:0.26933672939718556\n",
      "train loss:0.13252599162564982\n",
      "train loss:0.13388699815781388\n",
      "train loss:0.1626428996588714\n",
      "train loss:0.25299865031395413\n",
      "train loss:0.14336185636319274\n",
      "train loss:0.08964088926299142\n",
      "train loss:0.17972426306145736\n",
      "train loss:0.2358431762815102\n",
      "train loss:0.14241070675325268\n",
      "train loss:0.31396132658242726\n",
      "train loss:0.1230196139555244\n",
      "train loss:0.1446582630468681\n",
      "train loss:0.21112893227682242\n",
      "train loss:0.18131414130121684\n",
      "train loss:0.16461240019148218\n",
      "train loss:0.17349235175445155\n",
      "train loss:0.15379480308180696\n",
      "train loss:0.16505319849839428\n",
      "train loss:0.20537879581718566\n",
      "train loss:0.22794817369942552\n",
      "train loss:0.18023393956327535\n",
      "train loss:0.17953912115250695\n",
      "train loss:0.13431860793700146\n",
      "train loss:0.24351674655656688\n",
      "train loss:0.17141737526381065\n",
      "train loss:0.22354619508969825\n",
      "train loss:0.27423792258734314\n",
      "train loss:0.12873036163046597\n",
      "train loss:0.16089471109753536\n",
      "train loss:0.25041260763937934\n",
      "train loss:0.20755287316250076\n",
      "train loss:0.14247040059124583\n",
      "train loss:0.15849893919371807\n",
      "train loss:0.17176853738666956\n",
      "train loss:0.16950246925089008\n",
      "train loss:0.1250324115392316\n",
      "train loss:0.2797523516152257\n",
      "train loss:0.2882409282831377\n",
      "train loss:0.17669800132473462\n",
      "train loss:0.2007025366972934\n",
      "train loss:0.14547782682610946\n",
      "train loss:0.1835304340302244\n",
      "train loss:0.278062741901204\n",
      "train loss:0.23059604655249594\n",
      "train loss:0.30826729632931077\n",
      "train loss:0.21604836483717837\n",
      "train loss:0.2058878668347308\n",
      "train loss:0.20968728900807296\n",
      "train loss:0.15295325619976188\n",
      "train loss:0.21119056223471805\n",
      "train loss:0.16663757097445933\n",
      "train loss:0.1551640236245446\n",
      "train loss:0.2735503677191124\n",
      "train loss:0.17698456881966323\n",
      "train loss:0.1612215977906432\n",
      "train loss:0.20230151891181591\n",
      "train loss:0.14654060487421053\n",
      "train loss:0.2975560448537126\n",
      "train loss:0.050902681396569865\n",
      "train loss:0.15120436943120752\n",
      "train loss:0.17837827371103238\n",
      "train loss:0.17070516442682682\n",
      "train loss:0.3054261559001645\n",
      "train loss:0.15622072263607226\n",
      "train loss:0.32270392999051223\n",
      "train loss:0.3414675011881914\n",
      "train loss:0.12780599464985765\n",
      "train loss:0.19295461902212668\n",
      "train loss:0.18759916500503931\n",
      "train loss:0.3195841923014652\n",
      "train loss:0.1840953908473052\n",
      "train loss:0.19994315815108188\n",
      "train loss:0.2173390406261185\n",
      "train loss:0.18223374650502527\n",
      "train loss:0.21106790655869073\n",
      "train loss:0.14419135070409703\n",
      "train loss:0.2732269241014571\n",
      "train loss:0.256684210639006\n",
      "train loss:0.15332386416976548\n",
      "train loss:0.13384399322868987\n",
      "train loss:0.12567763314014624\n",
      "train loss:0.23343049710830946\n",
      "train loss:0.13611570568091413\n",
      "train loss:0.13419070108500358\n",
      "train loss:0.2042430909785264\n",
      "train loss:0.12693101881064073\n",
      "train loss:0.22192465872764525\n",
      "train loss:0.16583662121215487\n",
      "train loss:0.17898990525281952\n",
      "train loss:0.1901223506022378\n",
      "train loss:0.17536255937965123\n",
      "train loss:0.2191884191969934\n",
      "train loss:0.12577160224401976\n",
      "train loss:0.19542423040806842\n",
      "train loss:0.2664267204062324\n",
      "train loss:0.2276754200693902\n",
      "train loss:0.11712502340969456\n",
      "train loss:0.22845818859430492\n",
      "train loss:0.26541034585755546\n",
      "train loss:0.11413903158393111\n",
      "train loss:0.1834212635981432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.20527821825727854\n",
      "train loss:0.2142731349528197\n",
      "train loss:0.19307939459762186\n",
      "train loss:0.1448275650248627\n",
      "train loss:0.17210786628290228\n",
      "train loss:0.22947535600389926\n",
      "train loss:0.18234846974879168\n",
      "train loss:0.2628528472865608\n",
      "train loss:0.20789108037454845\n",
      "train loss:0.15290380414550978\n",
      "train loss:0.15060991423215578\n",
      "train loss:0.2167033987116091\n",
      "train loss:0.18056976438398784\n",
      "train loss:0.24122899779776663\n",
      "train loss:0.17478161508989964\n",
      "train loss:0.3243794576211287\n",
      "train loss:0.2758378189122452\n",
      "train loss:0.19530602356931223\n",
      "train loss:0.1498074310131218\n",
      "train loss:0.24105563837029048\n",
      "train loss:0.1139155595727831\n",
      "train loss:0.18827210321797025\n",
      "train loss:0.1968182246115819\n",
      "train loss:0.15573150804913416\n",
      "train loss:0.21286888252909356\n",
      "train loss:0.12677831124131594\n",
      "train loss:0.18107492486918225\n",
      "train loss:0.3229270010396668\n",
      "train loss:0.14399331616416214\n",
      "train loss:0.18443744719415794\n",
      "train loss:0.20613284697883028\n",
      "train loss:0.2315300529776001\n",
      "train loss:0.15083209794208366\n",
      "train loss:0.18194069947167651\n",
      "train loss:0.11212312675607\n",
      "train loss:0.17484754316298062\n",
      "train loss:0.15379322282447483\n",
      "train loss:0.15220460816657314\n",
      "train loss:0.21600450573372845\n",
      "train loss:0.2580816848214679\n",
      "train loss:0.15762889509155506\n",
      "train loss:0.1950732814730846\n",
      "train loss:0.21821263280064485\n",
      "train loss:0.24151241493415074\n",
      "train loss:0.17221177884698075\n",
      "train loss:0.12106202864919298\n",
      "train loss:0.15769239272490204\n",
      "train loss:0.19460915464848416\n",
      "train loss:0.22266955720213333\n",
      "train loss:0.22750956782777898\n",
      "train loss:0.23118758364729278\n",
      "train loss:0.2235273082442393\n",
      "train loss:0.19804288404436077\n",
      "train loss:0.2652684236294253\n",
      "train loss:0.14006693150197072\n",
      "train loss:0.2661400835579303\n",
      "train loss:0.17429502419260953\n",
      "train loss:0.17422671995906497\n",
      "train loss:0.21056428128401336\n",
      "train loss:0.1530499743793376\n",
      "train loss:0.22964992640075818\n",
      "train loss:0.29375468251289144\n",
      "train loss:0.27871421862783935\n",
      "train loss:0.23436895460332793\n",
      "train loss:0.18400017421911655\n",
      "train loss:0.23160906093683892\n",
      "train loss:0.20074169579980108\n",
      "train loss:0.13777123650619685\n",
      "train loss:0.18930566741618388\n",
      "train loss:0.15267604660477896\n",
      "train loss:0.23167979858665044\n",
      "train loss:0.10962342412404087\n",
      "train loss:0.3011579290684389\n",
      "train loss:0.14447972624863406\n",
      "train loss:0.18475316527314462\n",
      "train loss:0.21829860840674467\n",
      "train loss:0.2608194234979806\n",
      "train loss:0.14863699250819257\n",
      "train loss:0.22656521119370154\n",
      "train loss:0.14038791163263975\n",
      "train loss:0.20688276270383066\n",
      "train loss:0.15660671554900085\n",
      "train loss:0.17277659894241712\n",
      "train loss:0.23195827569315178\n",
      "train loss:0.2859989669224852\n",
      "train loss:0.16873313044494417\n",
      "train loss:0.1675258138846464\n",
      "train loss:0.2359842128201855\n",
      "train loss:0.179517282635456\n",
      "train loss:0.16630817760394817\n",
      "train loss:0.18262553246415453\n",
      "train loss:0.1360949419846896\n",
      "train loss:0.19827688765663287\n",
      "train loss:0.10657557531432765\n",
      "train loss:0.21957555765339087\n",
      "train loss:0.17692769556558105\n",
      "train loss:0.22210888502279644\n",
      "train loss:0.19630640748354655\n",
      "train loss:0.11666794057497447\n",
      "train loss:0.20020171087952998\n",
      "train loss:0.22345550375502896\n",
      "train loss:0.2661687702038212\n",
      "train loss:0.1309434790217704\n",
      "train loss:0.13298183431768995\n",
      "train loss:0.1733230603765168\n",
      "train loss:0.133162624474689\n",
      "train loss:0.19085827105553915\n",
      "train loss:0.17574817629937223\n",
      "train loss:0.22410179402065883\n",
      "train loss:0.1936317930935798\n",
      "train loss:0.15253144396950635\n",
      "train loss:0.1918206901597117\n",
      "train loss:0.18455214389675834\n",
      "train loss:0.14022723085129313\n",
      "train loss:0.23286744297657855\n",
      "train loss:0.1881365878908278\n",
      "train loss:0.15921814873227097\n",
      "train loss:0.25445063122907\n",
      "train loss:0.2684168982824422\n",
      "train loss:0.23021686203456482\n",
      "train loss:0.20981867721815764\n",
      "train loss:0.21651855875589143\n",
      "train loss:0.14558681221654415\n",
      "train loss:0.35878494703703867\n",
      "train loss:0.15051802256396496\n",
      "train loss:0.29723177934973544\n",
      "train loss:0.17549661862172478\n",
      "train loss:0.16233910121552758\n",
      "train loss:0.1307460776249196\n",
      "train loss:0.1765822849112861\n",
      "train loss:0.1410252513995189\n",
      "train loss:0.22148594760272095\n",
      "train loss:0.16242358026358122\n",
      "train loss:0.18950923608199483\n",
      "train loss:0.2588852175040697\n",
      "train loss:0.3021540434141261\n",
      "train loss:0.19433885956679306\n",
      "train loss:0.19265535135568457\n",
      "train loss:0.16086611753974947\n",
      "train loss:0.1885907172084221\n",
      "train loss:0.1988093914030525\n",
      "train loss:0.17042384916877132\n",
      "train loss:0.13415965031534255\n",
      "train loss:0.16862719003597834\n",
      "train loss:0.24860052417119483\n",
      "train loss:0.1694357700358638\n",
      "train loss:0.1377062203360569\n",
      "train loss:0.16907579862621577\n",
      "train loss:0.24592981397093927\n",
      "train loss:0.16406162574584837\n",
      "train loss:0.171360783590737\n",
      "train loss:0.17774715125439586\n",
      "train loss:0.09220273745086159\n",
      "train loss:0.19565864120497625\n",
      "train loss:0.20702752307131764\n",
      "train loss:0.1709891103779102\n",
      "train loss:0.2886538873092167\n",
      "train loss:0.1346032377378778\n",
      "train loss:0.14980306334695348\n",
      "train loss:0.2564234252887409\n",
      "train loss:0.15742670445511506\n",
      "train loss:0.2788806356878651\n",
      "train loss:0.2244960182427754\n",
      "train loss:0.22947705323052972\n",
      "train loss:0.21576440880596057\n",
      "train loss:0.1423173253155834\n",
      "train loss:0.11786482084924561\n",
      "train loss:0.17168952870523757\n",
      "train loss:0.21751508500444153\n",
      "train loss:0.1644448440564181\n",
      "train loss:0.11942158920492885\n",
      "train loss:0.12710314004691828\n",
      "train loss:0.19313587722739542\n",
      "train loss:0.2040867453799472\n",
      "train loss:0.07652569428836714\n",
      "train loss:0.15273098035372862\n",
      "train loss:0.13386587204188907\n",
      "train loss:0.11530478135356731\n",
      "train loss:0.13130907294896513\n",
      "train loss:0.09275460481024485\n",
      "train loss:0.23353288480932316\n",
      "train loss:0.15781914728868504\n",
      "train loss:0.1238520596539832\n",
      "train loss:0.1918621137678599\n",
      "train loss:0.11283323477253507\n",
      "train loss:0.2658756727789574\n",
      "train loss:0.17246906429105277\n",
      "train loss:0.11543206721859167\n",
      "train loss:0.2100724571478964\n",
      "train loss:0.12984691992245279\n",
      "train loss:0.2095465754065177\n",
      "train loss:0.13063731064286085\n",
      "train loss:0.1747445818886964\n",
      "train loss:0.16570389511902456\n",
      "train loss:0.11796385032633157\n",
      "train loss:0.2076598559678538\n",
      "train loss:0.13736405041133792\n",
      "train loss:0.246740771079277\n",
      "train loss:0.17014193024480206\n",
      "train loss:0.17476770679123965\n",
      "train loss:0.14661229737800693\n",
      "train loss:0.26734060473562304\n",
      "train loss:0.14664478251187554\n",
      "train loss:0.14731275331613258\n",
      "train loss:0.11426251862911238\n",
      "train loss:0.15649526907990352\n",
      "train loss:0.18231546394797615\n",
      "train loss:0.2978463101260999\n",
      "train loss:0.27497147759721363\n",
      "train loss:0.21298622085220445\n",
      "train loss:0.1736432134513565\n",
      "train loss:0.20300970499777857\n",
      "train loss:0.26266458729985825\n",
      "train loss:0.38394834560085533\n",
      "train loss:0.20188022540338596\n",
      "train loss:0.24778262785692873\n",
      "train loss:0.23795522654506684\n",
      "train loss:0.28561096824629373\n",
      "train loss:0.2552934155338695\n",
      "train loss:0.19311365568834252\n",
      "train loss:0.2538491470706878\n",
      "train loss:0.2664544961451813\n",
      "train loss:0.16979939921772302\n",
      "train loss:0.22437569573119046\n",
      "train loss:0.15401379339837262\n",
      "train loss:0.18399887822575156\n",
      "train loss:0.2276612184841385\n",
      "train loss:0.22654638757417767\n",
      "train loss:0.09872218246625591\n",
      "train loss:0.2007994292093368\n",
      "train loss:0.11176944873069802\n",
      "train loss:0.19267311967831738\n",
      "train loss:0.19116488460007455\n",
      "=== epoch:9, train acc:0.942, test acc:0.901 ===\n",
      "train loss:0.20599212128194014\n",
      "train loss:0.15031874489792638\n",
      "train loss:0.17076550640645397\n",
      "train loss:0.1690801762431569\n",
      "train loss:0.3236039316196979\n",
      "train loss:0.26059740739734794\n",
      "train loss:0.2786335360059421\n",
      "train loss:0.3456017793519526\n",
      "train loss:0.26581706476514155\n",
      "train loss:0.14661960212966918\n",
      "train loss:0.20138727567528658\n",
      "train loss:0.2530933266917682\n",
      "train loss:0.2309534229244238\n",
      "train loss:0.2064186030057706\n",
      "train loss:0.29387892469915716\n",
      "train loss:0.17068542372666126\n",
      "train loss:0.19184094423493556\n",
      "train loss:0.2150722043195676\n",
      "train loss:0.21875925132370672\n",
      "train loss:0.1593317793863595\n",
      "train loss:0.22883777223311497\n",
      "train loss:0.15885954760869703\n",
      "train loss:0.14625717739945432\n",
      "train loss:0.19681243016894645\n",
      "train loss:0.1463584654688805\n",
      "train loss:0.25837543622908093\n",
      "train loss:0.1750163938520823\n",
      "train loss:0.17678588024797784\n",
      "train loss:0.18708733968072483\n",
      "train loss:0.16635271769791893\n",
      "train loss:0.24060414073201927\n",
      "train loss:0.31585484600933084\n",
      "train loss:0.22542698559005683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.15109824449471793\n",
      "train loss:0.1942605792638676\n",
      "train loss:0.19058807081234413\n",
      "train loss:0.20178212730396786\n",
      "train loss:0.18851809467245878\n",
      "train loss:0.16323544913998428\n",
      "train loss:0.16423659192267967\n",
      "train loss:0.2062536109991768\n",
      "train loss:0.15725234360579918\n",
      "train loss:0.15607855431094883\n",
      "train loss:0.24061495341424893\n",
      "train loss:0.09952670898080088\n",
      "train loss:0.12601751800822417\n",
      "train loss:0.19168880386719853\n",
      "train loss:0.21220796280180443\n",
      "train loss:0.2022734139820766\n",
      "train loss:0.1861868121894421\n",
      "train loss:0.17718546853146694\n",
      "train loss:0.21854751340014694\n",
      "train loss:0.18547295770442015\n",
      "train loss:0.19113755442368632\n",
      "train loss:0.16260069626873286\n",
      "train loss:0.19530582576616431\n",
      "train loss:0.2728852637943114\n",
      "train loss:0.1545748766173941\n",
      "train loss:0.13854095859665005\n",
      "train loss:0.166181691203864\n",
      "train loss:0.1267260475305064\n",
      "train loss:0.249700574704452\n",
      "train loss:0.08312707540116276\n",
      "train loss:0.2737945931526573\n",
      "train loss:0.1575639251678204\n",
      "train loss:0.3863293748486379\n",
      "train loss:0.295206904510939\n",
      "train loss:0.1379068230067031\n",
      "train loss:0.17883429643782237\n",
      "train loss:0.10083040759438949\n",
      "train loss:0.12528924295038715\n",
      "train loss:0.14103265585994493\n",
      "train loss:0.10891342791391663\n",
      "train loss:0.22510619788891728\n",
      "train loss:0.14268555917881082\n",
      "train loss:0.16677170481182252\n",
      "train loss:0.08914061559288658\n",
      "train loss:0.21282011063409367\n",
      "train loss:0.28320403816877154\n",
      "train loss:0.16674408118272044\n",
      "train loss:0.17261908568090875\n",
      "train loss:0.11269572298595552\n",
      "train loss:0.12849081616164873\n",
      "train loss:0.18169299900337016\n",
      "train loss:0.25398955290836905\n",
      "train loss:0.2270792733423884\n",
      "train loss:0.13485604653163816\n",
      "train loss:0.16584985689075882\n",
      "train loss:0.16814894868358674\n",
      "train loss:0.1908902008449206\n",
      "train loss:0.15057591793063846\n",
      "train loss:0.21393712866736872\n",
      "train loss:0.17660773360856385\n",
      "train loss:0.18363447855704848\n",
      "train loss:0.13155451935648085\n",
      "train loss:0.2744629051545185\n",
      "train loss:0.19457709867761747\n",
      "train loss:0.22396229640197127\n",
      "train loss:0.21747544573543856\n",
      "train loss:0.18751012034781137\n",
      "train loss:0.10472635577111422\n",
      "train loss:0.1414661109165521\n",
      "train loss:0.2591619618403927\n",
      "train loss:0.11274012089438451\n",
      "train loss:0.19323486355317987\n",
      "train loss:0.15877616117624416\n",
      "train loss:0.17885629176165824\n",
      "train loss:0.17779832075428753\n",
      "train loss:0.1317802262060176\n",
      "train loss:0.1360897838443569\n",
      "train loss:0.18009411197137254\n",
      "train loss:0.19544761735857835\n",
      "train loss:0.2395147257859032\n",
      "train loss:0.1852346917237962\n",
      "train loss:0.20793103977114746\n",
      "train loss:0.14465984129937545\n",
      "train loss:0.25072625794026204\n",
      "train loss:0.15899447822005394\n",
      "train loss:0.22259404261467583\n",
      "train loss:0.1811411343518075\n",
      "train loss:0.18586117963477505\n",
      "train loss:0.20726174587086604\n",
      "train loss:0.14892839598618532\n",
      "train loss:0.22302288287484043\n",
      "train loss:0.23719708838725617\n",
      "train loss:0.15581446194538484\n",
      "train loss:0.2002032436655785\n",
      "train loss:0.20715486037170897\n",
      "train loss:0.19791340299870686\n",
      "train loss:0.24631392790995513\n",
      "train loss:0.11542707645770088\n",
      "train loss:0.1767014145588531\n",
      "train loss:0.2333289656824774\n",
      "train loss:0.24664550186570366\n",
      "train loss:0.1917515921558115\n",
      "train loss:0.11585753281822832\n",
      "train loss:0.20079062587026622\n",
      "train loss:0.15381384802175943\n",
      "train loss:0.24770039593292775\n",
      "train loss:0.15944944927603663\n",
      "train loss:0.24157967142525508\n",
      "train loss:0.1832847081803506\n",
      "train loss:0.2608169355611957\n",
      "train loss:0.13176996552572517\n",
      "train loss:0.2321529776570006\n",
      "train loss:0.1108264336233613\n",
      "train loss:0.13778438156824308\n",
      "train loss:0.1610995093202114\n",
      "train loss:0.14340317777901368\n",
      "train loss:0.14890547830994882\n",
      "train loss:0.15137728591867808\n",
      "train loss:0.1696031304406132\n",
      "train loss:0.14442979875824175\n",
      "train loss:0.10237072917614519\n",
      "train loss:0.16753276425994582\n",
      "train loss:0.14187672462805861\n",
      "train loss:0.18899308349063634\n",
      "train loss:0.12797064850098247\n",
      "train loss:0.2133958487991339\n",
      "train loss:0.23221525943075844\n",
      "train loss:0.22675788513128592\n",
      "train loss:0.16675534474364867\n",
      "train loss:0.16240621213040096\n",
      "train loss:0.2080315835205035\n",
      "train loss:0.25859002736121317\n",
      "train loss:0.14260907003790713\n",
      "train loss:0.2804908197678299\n",
      "train loss:0.1851118886930243\n",
      "train loss:0.11800937760375425\n",
      "train loss:0.22727743143333234\n",
      "train loss:0.23905805124900595\n",
      "train loss:0.18023377482648054\n",
      "train loss:0.2204444218455783\n",
      "train loss:0.13716346957120673\n",
      "train loss:0.2158126101384122\n",
      "train loss:0.19331254830704991\n",
      "train loss:0.14070337864147006\n",
      "train loss:0.16539661028609423\n",
      "train loss:0.22025702961106947\n",
      "train loss:0.070650689273108\n",
      "train loss:0.1569571425828703\n",
      "train loss:0.1955980760546652\n",
      "train loss:0.13848243358807774\n",
      "train loss:0.13988282263581195\n",
      "train loss:0.16783409761128737\n",
      "train loss:0.2367502262743785\n",
      "train loss:0.14287648312602824\n",
      "train loss:0.1652866166436408\n",
      "train loss:0.18758959203844852\n",
      "train loss:0.21712457692229215\n",
      "train loss:0.18359218572379052\n",
      "train loss:0.16463142984278073\n",
      "train loss:0.15820362312810363\n",
      "train loss:0.13617100036392185\n",
      "train loss:0.31533016104384887\n",
      "train loss:0.16408766779559522\n",
      "train loss:0.276537813547399\n",
      "train loss:0.13710909594690945\n",
      "train loss:0.2294389647952767\n",
      "train loss:0.1635433990949787\n",
      "train loss:0.16188090905141558\n",
      "train loss:0.18992306804633965\n",
      "train loss:0.21362868911179667\n",
      "train loss:0.19870358619334078\n",
      "train loss:0.14581557097712353\n",
      "train loss:0.13389022351543756\n",
      "train loss:0.1439796521155746\n",
      "train loss:0.22176944420539113\n",
      "train loss:0.19928433732514694\n",
      "train loss:0.15168184719017336\n",
      "train loss:0.2050108702882737\n",
      "train loss:0.1280814509631578\n",
      "train loss:0.12556699329893098\n",
      "train loss:0.2782512038884114\n",
      "train loss:0.18407067392007645\n",
      "train loss:0.22677134233389015\n",
      "train loss:0.179599385060394\n",
      "train loss:0.2530294588835255\n",
      "train loss:0.07773878183971548\n",
      "train loss:0.0778523836724035\n",
      "train loss:0.2622340637546059\n",
      "train loss:0.26083187454559015\n",
      "train loss:0.24648568616473\n",
      "train loss:0.21020452349463548\n",
      "train loss:0.24656999377454583\n",
      "train loss:0.21446414609482986\n",
      "train loss:0.2176996027943089\n",
      "train loss:0.14016747492191473\n",
      "train loss:0.11943638641416907\n",
      "train loss:0.19456044395093422\n",
      "train loss:0.21660301332798965\n",
      "train loss:0.31991130217589137\n",
      "train loss:0.1440621556766866\n",
      "train loss:0.18812585055319897\n",
      "train loss:0.34894508716419526\n",
      "train loss:0.09530936333640437\n",
      "train loss:0.16259191932542533\n",
      "train loss:0.1347106586649537\n",
      "train loss:0.12302025067599986\n",
      "train loss:0.2544723000569082\n",
      "train loss:0.2297434229260498\n",
      "train loss:0.2587314441377161\n",
      "train loss:0.09650173909916707\n",
      "train loss:0.20318599729589426\n",
      "train loss:0.2272863502940882\n",
      "train loss:0.1951665755344906\n",
      "train loss:0.18608796440270847\n",
      "train loss:0.2004536785686154\n",
      "train loss:0.11777719321744459\n",
      "train loss:0.15592693975616925\n",
      "train loss:0.16786509218867235\n",
      "train loss:0.1864102517074534\n",
      "train loss:0.20175745912967488\n",
      "train loss:0.22975155139927034\n",
      "train loss:0.12550880165160805\n",
      "train loss:0.2962075536346318\n",
      "train loss:0.1564860962119524\n",
      "train loss:0.21093986816374216\n",
      "train loss:0.17607128570146713\n",
      "train loss:0.09290781107672111\n",
      "train loss:0.24407412328278066\n",
      "train loss:0.2353315504870789\n",
      "train loss:0.26043674096003927\n",
      "train loss:0.17184133093902643\n",
      "train loss:0.1519713570167302\n",
      "train loss:0.2853110899058581\n",
      "train loss:0.12221763769758191\n",
      "train loss:0.13462157392598537\n",
      "train loss:0.21579760146772467\n",
      "train loss:0.18704024634593314\n",
      "train loss:0.19353851026223914\n",
      "train loss:0.11501565660636663\n",
      "train loss:0.14919920472647705\n",
      "train loss:0.15117284386079305\n",
      "train loss:0.1079047056547386\n",
      "train loss:0.21224593284861887\n",
      "train loss:0.2990757509932592\n",
      "train loss:0.1123687002284224\n",
      "train loss:0.22469477973433238\n",
      "train loss:0.14345027669832272\n",
      "train loss:0.24236519184529698\n",
      "train loss:0.215615442843404\n",
      "train loss:0.21882840104799517\n",
      "train loss:0.2283756050843252\n",
      "train loss:0.19799218937697194\n",
      "train loss:0.10472445980539909\n",
      "train loss:0.2000306576403953\n",
      "train loss:0.14981740620315676\n",
      "train loss:0.20854746592527348\n",
      "train loss:0.2714111098460343\n",
      "train loss:0.10858128090392333\n",
      "train loss:0.19342335577130185\n",
      "train loss:0.16696963409006554\n",
      "train loss:0.18649903089537292\n",
      "train loss:0.20892294789876928\n",
      "train loss:0.1098717170732612\n",
      "train loss:0.15440820705183023\n",
      "train loss:0.19137240090921115\n",
      "train loss:0.1607947156419306\n",
      "train loss:0.08406449833829717\n",
      "train loss:0.17347349803698342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.1715549860654249\n",
      "train loss:0.1918285644107958\n",
      "train loss:0.10563966431782498\n",
      "train loss:0.2539848161800926\n",
      "train loss:0.12905541873086357\n",
      "train loss:0.15829082483008253\n",
      "train loss:0.23307651869421533\n",
      "train loss:0.20531397418552033\n",
      "train loss:0.16008858097149056\n",
      "train loss:0.17938830717808185\n",
      "train loss:0.14174952865334361\n",
      "train loss:0.23204589911590134\n",
      "train loss:0.2147744297113419\n",
      "train loss:0.21224380396531561\n",
      "train loss:0.14484361057385856\n",
      "train loss:0.12186719191438129\n",
      "train loss:0.16280749915471504\n",
      "train loss:0.21601256285153977\n",
      "train loss:0.210181677341764\n",
      "train loss:0.1277439102877152\n",
      "train loss:0.17430813202753417\n",
      "train loss:0.11538031972940756\n",
      "train loss:0.10606215609008218\n",
      "train loss:0.28788878572526827\n",
      "train loss:0.20391916480579944\n",
      "train loss:0.17782689369397361\n",
      "train loss:0.21977920613005572\n",
      "train loss:0.1516777883321037\n",
      "train loss:0.15295179404133097\n",
      "train loss:0.13102821839160186\n",
      "train loss:0.18130377859657426\n",
      "train loss:0.20780505379173195\n",
      "train loss:0.16290925689771352\n",
      "train loss:0.16648867190720243\n",
      "train loss:0.16371567333291048\n",
      "train loss:0.1795315137935466\n",
      "train loss:0.12818600402443145\n",
      "train loss:0.20458391634249506\n",
      "train loss:0.22429470493243195\n",
      "train loss:0.13442611543285887\n",
      "train loss:0.11021582060428271\n",
      "train loss:0.17934532090216082\n",
      "train loss:0.11358812423723126\n",
      "train loss:0.18100869102476555\n",
      "train loss:0.20454789839365403\n",
      "train loss:0.17291332642811333\n",
      "train loss:0.15527269682578337\n",
      "train loss:0.10767500761425623\n",
      "train loss:0.12031968253822553\n",
      "train loss:0.18018073113699823\n",
      "train loss:0.09341948525241574\n",
      "train loss:0.2717444318995325\n",
      "train loss:0.26294996410152716\n",
      "train loss:0.2747537882173657\n",
      "train loss:0.16208797490578333\n",
      "train loss:0.1323924544377984\n",
      "train loss:0.09092761860061672\n",
      "train loss:0.11633010963511074\n",
      "train loss:0.21229665076526252\n",
      "train loss:0.1863535848592091\n",
      "train loss:0.13845168340507893\n",
      "train loss:0.19986967527500238\n",
      "train loss:0.12461434354194005\n",
      "train loss:0.2030308833065525\n",
      "train loss:0.16420193914024914\n",
      "train loss:0.2107075005405771\n",
      "train loss:0.2226239460038136\n",
      "train loss:0.10088353881458563\n",
      "train loss:0.20000215505266522\n",
      "train loss:0.26684806609083295\n",
      "train loss:0.13502953690802588\n",
      "train loss:0.267497019807315\n",
      "train loss:0.13502321749128274\n",
      "train loss:0.20157573259645725\n",
      "train loss:0.1626555648092837\n",
      "train loss:0.12338382122815233\n",
      "train loss:0.15351332445595514\n",
      "train loss:0.30179851036017963\n",
      "train loss:0.11763951230101212\n",
      "train loss:0.16610233302603625\n",
      "train loss:0.23178173000390903\n",
      "train loss:0.13539960419041625\n",
      "train loss:0.1612793028507631\n",
      "train loss:0.141068233928759\n",
      "train loss:0.2581733453797926\n",
      "train loss:0.1396777152448333\n",
      "train loss:0.16257001364060217\n",
      "train loss:0.19174324686859187\n",
      "train loss:0.12571601467067456\n",
      "train loss:0.1931720523849167\n",
      "train loss:0.17946971325581765\n",
      "train loss:0.17320523210502642\n",
      "train loss:0.19008285482540166\n",
      "train loss:0.31388209215453705\n",
      "train loss:0.19328469750185334\n",
      "train loss:0.09951072249831519\n",
      "train loss:0.27439834627635024\n",
      "train loss:0.1788759931867767\n",
      "train loss:0.20797289406432728\n",
      "train loss:0.12369726757417582\n",
      "train loss:0.15398142989766242\n",
      "train loss:0.14322586663744574\n",
      "train loss:0.12164744271367291\n",
      "train loss:0.10658872219126402\n",
      "train loss:0.24045356528126066\n",
      "train loss:0.1710933512729261\n",
      "train loss:0.10504952808311804\n",
      "train loss:0.18276756404592576\n",
      "train loss:0.3342073182542503\n",
      "train loss:0.20089844084200054\n",
      "train loss:0.26488455432889546\n",
      "train loss:0.12100000527144142\n",
      "train loss:0.12097508465803615\n",
      "train loss:0.15941611641631795\n",
      "train loss:0.13071220381420157\n",
      "train loss:0.1327976340336095\n",
      "train loss:0.14728044217310637\n",
      "train loss:0.1281970841989368\n",
      "train loss:0.1881079024096384\n",
      "train loss:0.11006170590865258\n",
      "train loss:0.16738251342546215\n",
      "train loss:0.03404271333292421\n",
      "train loss:0.16071890935684124\n",
      "train loss:0.19123188324278623\n",
      "train loss:0.28024651260929384\n",
      "train loss:0.20259737487190688\n",
      "train loss:0.15314593880923813\n",
      "train loss:0.17228194936823132\n",
      "train loss:0.3221389605289815\n",
      "train loss:0.24084579627334382\n",
      "train loss:0.16650021294866846\n",
      "train loss:0.12155146160932585\n",
      "train loss:0.1887478929870491\n",
      "train loss:0.27460732746879873\n",
      "train loss:0.09336405739734027\n",
      "train loss:0.18802490394492427\n",
      "train loss:0.15403202420121456\n",
      "train loss:0.1348708300823158\n",
      "train loss:0.2337957312398484\n",
      "train loss:0.13029831854024845\n",
      "train loss:0.20949951410354528\n",
      "train loss:0.1917381220335132\n",
      "train loss:0.1908349526232783\n",
      "train loss:0.15546573967015365\n",
      "train loss:0.16545260588728414\n",
      "train loss:0.11432933979780455\n",
      "train loss:0.11311703829082137\n",
      "train loss:0.12972447593918834\n",
      "train loss:0.11562710830775097\n",
      "train loss:0.19538709305504148\n",
      "train loss:0.23007389565557868\n",
      "train loss:0.19961143021925676\n",
      "train loss:0.15881307848471815\n",
      "train loss:0.12880842155482466\n",
      "train loss:0.15869228428914198\n",
      "train loss:0.17847218198891412\n",
      "train loss:0.12149072091155272\n",
      "train loss:0.1403325798850008\n",
      "train loss:0.2739255762144072\n",
      "train loss:0.32937159306107183\n",
      "train loss:0.1264876584353237\n",
      "train loss:0.13618315152460692\n",
      "train loss:0.1949072034529942\n",
      "train loss:0.06915346173058971\n",
      "train loss:0.17433837520101922\n",
      "train loss:0.24391065320434105\n",
      "train loss:0.12790132495854026\n",
      "train loss:0.23870546604850731\n",
      "train loss:0.19687650400936985\n",
      "train loss:0.13423647074465384\n",
      "train loss:0.21036619310784363\n",
      "train loss:0.13435499625531094\n",
      "train loss:0.202595517790645\n",
      "train loss:0.15373359611895368\n",
      "train loss:0.1406165628796103\n",
      "train loss:0.2120613654751834\n",
      "train loss:0.19760700297529174\n",
      "train loss:0.16847650549881252\n",
      "train loss:0.26503602115351044\n",
      "train loss:0.11220692563890677\n",
      "train loss:0.13120749538834744\n",
      "train loss:0.1876241662334725\n",
      "train loss:0.15632625674290304\n",
      "train loss:0.25407530262741446\n",
      "train loss:0.22495399590211676\n",
      "train loss:0.1613036680487288\n",
      "train loss:0.16976861283875755\n",
      "train loss:0.19401599550700388\n",
      "train loss:0.15102411055526244\n",
      "train loss:0.18154524224592306\n",
      "train loss:0.20338493652057676\n",
      "train loss:0.1171722494051749\n",
      "train loss:0.22480047603203\n",
      "train loss:0.15532401319247097\n",
      "train loss:0.1959562037367699\n",
      "train loss:0.1117815008112642\n",
      "train loss:0.18699921288607999\n",
      "train loss:0.2013824914893475\n",
      "train loss:0.13295518951646207\n",
      "train loss:0.20149661310480696\n",
      "train loss:0.18406934708058242\n",
      "train loss:0.28145981674311255\n",
      "train loss:0.1269900258281422\n",
      "train loss:0.21478950940481184\n",
      "train loss:0.15171474046882147\n",
      "train loss:0.23106410544530698\n",
      "train loss:0.10588151946388719\n",
      "train loss:0.11419125555248395\n",
      "train loss:0.18278563377322013\n",
      "train loss:0.18861784443664914\n",
      "train loss:0.19011330628846929\n",
      "train loss:0.2514540876034548\n",
      "train loss:0.16269872117356285\n",
      "train loss:0.09999535057473213\n",
      "train loss:0.2577676863672703\n",
      "train loss:0.2757186586182125\n",
      "train loss:0.10346960203511767\n",
      "train loss:0.1530276992137323\n",
      "train loss:0.10267246039537145\n",
      "train loss:0.2627012335880193\n",
      "train loss:0.10439732479667015\n",
      "train loss:0.16931547715312398\n",
      "train loss:0.19109950607393603\n",
      "train loss:0.2131554071758176\n",
      "train loss:0.25433732589644015\n",
      "train loss:0.21238840191603925\n",
      "train loss:0.3037845939829231\n",
      "train loss:0.11957545073412204\n",
      "train loss:0.14429118144900913\n",
      "train loss:0.2029276428061139\n",
      "train loss:0.14508342376712857\n",
      "train loss:0.1861275625597619\n",
      "train loss:0.1409805083785929\n",
      "train loss:0.20132618308312622\n",
      "train loss:0.10784788150249543\n",
      "train loss:0.16299479755427435\n",
      "train loss:0.2442871188079726\n",
      "train loss:0.18727890811739267\n",
      "train loss:0.19158109080982919\n",
      "train loss:0.2614412607345935\n",
      "train loss:0.13382757343505478\n",
      "train loss:0.22055182796529013\n",
      "train loss:0.1656540140601651\n",
      "train loss:0.16420483013304726\n",
      "train loss:0.13261197406411707\n",
      "train loss:0.2783388938533488\n",
      "train loss:0.14697676382177494\n",
      "train loss:0.22023827648813588\n",
      "train loss:0.1813681425070352\n",
      "train loss:0.19732267294917716\n",
      "train loss:0.13893018816216018\n",
      "train loss:0.20126831997768416\n",
      "train loss:0.2206798978233042\n",
      "train loss:0.23742364402783647\n",
      "train loss:0.1344449427416984\n",
      "train loss:0.12716932292824487\n",
      "train loss:0.14176961410303285\n",
      "train loss:0.1834518366371243\n",
      "train loss:0.17603872670391588\n",
      "train loss:0.21645311993934616\n",
      "train loss:0.07917749698821888\n",
      "train loss:0.22812704890417584\n",
      "train loss:0.2957152553717066\n",
      "train loss:0.21454240547028658\n",
      "train loss:0.12950262618186562\n",
      "train loss:0.26038278049689917\n",
      "train loss:0.27772672944096954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.22223267963060767\n",
      "train loss:0.25028096667372035\n",
      "train loss:0.14691633496604317\n",
      "train loss:0.1611474708636659\n",
      "train loss:0.17349425786096556\n",
      "train loss:0.143967715492271\n",
      "train loss:0.21597810466954454\n",
      "train loss:0.18900306965168245\n",
      "train loss:0.11802839849976342\n",
      "train loss:0.24151616389566674\n",
      "train loss:0.20031467876039188\n",
      "train loss:0.19322853725180514\n",
      "train loss:0.10824740951297818\n",
      "train loss:0.16299069383514633\n",
      "train loss:0.11703372615191929\n",
      "train loss:0.17295370883524597\n",
      "train loss:0.2453765428208452\n",
      "train loss:0.3060773026902538\n",
      "train loss:0.1990723639491641\n",
      "train loss:0.13070572176825482\n",
      "train loss:0.13989604653160256\n",
      "train loss:0.15108441564227684\n",
      "train loss:0.1358557589366292\n",
      "train loss:0.16465461765813788\n",
      "train loss:0.14809828048074544\n",
      "train loss:0.16962430937155074\n",
      "train loss:0.16595220140744832\n",
      "train loss:0.20324486348640355\n",
      "train loss:0.18250491239501943\n",
      "train loss:0.1659838455339816\n",
      "train loss:0.1487259933055339\n",
      "train loss:0.2180114094657407\n",
      "=== epoch:10, train acc:0.942, test acc:0.907 ===\n",
      "train loss:0.114403561423917\n",
      "train loss:0.14990073248673247\n",
      "train loss:0.2101224730276493\n",
      "train loss:0.14416307430378802\n",
      "train loss:0.1982066777526597\n",
      "train loss:0.24278513035351149\n",
      "train loss:0.1205907638304071\n",
      "train loss:0.2072630228463154\n",
      "train loss:0.18880729058403564\n",
      "train loss:0.255095840992757\n",
      "train loss:0.10873539460107105\n",
      "train loss:0.15084224443586977\n",
      "train loss:0.17785575027813072\n",
      "train loss:0.18854010631040047\n",
      "train loss:0.16206100191986164\n",
      "train loss:0.13484899803514855\n",
      "train loss:0.15299683512435644\n",
      "train loss:0.12475452266192966\n",
      "train loss:0.11122406885274376\n",
      "train loss:0.14575853590287757\n",
      "train loss:0.18217279676924253\n",
      "train loss:0.18276092928847087\n",
      "train loss:0.18046802443809726\n",
      "train loss:0.1435522785428121\n",
      "train loss:0.1795871570034343\n",
      "train loss:0.17921489771997495\n",
      "train loss:0.22964586286070424\n",
      "train loss:0.1446135422864515\n",
      "train loss:0.1603868849806076\n",
      "train loss:0.13823788691949535\n",
      "train loss:0.15916669863572938\n",
      "train loss:0.258915500017324\n",
      "train loss:0.29520287559706276\n",
      "train loss:0.2055213387749324\n",
      "train loss:0.13605020849680743\n",
      "train loss:0.22052892448120986\n",
      "train loss:0.26831093708666537\n",
      "train loss:0.1267983699521725\n",
      "train loss:0.17377576887586665\n",
      "train loss:0.23839113758209582\n",
      "train loss:0.21342468526735306\n",
      "train loss:0.10931754711261701\n",
      "train loss:0.12703311767800304\n",
      "train loss:0.15698882200537637\n",
      "train loss:0.12159805601284607\n",
      "train loss:0.22154234266051737\n",
      "train loss:0.1760951491645139\n",
      "train loss:0.19269912399449055\n",
      "train loss:0.18520918591863175\n",
      "train loss:0.08893910091958393\n",
      "train loss:0.12606682241730216\n",
      "train loss:0.14850205338005493\n",
      "train loss:0.10672029731437975\n",
      "train loss:0.13760065622811596\n",
      "train loss:0.15180545642279625\n",
      "train loss:0.18074735999072084\n",
      "train loss:0.1324809970794384\n",
      "train loss:0.24782074137527066\n",
      "train loss:0.14870150700985854\n",
      "train loss:0.2537195272010091\n",
      "train loss:0.15461375093068608\n",
      "train loss:0.1711781869743464\n",
      "train loss:0.14085594109882607\n",
      "train loss:0.20607568031820747\n",
      "train loss:0.14812880447825869\n",
      "train loss:0.19647560707655942\n",
      "train loss:0.2884230057911571\n",
      "train loss:0.12162203706354878\n",
      "train loss:0.18824196451159445\n",
      "train loss:0.19283667835958732\n",
      "train loss:0.17665915593107492\n",
      "train loss:0.1962795221914421\n",
      "train loss:0.22149725849385074\n",
      "train loss:0.1363742287153148\n",
      "train loss:0.20713895226959977\n",
      "train loss:0.23194980401819326\n",
      "train loss:0.17989531158774966\n",
      "train loss:0.19936158957228836\n",
      "train loss:0.13860839717214096\n",
      "train loss:0.13629160867903892\n",
      "train loss:0.25631601104889484\n",
      "train loss:0.3160363345024323\n",
      "train loss:0.32137311375842137\n",
      "train loss:0.16778872145768456\n",
      "train loss:0.15497808954641645\n",
      "train loss:0.23790682218769788\n",
      "train loss:0.1280783036337824\n",
      "train loss:0.10275725682999917\n",
      "train loss:0.15913065819306038\n",
      "train loss:0.1162633216696402\n",
      "train loss:0.16169274228511746\n",
      "train loss:0.24573537639593707\n",
      "train loss:0.1803052361043296\n",
      "train loss:0.22107231883414807\n",
      "train loss:0.28531303994202\n",
      "train loss:0.15563510877944395\n",
      "train loss:0.19810192365415857\n",
      "train loss:0.16872276274424958\n",
      "train loss:0.18672907024073787\n",
      "train loss:0.16755930103449365\n",
      "train loss:0.2162504399923552\n",
      "train loss:0.2893626933720077\n",
      "train loss:0.15491163388840656\n",
      "train loss:0.18936256560383435\n",
      "train loss:0.20776492064411034\n",
      "train loss:0.1871047895484626\n",
      "train loss:0.1725196467882229\n",
      "train loss:0.2260398188345024\n",
      "train loss:0.2107294354529074\n",
      "train loss:0.15268268378355426\n",
      "train loss:0.22151945358450204\n",
      "train loss:0.10841684204158249\n",
      "train loss:0.22346080594043058\n",
      "train loss:0.23729252766765757\n",
      "train loss:0.14767249844241387\n",
      "train loss:0.08520829532275082\n",
      "train loss:0.1695611336840321\n",
      "train loss:0.16455983542954455\n",
      "train loss:0.23287267400362668\n",
      "train loss:0.23883201988270855\n",
      "train loss:0.09190705534456747\n",
      "train loss:0.1374679319760528\n",
      "train loss:0.1472604332990786\n",
      "train loss:0.15427270632594683\n",
      "train loss:0.2320480092290541\n",
      "train loss:0.09417006653835283\n",
      "train loss:0.2169058588176067\n",
      "train loss:0.16131060914372383\n",
      "train loss:0.15478761044179312\n",
      "train loss:0.31670429828593205\n",
      "train loss:0.11635110401624366\n",
      "train loss:0.14223100662180108\n",
      "train loss:0.19524282030321122\n",
      "train loss:0.18896060053011868\n",
      "train loss:0.2827958558752566\n",
      "train loss:0.23373227732117738\n",
      "train loss:0.21322675190388496\n",
      "train loss:0.19681784213288292\n",
      "train loss:0.15879870645203828\n",
      "train loss:0.2884967396193\n",
      "train loss:0.1869355423968801\n",
      "train loss:0.20496219757702172\n",
      "train loss:0.17080887930169353\n",
      "train loss:0.2027609228813719\n",
      "train loss:0.18241375487348818\n",
      "train loss:0.08573154727657598\n",
      "train loss:0.21169439279659333\n",
      "train loss:0.19330351910401614\n",
      "train loss:0.20084100280551617\n",
      "train loss:0.10917444583213902\n",
      "train loss:0.13924428750395534\n",
      "train loss:0.1751381202187769\n",
      "train loss:0.23068672831620524\n",
      "train loss:0.13735204718052815\n",
      "train loss:0.1373509897462117\n",
      "train loss:0.1519710552535137\n",
      "train loss:0.11956629805696994\n",
      "train loss:0.19372675959088934\n",
      "train loss:0.23047869366136464\n",
      "train loss:0.15913161577307894\n",
      "train loss:0.07769686413427909\n",
      "train loss:0.18959387793016538\n",
      "train loss:0.1838822219729153\n",
      "train loss:0.24632057124925041\n",
      "train loss:0.13496987771785074\n",
      "train loss:0.08248228634561172\n",
      "train loss:0.21311023731473927\n",
      "train loss:0.12773492606416895\n",
      "train loss:0.3443610320280567\n",
      "train loss:0.17031335713474868\n",
      "train loss:0.16036300551377877\n",
      "train loss:0.19907123138423327\n",
      "train loss:0.18511560544857886\n",
      "train loss:0.18679979103723987\n",
      "train loss:0.1508864727106776\n",
      "train loss:0.18546366990104116\n",
      "train loss:0.13949651501743726\n",
      "train loss:0.1405222565312309\n",
      "train loss:0.3415713631650545\n",
      "train loss:0.1580757058226998\n",
      "train loss:0.09263739334600275\n",
      "train loss:0.13657599376123733\n",
      "train loss:0.22479078947268222\n",
      "train loss:0.16609183229787575\n",
      "train loss:0.0938301330992564\n",
      "train loss:0.09393844732038746\n",
      "train loss:0.10977941298030344\n",
      "train loss:0.10246153085029426\n",
      "train loss:0.168534712533346\n",
      "train loss:0.1518039657660496\n",
      "train loss:0.23217225326158658\n",
      "train loss:0.16141184497722377\n",
      "train loss:0.1451133146993878\n",
      "train loss:0.13949207490285853\n",
      "train loss:0.17297430590527899\n",
      "train loss:0.12280239771908734\n",
      "train loss:0.13546212364412552\n",
      "train loss:0.10859939654427013\n",
      "train loss:0.1509771310713259\n",
      "train loss:0.15204142517232955\n",
      "train loss:0.12220245245766184\n",
      "train loss:0.2211661556383463\n",
      "train loss:0.13695767153794283\n",
      "train loss:0.11728241916486354\n",
      "train loss:0.15238800413845083\n",
      "train loss:0.23628413259932293\n",
      "train loss:0.19975523096431896\n",
      "train loss:0.22150822418607546\n",
      "train loss:0.209222917834143\n",
      "train loss:0.2332403967047773\n",
      "train loss:0.2634691786764603\n",
      "train loss:0.21705461242463844\n",
      "train loss:0.141610656994029\n",
      "train loss:0.15858374441492507\n",
      "train loss:0.2716270931527893\n",
      "train loss:0.20324194632404016\n",
      "train loss:0.15331572733829948\n",
      "train loss:0.10145539821803322\n",
      "train loss:0.08150819633384895\n",
      "train loss:0.18442694519082786\n",
      "train loss:0.15151145494556675\n",
      "train loss:0.09957492620907868\n",
      "train loss:0.11590902560252862\n",
      "train loss:0.25709712508960936\n",
      "train loss:0.24420086806802155\n",
      "train loss:0.2580086276474091\n",
      "train loss:0.10301497805446633\n",
      "train loss:0.19373167850919068\n",
      "train loss:0.17354696596308117\n",
      "train loss:0.17708827141914224\n",
      "train loss:0.25281573537306135\n",
      "train loss:0.15406489060211423\n",
      "train loss:0.23630275153797778\n",
      "train loss:0.12585155900165118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.11267119266503207\n",
      "train loss:0.26175339311676776\n",
      "train loss:0.10746255658575482\n",
      "train loss:0.0890231046569423\n",
      "train loss:0.2020186007375759\n",
      "train loss:0.20127508717383158\n",
      "train loss:0.1444929446743989\n",
      "train loss:0.16564347230890342\n",
      "train loss:0.1549278427726598\n",
      "train loss:0.15211088889339744\n",
      "train loss:0.21250702766922225\n",
      "train loss:0.1601116966847435\n",
      "train loss:0.1306487720568142\n",
      "train loss:0.15617511668098458\n",
      "train loss:0.1805133613440715\n",
      "train loss:0.13650495123829912\n",
      "train loss:0.11202232573486504\n",
      "train loss:0.2434289945931214\n",
      "train loss:0.09895997103018567\n",
      "train loss:0.0963350960759371\n",
      "train loss:0.07427899906302894\n",
      "train loss:0.1058101742344965\n",
      "train loss:0.25387114305828645\n",
      "train loss:0.21104203651855807\n",
      "train loss:0.1458030110899408\n",
      "train loss:0.1326535147717447\n",
      "train loss:0.21429228469600065\n",
      "train loss:0.09519564962326632\n",
      "train loss:0.14088318732098606\n",
      "train loss:0.19403835105789444\n",
      "train loss:0.12770739504564996\n",
      "train loss:0.2018926916230484\n",
      "train loss:0.15930020120541621\n",
      "train loss:0.17094028556942795\n",
      "train loss:0.27912514757380913\n",
      "train loss:0.1766059692481023\n",
      "train loss:0.26080165484506673\n",
      "train loss:0.1772632320323514\n",
      "train loss:0.13484629044209356\n",
      "train loss:0.10464426241046879\n",
      "train loss:0.21943002478364884\n",
      "train loss:0.13710297229525603\n",
      "train loss:0.154869855429078\n",
      "train loss:0.20758733243339492\n",
      "train loss:0.20244184920816796\n",
      "train loss:0.17749376940180947\n",
      "train loss:0.18537172610594146\n",
      "train loss:0.15459633790143978\n",
      "train loss:0.16375530115070042\n",
      "train loss:0.1288709662384766\n",
      "train loss:0.18421612454008998\n",
      "train loss:0.14925766047626818\n",
      "train loss:0.1737621699575013\n",
      "train loss:0.14627374372178165\n",
      "train loss:0.16446291783413447\n",
      "train loss:0.1070528660745283\n",
      "train loss:0.1745289919547538\n",
      "train loss:0.24193189737363233\n",
      "train loss:0.2630549601999984\n",
      "train loss:0.11779999192201769\n",
      "train loss:0.13885302020466775\n",
      "train loss:0.13047640966656612\n",
      "train loss:0.12273732440329521\n",
      "train loss:0.14058982551381355\n",
      "train loss:0.14485594966116092\n",
      "train loss:0.1124455857162398\n",
      "train loss:0.11734503496040664\n",
      "train loss:0.13345568724543908\n",
      "train loss:0.10117301138935042\n",
      "train loss:0.19889120537955576\n",
      "train loss:0.206795676715938\n",
      "train loss:0.13759243052099526\n",
      "train loss:0.2454497477915276\n",
      "train loss:0.19244624073734568\n",
      "train loss:0.17216618216933757\n",
      "train loss:0.09319644633185269\n",
      "train loss:0.15295525182837116\n",
      "train loss:0.12535758976578149\n",
      "train loss:0.21584382841233007\n",
      "train loss:0.1752147891748857\n",
      "train loss:0.21513639427341277\n",
      "train loss:0.2537765048913777\n",
      "train loss:0.22203323689397997\n",
      "train loss:0.1306092813392554\n",
      "train loss:0.12146247410989472\n",
      "train loss:0.18719059982547084\n",
      "train loss:0.25347931959814546\n",
      "train loss:0.1121567954758193\n",
      "train loss:0.20047875846967556\n",
      "train loss:0.17988851599086833\n",
      "train loss:0.1405247383455329\n",
      "train loss:0.14049209501571644\n",
      "train loss:0.10859976067150302\n",
      "train loss:0.17717768245918272\n",
      "train loss:0.11226907153214734\n",
      "train loss:0.08999292618630977\n",
      "train loss:0.16026918899594392\n",
      "train loss:0.11139938288436238\n",
      "train loss:0.22847463707848917\n",
      "train loss:0.21340878831324964\n",
      "train loss:0.10112824503040374\n",
      "train loss:0.20208229659352075\n",
      "train loss:0.111179974074843\n",
      "train loss:0.12312367634901258\n",
      "train loss:0.13830505418322991\n",
      "train loss:0.18398152761461634\n",
      "train loss:0.12121162280533677\n",
      "train loss:0.1286757135257239\n",
      "train loss:0.22785390784557985\n",
      "train loss:0.09132290740636868\n",
      "train loss:0.20989866156131629\n",
      "train loss:0.14543171077474917\n",
      "train loss:0.19714040376488667\n",
      "train loss:0.21361577851853603\n",
      "train loss:0.277685671251713\n",
      "train loss:0.18442995188018668\n",
      "train loss:0.12866300695593716\n",
      "train loss:0.14018324140059632\n",
      "train loss:0.1923790543012483\n",
      "train loss:0.15728591387544572\n",
      "train loss:0.13939000478429248\n",
      "train loss:0.1565899258307647\n",
      "train loss:0.15945123570688227\n",
      "train loss:0.13195965254498584\n",
      "train loss:0.20624436976779012\n",
      "train loss:0.24179928286133812\n",
      "train loss:0.2121395369277668\n",
      "train loss:0.17895081631175255\n",
      "train loss:0.10248812362899068\n",
      "train loss:0.1205366308100592\n",
      "train loss:0.14076259762717308\n",
      "train loss:0.12828528471132303\n",
      "train loss:0.21826665749788954\n",
      "train loss:0.18035759171117932\n",
      "train loss:0.23523413938152443\n",
      "train loss:0.17133054178498847\n",
      "train loss:0.198597842134797\n",
      "train loss:0.14166269889987096\n",
      "train loss:0.16968899888197925\n",
      "train loss:0.22477801089700156\n",
      "train loss:0.1752048496306326\n",
      "train loss:0.18308438481173156\n",
      "train loss:0.14414091305738383\n",
      "train loss:0.11560076176937717\n",
      "train loss:0.18664445254404394\n",
      "train loss:0.09568904297126014\n",
      "train loss:0.1745938973277975\n",
      "train loss:0.15518978534391814\n",
      "train loss:0.13664530262546637\n",
      "train loss:0.1389254100630845\n",
      "train loss:0.14798403540678984\n",
      "train loss:0.06983940430826811\n",
      "train loss:0.14219690022868417\n",
      "train loss:0.11396426022833245\n",
      "train loss:0.09824844786288985\n",
      "train loss:0.21307727274273444\n",
      "train loss:0.11262994620603912\n",
      "train loss:0.15023454094826127\n",
      "train loss:0.22651645922929434\n",
      "train loss:0.11874242751130794\n",
      "train loss:0.15649591650367922\n",
      "train loss:0.14493392378364633\n",
      "train loss:0.15062637399763928\n",
      "train loss:0.2065195505483058\n",
      "train loss:0.23676926848563298\n",
      "train loss:0.09762293173893583\n",
      "train loss:0.16973985587738646\n",
      "train loss:0.19595034488344382\n",
      "train loss:0.16144128111559528\n",
      "train loss:0.2587987795686922\n",
      "train loss:0.32605974457027154\n",
      "train loss:0.13180387573240263\n",
      "train loss:0.23824099258613846\n",
      "train loss:0.13387856268662784\n",
      "train loss:0.09760459308784915\n",
      "train loss:0.1092255554652291\n",
      "train loss:0.08361226907914944\n",
      "train loss:0.1175838523674773\n",
      "train loss:0.1629555521891513\n",
      "train loss:0.12042531619294966\n",
      "train loss:0.14321149335840955\n",
      "train loss:0.13691373026205403\n",
      "train loss:0.16377422372077646\n",
      "train loss:0.19912222678108346\n",
      "train loss:0.1012231602432216\n",
      "train loss:0.14818951668756897\n",
      "train loss:0.13707479911491677\n",
      "train loss:0.17855434423078342\n",
      "train loss:0.1398538269304743\n",
      "train loss:0.1889149577434267\n",
      "train loss:0.15772757606341936\n",
      "train loss:0.23651179779044146\n",
      "train loss:0.10765242675717798\n",
      "train loss:0.15472784700972167\n",
      "train loss:0.15379862993005797\n",
      "train loss:0.13841436933177662\n",
      "train loss:0.19935596056510385\n",
      "train loss:0.14538363046709635\n",
      "train loss:0.10764433774737886\n",
      "train loss:0.23333023375813058\n",
      "train loss:0.15987820895358706\n",
      "train loss:0.1308294872673678\n",
      "train loss:0.17426734093470542\n",
      "train loss:0.11019585019720032\n",
      "train loss:0.12917392227503716\n",
      "train loss:0.3052117425864548\n",
      "train loss:0.16539997910600573\n",
      "train loss:0.17814604279405744\n",
      "train loss:0.1291547296060986\n",
      "train loss:0.09101705205801819\n",
      "train loss:0.21502243914493327\n",
      "train loss:0.20416062196512466\n",
      "train loss:0.18944378593891176\n",
      "train loss:0.1085854373325065\n",
      "train loss:0.11484711117330144\n",
      "train loss:0.2690292466878297\n",
      "train loss:0.23010436033742085\n",
      "train loss:0.20379562120823483\n",
      "train loss:0.3192685042563359\n",
      "train loss:0.18100867213054606\n",
      "train loss:0.16618395128145455\n",
      "train loss:0.20394402221299324\n",
      "train loss:0.17690863067988313\n",
      "train loss:0.1951743426037478\n",
      "train loss:0.10968678011706326\n",
      "train loss:0.10830668111046732\n",
      "train loss:0.07909656170994596\n",
      "train loss:0.17954857495338278\n",
      "train loss:0.1303857701571935\n",
      "train loss:0.1508498812730431\n",
      "train loss:0.2892633865003311\n",
      "train loss:0.13423941054936472\n",
      "train loss:0.19032664086527226\n",
      "train loss:0.13564771451353047\n",
      "train loss:0.14704227343041354\n",
      "train loss:0.11821185695878912\n",
      "train loss:0.16057851104502296\n",
      "train loss:0.1364179407326794\n",
      "train loss:0.1993353247475501\n",
      "train loss:0.1606163444655443\n",
      "train loss:0.15158398655185396\n",
      "train loss:0.13364621252939876\n",
      "train loss:0.11035641621682181\n",
      "train loss:0.17344605726816373\n",
      "train loss:0.2034463302996493\n",
      "train loss:0.12826783031292174\n",
      "train loss:0.14226800608330792\n",
      "train loss:0.08090648767368475\n",
      "train loss:0.13192948572495977\n",
      "train loss:0.13105079399531783\n",
      "train loss:0.1770699890518819\n",
      "train loss:0.2380741615064867\n",
      "train loss:0.11745428165194279\n",
      "train loss:0.192717086534656\n",
      "train loss:0.18895879512609887\n",
      "train loss:0.14143623271138445\n",
      "train loss:0.18910018630401024\n",
      "train loss:0.09033237000434421\n",
      "train loss:0.11916394178943918\n",
      "train loss:0.12481753386670062\n",
      "train loss:0.12801174642204688\n",
      "train loss:0.2023975911436384\n",
      "train loss:0.3637525381472366\n",
      "train loss:0.1012795792516284\n",
      "train loss:0.10616282132233228\n",
      "train loss:0.1618345302863004\n",
      "train loss:0.12121483108183505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.11731769782295365\n",
      "train loss:0.11798017342806004\n",
      "train loss:0.157713606112038\n",
      "train loss:0.31073161578591024\n",
      "train loss:0.15961594348463537\n",
      "train loss:0.16414933680553634\n",
      "train loss:0.08845061365694906\n",
      "train loss:0.10057216957116491\n",
      "train loss:0.16383467044989067\n",
      "train loss:0.16619981610247853\n",
      "train loss:0.10828505341997513\n",
      "train loss:0.21800016738114814\n",
      "train loss:0.15449285353354145\n",
      "train loss:0.13506433040230773\n",
      "train loss:0.11830468606849415\n",
      "train loss:0.18896580489153225\n",
      "train loss:0.10836685391816754\n",
      "train loss:0.23099830016686895\n",
      "train loss:0.18242697209830044\n",
      "train loss:0.13240926941735673\n",
      "train loss:0.2980431172925693\n",
      "train loss:0.15805145728370895\n",
      "train loss:0.23930430860984908\n",
      "train loss:0.12171887151920924\n",
      "train loss:0.15790355921625182\n",
      "train loss:0.1459960492180732\n",
      "train loss:0.05651298583681905\n",
      "train loss:0.13012613605619142\n",
      "train loss:0.15135448365493176\n",
      "train loss:0.2557574220768869\n",
      "train loss:0.18974276407302743\n",
      "train loss:0.05067922046552196\n",
      "train loss:0.23803991947688363\n",
      "train loss:0.09815390198448011\n",
      "train loss:0.13972506630355588\n",
      "train loss:0.1770786192889335\n",
      "train loss:0.14649102342879217\n",
      "train loss:0.08588502036194352\n",
      "train loss:0.1371768468234467\n",
      "train loss:0.14956918065724156\n",
      "train loss:0.0961784804603985\n",
      "train loss:0.09737559907117183\n",
      "train loss:0.07902321913396118\n",
      "train loss:0.1159821690395196\n",
      "train loss:0.2846632562100644\n",
      "train loss:0.1882708481636729\n",
      "train loss:0.10431662327903723\n",
      "train loss:0.09865645085431936\n",
      "train loss:0.15268368136110494\n",
      "train loss:0.2564343944091667\n",
      "train loss:0.15276276516090778\n",
      "train loss:0.15069083815378562\n",
      "train loss:0.1561610284892954\n",
      "train loss:0.16997229608678008\n",
      "train loss:0.11975874295813185\n",
      "train loss:0.1737048621653616\n",
      "train loss:0.10793410980442843\n",
      "train loss:0.10668299817803453\n",
      "train loss:0.08914919825491074\n",
      "train loss:0.16926546770534037\n",
      "train loss:0.129863469771818\n",
      "train loss:0.15860822241227238\n",
      "train loss:0.1741976541964018\n",
      "train loss:0.09204105193501869\n",
      "train loss:0.17130117145119128\n",
      "train loss:0.2462225905659837\n",
      "train loss:0.22432234332343856\n",
      "train loss:0.19762168923166115\n",
      "train loss:0.18717599868861806\n",
      "train loss:0.2579411738827603\n",
      "train loss:0.1196034559123675\n",
      "train loss:0.2720622687199252\n",
      "train loss:0.18807815232986902\n",
      "train loss:0.1895454565799257\n",
      "train loss:0.18916335295147935\n",
      "train loss:0.1718347347473366\n",
      "train loss:0.12845569306145502\n",
      "train loss:0.15434770116788019\n",
      "train loss:0.09277119079212262\n",
      "train loss:0.19960747082897584\n",
      "train loss:0.16885818518439735\n",
      "train loss:0.22870730439344494\n",
      "train loss:0.1045785945684096\n",
      "train loss:0.16894795810890012\n",
      "train loss:0.22276958925456178\n",
      "train loss:0.13242840943436965\n",
      "train loss:0.1970805739409756\n",
      "train loss:0.15694573250443672\n",
      "train loss:0.14371924775352507\n",
      "train loss:0.15011245936476966\n",
      "train loss:0.22345282393987925\n",
      "train loss:0.16224950674946817\n",
      "train loss:0.2593008638504604\n",
      "train loss:0.10627697698052169\n",
      "train loss:0.14562526730949443\n",
      "train loss:0.25223886490097924\n",
      "train loss:0.22180439554941195\n",
      "train loss:0.16043474772901448\n",
      "train loss:0.13678278842101352\n",
      "=== epoch:11, train acc:0.942, test acc:0.896 ===\n",
      "train loss:0.26135076889331604\n",
      "train loss:0.21152222648397964\n",
      "train loss:0.11865727949592872\n",
      "train loss:0.20373765494111\n",
      "train loss:0.23311358679308228\n",
      "train loss:0.16039635357703724\n",
      "train loss:0.30232813752285925\n",
      "train loss:0.12859963615882744\n",
      "train loss:0.09641718659938708\n",
      "train loss:0.20161180421422717\n",
      "train loss:0.16885017792915158\n",
      "train loss:0.13290623236152888\n",
      "train loss:0.1356543025025107\n",
      "train loss:0.13580340405758906\n",
      "train loss:0.08853812277621662\n",
      "train loss:0.1112444350837523\n",
      "train loss:0.20136327472015825\n",
      "train loss:0.14115696740381653\n",
      "train loss:0.1327834027139454\n",
      "train loss:0.1287450229423648\n",
      "train loss:0.16703897236226337\n",
      "train loss:0.13218277593190497\n",
      "train loss:0.14749971747129453\n",
      "train loss:0.13073980331502497\n",
      "train loss:0.07162652561997587\n",
      "train loss:0.18852783630395367\n",
      "train loss:0.1593147752680796\n",
      "train loss:0.1507656623624336\n",
      "train loss:0.17066051462527315\n",
      "train loss:0.20208440236786152\n",
      "train loss:0.10302118305561843\n",
      "train loss:0.14055883897980834\n",
      "train loss:0.10226331552535112\n",
      "train loss:0.25154293164450015\n",
      "train loss:0.1996707387787795\n",
      "train loss:0.1705977638098799\n",
      "train loss:0.16450953159839013\n",
      "train loss:0.18601083052422876\n",
      "train loss:0.10015395067678573\n",
      "train loss:0.07394765332633654\n",
      "train loss:0.23030262840674035\n",
      "train loss:0.1576521340614234\n",
      "train loss:0.2026725771924467\n",
      "train loss:0.2630020712052083\n",
      "train loss:0.15257852427668891\n",
      "train loss:0.08980761864102536\n",
      "train loss:0.1177314177865677\n",
      "train loss:0.17500957163095424\n",
      "train loss:0.25968004943258505\n",
      "train loss:0.18884647765191803\n",
      "train loss:0.10253519556793397\n",
      "train loss:0.16983317638686832\n",
      "train loss:0.13360438678093803\n",
      "train loss:0.14704196428114436\n",
      "train loss:0.14714265515476652\n",
      "train loss:0.16282022114000325\n",
      "train loss:0.19346864002313396\n",
      "train loss:0.09048731368190972\n",
      "train loss:0.18727161250100793\n",
      "train loss:0.0773482019927183\n",
      "train loss:0.14976006324503047\n",
      "train loss:0.17344610969288976\n",
      "train loss:0.20125134533675926\n",
      "train loss:0.104234713892329\n",
      "train loss:0.1642374211376225\n",
      "train loss:0.11205399593370677\n",
      "train loss:0.2665974578154168\n",
      "train loss:0.20456121116787235\n",
      "train loss:0.13755353456985675\n",
      "train loss:0.18510145059578476\n",
      "train loss:0.175015577995865\n",
      "train loss:0.1538890816245812\n",
      "train loss:0.10913042400621226\n",
      "train loss:0.1634707142383738\n",
      "train loss:0.15849028926883296\n",
      "train loss:0.17719910772333197\n",
      "train loss:0.15027721116750575\n",
      "train loss:0.1602387061835467\n",
      "train loss:0.19612568208493275\n",
      "train loss:0.17064229140875375\n",
      "train loss:0.25542482746619977\n",
      "train loss:0.2210288974062079\n",
      "train loss:0.1278178765021711\n",
      "train loss:0.06719391587962988\n",
      "train loss:0.09004330992259624\n",
      "train loss:0.11956600739910822\n",
      "train loss:0.1259857157946052\n",
      "train loss:0.14568349990388485\n",
      "train loss:0.1306952658907784\n",
      "train loss:0.079529761988094\n",
      "train loss:0.10792545902441714\n",
      "train loss:0.09520746547306894\n",
      "train loss:0.2040216815045261\n",
      "train loss:0.10027526246300326\n",
      "train loss:0.1723061969608117\n",
      "train loss:0.15503713487443826\n",
      "train loss:0.16034690885774341\n",
      "train loss:0.2151011892636563\n",
      "train loss:0.08268162002304576\n",
      "train loss:0.16832418037859742\n",
      "train loss:0.13598122714714644\n",
      "train loss:0.22041945785288225\n",
      "train loss:0.14644037588750297\n",
      "train loss:0.20139543394285167\n",
      "train loss:0.15762818448137814\n",
      "train loss:0.2252297300622369\n",
      "train loss:0.06192866421765173\n",
      "train loss:0.08180321940790845\n",
      "train loss:0.13934670806100125\n",
      "train loss:0.19292488192521925\n",
      "train loss:0.1645892908287454\n",
      "train loss:0.20740377501679577\n",
      "train loss:0.17730261083167606\n",
      "train loss:0.1444766106646519\n",
      "train loss:0.1296453969920439\n",
      "train loss:0.08041005122811704\n",
      "train loss:0.11900581350612593\n",
      "train loss:0.12803367020486975\n",
      "train loss:0.10441800247931717\n",
      "train loss:0.08376870294187158\n",
      "train loss:0.1557382525389994\n",
      "train loss:0.12015375310486187\n",
      "train loss:0.14963995151260664\n",
      "train loss:0.14939014082852328\n",
      "train loss:0.11112450958081625\n",
      "train loss:0.14706272992746863\n",
      "train loss:0.20394455061196723\n",
      "train loss:0.1462885687677089\n",
      "train loss:0.15598493522341164\n",
      "train loss:0.053555378339149015\n",
      "train loss:0.13591694097602325\n",
      "train loss:0.16348215954055614\n",
      "train loss:0.10831377549219962\n",
      "train loss:0.1491846813776631\n",
      "train loss:0.0729228118325601\n",
      "train loss:0.1835364237232372\n",
      "train loss:0.08663383138991482\n",
      "train loss:0.21624328213057303\n",
      "train loss:0.1416349663578607\n",
      "train loss:0.2271196104649902\n",
      "train loss:0.2218179322127903\n",
      "train loss:0.1399863033198368\n",
      "train loss:0.12009371633680185\n",
      "train loss:0.18124560086402178\n",
      "train loss:0.13039240241240851\n",
      "train loss:0.1057907334435874\n",
      "train loss:0.11458874164421039\n",
      "train loss:0.15676310722350148\n",
      "train loss:0.13640484394121496\n",
      "train loss:0.13548677922532545\n",
      "train loss:0.10235416547872006\n",
      "train loss:0.10898699470571374\n",
      "train loss:0.14474494030656337\n",
      "train loss:0.11169439203761511\n",
      "train loss:0.19915232676185946\n",
      "train loss:0.1946449884376111\n",
      "train loss:0.06720143894712284\n",
      "train loss:0.0903997642657677\n",
      "train loss:0.09871321542479963\n",
      "train loss:0.168960784474621\n",
      "train loss:0.2023101407391589\n",
      "train loss:0.19549839060710453\n",
      "train loss:0.22581923076189686\n",
      "train loss:0.18193718729264044\n",
      "train loss:0.06284601747173874\n",
      "train loss:0.13217302217899837\n",
      "train loss:0.11145577998375882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.17519735688972754\n",
      "train loss:0.1672611465823409\n",
      "train loss:0.1383485616381807\n",
      "train loss:0.12931623839742656\n",
      "train loss:0.11023816054783005\n",
      "train loss:0.2477000414182319\n",
      "train loss:0.16079125602041558\n",
      "train loss:0.13781142094073925\n",
      "train loss:0.13375977537617628\n",
      "train loss:0.10492951861427383\n",
      "train loss:0.14979118131957309\n",
      "train loss:0.07121732686737606\n",
      "train loss:0.17640871180924886\n",
      "train loss:0.1306023332138152\n",
      "train loss:0.11773303813236097\n",
      "train loss:0.13042573961453596\n",
      "train loss:0.12167850513523837\n",
      "train loss:0.11747619052740348\n",
      "train loss:0.1992324003689709\n",
      "train loss:0.15587961325845842\n",
      "train loss:0.11883106995476428\n",
      "train loss:0.13090286751101654\n",
      "train loss:0.10479802387923483\n",
      "train loss:0.14084755188322687\n",
      "train loss:0.1406921617363123\n",
      "train loss:0.1032135322339084\n",
      "train loss:0.16908802648455484\n",
      "train loss:0.1365701091269772\n",
      "train loss:0.20567254756997233\n",
      "train loss:0.1646989586847247\n",
      "train loss:0.11046651242962525\n",
      "train loss:0.13386528260695252\n",
      "train loss:0.09427709068714646\n",
      "train loss:0.1011754211019049\n",
      "train loss:0.0705761630167934\n",
      "train loss:0.22323134452546156\n",
      "train loss:0.14969228206378657\n",
      "train loss:0.1381085248987976\n",
      "train loss:0.10503970513067179\n",
      "train loss:0.27957032689687333\n",
      "train loss:0.16989584369038532\n",
      "train loss:0.1345997227543703\n",
      "train loss:0.09641700213650944\n",
      "train loss:0.1454351995860176\n",
      "train loss:0.25160715944706014\n",
      "train loss:0.16230412162506755\n",
      "train loss:0.15048058723734115\n",
      "train loss:0.16213189860510824\n",
      "train loss:0.21133000465338841\n",
      "train loss:0.13519422474288315\n",
      "train loss:0.2173809575918578\n",
      "train loss:0.22529319245623433\n",
      "train loss:0.18659095384555313\n",
      "train loss:0.15935581542099847\n",
      "train loss:0.11459478596232038\n",
      "train loss:0.09267079118343531\n",
      "train loss:0.12370689332888192\n",
      "train loss:0.2155759750149232\n",
      "train loss:0.12395322770821349\n",
      "train loss:0.07838804960029012\n",
      "train loss:0.13831814336993264\n",
      "train loss:0.11416237479160966\n",
      "train loss:0.17093591059448077\n",
      "train loss:0.17580422646573746\n",
      "train loss:0.13316100989324606\n",
      "train loss:0.15859473967195814\n",
      "train loss:0.17186873018207424\n",
      "train loss:0.21002985818392755\n",
      "train loss:0.1311073200213958\n",
      "train loss:0.1307221804588934\n",
      "train loss:0.20310007110450012\n",
      "train loss:0.13664235282462392\n",
      "train loss:0.13788495163279743\n",
      "train loss:0.2014108386844918\n",
      "train loss:0.12416080549546678\n",
      "train loss:0.14984219435065868\n",
      "train loss:0.1383590476028677\n",
      "train loss:0.19143758730746258\n",
      "train loss:0.07605666730761075\n",
      "train loss:0.10482813558410699\n",
      "train loss:0.17624154100300563\n",
      "train loss:0.15509772714025696\n",
      "train loss:0.13974716374508345\n",
      "train loss:0.12385041663531922\n",
      "train loss:0.13209394047055015\n",
      "train loss:0.1096882885425504\n",
      "train loss:0.11095361750639089\n",
      "train loss:0.14232229303982014\n",
      "train loss:0.21358884565159844\n",
      "train loss:0.12962918570724896\n",
      "train loss:0.2596204683799771\n",
      "train loss:0.07646382440230262\n",
      "train loss:0.09912908351812265\n",
      "train loss:0.15022211762205154\n",
      "train loss:0.10487079617007615\n",
      "train loss:0.12963532870523187\n",
      "train loss:0.16482221763122354\n",
      "train loss:0.11493008904616409\n",
      "train loss:0.1902628151612414\n",
      "train loss:0.09111246265502063\n",
      "train loss:0.09542140183372742\n",
      "train loss:0.10549818471621515\n",
      "train loss:0.2062684297265996\n",
      "train loss:0.27115837364617706\n",
      "train loss:0.20022972805803904\n",
      "train loss:0.19611156067161808\n",
      "train loss:0.21189349657418322\n",
      "train loss:0.10724929486227602\n",
      "train loss:0.15731690733609077\n",
      "train loss:0.15606129826143772\n",
      "train loss:0.14319585082880362\n",
      "train loss:0.09564125026920521\n",
      "train loss:0.20081671670676152\n",
      "train loss:0.2706125794566823\n",
      "train loss:0.16867108718521556\n",
      "train loss:0.2480042588721301\n",
      "train loss:0.21355398819555904\n",
      "train loss:0.13412222510764665\n",
      "train loss:0.15714004653587302\n",
      "train loss:0.2104833724529251\n",
      "train loss:0.16825632003987592\n",
      "train loss:0.25054803457634006\n",
      "train loss:0.15755714092714443\n",
      "train loss:0.10976255276054248\n",
      "train loss:0.21712107660478094\n",
      "train loss:0.20439790135263702\n",
      "train loss:0.23571513291682156\n",
      "train loss:0.10655472928620391\n",
      "train loss:0.14732580959211034\n",
      "train loss:0.16132804465225495\n",
      "train loss:0.14475818869544693\n",
      "train loss:0.17209996982071754\n",
      "train loss:0.16362843872307503\n",
      "train loss:0.20689181446548788\n",
      "train loss:0.16793467156993935\n",
      "train loss:0.16241767878168198\n",
      "train loss:0.09780801468548182\n",
      "train loss:0.1422736293614591\n",
      "train loss:0.09927669243141976\n",
      "train loss:0.19138099296311709\n",
      "train loss:0.1401248360234084\n",
      "train loss:0.07775864132559476\n",
      "train loss:0.193125249191726\n",
      "train loss:0.14346858073793334\n",
      "train loss:0.09786536797762636\n",
      "train loss:0.21667638088688088\n",
      "train loss:0.23206453155260542\n",
      "train loss:0.12978440608191116\n",
      "train loss:0.0871286922442917\n",
      "train loss:0.13576546993545816\n",
      "train loss:0.11643206849177838\n",
      "train loss:0.13862161268434345\n",
      "train loss:0.21078988263683993\n",
      "train loss:0.16337977642648815\n",
      "train loss:0.23689627142696829\n",
      "train loss:0.1470922060592697\n",
      "train loss:0.10857752688812448\n",
      "train loss:0.10600191546596335\n",
      "train loss:0.13914573283294654\n",
      "train loss:0.1310800354694379\n",
      "train loss:0.1198919693684415\n",
      "train loss:0.08481068365521147\n",
      "train loss:0.13926170576250782\n",
      "train loss:0.10014249739496106\n",
      "train loss:0.11443198590561211\n",
      "train loss:0.1795027244144093\n",
      "train loss:0.16513274983929926\n",
      "train loss:0.10303599231673756\n",
      "train loss:0.2286797288752008\n",
      "train loss:0.1083270522967781\n",
      "train loss:0.12639250964353255\n",
      "train loss:0.07563838278419321\n",
      "train loss:0.15806746174783837\n",
      "train loss:0.1509534000733197\n",
      "train loss:0.1781697291136349\n",
      "train loss:0.12766277208730276\n",
      "train loss:0.07729357822471834\n",
      "train loss:0.1084620461621218\n",
      "train loss:0.15448369486920976\n",
      "train loss:0.11919187883609446\n",
      "train loss:0.07832072544205419\n",
      "train loss:0.06687643342459854\n",
      "train loss:0.14803894480184052\n",
      "train loss:0.13383415852344974\n",
      "train loss:0.12591920084895813\n",
      "train loss:0.05239882683245543\n",
      "train loss:0.19485730266025109\n",
      "train loss:0.09717820084599467\n",
      "train loss:0.15888455834889204\n",
      "train loss:0.11496268601222198\n",
      "train loss:0.13747979883975872\n",
      "train loss:0.15601327524915293\n",
      "train loss:0.1609317118670038\n",
      "train loss:0.17722018199342046\n",
      "train loss:0.1502976269573961\n",
      "train loss:0.15733398972556129\n",
      "train loss:0.15384443314847546\n",
      "train loss:0.31302489737875105\n",
      "train loss:0.13996704093918422\n",
      "train loss:0.12970782863894004\n",
      "train loss:0.10531391288507404\n",
      "train loss:0.2084108233543074\n",
      "train loss:0.05839206275127828\n",
      "train loss:0.23021601885381685\n",
      "train loss:0.1444144315908335\n",
      "train loss:0.1521859238808838\n",
      "train loss:0.12399185810537912\n",
      "train loss:0.2099414274983809\n",
      "train loss:0.11756211802007474\n",
      "train loss:0.1035174303616563\n",
      "train loss:0.11111337303082788\n",
      "train loss:0.16252811476784373\n",
      "train loss:0.13439639228693545\n",
      "train loss:0.10292056709414328\n",
      "train loss:0.13457362620598076\n",
      "train loss:0.15526806729990533\n",
      "train loss:0.2159243786492521\n",
      "train loss:0.18855106051767223\n",
      "train loss:0.17537341196068218\n",
      "train loss:0.15121991967372284\n",
      "train loss:0.16381715694268337\n",
      "train loss:0.13678855542374577\n",
      "train loss:0.27308090417382574\n",
      "train loss:0.1443661737585228\n",
      "train loss:0.13019826408202456\n",
      "train loss:0.16732653576454065\n",
      "train loss:0.13002019480657415\n",
      "train loss:0.11583574938095406\n",
      "train loss:0.1425355675737063\n",
      "train loss:0.16782251993342226\n",
      "train loss:0.2054204417505413\n",
      "train loss:0.2740970651684605\n",
      "train loss:0.10505328764201673\n",
      "train loss:0.0964971144882773\n",
      "train loss:0.1342022596333597\n",
      "train loss:0.09956164303599378\n",
      "train loss:0.28547473744325447\n",
      "train loss:0.20468646180541597\n",
      "train loss:0.13349723980729492\n",
      "train loss:0.06943025034288057\n",
      "train loss:0.12196798302356805\n",
      "train loss:0.0712815275457405\n",
      "train loss:0.16435383215915164\n",
      "train loss:0.13254829402032273\n",
      "train loss:0.21007665328535832\n",
      "train loss:0.07066762448475897\n",
      "train loss:0.1280295411911294\n",
      "train loss:0.19853698396475913\n",
      "train loss:0.10553582001434901\n",
      "train loss:0.22601548417465656\n",
      "train loss:0.10547818532885543\n",
      "train loss:0.10760604817323151\n",
      "train loss:0.24427174150843872\n",
      "train loss:0.1553473531270465\n",
      "train loss:0.2345042492656697\n",
      "train loss:0.1554648167295622\n",
      "train loss:0.08871418290531778\n",
      "train loss:0.17801930050162912\n",
      "train loss:0.07436296662638937\n",
      "train loss:0.1479873394028601\n",
      "train loss:0.14181849065970434\n",
      "train loss:0.2750304333582485\n",
      "train loss:0.19639886515424407\n",
      "train loss:0.11646014417813301\n",
      "train loss:0.09077424156991844\n",
      "train loss:0.18726586715440802\n",
      "train loss:0.16970745750913946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.15720889255041598\n",
      "train loss:0.14369610041677014\n",
      "train loss:0.12265065428229065\n",
      "train loss:0.13106345516902804\n",
      "train loss:0.1210777239464196\n",
      "train loss:0.14443918455622165\n",
      "train loss:0.22870403808399825\n",
      "train loss:0.14492150409103816\n",
      "train loss:0.18202186987982588\n",
      "train loss:0.20830475363062306\n",
      "train loss:0.15311354983826145\n",
      "train loss:0.19704586749231204\n",
      "train loss:0.26738335696169435\n",
      "train loss:0.12777342702439073\n",
      "train loss:0.09729862794286699\n",
      "train loss:0.14373881852073625\n",
      "train loss:0.14076173349726706\n",
      "train loss:0.11085293818530552\n",
      "train loss:0.2547094757083819\n",
      "train loss:0.22190455154254196\n",
      "train loss:0.11149428965187116\n",
      "train loss:0.12267793173537946\n",
      "train loss:0.26254229226984893\n",
      "train loss:0.14213436650447933\n",
      "train loss:0.11785543687694902\n",
      "train loss:0.2294220615634785\n",
      "train loss:0.09901011528062192\n",
      "train loss:0.17396072768784662\n",
      "train loss:0.05953574331650167\n",
      "train loss:0.16571204859540653\n",
      "train loss:0.13549458941918793\n",
      "train loss:0.1575568649425273\n",
      "train loss:0.13108383958673936\n",
      "train loss:0.10619204065012353\n",
      "train loss:0.2185856333386588\n",
      "train loss:0.10433544006975297\n",
      "train loss:0.06311059233146557\n",
      "train loss:0.12024506229083638\n",
      "train loss:0.12667174552487576\n",
      "train loss:0.20933422264945098\n",
      "train loss:0.1509510983663232\n",
      "train loss:0.13955396938758632\n",
      "train loss:0.23612813921401887\n",
      "train loss:0.16605074472285328\n",
      "train loss:0.15779454152823158\n",
      "train loss:0.08615200240675147\n",
      "train loss:0.203432913069053\n",
      "train loss:0.18758206126084495\n",
      "train loss:0.10489409908008934\n",
      "train loss:0.14793436999948248\n",
      "train loss:0.07860873379107504\n",
      "train loss:0.11075537215939578\n",
      "train loss:0.1835369402261865\n",
      "train loss:0.10162642315796779\n",
      "train loss:0.17190774946133577\n",
      "train loss:0.12985575466908184\n",
      "train loss:0.2032860684006236\n",
      "train loss:0.11345919946553891\n",
      "train loss:0.13370843851349798\n",
      "train loss:0.11176977824229149\n",
      "train loss:0.18189945326681334\n",
      "train loss:0.1362526407228656\n",
      "train loss:0.13527253409906387\n",
      "train loss:0.10586134837671692\n",
      "train loss:0.1665497564347052\n",
      "train loss:0.08076853227338304\n",
      "train loss:0.1747992926664355\n",
      "train loss:0.1786348107082803\n",
      "train loss:0.21249649185515046\n",
      "train loss:0.1433899904308303\n",
      "train loss:0.1913641152221031\n",
      "train loss:0.207686854667998\n",
      "train loss:0.21778070820761353\n",
      "train loss:0.11934121407373123\n",
      "train loss:0.18136845949652927\n",
      "train loss:0.15979153957319947\n",
      "train loss:0.12413621537641749\n",
      "train loss:0.15611399332033163\n",
      "train loss:0.16304164345636377\n",
      "train loss:0.08237426513853219\n",
      "train loss:0.10238602444546557\n",
      "train loss:0.1424237128980008\n",
      "train loss:0.13197042298337733\n",
      "train loss:0.145189769262555\n",
      "train loss:0.0928271719571122\n",
      "train loss:0.10256809521487298\n",
      "train loss:0.11831679772993368\n",
      "train loss:0.12186067572453968\n",
      "train loss:0.25606812932359946\n",
      "train loss:0.19808670398108608\n",
      "train loss:0.16024856083866712\n",
      "train loss:0.10168220944215355\n",
      "train loss:0.17382032561171312\n",
      "train loss:0.10978252600620796\n",
      "train loss:0.2157456751520267\n",
      "train loss:0.13896582506885485\n",
      "train loss:0.09255462734686469\n",
      "train loss:0.14280723426074413\n",
      "train loss:0.09655391381824106\n",
      "train loss:0.13216962200408777\n",
      "train loss:0.1341596849413911\n",
      "train loss:0.10662188598794342\n",
      "train loss:0.237226436533132\n",
      "train loss:0.20106802940489518\n",
      "train loss:0.22390496908380114\n",
      "train loss:0.18301217719510984\n",
      "train loss:0.06333530417609431\n",
      "train loss:0.18878482817235237\n",
      "train loss:0.16395308619720741\n",
      "train loss:0.1857440240779512\n",
      "train loss:0.10517526720908087\n",
      "train loss:0.09173020557606348\n",
      "train loss:0.154444008509869\n",
      "train loss:0.08837291931195582\n",
      "train loss:0.14143405760237274\n",
      "train loss:0.17393315912351123\n",
      "train loss:0.09418458036369257\n",
      "train loss:0.10159182981397702\n",
      "train loss:0.09557010755817061\n",
      "train loss:0.13338430308987725\n",
      "train loss:0.086323535767254\n",
      "train loss:0.068705889595465\n",
      "train loss:0.09682739876009451\n",
      "train loss:0.10532901221089533\n",
      "train loss:0.21431664332992056\n",
      "train loss:0.1864900561240325\n",
      "train loss:0.15539671495140753\n",
      "train loss:0.1385680981272649\n",
      "train loss:0.13537939284437758\n",
      "train loss:0.21185613812160184\n",
      "train loss:0.17709453365698713\n",
      "train loss:0.167571354353408\n",
      "train loss:0.08600277868118772\n",
      "train loss:0.13948338940745678\n",
      "train loss:0.11963782845809448\n",
      "train loss:0.18846895940151195\n",
      "train loss:0.17177037045493726\n",
      "train loss:0.14667000773921818\n",
      "train loss:0.16395165627035854\n",
      "train loss:0.10101204849551479\n",
      "train loss:0.16492770021798023\n",
      "train loss:0.1454219171366416\n",
      "train loss:0.15802630937395662\n",
      "train loss:0.17241588020293946\n",
      "train loss:0.11036072507242597\n",
      "train loss:0.09036654232737279\n",
      "train loss:0.19647479579198598\n",
      "train loss:0.1308453523546504\n",
      "train loss:0.16479993958681535\n",
      "train loss:0.22720366235709644\n",
      "train loss:0.13749584016547026\n",
      "train loss:0.2369847827482383\n",
      "train loss:0.17478468853984475\n",
      "train loss:0.1507677258789054\n",
      "train loss:0.11323316512980379\n",
      "train loss:0.07714699869028711\n",
      "train loss:0.13538373295338782\n",
      "train loss:0.12906087388691068\n",
      "train loss:0.21737940725437993\n",
      "train loss:0.08206146303699884\n",
      "train loss:0.14232604982013755\n",
      "train loss:0.15728530132422558\n",
      "train loss:0.08131004205523086\n",
      "train loss:0.11815406615664083\n",
      "train loss:0.14852272366781225\n",
      "train loss:0.2560244420731444\n",
      "=== epoch:12, train acc:0.956, test acc:0.911 ===\n",
      "train loss:0.10685431148630256\n",
      "train loss:0.19523450578074397\n",
      "train loss:0.19174636195661193\n",
      "train loss:0.2676969424243934\n",
      "train loss:0.133341771336315\n",
      "train loss:0.13046403964787104\n",
      "train loss:0.17538650788483123\n",
      "train loss:0.21890476546185536\n",
      "train loss:0.1732425762169607\n",
      "train loss:0.14426430685193034\n",
      "train loss:0.1940280650148677\n",
      "train loss:0.14009177452253824\n",
      "train loss:0.3261646593855954\n",
      "train loss:0.09066376668667755\n",
      "train loss:0.09912690638539079\n",
      "train loss:0.21310600424811504\n",
      "train loss:0.14491965333348403\n",
      "train loss:0.14718525060152327\n",
      "train loss:0.08571564081789823\n",
      "train loss:0.06073760900564975\n",
      "train loss:0.1384322368362298\n",
      "train loss:0.13009504890579687\n",
      "train loss:0.14293500169106724\n",
      "train loss:0.15064078612085258\n",
      "train loss:0.15229480364116887\n",
      "train loss:0.14074880262656875\n",
      "train loss:0.10913191244921411\n",
      "train loss:0.11165856656322705\n",
      "train loss:0.08407097774393125\n",
      "train loss:0.16089749816197765\n",
      "train loss:0.21621996281646777\n",
      "train loss:0.14799091424208716\n",
      "train loss:0.15818273616972775\n",
      "train loss:0.18021926726127951\n",
      "train loss:0.17685938825689757\n",
      "train loss:0.14613179775963112\n",
      "train loss:0.1873280801050306\n",
      "train loss:0.09780015401578926\n",
      "train loss:0.12356958108390965\n",
      "train loss:0.10654276124350082\n",
      "train loss:0.1015049508108174\n",
      "train loss:0.13389614866591174\n",
      "train loss:0.2054875440452251\n",
      "train loss:0.12086112004505076\n",
      "train loss:0.2155957981846086\n",
      "train loss:0.16849777158127785\n",
      "train loss:0.10068685407236835\n",
      "train loss:0.11912692833431543\n",
      "train loss:0.20579231209497365\n",
      "train loss:0.0955278205316576\n",
      "train loss:0.1947587686957012\n",
      "train loss:0.12794005729820668\n",
      "train loss:0.19997408173716724\n",
      "train loss:0.11658324236694956\n",
      "train loss:0.17265389687897975\n",
      "train loss:0.21369158954849063\n",
      "train loss:0.1313802068484241\n",
      "train loss:0.07912125578173615\n",
      "train loss:0.17481505176658874\n",
      "train loss:0.22267058706904955\n",
      "train loss:0.1782053746855691\n",
      "train loss:0.15613791615927655\n",
      "train loss:0.11067989705201167\n",
      "train loss:0.16368681211367203\n",
      "train loss:0.16812696295363658\n",
      "train loss:0.08875444524442372\n",
      "train loss:0.1303814623612418\n",
      "train loss:0.097440024951726\n",
      "train loss:0.13550675477298085\n",
      "train loss:0.12273964919319882\n",
      "train loss:0.12193070999450714\n",
      "train loss:0.15899525604238945\n",
      "train loss:0.06807166157031691\n",
      "train loss:0.17931860053217974\n",
      "train loss:0.14095799875202844\n",
      "train loss:0.13464272361555674\n",
      "train loss:0.09194295449334126\n",
      "train loss:0.23133130305766272\n",
      "train loss:0.10567306455716503\n",
      "train loss:0.11433416568577226\n",
      "train loss:0.1465960857027798\n",
      "train loss:0.10407318124250814\n",
      "train loss:0.17953381111536826\n",
      "train loss:0.11968072624140617\n",
      "train loss:0.12591951937738607\n",
      "train loss:0.17860882890017515\n",
      "train loss:0.1999217003621229\n",
      "train loss:0.13741172925927225\n",
      "train loss:0.14526066394482004\n",
      "train loss:0.16028042379746651\n",
      "train loss:0.1629882214262766\n",
      "train loss:0.09674751274316479\n",
      "train loss:0.17510153522501667\n",
      "train loss:0.14050927495841506\n",
      "train loss:0.20825132695252527\n",
      "train loss:0.12448246419712257\n",
      "train loss:0.12085627299892505\n",
      "train loss:0.26082670563851457\n",
      "train loss:0.041719239284762226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.2794564939811875\n",
      "train loss:0.18394897936764873\n",
      "train loss:0.09042632077637373\n",
      "train loss:0.1631845387090357\n",
      "train loss:0.08242375792518375\n",
      "train loss:0.12285890687559325\n",
      "train loss:0.11475341761687902\n",
      "train loss:0.08555473349723153\n",
      "train loss:0.13286319989536197\n",
      "train loss:0.1027570986172948\n",
      "train loss:0.09259464262675174\n",
      "train loss:0.1235096313745726\n",
      "train loss:0.14854303028464308\n",
      "train loss:0.12879561479007814\n",
      "train loss:0.12195857567563902\n",
      "train loss:0.13718260082716371\n",
      "train loss:0.15190694002409802\n",
      "train loss:0.14618030392606313\n",
      "train loss:0.13784142835947863\n",
      "train loss:0.161658321312861\n",
      "train loss:0.07896918917218958\n",
      "train loss:0.10233105173475479\n",
      "train loss:0.1010395734979112\n",
      "train loss:0.0659482318502153\n",
      "train loss:0.27630083006128603\n",
      "train loss:0.12560776572083615\n",
      "train loss:0.11350771408539517\n",
      "train loss:0.09273360637472589\n",
      "train loss:0.1259857943571009\n",
      "train loss:0.1329282505409901\n",
      "train loss:0.15241131727294058\n",
      "train loss:0.2130046927652261\n",
      "train loss:0.05963021975089339\n",
      "train loss:0.1189031548833569\n",
      "train loss:0.1393217163386157\n",
      "train loss:0.1454572071917682\n",
      "train loss:0.11111587023891462\n",
      "train loss:0.15317335906742535\n",
      "train loss:0.14502351220128168\n",
      "train loss:0.24001428607388658\n",
      "train loss:0.13122735298192872\n",
      "train loss:0.1559537667603154\n",
      "train loss:0.16435616681760692\n",
      "train loss:0.14922525048988466\n",
      "train loss:0.18143522347037894\n",
      "train loss:0.11515375902986519\n",
      "train loss:0.15178979612220184\n",
      "train loss:0.13708594738022864\n",
      "train loss:0.20071439194124174\n",
      "train loss:0.12612652887834744\n",
      "train loss:0.168781609044465\n",
      "train loss:0.17337525501112355\n",
      "train loss:0.15982312610377514\n",
      "train loss:0.11122748820877257\n",
      "train loss:0.22027562708752962\n",
      "train loss:0.13297482793303347\n",
      "train loss:0.13006105165359647\n",
      "train loss:0.1718860613320074\n",
      "train loss:0.23407444713696676\n",
      "train loss:0.233848072892328\n",
      "train loss:0.2515876173298794\n",
      "train loss:0.2031227001757213\n",
      "train loss:0.22900406840972348\n",
      "train loss:0.08688228175220265\n",
      "train loss:0.11978188156358362\n",
      "train loss:0.06128746357171397\n",
      "train loss:0.19230672079556935\n",
      "train loss:0.09537176961344324\n",
      "train loss:0.15733440148768\n",
      "train loss:0.15503998274676137\n",
      "train loss:0.189810379496526\n",
      "train loss:0.08017493453913545\n",
      "train loss:0.12212080941814801\n",
      "train loss:0.16857006804384123\n",
      "train loss:0.11422873132184379\n",
      "train loss:0.11614034521992378\n",
      "train loss:0.08701666164189932\n",
      "train loss:0.13964631136052946\n",
      "train loss:0.13346588997202266\n",
      "train loss:0.09154482526585182\n",
      "train loss:0.2129173201306628\n",
      "train loss:0.11101679972256935\n",
      "train loss:0.12398540199717542\n",
      "train loss:0.1403337081082522\n",
      "train loss:0.10216203471079444\n",
      "train loss:0.1770600447359868\n",
      "train loss:0.17393675060212188\n",
      "train loss:0.06914725286038963\n",
      "train loss:0.08149301145412245\n",
      "train loss:0.1278948436056223\n",
      "train loss:0.2162384829695569\n",
      "train loss:0.1075617576736231\n",
      "train loss:0.09079613389893655\n",
      "train loss:0.17373544823531437\n",
      "train loss:0.11224435886875096\n",
      "train loss:0.21461842071922616\n",
      "train loss:0.20768703796871146\n",
      "train loss:0.0704524343923449\n",
      "train loss:0.2335768835326681\n",
      "train loss:0.18318948916654165\n",
      "train loss:0.14713264253400035\n",
      "train loss:0.08433937333092686\n",
      "train loss:0.0844799914895252\n",
      "train loss:0.16535939323058294\n",
      "train loss:0.12130109350440796\n",
      "train loss:0.08445991310378967\n",
      "train loss:0.0771326372052526\n",
      "train loss:0.18387409451355513\n",
      "train loss:0.11527920116325512\n",
      "train loss:0.1772989905314411\n",
      "train loss:0.14246584320430544\n",
      "train loss:0.17712028311987726\n",
      "train loss:0.15785101941978233\n",
      "train loss:0.1484512816570846\n",
      "train loss:0.124363201388816\n",
      "train loss:0.14933058493465354\n",
      "train loss:0.16659063333097898\n",
      "train loss:0.12646597475225424\n",
      "train loss:0.14335932397833676\n",
      "train loss:0.24320418290025878\n",
      "train loss:0.12309725091215315\n",
      "train loss:0.07667929163498649\n",
      "train loss:0.16241511092644953\n",
      "train loss:0.14371153995133645\n",
      "train loss:0.16352083472004925\n",
      "train loss:0.12541058838585342\n",
      "train loss:0.06600246594391178\n",
      "train loss:0.1677813281789362\n",
      "train loss:0.20951862456354103\n",
      "train loss:0.1944453494860967\n",
      "train loss:0.13758471326953345\n",
      "train loss:0.23157518636664937\n",
      "train loss:0.13771997132197245\n",
      "train loss:0.1251574280109459\n",
      "train loss:0.0847279451839016\n",
      "train loss:0.16757449648904807\n",
      "train loss:0.11230642893885967\n",
      "train loss:0.196154183543597\n",
      "train loss:0.10128483609166712\n",
      "train loss:0.2444355766435392\n",
      "train loss:0.07679239684839702\n",
      "train loss:0.17228664569153476\n",
      "train loss:0.16620844791781728\n",
      "train loss:0.13308396568385517\n",
      "train loss:0.2094181499579443\n",
      "train loss:0.14819350814978782\n",
      "train loss:0.10873007754628325\n",
      "train loss:0.1257309393509937\n",
      "train loss:0.15410501019549394\n",
      "train loss:0.06148067099513649\n",
      "train loss:0.17594264137442997\n",
      "train loss:0.10353380659255856\n",
      "train loss:0.23671443296967218\n",
      "train loss:0.23378684416803377\n",
      "train loss:0.07419692692179967\n",
      "train loss:0.09771610521933978\n",
      "train loss:0.14976580689643065\n",
      "train loss:0.22937224404170325\n",
      "train loss:0.09116689105223036\n",
      "train loss:0.16102100967596403\n",
      "train loss:0.11030165551626146\n",
      "train loss:0.1455358966958183\n",
      "train loss:0.17051824359093323\n",
      "train loss:0.11392079281491585\n",
      "train loss:0.17409178321630875\n",
      "train loss:0.10705931227033508\n",
      "train loss:0.12996229381938457\n",
      "train loss:0.13395149349833665\n",
      "train loss:0.11764959031707095\n",
      "train loss:0.16208010647911986\n",
      "train loss:0.1539057681920586\n",
      "train loss:0.139141691634857\n",
      "train loss:0.1448671692842681\n",
      "train loss:0.24350398857530364\n",
      "train loss:0.14560242683451585\n",
      "train loss:0.16548318910667814\n",
      "train loss:0.11871296446814675\n",
      "train loss:0.14279051103601992\n",
      "train loss:0.15243651506802586\n",
      "train loss:0.12493894479349668\n",
      "train loss:0.1197307238231956\n",
      "train loss:0.08475653196287478\n",
      "train loss:0.12412432057752051\n",
      "train loss:0.11161007854563457\n",
      "train loss:0.09474647233734483\n",
      "train loss:0.08974735234983772\n",
      "train loss:0.1811489372149996\n",
      "train loss:0.23936510261601956\n",
      "train loss:0.1531468777494807\n",
      "train loss:0.08154780002552092\n",
      "train loss:0.08283560325611593\n",
      "train loss:0.08865799346484912\n",
      "train loss:0.07898676470428767\n",
      "train loss:0.27276590516169336\n",
      "train loss:0.19068737557846485\n",
      "train loss:0.12020647080511715\n",
      "train loss:0.14767278335028342\n",
      "train loss:0.12094086290219402\n",
      "train loss:0.17037192721684896\n",
      "train loss:0.10070759956444883\n",
      "train loss:0.15224355086290875\n",
      "train loss:0.1033907385639714\n",
      "train loss:0.15261733003636038\n",
      "train loss:0.09479889606385301\n",
      "train loss:0.16088510939267597\n",
      "train loss:0.10875101502033103\n",
      "train loss:0.09439489975261449\n",
      "train loss:0.1845731166209464\n",
      "train loss:0.056678711747562296\n",
      "train loss:0.08349164265946946\n",
      "train loss:0.11465502508810911\n",
      "train loss:0.1296167610492995\n",
      "train loss:0.17977028026102718\n",
      "train loss:0.10846681293133226\n",
      "train loss:0.12368210384575842\n",
      "train loss:0.2233714080892477\n",
      "train loss:0.09234822112552649\n",
      "train loss:0.12032579728962027\n",
      "train loss:0.08368657788993313\n",
      "train loss:0.0920367791479769\n",
      "train loss:0.1315111705308179\n",
      "train loss:0.1632522216569996\n",
      "train loss:0.14034313551287225\n",
      "train loss:0.12720856469182257\n",
      "train loss:0.2357194761042792\n",
      "train loss:0.1395404498015213\n",
      "train loss:0.056108314290167265\n",
      "train loss:0.14844447685775897\n",
      "train loss:0.21338110962325513\n",
      "train loss:0.2268758525457517\n",
      "train loss:0.2125367619970419\n",
      "train loss:0.24798693803979738\n",
      "train loss:0.13123461069777279\n",
      "train loss:0.15423803194190117\n",
      "train loss:0.15404139435495312\n",
      "train loss:0.13705126260836248\n",
      "train loss:0.16439358820497754\n",
      "train loss:0.11838198773212204\n",
      "train loss:0.11682903216280101\n",
      "train loss:0.12628692559385118\n",
      "train loss:0.21290343528010944\n",
      "train loss:0.14396304307680338\n",
      "train loss:0.14728254156247567\n",
      "train loss:0.0973315396843376\n",
      "train loss:0.10988929352217229\n",
      "train loss:0.17176470029364116\n",
      "train loss:0.07786650321976274\n",
      "train loss:0.15412527874898457\n",
      "train loss:0.11328216231239464\n",
      "train loss:0.1098148867343688\n",
      "train loss:0.16111094971709844\n",
      "train loss:0.2086159782800977\n",
      "train loss:0.16667550976799517\n",
      "train loss:0.06918012441081803\n",
      "train loss:0.14517541029028044\n",
      "train loss:0.09046474647117236\n",
      "train loss:0.10580448013520861\n",
      "train loss:0.09529917972631012\n",
      "train loss:0.15373395779599983\n",
      "train loss:0.21253000461744612\n",
      "train loss:0.1806526748536424\n",
      "train loss:0.1324860066318864\n",
      "train loss:0.06940644630923729\n",
      "train loss:0.1520296568363389\n",
      "train loss:0.15326128727052496\n",
      "train loss:0.13780139841189293\n",
      "train loss:0.18341032017837017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.07529609720232734\n",
      "train loss:0.0857743026651391\n",
      "train loss:0.24213925000686706\n",
      "train loss:0.17291016366429784\n",
      "train loss:0.13351574338817115\n",
      "train loss:0.1564379602765259\n",
      "train loss:0.17662805963507627\n",
      "train loss:0.14877780068040306\n",
      "train loss:0.10524035080597789\n",
      "train loss:0.09147892511509301\n",
      "train loss:0.09839458961560427\n",
      "train loss:0.13051514989044202\n",
      "train loss:0.1360575188391637\n",
      "train loss:0.07285894324339737\n",
      "train loss:0.18741257216667062\n",
      "train loss:0.16958714818300083\n",
      "train loss:0.14232400003754406\n",
      "train loss:0.2109535764642514\n",
      "train loss:0.12422583078477409\n",
      "train loss:0.11247668768262177\n",
      "train loss:0.12045178267069545\n",
      "train loss:0.14799439422087432\n",
      "train loss:0.13239845524407612\n",
      "train loss:0.156752036724562\n",
      "train loss:0.06335139642395438\n",
      "train loss:0.09424192407866862\n",
      "train loss:0.1612063397551228\n",
      "train loss:0.09679953546892257\n",
      "train loss:0.12292615585559127\n",
      "train loss:0.0762159711443584\n",
      "train loss:0.10646124847723874\n",
      "train loss:0.1494329558026164\n",
      "train loss:0.14646621986902977\n",
      "train loss:0.15049491500810108\n",
      "train loss:0.1485214311062489\n",
      "train loss:0.0851747979101922\n",
      "train loss:0.1675037008711946\n",
      "train loss:0.1894713961163172\n",
      "train loss:0.14919216518573197\n",
      "train loss:0.10786034633195937\n",
      "train loss:0.3027830096371355\n",
      "train loss:0.11868995597642136\n",
      "train loss:0.130269368894519\n",
      "train loss:0.1351431707521907\n",
      "train loss:0.08162319055358326\n",
      "train loss:0.11022133494207614\n",
      "train loss:0.23860193132157087\n",
      "train loss:0.17454255296578147\n",
      "train loss:0.17027604376277844\n",
      "train loss:0.0717318211469501\n",
      "train loss:0.17046422547738277\n",
      "train loss:0.16032676360182965\n",
      "train loss:0.14155042810647606\n",
      "train loss:0.16201940319984506\n",
      "train loss:0.14328687837075854\n",
      "train loss:0.3284102993887659\n",
      "train loss:0.14798719719573644\n",
      "train loss:0.10781516516936901\n",
      "train loss:0.10000171301911483\n",
      "train loss:0.19796287576484292\n",
      "train loss:0.1025278884216198\n",
      "train loss:0.06837345505230179\n",
      "train loss:0.18954895402252292\n",
      "train loss:0.12025145422708892\n",
      "train loss:0.13044909310428518\n",
      "train loss:0.13443847517030527\n",
      "train loss:0.15324743566903698\n",
      "train loss:0.14440334454989226\n",
      "train loss:0.17147254608487617\n",
      "train loss:0.11489971040563031\n",
      "train loss:0.1497260416423526\n",
      "train loss:0.08249311246460188\n",
      "train loss:0.12302327332542745\n",
      "train loss:0.1340810062121386\n",
      "train loss:0.06900698916777043\n",
      "train loss:0.2031683872186046\n",
      "train loss:0.12502109245299942\n",
      "train loss:0.1184652469538283\n",
      "train loss:0.14058869787320147\n",
      "train loss:0.09248299305050937\n",
      "train loss:0.10227690977213812\n",
      "train loss:0.15408753551117316\n",
      "train loss:0.14752449874197296\n",
      "train loss:0.07965646702228964\n",
      "train loss:0.12616878986754632\n",
      "train loss:0.18969496415809953\n",
      "train loss:0.14626410812639837\n",
      "train loss:0.16026172538191485\n",
      "train loss:0.21402066506773032\n",
      "train loss:0.1636488552053021\n",
      "train loss:0.13306608362525663\n",
      "train loss:0.0773805740751044\n",
      "train loss:0.13481938056208004\n",
      "train loss:0.09764244318658039\n",
      "train loss:0.16112559506369542\n",
      "train loss:0.16362022354001646\n",
      "train loss:0.08841863594450099\n",
      "train loss:0.12468026425287243\n",
      "train loss:0.14004044261266166\n",
      "train loss:0.12621284762881044\n",
      "train loss:0.2100949644721621\n",
      "train loss:0.13061387564960214\n",
      "train loss:0.2512596369063834\n",
      "train loss:0.12547972688205514\n",
      "train loss:0.21372226087467516\n",
      "train loss:0.16854637698765434\n",
      "train loss:0.1497748019697038\n",
      "train loss:0.17872302495094586\n",
      "train loss:0.1684570782654251\n",
      "train loss:0.07308106702144208\n",
      "train loss:0.17405242515763425\n",
      "train loss:0.11228727210074528\n",
      "train loss:0.1612049129643112\n",
      "train loss:0.13442994011519377\n",
      "train loss:0.10861391656070549\n",
      "train loss:0.15778421443487992\n",
      "train loss:0.14592458196192756\n",
      "train loss:0.056885254571485994\n",
      "train loss:0.06942402822500679\n",
      "train loss:0.20104724858135112\n",
      "train loss:0.10622621941868612\n",
      "train loss:0.200807694482861\n",
      "train loss:0.09799730500827523\n",
      "train loss:0.15960312582889338\n",
      "train loss:0.05511373660736072\n",
      "train loss:0.1429772671751203\n",
      "train loss:0.14330175598683523\n",
      "train loss:0.25302247283308044\n",
      "train loss:0.10995073033518922\n",
      "train loss:0.15924859640051242\n",
      "train loss:0.12376686419730973\n",
      "train loss:0.23759439392620973\n",
      "train loss:0.14110022724061047\n",
      "train loss:0.17035887608594716\n",
      "train loss:0.11179347409860611\n",
      "train loss:0.07252613728317595\n",
      "train loss:0.15244031321928708\n",
      "train loss:0.1458398104194392\n",
      "train loss:0.15788502740449473\n",
      "train loss:0.14115177653155167\n",
      "train loss:0.10091844277809146\n",
      "train loss:0.15163126451556136\n",
      "train loss:0.10223849328294633\n",
      "train loss:0.13023832673742433\n",
      "train loss:0.07922702172098328\n",
      "train loss:0.1766399342601054\n",
      "train loss:0.16202709859721495\n",
      "train loss:0.20817766283418213\n",
      "train loss:0.17806717799883484\n",
      "train loss:0.22083848765928352\n",
      "train loss:0.15853929316924872\n",
      "train loss:0.10272462114504871\n",
      "train loss:0.12443748386235018\n",
      "train loss:0.10891251557367139\n",
      "train loss:0.09663157372151993\n",
      "train loss:0.10731530442410821\n",
      "train loss:0.1580908753029459\n",
      "train loss:0.17275991666664361\n",
      "train loss:0.1383016447757288\n",
      "train loss:0.17244457757718365\n",
      "train loss:0.13002522801160737\n",
      "train loss:0.140902703220817\n",
      "train loss:0.11866256808084548\n",
      "train loss:0.13025350388401744\n",
      "train loss:0.10087764386527259\n",
      "train loss:0.09485913399488584\n",
      "train loss:0.05742756414881967\n",
      "train loss:0.10868975046112116\n",
      "train loss:0.15979845058530218\n",
      "train loss:0.19545161261306024\n",
      "train loss:0.24392186885378017\n",
      "train loss:0.10224219675060392\n",
      "train loss:0.088799613452047\n",
      "train loss:0.14486498098246703\n",
      "train loss:0.10577260502619851\n",
      "train loss:0.0821945059641288\n",
      "train loss:0.09804667680192841\n",
      "train loss:0.1274067282294404\n",
      "train loss:0.1607842143512156\n",
      "train loss:0.05509943416690785\n",
      "train loss:0.13690824529156082\n",
      "train loss:0.052243150936477134\n",
      "train loss:0.08574052574197565\n",
      "train loss:0.167563285791651\n",
      "train loss:0.2120676778861313\n",
      "train loss:0.14050584708136588\n",
      "train loss:0.13238434828584153\n",
      "train loss:0.10445593231330964\n",
      "train loss:0.06563840550698914\n",
      "train loss:0.048068968406170705\n",
      "train loss:0.05823803911658967\n",
      "train loss:0.14742997494292528\n",
      "train loss:0.07300976441218868\n",
      "train loss:0.11686856283796582\n",
      "train loss:0.1335572427461703\n",
      "train loss:0.15280216671056457\n",
      "train loss:0.1428578440513699\n",
      "train loss:0.10368860438898703\n",
      "train loss:0.15182878107809478\n",
      "train loss:0.21238654369689536\n",
      "train loss:0.17380106721012895\n",
      "train loss:0.1002508138083755\n",
      "train loss:0.11796331967974641\n",
      "train loss:0.19259345727199245\n",
      "train loss:0.09660139005165731\n",
      "train loss:0.1598605982815467\n",
      "train loss:0.12027108225981864\n",
      "train loss:0.08537708575655108\n",
      "train loss:0.16320110631797122\n",
      "train loss:0.16814518471061796\n",
      "train loss:0.12731792211330778\n",
      "train loss:0.11622256936493533\n",
      "train loss:0.08570019832101526\n",
      "train loss:0.07407245015884\n",
      "train loss:0.09688100894667269\n",
      "train loss:0.09174769250835922\n",
      "train loss:0.1782531440253109\n",
      "train loss:0.14926368370341767\n",
      "train loss:0.10171679390816715\n",
      "train loss:0.12362786857864272\n",
      "train loss:0.1834675488398236\n",
      "train loss:0.09864922763293378\n",
      "train loss:0.2282555529901329\n",
      "train loss:0.13874979857652345\n",
      "train loss:0.1790808417387695\n",
      "train loss:0.16601865070905267\n",
      "train loss:0.11576262347110591\n",
      "train loss:0.18230818952818773\n",
      "train loss:0.13150030230335039\n",
      "train loss:0.08909952704258876\n",
      "train loss:0.12224056075277646\n",
      "train loss:0.13081663367447013\n",
      "train loss:0.08957140690396237\n",
      "train loss:0.19788243778662207\n",
      "=== epoch:13, train acc:0.96, test acc:0.906 ===\n",
      "train loss:0.2035249093701801\n",
      "train loss:0.08561079014160043\n",
      "train loss:0.11955813321342516\n",
      "train loss:0.19031244843060796\n",
      "train loss:0.15194183080619364\n",
      "train loss:0.11860752253792775\n",
      "train loss:0.19156501058678616\n",
      "train loss:0.15392556008476574\n",
      "train loss:0.1450886963531126\n",
      "train loss:0.13843625143980073\n",
      "train loss:0.11957228602798069\n",
      "train loss:0.097714652653961\n",
      "train loss:0.12858402473669606\n",
      "train loss:0.12198409631784354\n",
      "train loss:0.17564448025776158\n",
      "train loss:0.08299889203901248\n",
      "train loss:0.1419126839651792\n",
      "train loss:0.30238456700216354\n",
      "train loss:0.13861011404831086\n",
      "train loss:0.17117587342494248\n",
      "train loss:0.1274994876667579\n",
      "train loss:0.16849536555533173\n",
      "train loss:0.10355452627041661\n",
      "train loss:0.0845597818681731\n",
      "train loss:0.16205046083376817\n",
      "train loss:0.12247770674272983\n",
      "train loss:0.17282252712768564\n",
      "train loss:0.08966285352292605\n",
      "train loss:0.14089944017061515\n",
      "train loss:0.1115877888736491\n",
      "train loss:0.1575182840465678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.11531071782887985\n",
      "train loss:0.11802443818773016\n",
      "train loss:0.12542474291151556\n",
      "train loss:0.1071531328823006\n",
      "train loss:0.06520025959283825\n",
      "train loss:0.11418674612294012\n",
      "train loss:0.10403668575193273\n",
      "train loss:0.10619992930531084\n",
      "train loss:0.1535983746168233\n",
      "train loss:0.1425814572483187\n",
      "train loss:0.14984170801896074\n",
      "train loss:0.14652208242998246\n",
      "train loss:0.061067864136787\n",
      "train loss:0.12319183933480815\n",
      "train loss:0.09542784324452684\n",
      "train loss:0.16705215537206994\n",
      "train loss:0.1158697488978599\n",
      "train loss:0.12959978669412775\n",
      "train loss:0.11542798786734859\n",
      "train loss:0.12407263533936379\n",
      "train loss:0.07870646930794259\n",
      "train loss:0.17079637231810887\n",
      "train loss:0.06021662690357941\n",
      "train loss:0.10100887910598591\n",
      "train loss:0.15677472769926878\n",
      "train loss:0.0845139755545394\n",
      "train loss:0.12181208839425342\n",
      "train loss:0.11631535594994251\n",
      "train loss:0.13087901110066247\n",
      "train loss:0.10199148927691658\n",
      "train loss:0.1004312235624667\n",
      "train loss:0.10984354853356311\n",
      "train loss:0.18145227595319535\n",
      "train loss:0.1665517681576302\n",
      "train loss:0.10391518063924057\n",
      "train loss:0.09069048848505665\n",
      "train loss:0.12788428580786815\n",
      "train loss:0.10498212462688655\n",
      "train loss:0.1630643645853903\n",
      "train loss:0.0968631196904697\n",
      "train loss:0.17929871433569292\n",
      "train loss:0.102647797084284\n",
      "train loss:0.16909539453560885\n",
      "train loss:0.08376378442481623\n",
      "train loss:0.06054762333225891\n",
      "train loss:0.10643872414266252\n",
      "train loss:0.156553082474019\n",
      "train loss:0.16190483109226472\n",
      "train loss:0.1370733967673251\n",
      "train loss:0.14108701287176845\n",
      "train loss:0.1381489327806294\n",
      "train loss:0.14358021837509052\n",
      "train loss:0.1433525255590929\n",
      "train loss:0.19749683811864535\n",
      "train loss:0.08964866051721182\n",
      "train loss:0.11087151639258214\n",
      "train loss:0.12366110346423033\n",
      "train loss:0.08424915359370026\n",
      "train loss:0.09820157147787308\n",
      "train loss:0.1217225699226835\n",
      "train loss:0.1892012859988549\n",
      "train loss:0.1381583394616757\n",
      "train loss:0.11440141911911733\n",
      "train loss:0.11422727007018152\n",
      "train loss:0.09164415407441182\n",
      "train loss:0.12206320934029327\n",
      "train loss:0.1533581540638377\n",
      "train loss:0.1535504173494688\n",
      "train loss:0.13100557805534263\n",
      "train loss:0.04472873192116434\n",
      "train loss:0.10960442718883068\n",
      "train loss:0.12224710177329542\n",
      "train loss:0.09585673099979236\n",
      "train loss:0.09757598627457126\n",
      "train loss:0.1296648907849587\n",
      "train loss:0.19839884831136254\n",
      "train loss:0.13792332825875345\n",
      "train loss:0.07878458131004117\n",
      "train loss:0.1431716372550727\n",
      "train loss:0.17482242572733955\n",
      "train loss:0.1244438657964585\n",
      "train loss:0.14566517376799828\n",
      "train loss:0.11516439965441501\n",
      "train loss:0.09830640910608614\n",
      "train loss:0.13835732769379244\n",
      "train loss:0.16336615954628808\n",
      "train loss:0.131433552535292\n",
      "train loss:0.23246507230358507\n",
      "train loss:0.12596373119357152\n",
      "train loss:0.1136171349030368\n",
      "train loss:0.08810336564969547\n",
      "train loss:0.14701337130723746\n",
      "train loss:0.14316625002343436\n",
      "train loss:0.17797962215679178\n",
      "train loss:0.16156477637086572\n",
      "train loss:0.10385693665036505\n",
      "train loss:0.16994232817409619\n",
      "train loss:0.12455139251283034\n",
      "train loss:0.18248058369450004\n",
      "train loss:0.1736696454134901\n",
      "train loss:0.09636752636937528\n",
      "train loss:0.14317243825457626\n",
      "train loss:0.22299216738251323\n",
      "train loss:0.11250955700727197\n",
      "train loss:0.149955740882482\n",
      "train loss:0.1428684775678009\n",
      "train loss:0.11266884459505558\n",
      "train loss:0.11947799024731358\n",
      "train loss:0.06235771795850051\n",
      "train loss:0.12413908036593567\n",
      "train loss:0.20973195532554764\n",
      "train loss:0.11953372780720155\n",
      "train loss:0.14270122270856672\n",
      "train loss:0.09726419457280219\n",
      "train loss:0.17478070515902444\n",
      "train loss:0.06675214734754822\n",
      "train loss:0.08980804312049788\n",
      "train loss:0.08620783970882658\n",
      "train loss:0.10941171431876073\n",
      "train loss:0.05557772919806668\n",
      "train loss:0.10921043410828805\n",
      "train loss:0.10363682900416858\n",
      "train loss:0.19709004457701954\n",
      "train loss:0.11582236617813096\n",
      "train loss:0.11351186051296447\n",
      "train loss:0.09913839785480412\n",
      "train loss:0.15535594459369595\n",
      "train loss:0.06005853637369654\n",
      "train loss:0.05782978719560623\n",
      "train loss:0.06729761664302768\n",
      "train loss:0.09664239290949123\n",
      "train loss:0.1778805394627223\n",
      "train loss:0.15700961403635963\n",
      "train loss:0.20840344659648605\n",
      "train loss:0.21573772568876134\n",
      "train loss:0.16479648550719386\n",
      "train loss:0.07077727028582541\n",
      "train loss:0.1030859445068489\n",
      "train loss:0.11844848867931501\n",
      "train loss:0.14830932144845252\n",
      "train loss:0.09240898658962717\n",
      "train loss:0.09767837649500707\n",
      "train loss:0.08422545673577247\n",
      "train loss:0.14331162740709116\n",
      "train loss:0.13073951480827123\n",
      "train loss:0.0779866206289429\n",
      "train loss:0.10165920972535485\n",
      "train loss:0.09187496402132975\n",
      "train loss:0.11822140860961497\n",
      "train loss:0.15204610546628927\n",
      "train loss:0.09972628187075243\n",
      "train loss:0.17416134593303934\n",
      "train loss:0.15699773252142812\n",
      "train loss:0.11409132962662896\n",
      "train loss:0.10931681253743708\n",
      "train loss:0.14745480024784155\n",
      "train loss:0.1047147283815041\n",
      "train loss:0.09816548093463409\n",
      "train loss:0.0866371849259688\n",
      "train loss:0.18470687090675128\n",
      "train loss:0.1808894952870195\n",
      "train loss:0.15679272828377402\n",
      "train loss:0.08824845136762878\n",
      "train loss:0.11190257962673854\n",
      "train loss:0.06513795081689383\n",
      "train loss:0.11438495104361039\n",
      "train loss:0.12553886442242\n",
      "train loss:0.1581610463386166\n",
      "train loss:0.13468735234501458\n",
      "train loss:0.12376381833872373\n",
      "train loss:0.12308828882634432\n",
      "train loss:0.1673048290138701\n",
      "train loss:0.21328893003896798\n",
      "train loss:0.12333694807057898\n",
      "train loss:0.13586961122651545\n",
      "train loss:0.06989597451007488\n",
      "train loss:0.1538404210212384\n",
      "train loss:0.10024360159471556\n",
      "train loss:0.07787172159474355\n",
      "train loss:0.22609980108571648\n",
      "train loss:0.08810766446770868\n",
      "train loss:0.10806656776266077\n",
      "train loss:0.14171328935697466\n",
      "train loss:0.09863289964909916\n",
      "train loss:0.11609044157345444\n",
      "train loss:0.17157912419684695\n",
      "train loss:0.23301259173248456\n",
      "train loss:0.18514438007254053\n",
      "train loss:0.1575470067198932\n",
      "train loss:0.07380377081290386\n",
      "train loss:0.16623514756606292\n",
      "train loss:0.09565212350631462\n",
      "train loss:0.12877555789272016\n",
      "train loss:0.10677272669138625\n",
      "train loss:0.11722477068224879\n",
      "train loss:0.10107345432101011\n",
      "train loss:0.11955892425186011\n",
      "train loss:0.24650852384071764\n",
      "train loss:0.037509851471340915\n",
      "train loss:0.1716693702481679\n",
      "train loss:0.1411274016014606\n",
      "train loss:0.09565659420865093\n",
      "train loss:0.12985214599666048\n",
      "train loss:0.1933190317550534\n",
      "train loss:0.15343376171770526\n",
      "train loss:0.14472183331546273\n",
      "train loss:0.21630415269898826\n",
      "train loss:0.15587858516051145\n",
      "train loss:0.17104430541948698\n",
      "train loss:0.16445689098001837\n",
      "train loss:0.07758982193783681\n",
      "train loss:0.13080627114804047\n",
      "train loss:0.06502358599923981\n",
      "train loss:0.13596736437027104\n",
      "train loss:0.1565002851799008\n",
      "train loss:0.18103819220352943\n",
      "train loss:0.08272328132745325\n",
      "train loss:0.10085055933852621\n",
      "train loss:0.1874695209295534\n",
      "train loss:0.15073006509109382\n",
      "train loss:0.14678219229431502\n",
      "train loss:0.07483848808630267\n",
      "train loss:0.10090582001084973\n",
      "train loss:0.0698937653668812\n",
      "train loss:0.13512125071592612\n",
      "train loss:0.13874762811547164\n",
      "train loss:0.10132699247149259\n",
      "train loss:0.11062869841891104\n",
      "train loss:0.16277374808557035\n",
      "train loss:0.14881818510741238\n",
      "train loss:0.11696060668772577\n",
      "train loss:0.07556802276112191\n",
      "train loss:0.10910369332982815\n",
      "train loss:0.15006315989577682\n",
      "train loss:0.08958909838854584\n",
      "train loss:0.07040711090271759\n",
      "train loss:0.08377919857923327\n",
      "train loss:0.11171263399219403\n",
      "train loss:0.12730609350848224\n",
      "train loss:0.15637307594168542\n",
      "train loss:0.09011991242873675\n",
      "train loss:0.13760487573234023\n",
      "train loss:0.08655498314525252\n",
      "train loss:0.1492804144757117\n",
      "train loss:0.09595103026212172\n",
      "train loss:0.22256516215787112\n",
      "train loss:0.08984255601751019\n",
      "train loss:0.20455779456686884\n",
      "train loss:0.040190154219843954\n",
      "train loss:0.1513911597770955\n",
      "train loss:0.12031246433795689\n",
      "train loss:0.045869059671195284\n",
      "train loss:0.11337562272521254\n",
      "train loss:0.10083235672129147\n",
      "train loss:0.0954179742635174\n",
      "train loss:0.2201159888405644\n",
      "train loss:0.10786125206993988\n",
      "train loss:0.20299486100266464\n",
      "train loss:0.09847280741120698\n",
      "train loss:0.15005266512104165\n",
      "train loss:0.128384337888316\n",
      "train loss:0.18699940661591136\n",
      "train loss:0.17325402997653455\n",
      "train loss:0.09090664474928097\n",
      "train loss:0.12549248026399784\n",
      "train loss:0.08835154410306753\n",
      "train loss:0.09382326610187769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.08269402019806218\n",
      "train loss:0.12330704551967349\n",
      "train loss:0.09901117652928214\n",
      "train loss:0.1195390648501891\n",
      "train loss:0.12034494705621675\n",
      "train loss:0.0598675186543756\n",
      "train loss:0.10002407389972102\n",
      "train loss:0.16836942392704532\n",
      "train loss:0.16737980664069813\n",
      "train loss:0.11791986339614026\n",
      "train loss:0.09858397761968343\n",
      "train loss:0.13336999134431082\n",
      "train loss:0.134238985691442\n",
      "train loss:0.11614670778753171\n",
      "train loss:0.12770909261979557\n",
      "train loss:0.10367297798260801\n",
      "train loss:0.13586691886591926\n",
      "train loss:0.20735949913929339\n",
      "train loss:0.10389789710045287\n",
      "train loss:0.1353300051317066\n",
      "train loss:0.1998750004389483\n",
      "train loss:0.06351510406518654\n",
      "train loss:0.16705349017055837\n",
      "train loss:0.12336991563211376\n",
      "train loss:0.08812684749891955\n",
      "train loss:0.0981109996781987\n",
      "train loss:0.10360588905894927\n",
      "train loss:0.140552881807409\n",
      "train loss:0.15299443627151238\n",
      "train loss:0.09828859281595395\n",
      "train loss:0.19016968635666529\n",
      "train loss:0.14626897076745246\n",
      "train loss:0.11173346348839028\n",
      "train loss:0.10873177769765967\n",
      "train loss:0.11608477273813296\n",
      "train loss:0.24175185885056366\n",
      "train loss:0.19407406127747134\n",
      "train loss:0.07241925214360583\n",
      "train loss:0.15719065669634186\n",
      "train loss:0.2271588967656023\n",
      "train loss:0.15079505902777593\n",
      "train loss:0.08296033898931209\n",
      "train loss:0.25324868545836954\n",
      "train loss:0.10148379987936629\n",
      "train loss:0.10343384853155622\n",
      "train loss:0.09466053890255541\n",
      "train loss:0.06773222141543121\n",
      "train loss:0.07683988580215619\n",
      "train loss:0.13521571819166753\n",
      "train loss:0.12416123334596559\n",
      "train loss:0.1650982672718906\n",
      "train loss:0.10989069840350096\n",
      "train loss:0.10369924859763895\n",
      "train loss:0.07144636227588702\n",
      "train loss:0.15778539217442777\n",
      "train loss:0.11065911246259055\n",
      "train loss:0.19895184063536278\n",
      "train loss:0.11379740074554759\n",
      "train loss:0.14339425397589908\n",
      "train loss:0.05654603708551759\n",
      "train loss:0.08166389164439662\n",
      "train loss:0.122455916910123\n",
      "train loss:0.1098728446807024\n",
      "train loss:0.16027930693850617\n",
      "train loss:0.10376333104661661\n",
      "train loss:0.050854677093347365\n",
      "train loss:0.1391686599593204\n",
      "train loss:0.11773330155428528\n",
      "train loss:0.15310827427486903\n",
      "train loss:0.16056713056887478\n",
      "train loss:0.11210011060644959\n",
      "train loss:0.0704672626529856\n",
      "train loss:0.14435201383300414\n",
      "train loss:0.1221108349884326\n",
      "train loss:0.06797013478952163\n",
      "train loss:0.06854710456868128\n",
      "train loss:0.1165482049615511\n",
      "train loss:0.10626561768479018\n",
      "train loss:0.10854531402908117\n",
      "train loss:0.130995076370053\n",
      "train loss:0.06097828593537799\n",
      "train loss:0.13195212785994495\n",
      "train loss:0.129669693993396\n",
      "train loss:0.10617962061050784\n",
      "train loss:0.11459185600955295\n",
      "train loss:0.19972238282175375\n",
      "train loss:0.15039896504032885\n",
      "train loss:0.10030779228556255\n",
      "train loss:0.10048241396497819\n",
      "train loss:0.1520205415037665\n",
      "train loss:0.13897323563982641\n",
      "train loss:0.24550231596700997\n",
      "train loss:0.1416545126063418\n",
      "train loss:0.07889154708019999\n",
      "train loss:0.17874634277881324\n",
      "train loss:0.1789725147389767\n",
      "train loss:0.09425183247475145\n",
      "train loss:0.1620802654914143\n",
      "train loss:0.12885384283697376\n",
      "train loss:0.12712596977234963\n",
      "train loss:0.1402467123990854\n",
      "train loss:0.11339104321410154\n",
      "train loss:0.2252916916468981\n",
      "train loss:0.055819520507312516\n",
      "train loss:0.14453781658696446\n",
      "train loss:0.10208441214062358\n",
      "train loss:0.11523948793489401\n",
      "train loss:0.09918648281665922\n",
      "train loss:0.198843938426323\n",
      "train loss:0.1384061407950153\n",
      "train loss:0.13146026247511458\n",
      "train loss:0.07457870775071256\n",
      "train loss:0.22846245615766514\n",
      "train loss:0.1694898556568982\n",
      "train loss:0.15005470821561948\n",
      "train loss:0.09727181323606461\n",
      "train loss:0.08736904482174424\n",
      "train loss:0.184863474651814\n",
      "train loss:0.11607040923860602\n",
      "train loss:0.07932196053950918\n",
      "train loss:0.09639344051132513\n",
      "train loss:0.18254403689951673\n",
      "train loss:0.06125645836211363\n",
      "train loss:0.09107012966573942\n",
      "train loss:0.2505397981851546\n",
      "train loss:0.11303356012278355\n",
      "train loss:0.10515036281945958\n",
      "train loss:0.1479006985039872\n",
      "train loss:0.17295414745874768\n",
      "train loss:0.13999639170407288\n",
      "train loss:0.20056175466159126\n",
      "train loss:0.12261573353475075\n",
      "train loss:0.1392827793613198\n",
      "train loss:0.10400994756670393\n",
      "train loss:0.10513096804130832\n",
      "train loss:0.17166596408901227\n",
      "train loss:0.15846983915552532\n",
      "train loss:0.2162157252728326\n",
      "train loss:0.1392741916878501\n",
      "train loss:0.16959419098191492\n",
      "train loss:0.12028646455152128\n",
      "train loss:0.21429085299701522\n",
      "train loss:0.1264265442906706\n",
      "train loss:0.13955223620038065\n",
      "train loss:0.1430912023786497\n",
      "train loss:0.12662514754524265\n",
      "train loss:0.050177351944629904\n",
      "train loss:0.1520988003274796\n",
      "train loss:0.15650480085740068\n",
      "train loss:0.11941395089369782\n",
      "train loss:0.12597362272430643\n",
      "train loss:0.20251230631556638\n",
      "train loss:0.14121710891243702\n",
      "train loss:0.11705615751382638\n",
      "train loss:0.07847313809207974\n",
      "train loss:0.14955645452132346\n",
      "train loss:0.09031371683779865\n",
      "train loss:0.10294080357609223\n",
      "train loss:0.09459095499304519\n",
      "train loss:0.1303006868603613\n",
      "train loss:0.11619543697267488\n",
      "train loss:0.12410440699796946\n",
      "train loss:0.08299855301394773\n",
      "train loss:0.21997266058797385\n",
      "train loss:0.09628317376123123\n",
      "train loss:0.0932397455432359\n",
      "train loss:0.17706554307400565\n",
      "train loss:0.17286749092049233\n",
      "train loss:0.15376403582785605\n",
      "train loss:0.18649030623301732\n",
      "train loss:0.16738364733928524\n",
      "train loss:0.1757746375746082\n",
      "train loss:0.1176688962895172\n",
      "train loss:0.11692160095485704\n",
      "train loss:0.10029697688361378\n",
      "train loss:0.10025363633534956\n",
      "train loss:0.10236115377988217\n",
      "train loss:0.14253838602602575\n",
      "train loss:0.12470156644782017\n",
      "train loss:0.2091890834059401\n",
      "train loss:0.1543745291926794\n",
      "train loss:0.06983596327077261\n",
      "train loss:0.25534169058218287\n",
      "train loss:0.1510423513062655\n",
      "train loss:0.18716978666273826\n",
      "train loss:0.11547843934750698\n",
      "train loss:0.12551794669260807\n",
      "train loss:0.08486112438032953\n",
      "train loss:0.09143930279725351\n",
      "train loss:0.12018032908318033\n",
      "train loss:0.1363615098291752\n",
      "train loss:0.058032565339310595\n",
      "train loss:0.09623029738231431\n",
      "train loss:0.09479535557011974\n",
      "train loss:0.18766077387442653\n",
      "train loss:0.12133932762375803\n",
      "train loss:0.11664483794986807\n",
      "train loss:0.16170249985860752\n",
      "train loss:0.1316349707197062\n",
      "train loss:0.11570592106575864\n",
      "train loss:0.15613088157803245\n",
      "train loss:0.10263074849536012\n",
      "train loss:0.15778366081942227\n",
      "train loss:0.1161429792830016\n",
      "train loss:0.15544724012911867\n",
      "train loss:0.09831512668069699\n",
      "train loss:0.11119360447563001\n",
      "train loss:0.07483418785465917\n",
      "train loss:0.11939601460005136\n",
      "train loss:0.0962858180091261\n",
      "train loss:0.16171378375829082\n",
      "train loss:0.09936549187606493\n",
      "train loss:0.09468293421831031\n",
      "train loss:0.213446845274894\n",
      "train loss:0.17326277348748437\n",
      "train loss:0.09188964316088724\n",
      "train loss:0.094863216333093\n",
      "train loss:0.07935482910809194\n",
      "train loss:0.13101371915372143\n",
      "train loss:0.16499680602683583\n",
      "train loss:0.08426601190607\n",
      "train loss:0.13135780021835677\n",
      "train loss:0.09243907649995455\n",
      "train loss:0.07870884701949242\n",
      "train loss:0.12219104669638262\n",
      "train loss:0.10666399529515895\n",
      "train loss:0.11258106459385266\n",
      "train loss:0.08480056668539991\n",
      "train loss:0.09847030208140413\n",
      "train loss:0.07106102029397178\n",
      "train loss:0.08541171402697242\n",
      "train loss:0.11513492976992032\n",
      "train loss:0.0708073039872566\n",
      "train loss:0.15281697149528203\n",
      "train loss:0.08895332435499706\n",
      "train loss:0.0712823861037473\n",
      "train loss:0.09036002783119444\n",
      "train loss:0.1667681444322422\n",
      "train loss:0.08483455386571473\n",
      "train loss:0.14983807859015216\n",
      "train loss:0.1940758019666834\n",
      "train loss:0.1889824795997516\n",
      "train loss:0.1389872641248466\n",
      "train loss:0.10109344318206206\n",
      "train loss:0.1258356957607346\n",
      "train loss:0.10319784054524578\n",
      "train loss:0.12210833999786978\n",
      "train loss:0.16835562927957412\n",
      "train loss:0.19829738820963297\n",
      "train loss:0.18383615802298234\n",
      "train loss:0.12692212316077528\n",
      "train loss:0.09741860040135653\n",
      "train loss:0.26507038240193787\n",
      "train loss:0.11311743305175563\n",
      "train loss:0.16986702395927317\n",
      "train loss:0.12141633514145919\n",
      "train loss:0.15894504493413672\n",
      "train loss:0.07221423585092601\n",
      "train loss:0.06497013613560725\n",
      "train loss:0.13447926110301778\n",
      "train loss:0.13606530457980157\n",
      "train loss:0.11030273454008992\n",
      "train loss:0.0630766981151948\n",
      "train loss:0.15054126614408977\n",
      "train loss:0.1638190827702454\n",
      "train loss:0.15477853549534523\n",
      "train loss:0.16424244932780496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.08180473054525624\n",
      "train loss:0.12091580477681947\n",
      "train loss:0.06179942593528153\n",
      "train loss:0.07372454346103\n",
      "train loss:0.07391347998987777\n",
      "train loss:0.07831354867926968\n",
      "train loss:0.1778873870914589\n",
      "train loss:0.12556353705058154\n",
      "train loss:0.12953531079758465\n",
      "train loss:0.07174763771549736\n",
      "train loss:0.1843478523960395\n",
      "train loss:0.06280628272113228\n",
      "train loss:0.14528766887770414\n",
      "train loss:0.1622433062691712\n",
      "train loss:0.15684731106510416\n",
      "train loss:0.11997966572884586\n",
      "train loss:0.13080752991479735\n",
      "train loss:0.1266125279330934\n",
      "train loss:0.05643965707752658\n",
      "train loss:0.14302089129617504\n",
      "train loss:0.1105411032384866\n",
      "train loss:0.09981059954223952\n",
      "train loss:0.13519622821514438\n",
      "train loss:0.1353089689300333\n",
      "train loss:0.11692051776828484\n",
      "train loss:0.1142661284352474\n",
      "train loss:0.17132736975761098\n",
      "train loss:0.11245404390738517\n",
      "train loss:0.06499772687193138\n",
      "train loss:0.19897364240549698\n",
      "train loss:0.07415030224258502\n",
      "train loss:0.10130681949171545\n",
      "train loss:0.10670178127361098\n",
      "train loss:0.18780929058331297\n",
      "train loss:0.09772909401995233\n",
      "=== epoch:14, train acc:0.956, test acc:0.917 ===\n",
      "train loss:0.1150857553792973\n",
      "train loss:0.13676603277995247\n",
      "train loss:0.1017580167527773\n",
      "train loss:0.0879595724265258\n",
      "train loss:0.23045671845876495\n",
      "train loss:0.16997832901112603\n",
      "train loss:0.139086134890027\n",
      "train loss:0.11214115500824583\n",
      "train loss:0.21950077996180295\n",
      "train loss:0.04889446545145198\n",
      "train loss:0.05695961346130627\n",
      "train loss:0.07227676202480299\n",
      "train loss:0.15542883245459518\n",
      "train loss:0.15381135941836077\n",
      "train loss:0.12712156956861434\n",
      "train loss:0.11775368592638678\n",
      "train loss:0.09213266742841178\n",
      "train loss:0.07743516901727855\n",
      "train loss:0.10872228550281995\n",
      "train loss:0.1012581279671326\n",
      "train loss:0.11620834617463532\n",
      "train loss:0.13598586996931983\n",
      "train loss:0.10968202225011281\n",
      "train loss:0.1321218781059512\n",
      "train loss:0.11115789664488746\n",
      "train loss:0.08927571522981301\n",
      "train loss:0.13599978011239947\n",
      "train loss:0.13333513918213563\n",
      "train loss:0.1647127504994467\n",
      "train loss:0.08051563764590357\n",
      "train loss:0.1112381646427745\n",
      "train loss:0.1608732282880035\n",
      "train loss:0.10643377868275959\n",
      "train loss:0.1150205176253227\n",
      "train loss:0.21329077718408598\n",
      "train loss:0.06348827054774876\n",
      "train loss:0.12235327365869841\n",
      "train loss:0.10090906272322347\n",
      "train loss:0.07947363372856682\n",
      "train loss:0.13268245597031258\n",
      "train loss:0.07883146477679101\n",
      "train loss:0.08959850623022718\n",
      "train loss:0.1065915105233066\n",
      "train loss:0.0791343712979472\n",
      "train loss:0.12330795240143681\n",
      "train loss:0.09367213934232846\n",
      "train loss:0.1285502573515828\n",
      "train loss:0.0927369500873119\n",
      "train loss:0.195695331622003\n",
      "train loss:0.24708862890845126\n",
      "train loss:0.12869215574001666\n",
      "train loss:0.07703785727221668\n",
      "train loss:0.2246183346288254\n",
      "train loss:0.04923578380649506\n",
      "train loss:0.09940245937765894\n",
      "train loss:0.08463293603855576\n",
      "train loss:0.19038433398304316\n",
      "train loss:0.13645767640610043\n",
      "train loss:0.09999769186168281\n",
      "train loss:0.1462897272507775\n",
      "train loss:0.17080661334028668\n",
      "train loss:0.0550415972461445\n",
      "train loss:0.10698935366936371\n",
      "train loss:0.11130071205735749\n",
      "train loss:0.14193462705502877\n",
      "train loss:0.06553242742886409\n",
      "train loss:0.12565455036997847\n",
      "train loss:0.21495440210658587\n",
      "train loss:0.07805717621542195\n",
      "train loss:0.1520776987711388\n",
      "train loss:0.11578183316006924\n",
      "train loss:0.15692359026537794\n",
      "train loss:0.0822058799245747\n",
      "train loss:0.1112462691597189\n",
      "train loss:0.1399934692002322\n",
      "train loss:0.06968194691977143\n",
      "train loss:0.2118882661059635\n",
      "train loss:0.13134782627216993\n",
      "train loss:0.268286272852451\n",
      "train loss:0.12810074488287182\n",
      "train loss:0.16331594672620178\n",
      "train loss:0.11795015656182904\n",
      "train loss:0.08318175481374768\n",
      "train loss:0.09220043026305133\n",
      "train loss:0.14037777615928615\n",
      "train loss:0.11125817033738619\n",
      "train loss:0.14915463487625102\n",
      "train loss:0.11392894070070074\n",
      "train loss:0.22766856445512598\n",
      "train loss:0.15000955453191472\n",
      "train loss:0.17507581673004963\n",
      "train loss:0.10048325264639661\n",
      "train loss:0.08725588719959604\n",
      "train loss:0.11141870518060863\n",
      "train loss:0.15910500871796882\n",
      "train loss:0.036435364649330025\n",
      "train loss:0.17497469363036913\n",
      "train loss:0.16345435288100224\n",
      "train loss:0.09778454421067667\n",
      "train loss:0.11582643365756821\n",
      "train loss:0.1568163056964825\n",
      "train loss:0.13407703545285912\n",
      "train loss:0.0916145791806841\n",
      "train loss:0.12401626729507856\n",
      "train loss:0.1304770412141817\n",
      "train loss:0.1536177129270281\n",
      "train loss:0.06715387160469348\n",
      "train loss:0.07662330039042159\n",
      "train loss:0.09007266617507778\n",
      "train loss:0.11607707594046028\n",
      "train loss:0.1255222062052799\n",
      "train loss:0.11372129301045071\n",
      "train loss:0.09276742669036041\n",
      "train loss:0.11455149378299319\n",
      "train loss:0.11120109963344323\n",
      "train loss:0.1117970015222459\n",
      "train loss:0.16575309192127302\n",
      "train loss:0.15296054895668415\n",
      "train loss:0.18251498736878694\n",
      "train loss:0.24512101893718666\n",
      "train loss:0.1141310152392182\n",
      "train loss:0.06265090281599885\n",
      "train loss:0.15781966988165666\n",
      "train loss:0.1614865833113589\n",
      "train loss:0.19063404470729947\n",
      "train loss:0.12020952779004515\n",
      "train loss:0.1141824577163279\n",
      "train loss:0.20230448517462826\n",
      "train loss:0.18653997761683594\n",
      "train loss:0.09481880353849846\n",
      "train loss:0.12947242240094767\n",
      "train loss:0.07602701232179453\n",
      "train loss:0.0642463844934605\n",
      "train loss:0.1583132632194018\n",
      "train loss:0.08568300065913446\n",
      "train loss:0.08093574316778858\n",
      "train loss:0.06072935939593486\n",
      "train loss:0.11323466673703787\n",
      "train loss:0.17723159613140727\n",
      "train loss:0.09895592405654409\n",
      "train loss:0.1861887870472041\n",
      "train loss:0.06105507513785971\n",
      "train loss:0.08759594138438796\n",
      "train loss:0.11928993723757778\n",
      "train loss:0.11540717453473105\n",
      "train loss:0.118733637204\n",
      "train loss:0.14379014744004195\n",
      "train loss:0.06535738563818343\n",
      "train loss:0.274417586235353\n",
      "train loss:0.16550654135518506\n",
      "train loss:0.13360708178376077\n",
      "train loss:0.14308828630614387\n",
      "train loss:0.08617179114062629\n",
      "train loss:0.15047837461011765\n",
      "train loss:0.05822244360368084\n",
      "train loss:0.163411804955094\n",
      "train loss:0.12392917103245456\n",
      "train loss:0.14112501829391855\n",
      "train loss:0.12295499196162002\n",
      "train loss:0.1508562534560569\n",
      "train loss:0.20833738773375024\n",
      "train loss:0.1115301940237046\n",
      "train loss:0.13330409911057164\n",
      "train loss:0.13563289241084486\n",
      "train loss:0.09598233865915336\n",
      "train loss:0.06819357551096097\n",
      "train loss:0.05900711352982761\n",
      "train loss:0.10256689291730871\n",
      "train loss:0.08252112143384871\n",
      "train loss:0.11363998040644065\n",
      "train loss:0.16059250179342904\n",
      "train loss:0.046088044752754166\n",
      "train loss:0.12326503552305018\n",
      "train loss:0.17765969901820117\n",
      "train loss:0.12648963351544323\n",
      "train loss:0.08834236263585972\n",
      "train loss:0.06570841493204216\n",
      "train loss:0.1564462283314971\n",
      "train loss:0.10128258216493957\n",
      "train loss:0.08997336511357266\n",
      "train loss:0.12431223467440743\n",
      "train loss:0.059037371536860485\n",
      "train loss:0.09124366097288117\n",
      "train loss:0.07324745063219608\n",
      "train loss:0.06353307621973535\n",
      "train loss:0.08419056603853128\n",
      "train loss:0.05457957406688154\n",
      "train loss:0.12763878803107132\n",
      "train loss:0.10797948101526787\n",
      "train loss:0.10539607921220898\n",
      "train loss:0.1778786652343002\n",
      "train loss:0.10388602856782354\n",
      "train loss:0.14554520590691739\n",
      "train loss:0.1134923982174851\n",
      "train loss:0.09516871219481966\n",
      "train loss:0.21454450975093853\n",
      "train loss:0.18174051801850283\n",
      "train loss:0.08132720465749482\n",
      "train loss:0.14445153226380159\n",
      "train loss:0.10792292295586382\n",
      "train loss:0.12768721112776069\n",
      "train loss:0.15715041467581342\n",
      "train loss:0.0992469766438777\n",
      "train loss:0.0825447451305923\n",
      "train loss:0.07550897836345567\n",
      "train loss:0.07446277733287167\n",
      "train loss:0.07578717291590344\n",
      "train loss:0.2082124606592785\n",
      "train loss:0.1141731745154504\n",
      "train loss:0.1870753953980899\n",
      "train loss:0.08167177914183286\n",
      "train loss:0.10066326063727564\n",
      "train loss:0.10515419731922039\n",
      "train loss:0.1712219598559896\n",
      "train loss:0.09019212968072318\n",
      "train loss:0.10409366972479268\n",
      "train loss:0.1459748340228334\n",
      "train loss:0.07906977319367521\n",
      "train loss:0.20493511055489322\n",
      "train loss:0.14101313273918228\n",
      "train loss:0.06945996204202483\n",
      "train loss:0.08998748200188736\n",
      "train loss:0.19440859077935552\n",
      "train loss:0.07560925515792674\n",
      "train loss:0.16979623803090593\n",
      "train loss:0.11960783277164885\n",
      "train loss:0.06195735784200882\n",
      "train loss:0.18851640348351037\n",
      "train loss:0.12593876806476134\n",
      "train loss:0.12060525895608203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.14435819341640505\n",
      "train loss:0.057004201364031726\n",
      "train loss:0.10288192461368162\n",
      "train loss:0.14923601512466317\n",
      "train loss:0.15041454693523534\n",
      "train loss:0.07148952875710321\n",
      "train loss:0.12074335500605965\n",
      "train loss:0.09595036834954188\n",
      "train loss:0.06437488597514525\n",
      "train loss:0.13312294888626786\n",
      "train loss:0.139138391514577\n",
      "train loss:0.19473820912048873\n",
      "train loss:0.15953144117326543\n",
      "train loss:0.10481550633208889\n",
      "train loss:0.05937366654460417\n",
      "train loss:0.13069472457141676\n",
      "train loss:0.113095500030996\n",
      "train loss:0.09074070510488463\n",
      "train loss:0.15681976229233285\n",
      "train loss:0.18038650508046924\n",
      "train loss:0.07932417109346393\n",
      "train loss:0.25313960515630646\n",
      "train loss:0.11689526162766128\n",
      "train loss:0.051352538015096434\n",
      "train loss:0.14227802355677505\n",
      "train loss:0.06525856350709007\n",
      "train loss:0.14353405018999946\n",
      "train loss:0.12326387601240424\n",
      "train loss:0.07304613481609644\n",
      "train loss:0.07463145063747438\n",
      "train loss:0.1299638577216673\n",
      "train loss:0.09655041569679304\n",
      "train loss:0.13179849894584822\n",
      "train loss:0.15677662409122672\n",
      "train loss:0.07977501539653704\n",
      "train loss:0.12650291081676832\n",
      "train loss:0.10966736735330004\n",
      "train loss:0.09171220655804393\n",
      "train loss:0.09618106606005916\n",
      "train loss:0.0910179496395887\n",
      "train loss:0.17559303929832673\n",
      "train loss:0.10840850933387891\n",
      "train loss:0.0619913895539021\n",
      "train loss:0.1165087605292662\n",
      "train loss:0.1543968005833096\n",
      "train loss:0.0994165607281344\n",
      "train loss:0.1660678558705281\n",
      "train loss:0.09115660161055344\n",
      "train loss:0.1406097989917727\n",
      "train loss:0.09465482352848877\n",
      "train loss:0.18282562220277337\n",
      "train loss:0.11833946965616633\n",
      "train loss:0.12144256085282891\n",
      "train loss:0.0667237086432094\n",
      "train loss:0.06479122430302282\n",
      "train loss:0.08100358863359525\n",
      "train loss:0.12549444407756835\n",
      "train loss:0.10599793751199751\n",
      "train loss:0.09896756571297376\n",
      "train loss:0.09910880150882553\n",
      "train loss:0.06260635325804627\n",
      "train loss:0.07004900657380811\n",
      "train loss:0.1143509333807354\n",
      "train loss:0.10792415835538423\n",
      "train loss:0.08962696287372358\n",
      "train loss:0.20255081231173894\n",
      "train loss:0.06319926017405468\n",
      "train loss:0.04669962793309329\n",
      "train loss:0.06728623623160862\n",
      "train loss:0.07060520557998201\n",
      "train loss:0.12772307850319156\n",
      "train loss:0.08641135553747091\n",
      "train loss:0.11857415605048724\n",
      "train loss:0.04829530667750815\n",
      "train loss:0.0889222582396166\n",
      "train loss:0.10483182419901935\n",
      "train loss:0.06505041037905801\n",
      "train loss:0.1348681448048093\n",
      "train loss:0.07984068016824654\n",
      "train loss:0.19235079459643983\n",
      "train loss:0.08684791373996337\n",
      "train loss:0.05409796852811754\n",
      "train loss:0.09355634678772906\n",
      "train loss:0.09520792519917076\n",
      "train loss:0.11559738169726215\n",
      "train loss:0.06492294879448074\n",
      "train loss:0.0811094734025711\n",
      "train loss:0.18354609629830712\n",
      "train loss:0.16563845933476606\n",
      "train loss:0.12080896859585899\n",
      "train loss:0.10201512664015831\n",
      "train loss:0.07362649507652268\n",
      "train loss:0.13950073329465548\n",
      "train loss:0.07548782196612619\n",
      "train loss:0.1462034874173124\n",
      "train loss:0.07397314956686335\n",
      "train loss:0.05802441828287791\n",
      "train loss:0.08924460598194324\n",
      "train loss:0.11694429677763778\n",
      "train loss:0.24063000987522468\n",
      "train loss:0.12161136732490346\n",
      "train loss:0.11805365686288866\n",
      "train loss:0.09326092655933603\n",
      "train loss:0.10742953501097943\n",
      "train loss:0.06681722625158054\n",
      "train loss:0.050025797224208836\n",
      "train loss:0.08505641541641777\n",
      "train loss:0.11733507116307136\n",
      "train loss:0.08134095248444043\n",
      "train loss:0.1727055250175104\n",
      "train loss:0.10276095556040842\n",
      "train loss:0.1251734011385012\n",
      "train loss:0.13488549794346708\n",
      "train loss:0.1805825577549691\n",
      "train loss:0.05241494599199352\n",
      "train loss:0.056482859296518445\n",
      "train loss:0.22669332744164783\n",
      "train loss:0.07488920840099729\n",
      "train loss:0.1514601539495805\n",
      "train loss:0.06327111081055375\n",
      "train loss:0.0827309518002073\n",
      "train loss:0.12726591256380815\n",
      "train loss:0.05144879055589694\n",
      "train loss:0.12089164950706918\n",
      "train loss:0.1257760884647815\n",
      "train loss:0.12145190110905321\n",
      "train loss:0.2024600144063733\n",
      "train loss:0.1423077722464985\n",
      "train loss:0.14345221481554563\n",
      "train loss:0.15478828668045097\n",
      "train loss:0.09230004038604633\n",
      "train loss:0.16396621490920407\n",
      "train loss:0.1174337239757153\n",
      "train loss:0.12499456417474182\n",
      "train loss:0.12116380935454496\n",
      "train loss:0.0685296405926345\n",
      "train loss:0.07469885869934019\n",
      "train loss:0.08942534273291235\n",
      "train loss:0.04806291153706959\n",
      "train loss:0.11046058346497968\n",
      "train loss:0.10913855156795836\n",
      "train loss:0.12287178532224567\n",
      "train loss:0.0996430706672308\n",
      "train loss:0.15435551500992986\n",
      "train loss:0.17015984724733751\n",
      "train loss:0.10531872255478056\n",
      "train loss:0.12057664159310467\n",
      "train loss:0.17450449672588092\n",
      "train loss:0.17199706756821903\n",
      "train loss:0.1074833390675411\n",
      "train loss:0.1251267183911436\n",
      "train loss:0.1569940278589441\n",
      "train loss:0.09801513256163498\n",
      "train loss:0.20383437461788856\n",
      "train loss:0.09081928221618794\n",
      "train loss:0.128967093910088\n",
      "train loss:0.07173885325294888\n",
      "train loss:0.05528615738651707\n",
      "train loss:0.10525922032573941\n",
      "train loss:0.08503483086461497\n",
      "train loss:0.10927901783067712\n",
      "train loss:0.15746465199665452\n",
      "train loss:0.16425840820303755\n",
      "train loss:0.12156336337502802\n",
      "train loss:0.082404363143401\n",
      "train loss:0.15622022769226157\n",
      "train loss:0.09848958465952604\n",
      "train loss:0.12930109269110154\n",
      "train loss:0.10234568967839104\n",
      "train loss:0.09154271302227344\n",
      "train loss:0.1261169019272423\n",
      "train loss:0.1141471344618399\n",
      "train loss:0.11463848096461154\n",
      "train loss:0.08129097768380261\n",
      "train loss:0.13760978497401466\n",
      "train loss:0.13866673976155247\n",
      "train loss:0.12623507125585443\n",
      "train loss:0.08487209704353972\n",
      "train loss:0.09374921488387422\n",
      "train loss:0.08338703744717604\n",
      "train loss:0.08314122121845767\n",
      "train loss:0.1818541842606064\n",
      "train loss:0.10619801204035857\n",
      "train loss:0.08666748419559311\n",
      "train loss:0.06964375490565483\n",
      "train loss:0.07350568262352312\n",
      "train loss:0.18127322508348198\n",
      "train loss:0.11960164546152992\n",
      "train loss:0.10472350102230958\n",
      "train loss:0.15125508199794513\n",
      "train loss:0.18748131683918473\n",
      "train loss:0.08783053080779771\n",
      "train loss:0.13144053154699734\n",
      "train loss:0.1216968535873395\n",
      "train loss:0.19420776934827155\n",
      "train loss:0.12459803436420862\n",
      "train loss:0.1940188077900839\n",
      "train loss:0.13315505481979137\n",
      "train loss:0.16271013384258062\n",
      "train loss:0.11662226722152542\n",
      "train loss:0.07059936571489304\n",
      "train loss:0.11206852850559437\n",
      "train loss:0.10840888259138126\n",
      "train loss:0.09598977521859947\n",
      "train loss:0.14544523888910715\n",
      "train loss:0.07273920000682715\n",
      "train loss:0.051440384220901574\n",
      "train loss:0.13676219663539427\n",
      "train loss:0.07016593647655771\n",
      "train loss:0.1131885407755552\n",
      "train loss:0.0992757208033434\n",
      "train loss:0.11622190421883519\n",
      "train loss:0.15581026813276147\n",
      "train loss:0.19504487739645957\n",
      "train loss:0.20411675206664992\n",
      "train loss:0.10429834889573772\n",
      "train loss:0.0938997100924799\n",
      "train loss:0.1438569466637309\n",
      "train loss:0.1352227557835315\n",
      "train loss:0.08180827366515202\n",
      "train loss:0.09095894714159529\n",
      "train loss:0.08197962160071048\n",
      "train loss:0.15140439722754967\n",
      "train loss:0.15068432898109616\n",
      "train loss:0.09352050939018428\n",
      "train loss:0.11932274635051027\n",
      "train loss:0.11660453210028551\n",
      "train loss:0.09817433984037321\n",
      "train loss:0.21203392258846687\n",
      "train loss:0.1462273414700795\n",
      "train loss:0.07488598063664931\n",
      "train loss:0.07514755102977333\n",
      "train loss:0.11703775327722131\n",
      "train loss:0.1311764378431144\n",
      "train loss:0.08482304393229777\n",
      "train loss:0.11641433346683291\n",
      "train loss:0.05549280923227481\n",
      "train loss:0.0940370612228208\n",
      "train loss:0.10618443801553866\n",
      "train loss:0.08190025623277443\n",
      "train loss:0.10722786205229515\n",
      "train loss:0.14937236815386343\n",
      "train loss:0.10790067786666682\n",
      "train loss:0.07560819386209557\n",
      "train loss:0.08455685498217637\n",
      "train loss:0.07364408176301417\n",
      "train loss:0.14949316250944925\n",
      "train loss:0.09697404251493984\n",
      "train loss:0.05262258460660719\n",
      "train loss:0.1818451306882846\n",
      "train loss:0.05113499150973653\n",
      "train loss:0.1129140225847517\n",
      "train loss:0.06340712217998733\n",
      "train loss:0.1433417930295214\n",
      "train loss:0.18760554743666624\n",
      "train loss:0.08294622746341095\n",
      "train loss:0.12291647201157371\n",
      "train loss:0.08786203872016107\n",
      "train loss:0.10144559603767603\n",
      "train loss:0.07887235055968164\n",
      "train loss:0.12393833601731138\n",
      "train loss:0.06499664499958278\n",
      "train loss:0.08580411376206758\n",
      "train loss:0.05484887157571693\n",
      "train loss:0.06684210399943483\n",
      "train loss:0.13731201064591161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.050274882077345345\n",
      "train loss:0.11250376878107314\n",
      "train loss:0.08989603050072115\n",
      "train loss:0.13242128118277896\n",
      "train loss:0.09216282304452546\n",
      "train loss:0.10537656842277722\n",
      "train loss:0.22114175903476332\n",
      "train loss:0.16642170817247753\n",
      "train loss:0.04667183033516457\n",
      "train loss:0.0844657953407536\n",
      "train loss:0.13278831783567088\n",
      "train loss:0.1697064249503447\n",
      "train loss:0.10845537478876459\n",
      "train loss:0.1206582727270217\n",
      "train loss:0.04467284948333666\n",
      "train loss:0.07916551708329242\n",
      "train loss:0.18242275356719392\n",
      "train loss:0.17227860039338339\n",
      "train loss:0.05764454829633645\n",
      "train loss:0.1083866774741434\n",
      "train loss:0.05813343187058777\n",
      "train loss:0.04965970228537753\n",
      "train loss:0.06268185347495653\n",
      "train loss:0.09193831814875975\n",
      "train loss:0.10154909289053526\n",
      "train loss:0.3095570954669629\n",
      "train loss:0.12124062161922344\n",
      "train loss:0.08906704284682514\n",
      "train loss:0.0772029752386175\n",
      "train loss:0.10715774224763228\n",
      "train loss:0.10217694495451772\n",
      "train loss:0.21878035465375864\n",
      "train loss:0.17354812508096312\n",
      "train loss:0.19633042415626967\n",
      "train loss:0.12335748031349215\n",
      "train loss:0.08047423672443374\n",
      "train loss:0.12274258265141764\n",
      "train loss:0.14229083856340796\n",
      "train loss:0.12697758039515944\n",
      "train loss:0.04360338163826561\n",
      "train loss:0.06741244316816433\n",
      "train loss:0.1317993737442601\n",
      "train loss:0.08271101562820929\n",
      "train loss:0.08460130123743535\n",
      "train loss:0.0492628244689731\n",
      "train loss:0.1587377498794168\n",
      "train loss:0.1613104378904772\n",
      "train loss:0.10648156859468999\n",
      "train loss:0.11466246487571162\n",
      "train loss:0.10280111086952962\n",
      "train loss:0.03284145891955208\n",
      "train loss:0.09772346097145808\n",
      "train loss:0.14028805971824915\n",
      "train loss:0.15686607925253632\n",
      "train loss:0.1087236825740756\n",
      "train loss:0.13115774496711594\n",
      "train loss:0.08342889786278229\n",
      "train loss:0.09905665865983007\n",
      "train loss:0.14728583149780713\n",
      "train loss:0.06735525369570493\n",
      "train loss:0.25259979266978155\n",
      "train loss:0.09585770972130782\n",
      "train loss:0.11217487709657625\n",
      "train loss:0.09294187400521571\n",
      "train loss:0.0958393081163615\n",
      "train loss:0.10265557416342042\n",
      "train loss:0.09809627392640038\n",
      "train loss:0.07652174069878943\n",
      "train loss:0.16576167424569188\n",
      "train loss:0.1340007556640221\n",
      "train loss:0.11533488185527845\n",
      "train loss:0.12548430205647182\n",
      "train loss:0.17392779006842435\n",
      "train loss:0.08212556414613599\n",
      "train loss:0.08527137896245732\n",
      "train loss:0.1876773997804409\n",
      "train loss:0.061887938819699215\n",
      "train loss:0.1698841372720057\n",
      "train loss:0.07298962318321495\n",
      "train loss:0.06520772553099896\n",
      "train loss:0.10216131376439604\n",
      "train loss:0.10286323096510694\n",
      "train loss:0.07741450667948757\n",
      "train loss:0.1410497918045143\n",
      "train loss:0.1130916692727389\n",
      "train loss:0.10690093839033801\n",
      "train loss:0.08365057787942506\n",
      "train loss:0.11357322023691246\n",
      "train loss:0.09770264384289026\n",
      "train loss:0.11752715299451945\n",
      "train loss:0.0860540207214031\n",
      "train loss:0.11251039500586309\n",
      "train loss:0.040770818388818235\n",
      "train loss:0.07741481450893357\n",
      "train loss:0.05608497510179143\n",
      "train loss:0.10664757659683366\n",
      "train loss:0.11762226576260668\n",
      "train loss:0.06991272976838289\n",
      "train loss:0.1967813520323528\n",
      "train loss:0.09861918429864919\n",
      "train loss:0.11753014944757925\n",
      "train loss:0.10163031802772365\n",
      "train loss:0.10499610008111959\n",
      "train loss:0.15303369377838588\n",
      "=== epoch:15, train acc:0.963, test acc:0.913 ===\n",
      "train loss:0.044788162206616314\n",
      "train loss:0.07201110406307275\n",
      "train loss:0.20248540113704536\n",
      "train loss:0.14623570529204377\n",
      "train loss:0.05187361733247691\n",
      "train loss:0.10026357280904773\n",
      "train loss:0.12465575937054824\n",
      "train loss:0.16056327735317155\n",
      "train loss:0.061936949999286214\n",
      "train loss:0.0900783125456489\n",
      "train loss:0.15457566903575531\n",
      "train loss:0.10144566712662398\n",
      "train loss:0.09411646153721183\n",
      "train loss:0.09715331357559151\n",
      "train loss:0.09897874389815726\n",
      "train loss:0.1540840392984839\n",
      "train loss:0.10636404788654395\n",
      "train loss:0.16387955051745684\n",
      "train loss:0.10294070295719682\n",
      "train loss:0.08553985665564118\n",
      "train loss:0.07958172609933968\n",
      "train loss:0.16232932760190233\n",
      "train loss:0.14166675655108554\n",
      "train loss:0.08951470883923525\n",
      "train loss:0.060804933475003445\n",
      "train loss:0.11438316522350213\n",
      "train loss:0.12072332122613418\n",
      "train loss:0.14353234790347227\n",
      "train loss:0.05523311620628455\n",
      "train loss:0.045103317170027114\n",
      "train loss:0.16518330096437392\n",
      "train loss:0.20024862841242233\n",
      "train loss:0.10556959670160455\n",
      "train loss:0.08070173793667587\n",
      "train loss:0.051075015315184616\n",
      "train loss:0.11522288232256216\n",
      "train loss:0.06441969809642788\n",
      "train loss:0.11688878315837525\n",
      "train loss:0.2180350771342801\n",
      "train loss:0.09297034380275529\n",
      "train loss:0.1893977490566672\n",
      "train loss:0.19369076548656544\n",
      "train loss:0.18697378007020693\n",
      "train loss:0.19940153636874147\n",
      "train loss:0.17416510437789945\n",
      "train loss:0.13740278401205294\n",
      "train loss:0.1265755259290419\n",
      "train loss:0.14230475466260217\n",
      "train loss:0.1038392060859659\n",
      "train loss:0.04998337177404295\n",
      "train loss:0.1314369841455819\n",
      "train loss:0.11484507270207135\n",
      "train loss:0.11402680029634031\n",
      "train loss:0.09249508504724985\n",
      "train loss:0.1248396002934419\n",
      "train loss:0.15459750625178897\n",
      "train loss:0.07342200792126104\n",
      "train loss:0.13765735280072927\n",
      "train loss:0.10911154851732674\n",
      "train loss:0.10286389302832849\n",
      "train loss:0.14471238959384208\n",
      "train loss:0.21135102789136453\n",
      "train loss:0.15090198874720234\n",
      "train loss:0.1881316642457978\n",
      "train loss:0.1104213123874267\n",
      "train loss:0.15700333125606836\n",
      "train loss:0.151693232600967\n",
      "train loss:0.12842276579186515\n",
      "train loss:0.11975665619649367\n",
      "train loss:0.12612314357954424\n",
      "train loss:0.1059726089043237\n",
      "train loss:0.162180185290664\n",
      "train loss:0.09626729283943218\n",
      "train loss:0.11532052175653136\n",
      "train loss:0.10808532719822565\n",
      "train loss:0.06790844389426316\n",
      "train loss:0.10788190075988446\n",
      "train loss:0.14424580430142858\n",
      "train loss:0.06708089450684515\n",
      "train loss:0.1204249993287043\n",
      "train loss:0.14973817439811488\n",
      "train loss:0.13077929328414245\n",
      "train loss:0.0810130930125508\n",
      "train loss:0.153982886875682\n",
      "train loss:0.12386758728849337\n",
      "train loss:0.07157403080852114\n",
      "train loss:0.15453603342441913\n",
      "train loss:0.21402373485571582\n",
      "train loss:0.06513223938750279\n",
      "train loss:0.136842093235093\n",
      "train loss:0.12239170065478908\n",
      "train loss:0.09516914399499327\n",
      "train loss:0.08641521584949893\n",
      "train loss:0.09986316653136526\n",
      "train loss:0.1216611131678956\n",
      "train loss:0.1768848354028433\n",
      "train loss:0.05845825579764769\n",
      "train loss:0.14101190656450513\n",
      "train loss:0.1647026662988311\n",
      "train loss:0.10569601107830472\n",
      "train loss:0.11117151907464351\n",
      "train loss:0.08295004920181594\n",
      "train loss:0.12999498621717628\n",
      "train loss:0.09043048046916816\n",
      "train loss:0.13240062375776246\n",
      "train loss:0.19733197202718375\n",
      "train loss:0.10023775639437105\n",
      "train loss:0.045259808384370534\n",
      "train loss:0.12039156581505754\n",
      "train loss:0.08991316996374929\n",
      "train loss:0.19329629220373806\n",
      "train loss:0.164799753377337\n",
      "train loss:0.1597460629921251\n",
      "train loss:0.0809984714781501\n",
      "train loss:0.06787520876591491\n",
      "train loss:0.16615423040233956\n",
      "train loss:0.16795523656049538\n",
      "train loss:0.1146202223601536\n",
      "train loss:0.14758655437322654\n",
      "train loss:0.09013854801382984\n",
      "train loss:0.16417718119456493\n",
      "train loss:0.09649181474881904\n",
      "train loss:0.14038921610419527\n",
      "train loss:0.13383865766534586\n",
      "train loss:0.1058385374362264\n",
      "train loss:0.17250077797440444\n",
      "train loss:0.06232142274301143\n",
      "train loss:0.09753351382387754\n",
      "train loss:0.2032109459091914\n",
      "train loss:0.14980314354322458\n",
      "train loss:0.10021924186674278\n",
      "train loss:0.0821238788186332\n",
      "train loss:0.11559123330529307\n",
      "train loss:0.05470273957551483\n",
      "train loss:0.10105523518746011\n",
      "train loss:0.09129161297321157\n",
      "train loss:0.14622008659474062\n",
      "train loss:0.10156567026609792\n",
      "train loss:0.06281676743573877\n",
      "train loss:0.0554828185682044\n",
      "train loss:0.21775652686731836\n",
      "train loss:0.16864849188225708\n",
      "train loss:0.14289223810255336\n",
      "train loss:0.056593982602920326\n",
      "train loss:0.11097734983600036\n",
      "train loss:0.07497665944770866\n",
      "train loss:0.08214200383958929\n",
      "train loss:0.08889021537484336\n",
      "train loss:0.06648337565486223\n",
      "train loss:0.1023348031471921\n",
      "train loss:0.12787499304903993\n",
      "train loss:0.10904625526270274\n",
      "train loss:0.12419801979296953\n",
      "train loss:0.0721522676381952\n",
      "train loss:0.07512302135737346\n",
      "train loss:0.13043198250565743\n",
      "train loss:0.03746271338328067\n",
      "train loss:0.0946859571045092\n",
      "train loss:0.142905614042035\n",
      "train loss:0.14563645303817913\n",
      "train loss:0.09912313958608657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.12020599718536973\n",
      "train loss:0.08496787824535548\n",
      "train loss:0.09442782793293324\n",
      "train loss:0.11355284880994372\n",
      "train loss:0.11496713943426143\n",
      "train loss:0.11524395162464174\n",
      "train loss:0.07670236110841111\n",
      "train loss:0.046412593026183224\n",
      "train loss:0.08571881760985935\n",
      "train loss:0.16246634090326734\n",
      "train loss:0.068315727874661\n",
      "train loss:0.11366715098406738\n",
      "train loss:0.07005584382663486\n",
      "train loss:0.07384112148151065\n",
      "train loss:0.11751885599500729\n",
      "train loss:0.1045273031662779\n",
      "train loss:0.17265613895630197\n",
      "train loss:0.0953305763470994\n",
      "train loss:0.14065608422069673\n",
      "train loss:0.16920485976869645\n",
      "train loss:0.07338440966690389\n",
      "train loss:0.08263130602832114\n",
      "train loss:0.17438301925851107\n",
      "train loss:0.046452179352048845\n",
      "train loss:0.13795586272177826\n",
      "train loss:0.09070773898419952\n",
      "train loss:0.14834312024978874\n",
      "train loss:0.10868517547993971\n",
      "train loss:0.07626022171619504\n",
      "train loss:0.07134689170400339\n",
      "train loss:0.1653467093047525\n",
      "train loss:0.1616688481378598\n",
      "train loss:0.08055293454040653\n",
      "train loss:0.1144762865499187\n",
      "train loss:0.03847700447570018\n",
      "train loss:0.05266548102561865\n",
      "train loss:0.13154067848179202\n",
      "train loss:0.058197227136239385\n",
      "train loss:0.10486063265563335\n",
      "train loss:0.08511446632109085\n",
      "train loss:0.0605707225773449\n",
      "train loss:0.12146160632789944\n",
      "train loss:0.05148211315570191\n",
      "train loss:0.14061237008405658\n",
      "train loss:0.1082228304591285\n",
      "train loss:0.050035322334397225\n",
      "train loss:0.17495972010065927\n",
      "train loss:0.11962726180064445\n",
      "train loss:0.05376966371009086\n",
      "train loss:0.10083955944534402\n",
      "train loss:0.08796362685491145\n",
      "train loss:0.10918884712108062\n",
      "train loss:0.09941684535720816\n",
      "train loss:0.15983924078623735\n",
      "train loss:0.09498686204639134\n",
      "train loss:0.10269855420661797\n",
      "train loss:0.1041944574855068\n",
      "train loss:0.07829126388263727\n",
      "train loss:0.07681392334168033\n",
      "train loss:0.15517828922676283\n",
      "train loss:0.13201751148767576\n",
      "train loss:0.10663965106582379\n",
      "train loss:0.07429395310854088\n",
      "train loss:0.16586749210317708\n",
      "train loss:0.09670798166505845\n",
      "train loss:0.045659304298090835\n",
      "train loss:0.055906807959157596\n",
      "train loss:0.08462281457505266\n",
      "train loss:0.07071932751537206\n",
      "train loss:0.08336182424345873\n",
      "train loss:0.057473466806375564\n",
      "train loss:0.04596714245654418\n",
      "train loss:0.14656109403596004\n",
      "train loss:0.07760281200302231\n",
      "train loss:0.09779986964841413\n",
      "train loss:0.0974184101981408\n",
      "train loss:0.0655256453903482\n",
      "train loss:0.06235453202784935\n",
      "train loss:0.13531999945332307\n",
      "train loss:0.15842248783259122\n",
      "train loss:0.09689728672576774\n",
      "train loss:0.13678029020883964\n",
      "train loss:0.1637889365816042\n",
      "train loss:0.14755163936127216\n",
      "train loss:0.14596032547572008\n",
      "train loss:0.1235164099574609\n",
      "train loss:0.06619883978641386\n",
      "train loss:0.039802571125932204\n",
      "train loss:0.1696682413979865\n",
      "train loss:0.11380553836237053\n",
      "train loss:0.036995462868585155\n",
      "train loss:0.15308290214611436\n",
      "train loss:0.03200678746046687\n",
      "train loss:0.10338634220859054\n",
      "train loss:0.21621469248330072\n",
      "train loss:0.07504174284562193\n",
      "train loss:0.11288030039452801\n",
      "train loss:0.0838975123054861\n",
      "train loss:0.06981377276305686\n",
      "train loss:0.1454794787280603\n",
      "train loss:0.115327256553851\n",
      "train loss:0.09388196683038366\n",
      "train loss:0.10870324108628085\n",
      "train loss:0.21908399221617095\n",
      "train loss:0.0551666433083408\n",
      "train loss:0.08325945666253282\n",
      "train loss:0.09925613729136716\n",
      "train loss:0.13643229360681575\n",
      "train loss:0.06507952241873075\n",
      "train loss:0.10611017176911083\n",
      "train loss:0.09353576708961336\n",
      "train loss:0.05195884393775391\n",
      "train loss:0.10808455465162548\n",
      "train loss:0.1481732957168791\n",
      "train loss:0.12295654794498485\n",
      "train loss:0.1097045424376141\n",
      "train loss:0.08920765072063164\n",
      "train loss:0.10213820272348113\n",
      "train loss:0.15849348168302854\n",
      "train loss:0.06896580725810718\n",
      "train loss:0.11372100970926702\n",
      "train loss:0.1254154714642465\n",
      "train loss:0.09145552051420147\n",
      "train loss:0.09186205252700388\n",
      "train loss:0.08981987420997292\n",
      "train loss:0.12033565935135694\n",
      "train loss:0.059138817947059844\n",
      "train loss:0.049200216345341295\n",
      "train loss:0.08841340227504864\n",
      "train loss:0.06211808024001523\n",
      "train loss:0.09164692490030331\n",
      "train loss:0.09514804125610617\n",
      "train loss:0.10404154682764055\n",
      "train loss:0.059780047024087526\n",
      "train loss:0.040285576819913294\n",
      "train loss:0.1740693822409524\n",
      "train loss:0.05656021390189521\n",
      "train loss:0.14896401144267227\n",
      "train loss:0.0886676754790816\n",
      "train loss:0.07825641015163921\n",
      "train loss:0.059518808544829424\n",
      "train loss:0.1705496856452459\n",
      "train loss:0.13877402368564007\n",
      "train loss:0.12346516113449679\n",
      "train loss:0.09553595528177494\n",
      "train loss:0.09346749166870158\n",
      "train loss:0.09424295421990948\n",
      "train loss:0.06504963001026659\n",
      "train loss:0.09322452070326107\n",
      "train loss:0.21990188082459425\n",
      "train loss:0.13245749617757854\n",
      "train loss:0.1791661187099513\n",
      "train loss:0.08658883910573457\n",
      "train loss:0.06110729843931929\n",
      "train loss:0.1392736701588602\n",
      "train loss:0.08598032167372892\n",
      "train loss:0.08317877689326707\n",
      "train loss:0.1397875645370394\n",
      "train loss:0.09513086750605602\n",
      "train loss:0.17652971933205475\n",
      "train loss:0.07878186096100974\n",
      "train loss:0.03741874761112875\n",
      "train loss:0.05684246550526299\n",
      "train loss:0.11135651097155146\n",
      "train loss:0.19513675572159905\n",
      "train loss:0.20163468893627737\n",
      "train loss:0.1521612373344669\n",
      "train loss:0.14360802140611267\n",
      "train loss:0.06756483561423555\n",
      "train loss:0.08898008120228612\n",
      "train loss:0.1195953152126616\n",
      "train loss:0.15894710030779197\n",
      "train loss:0.15522493453513886\n",
      "train loss:0.07685359165487735\n",
      "train loss:0.1430246453437066\n",
      "train loss:0.09188099984198293\n",
      "train loss:0.045322864782333376\n",
      "train loss:0.07914272613529044\n",
      "train loss:0.12089589547450194\n",
      "train loss:0.06537108153279061\n",
      "train loss:0.11296323979158261\n",
      "train loss:0.0838002613161783\n",
      "train loss:0.08593017108049228\n",
      "train loss:0.13177837796932101\n",
      "train loss:0.04990449730214306\n",
      "train loss:0.15446643975050406\n",
      "train loss:0.03950391228864343\n",
      "train loss:0.11585997448810709\n",
      "train loss:0.20461829161921913\n",
      "train loss:0.16042268939335666\n",
      "train loss:0.0841690783803508\n",
      "train loss:0.07137905699023733\n",
      "train loss:0.08430372791269203\n",
      "train loss:0.12507889679873213\n",
      "train loss:0.07812126992900512\n",
      "train loss:0.05318013542215899\n",
      "train loss:0.11145206980624174\n",
      "train loss:0.09280217128887935\n",
      "train loss:0.12171406524745625\n",
      "train loss:0.02823919834626153\n",
      "train loss:0.11204877400547057\n",
      "train loss:0.12319546644250529\n",
      "train loss:0.0719842132580431\n",
      "train loss:0.1371084035341302\n",
      "train loss:0.08556513444498143\n",
      "train loss:0.09910502673903508\n",
      "train loss:0.10868493754887565\n",
      "train loss:0.10721712336398713\n",
      "train loss:0.2186391379552552\n",
      "train loss:0.06593844984272193\n",
      "train loss:0.08455063526173649\n",
      "train loss:0.10330217468968225\n",
      "train loss:0.08821621633115243\n",
      "train loss:0.08194175030675581\n",
      "train loss:0.044899443583979244\n",
      "train loss:0.10232846987230645\n",
      "train loss:0.14744880936949423\n",
      "train loss:0.08709483071052018\n",
      "train loss:0.11666464839115685\n",
      "train loss:0.11686076084217026\n",
      "train loss:0.0648955223112422\n",
      "train loss:0.07276055213927357\n",
      "train loss:0.0887842676036495\n",
      "train loss:0.14131652536213854\n",
      "train loss:0.10283157816613128\n",
      "train loss:0.15820015728716372\n",
      "train loss:0.2094994362067471\n",
      "train loss:0.10070281278131231\n",
      "train loss:0.08108822050129812\n",
      "train loss:0.1924150610668097\n",
      "train loss:0.11045132524683263\n",
      "train loss:0.1723989430633827\n",
      "train loss:0.1134214506222284\n",
      "train loss:0.07299227541449695\n",
      "train loss:0.07673761468258203\n",
      "train loss:0.06150187127341746\n",
      "train loss:0.0923651182462904\n",
      "train loss:0.12357952875311173\n",
      "train loss:0.0788507156269663\n",
      "train loss:0.09412172060785025\n",
      "train loss:0.08784767637292772\n",
      "train loss:0.072052151542275\n",
      "train loss:0.1052544684480993\n",
      "train loss:0.08115315313676115\n",
      "train loss:0.06153726402992839\n",
      "train loss:0.049773797929415144\n",
      "train loss:0.08440549415492087\n",
      "train loss:0.08682333144595678\n",
      "train loss:0.06317973062328174\n",
      "train loss:0.1837636731066088\n",
      "train loss:0.11906589879183001\n",
      "train loss:0.0786178033947572\n",
      "train loss:0.14433274506416802\n",
      "train loss:0.103725566555696\n",
      "train loss:0.11578367368137218\n",
      "train loss:0.09033440253683508\n",
      "train loss:0.10999871516725694\n",
      "train loss:0.06264016654709763\n",
      "train loss:0.06256685573534397\n",
      "train loss:0.10839213958350422\n",
      "train loss:0.17269934922427058\n",
      "train loss:0.1265065892768079\n",
      "train loss:0.07490902449240186\n",
      "train loss:0.18868054497486217\n",
      "train loss:0.06798115577711969\n",
      "train loss:0.09516685939241055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.06647696546206577\n",
      "train loss:0.16802689928450398\n",
      "train loss:0.1406062820418078\n",
      "train loss:0.04986124607671884\n",
      "train loss:0.07425777064854881\n",
      "train loss:0.05594138916737409\n",
      "train loss:0.15748450751053508\n",
      "train loss:0.12928560878542805\n",
      "train loss:0.11402738190180649\n",
      "train loss:0.17647627686290587\n",
      "train loss:0.11977826436175378\n",
      "train loss:0.11708595220298422\n",
      "train loss:0.0698755433198071\n",
      "train loss:0.11254659198610632\n",
      "train loss:0.07762624627785696\n",
      "train loss:0.0827152989335581\n",
      "train loss:0.14644643563325171\n",
      "train loss:0.2115460064415759\n",
      "train loss:0.11000186715053684\n",
      "train loss:0.07459385834972813\n",
      "train loss:0.05095071085876941\n",
      "train loss:0.07385840357889945\n",
      "train loss:0.16600983465852648\n",
      "train loss:0.10906013181191954\n",
      "train loss:0.06513740210280634\n",
      "train loss:0.08992439073685278\n",
      "train loss:0.04143953604104677\n",
      "train loss:0.10378726262091745\n",
      "train loss:0.052918996968016635\n",
      "train loss:0.12498982121665471\n",
      "train loss:0.19844092343797962\n",
      "train loss:0.07551568133989782\n",
      "train loss:0.08522657131529533\n",
      "train loss:0.1329328080398251\n",
      "train loss:0.1347237067304002\n",
      "train loss:0.06940523124925926\n",
      "train loss:0.1394590300674982\n",
      "train loss:0.1109682734912579\n",
      "train loss:0.08211695974788576\n",
      "train loss:0.07925211668189194\n",
      "train loss:0.04014503817479129\n",
      "train loss:0.11339023662137857\n",
      "train loss:0.08619714493700266\n",
      "train loss:0.1816258626431733\n",
      "train loss:0.09206412984571045\n",
      "train loss:0.07333886479154547\n",
      "train loss:0.09967865124776075\n",
      "train loss:0.08262830804738565\n",
      "train loss:0.12521356818148374\n",
      "train loss:0.11284797524190177\n",
      "train loss:0.10528334464227194\n",
      "train loss:0.07559980041874942\n",
      "train loss:0.10011071369500103\n",
      "train loss:0.1390326216361055\n",
      "train loss:0.07229722175257919\n",
      "train loss:0.16547592433620495\n",
      "train loss:0.11125286964549948\n",
      "train loss:0.12331745918143865\n",
      "train loss:0.08554163419708725\n",
      "train loss:0.0806501606371386\n",
      "train loss:0.1411122698022067\n",
      "train loss:0.06727641411120461\n",
      "train loss:0.08501742733448445\n",
      "train loss:0.09349949676907596\n",
      "train loss:0.056168108203988903\n",
      "train loss:0.09824194436105428\n",
      "train loss:0.18262609509256414\n",
      "train loss:0.11296410779906921\n",
      "train loss:0.11989020477192439\n",
      "train loss:0.11748158316112717\n",
      "train loss:0.08646004712005691\n",
      "train loss:0.09205398295296478\n",
      "train loss:0.15409795454793604\n",
      "train loss:0.07803589358999967\n",
      "train loss:0.10072800015990044\n",
      "train loss:0.09901544594532848\n",
      "train loss:0.06810747675985587\n",
      "train loss:0.052703391180002813\n",
      "train loss:0.113398864696884\n",
      "train loss:0.14642860164719818\n",
      "train loss:0.05825106995369226\n",
      "train loss:0.1349263243552092\n",
      "train loss:0.08588291988357882\n",
      "train loss:0.0800740751820762\n",
      "train loss:0.09448745268444904\n",
      "train loss:0.06729689599203381\n",
      "train loss:0.04444951605339855\n",
      "train loss:0.10325579625881996\n",
      "train loss:0.11831108765152766\n",
      "train loss:0.10413943153922496\n",
      "train loss:0.10217460690583492\n",
      "train loss:0.07951220697710627\n",
      "train loss:0.13216908210897393\n",
      "train loss:0.12270704677238241\n",
      "train loss:0.0992164159060335\n",
      "train loss:0.22156086580659942\n",
      "train loss:0.15640745031683942\n",
      "train loss:0.09325642325774634\n",
      "train loss:0.13978355030453515\n",
      "train loss:0.12972621540174079\n",
      "train loss:0.05178618487586439\n",
      "train loss:0.11946257157376318\n",
      "train loss:0.1470016704626409\n",
      "train loss:0.08616915838968252\n",
      "train loss:0.0968146064620115\n",
      "train loss:0.10540162222234185\n",
      "train loss:0.2284227359983231\n",
      "train loss:0.052926172766760884\n",
      "train loss:0.11633993930602758\n",
      "train loss:0.13731110931872492\n",
      "train loss:0.06416382195942985\n",
      "train loss:0.06589617162155358\n",
      "train loss:0.0668607088318286\n",
      "train loss:0.18341519460131747\n",
      "train loss:0.061526001935970756\n",
      "train loss:0.10620750035649446\n",
      "train loss:0.053157259491470585\n",
      "train loss:0.058762708854260604\n",
      "train loss:0.12204527992405226\n",
      "train loss:0.15236778009654098\n",
      "train loss:0.06708008355506934\n",
      "train loss:0.13318644013004083\n",
      "train loss:0.08380613182880409\n",
      "train loss:0.11753237577022144\n",
      "train loss:0.08900940946538817\n",
      "train loss:0.15566455635460213\n",
      "train loss:0.0847241820642126\n",
      "train loss:0.12671039760490996\n",
      "train loss:0.045191666433018494\n",
      "train loss:0.14652057010425518\n",
      "train loss:0.06633958699825722\n",
      "train loss:0.10633157255210537\n",
      "train loss:0.07199929578245695\n",
      "train loss:0.07132047701401587\n",
      "train loss:0.13102275356261303\n",
      "train loss:0.09714946118851092\n",
      "train loss:0.1473196119521867\n",
      "train loss:0.2766005935296498\n",
      "train loss:0.07471384592997611\n",
      "train loss:0.09960123172433528\n",
      "train loss:0.07238624696119604\n",
      "train loss:0.11205070964636303\n",
      "train loss:0.11027281938231467\n",
      "train loss:0.2094104078780875\n",
      "train loss:0.08686953787019086\n",
      "train loss:0.09693732125446015\n",
      "train loss:0.08059625533788858\n",
      "train loss:0.09248341469004517\n",
      "train loss:0.12701196777870416\n",
      "train loss:0.11802614863072942\n",
      "train loss:0.12311895863236204\n",
      "train loss:0.08801322034307582\n",
      "train loss:0.10037605716866174\n",
      "train loss:0.1601511365065768\n",
      "train loss:0.06092892525918345\n",
      "train loss:0.13462693163128112\n",
      "train loss:0.06205066827404861\n",
      "train loss:0.0953706192008079\n",
      "train loss:0.06219524096761324\n",
      "train loss:0.058568907212385085\n",
      "train loss:0.104530444096654\n",
      "train loss:0.0877764530503314\n",
      "train loss:0.10745152816460887\n",
      "train loss:0.14306121880060074\n",
      "train loss:0.11292166192676883\n",
      "train loss:0.15950971645367984\n",
      "train loss:0.11301914433143942\n",
      "train loss:0.06185257228240663\n",
      "train loss:0.1102407165749785\n",
      "train loss:0.07996285476973072\n",
      "train loss:0.09969105738065943\n",
      "train loss:0.10665215372709805\n",
      "train loss:0.10666553895392433\n",
      "=== epoch:16, train acc:0.969, test acc:0.912 ===\n",
      "train loss:0.09655398283861548\n",
      "train loss:0.05906123208818007\n",
      "train loss:0.08683663184540173\n",
      "train loss:0.06634501757724424\n",
      "train loss:0.13001350069139045\n",
      "train loss:0.1574044482509405\n",
      "train loss:0.10277719561001059\n",
      "train loss:0.11364541152555407\n",
      "train loss:0.07429966378388725\n",
      "train loss:0.15513377703948283\n",
      "train loss:0.12124757003383253\n",
      "train loss:0.0846799104302668\n",
      "train loss:0.10007270070238061\n",
      "train loss:0.0977889018960901\n",
      "train loss:0.12830487835237991\n",
      "train loss:0.08131148672484718\n",
      "train loss:0.1025794005076452\n",
      "train loss:0.09092598686197338\n",
      "train loss:0.09008355386165447\n",
      "train loss:0.10530533509711307\n",
      "train loss:0.10896565812048928\n",
      "train loss:0.17579423097636482\n",
      "train loss:0.13054497519013247\n",
      "train loss:0.07668217976534138\n",
      "train loss:0.17380428458619562\n",
      "train loss:0.08296207029802499\n",
      "train loss:0.05334720575621458\n",
      "train loss:0.08043083600327235\n",
      "train loss:0.06888145958518217\n",
      "train loss:0.09577892489151996\n",
      "train loss:0.03976450446727994\n",
      "train loss:0.09086572133425933\n",
      "train loss:0.09780565332831082\n",
      "train loss:0.12091783538822405\n",
      "train loss:0.0459722620938766\n",
      "train loss:0.08723538864426608\n",
      "train loss:0.130629541799772\n",
      "train loss:0.04858063698386881\n",
      "train loss:0.07596151857676596\n",
      "train loss:0.0816853420648329\n",
      "train loss:0.14632397289188753\n",
      "train loss:0.07784849045651283\n",
      "train loss:0.1296152012544142\n",
      "train loss:0.09508857681628474\n",
      "train loss:0.1089393971267098\n",
      "train loss:0.10146033235198068\n",
      "train loss:0.16967883861571867\n",
      "train loss:0.03819978176426045\n",
      "train loss:0.13192890690511475\n",
      "train loss:0.07311216232676838\n",
      "train loss:0.07500571228962577\n",
      "train loss:0.1148200077422036\n",
      "train loss:0.10805874856945136\n",
      "train loss:0.0735964235797082\n",
      "train loss:0.10417124746283407\n",
      "train loss:0.10477770298308921\n",
      "train loss:0.15895969198499577\n",
      "train loss:0.08555080339750373\n",
      "train loss:0.09570649988308765\n",
      "train loss:0.13950440060880212\n",
      "train loss:0.07718562329698507\n",
      "train loss:0.13355831963974724\n",
      "train loss:0.07754365959465062\n",
      "train loss:0.1176791829708336\n",
      "train loss:0.08469737587870357\n",
      "train loss:0.1383605611891475\n",
      "train loss:0.06800157539055013\n",
      "train loss:0.19967585723586587\n",
      "train loss:0.11490609013743726\n",
      "train loss:0.07121265894400552\n",
      "train loss:0.08732172282734554\n",
      "train loss:0.0728837444940984\n",
      "train loss:0.10426678050986667\n",
      "train loss:0.08904442454167008\n",
      "train loss:0.11650680316800066\n",
      "train loss:0.07154182435910755\n",
      "train loss:0.11350705487008295\n",
      "train loss:0.12124838833337419\n",
      "train loss:0.0947752864180635\n",
      "train loss:0.08204937326128219\n",
      "train loss:0.14759242223966973\n",
      "train loss:0.10366605096619615\n",
      "train loss:0.049191080430971715\n",
      "train loss:0.08809217570265034\n",
      "train loss:0.09086699516506125\n",
      "train loss:0.1519614938771627\n",
      "train loss:0.07451550700014989\n",
      "train loss:0.1481747306427214\n",
      "train loss:0.02801287158122663\n",
      "train loss:0.09600053067857851\n",
      "train loss:0.02883279272784366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.09379061246086684\n",
      "train loss:0.07788193670649016\n",
      "train loss:0.07086386448881124\n",
      "train loss:0.09373436668441809\n",
      "train loss:0.11391498327766497\n",
      "train loss:0.0653831081081026\n",
      "train loss:0.14955523906752974\n",
      "train loss:0.08926764721881339\n",
      "train loss:0.07358669710475021\n",
      "train loss:0.09009408433877236\n",
      "train loss:0.14106703839629936\n",
      "train loss:0.10947174642080863\n",
      "train loss:0.055586832068274805\n",
      "train loss:0.10124008738399373\n",
      "train loss:0.08352689084356384\n",
      "train loss:0.0949012797212038\n",
      "train loss:0.23370132942161675\n",
      "train loss:0.12736351486538536\n",
      "train loss:0.09494087366411832\n",
      "train loss:0.11615595116035544\n",
      "train loss:0.10639733167892666\n",
      "train loss:0.0855009956093118\n",
      "train loss:0.12736771467345542\n",
      "train loss:0.07928316724234724\n",
      "train loss:0.15106141465312928\n",
      "train loss:0.06371285117530995\n",
      "train loss:0.12416554738328722\n",
      "train loss:0.09145903481410515\n",
      "train loss:0.10148727623104639\n",
      "train loss:0.12350884857696479\n",
      "train loss:0.11474937756857964\n",
      "train loss:0.09545800814766915\n",
      "train loss:0.1874889480964826\n",
      "train loss:0.08226780454572126\n",
      "train loss:0.16453988672341016\n",
      "train loss:0.06267349122991213\n",
      "train loss:0.1352774452647327\n",
      "train loss:0.10240434193504316\n",
      "train loss:0.12563003597358854\n",
      "train loss:0.07586784968432923\n",
      "train loss:0.06076248396217845\n",
      "train loss:0.14120594763520236\n",
      "train loss:0.09346437441339703\n",
      "train loss:0.10115093588155567\n",
      "train loss:0.07160416074546677\n",
      "train loss:0.058090610322462786\n",
      "train loss:0.09701943030473986\n",
      "train loss:0.11010241603477303\n",
      "train loss:0.1292485592837245\n",
      "train loss:0.11946853658997711\n",
      "train loss:0.1011373317932415\n",
      "train loss:0.10834688446629868\n",
      "train loss:0.08149364399747984\n",
      "train loss:0.11414141270938531\n",
      "train loss:0.066807051358827\n",
      "train loss:0.06913400671788084\n",
      "train loss:0.0806228114667612\n",
      "train loss:0.05105571080291016\n",
      "train loss:0.05934298625300987\n",
      "train loss:0.045074933069600656\n",
      "train loss:0.08765608772889825\n",
      "train loss:0.11308171975183472\n",
      "train loss:0.13314480062089465\n",
      "train loss:0.14481543496192983\n",
      "train loss:0.10104930978099005\n",
      "train loss:0.08111400130608373\n",
      "train loss:0.09554161438195019\n",
      "train loss:0.10953431996564493\n",
      "train loss:0.1406530776651554\n",
      "train loss:0.08171514250365121\n",
      "train loss:0.058280689286533266\n",
      "train loss:0.09088855663321116\n",
      "train loss:0.10194749290499829\n",
      "train loss:0.052115565701735686\n",
      "train loss:0.0884384216693446\n",
      "train loss:0.06394518737405748\n",
      "train loss:0.08740885255728191\n",
      "train loss:0.07664439398760732\n",
      "train loss:0.09017131656369981\n",
      "train loss:0.051661899210835215\n",
      "train loss:0.10271585546129089\n",
      "train loss:0.16067020065976312\n",
      "train loss:0.03671939098353999\n",
      "train loss:0.08389729744613225\n",
      "train loss:0.1285662456845625\n",
      "train loss:0.09154749698040471\n",
      "train loss:0.06466579784324746\n",
      "train loss:0.1138096480844375\n",
      "train loss:0.10625018186619391\n",
      "train loss:0.07763770731055081\n",
      "train loss:0.06319550237140809\n",
      "train loss:0.09604392184707011\n",
      "train loss:0.10289210615736641\n",
      "train loss:0.08955018061460987\n",
      "train loss:0.07010022747701895\n",
      "train loss:0.11341094895899055\n",
      "train loss:0.09601225458007134\n",
      "train loss:0.07979981611204219\n",
      "train loss:0.12007448179672016\n",
      "train loss:0.1086699487676997\n",
      "train loss:0.10298384966217808\n",
      "train loss:0.0888993274332325\n",
      "train loss:0.05917963908425904\n",
      "train loss:0.10603313804914283\n",
      "train loss:0.10173540880667804\n",
      "train loss:0.10593493888968508\n",
      "train loss:0.15674836514243487\n",
      "train loss:0.07718598318015477\n",
      "train loss:0.16300693594410134\n",
      "train loss:0.06926050425875713\n",
      "train loss:0.1188612827741877\n",
      "train loss:0.12934932919604636\n",
      "train loss:0.08445363210806577\n",
      "train loss:0.13553563260289914\n",
      "train loss:0.0878328333365962\n",
      "train loss:0.1526382126247835\n",
      "train loss:0.0958783621006332\n",
      "train loss:0.05046610539776915\n",
      "train loss:0.21781216189286134\n",
      "train loss:0.046223220423684035\n",
      "train loss:0.12480483205699494\n",
      "train loss:0.1329633834010471\n",
      "train loss:0.23168514279390046\n",
      "train loss:0.14475828750773337\n",
      "train loss:0.10633865213452946\n",
      "train loss:0.07521320700986898\n",
      "train loss:0.08976375141276387\n",
      "train loss:0.06298612869765322\n",
      "train loss:0.051332992425831774\n",
      "train loss:0.09158886190104745\n",
      "train loss:0.07101327253174987\n",
      "train loss:0.09534950610078856\n",
      "train loss:0.09245956839568867\n",
      "train loss:0.04244195982856563\n",
      "train loss:0.048953138675458294\n",
      "train loss:0.09777257627345995\n",
      "train loss:0.05751481625745226\n",
      "train loss:0.02818474844785652\n",
      "train loss:0.06897379184906863\n",
      "train loss:0.12528113998470908\n",
      "train loss:0.20419622284002187\n",
      "train loss:0.0812627476762296\n",
      "train loss:0.07029410138837887\n",
      "train loss:0.08463510988305362\n",
      "train loss:0.12631491182838653\n",
      "train loss:0.11345310156928873\n",
      "train loss:0.10956622278393463\n",
      "train loss:0.09614656492960183\n",
      "train loss:0.04982535059877755\n",
      "train loss:0.15516682861359862\n",
      "train loss:0.08056503970534917\n",
      "train loss:0.10300674874174241\n",
      "train loss:0.09847317940462513\n",
      "train loss:0.1621966919754752\n",
      "train loss:0.12631741913372813\n",
      "train loss:0.06588064991251164\n",
      "train loss:0.05194824429634012\n",
      "train loss:0.13857415576311158\n",
      "train loss:0.08024233821605034\n",
      "train loss:0.18148653738717627\n",
      "train loss:0.06424351613862792\n",
      "train loss:0.07633204085645795\n",
      "train loss:0.06731217870482166\n",
      "train loss:0.1242581842531563\n",
      "train loss:0.08663407986579186\n",
      "train loss:0.05020529773244916\n",
      "train loss:0.12401426031972523\n",
      "train loss:0.10588952534704088\n",
      "train loss:0.07623720450315907\n",
      "train loss:0.08887276067321555\n",
      "train loss:0.07856063847216611\n",
      "train loss:0.0641171485187873\n",
      "train loss:0.07206656867335744\n",
      "train loss:0.08829021672555847\n",
      "train loss:0.10771928171178086\n",
      "train loss:0.07560572720360396\n",
      "train loss:0.09665827823256767\n",
      "train loss:0.0635790396685686\n",
      "train loss:0.08679678145443186\n",
      "train loss:0.10035675253039221\n",
      "train loss:0.04294887600345394\n",
      "train loss:0.13568493744342208\n",
      "train loss:0.15747183071524304\n",
      "train loss:0.1033112091804326\n",
      "train loss:0.09987170547106902\n",
      "train loss:0.0866707597733744\n",
      "train loss:0.07332301521274444\n",
      "train loss:0.03854915337330409\n",
      "train loss:0.0877419157810548\n",
      "train loss:0.08482277554411002\n",
      "train loss:0.08337757459208354\n",
      "train loss:0.13829153093476765\n",
      "train loss:0.08543912833747096\n",
      "train loss:0.08322055655854674\n",
      "train loss:0.0792778558227537\n",
      "train loss:0.1082511452297994\n",
      "train loss:0.0995991287258183\n",
      "train loss:0.10785693978841543\n",
      "train loss:0.074267091640057\n",
      "train loss:0.09367374552732631\n",
      "train loss:0.11834862341460979\n",
      "train loss:0.10966710571898655\n",
      "train loss:0.05960735546092785\n",
      "train loss:0.06055734628979639\n",
      "train loss:0.09539619959553976\n",
      "train loss:0.08762864214842798\n",
      "train loss:0.0498923426283061\n",
      "train loss:0.08042172970810865\n",
      "train loss:0.07483080545904519\n",
      "train loss:0.14987151790885775\n",
      "train loss:0.144248864542283\n",
      "train loss:0.16306246414068898\n",
      "train loss:0.14701578498604617\n",
      "train loss:0.09120193061023912\n",
      "train loss:0.08126909739236393\n",
      "train loss:0.11975173952983514\n",
      "train loss:0.0988991776991355\n",
      "train loss:0.10254577282026524\n",
      "train loss:0.10709357176561957\n",
      "train loss:0.10053652663281577\n",
      "train loss:0.0844692505314029\n",
      "train loss:0.044322943595254995\n",
      "train loss:0.06800316923709426\n",
      "train loss:0.12399228028982552\n",
      "train loss:0.12881861295808938\n",
      "train loss:0.06759124296085338\n",
      "train loss:0.1234346737881507\n",
      "train loss:0.13703971809682963\n",
      "train loss:0.10150349799787542\n",
      "train loss:0.08370059735675016\n",
      "train loss:0.09447849842019032\n",
      "train loss:0.11526475500540498\n",
      "train loss:0.0418856305474377\n",
      "train loss:0.05584684882981384\n",
      "train loss:0.07731821095282339\n",
      "train loss:0.08515242496013849\n",
      "train loss:0.11587991784030527\n",
      "train loss:0.06447887288626783\n",
      "train loss:0.09658545627453133\n",
      "train loss:0.07665541045275868\n",
      "train loss:0.062227502352486364\n",
      "train loss:0.0759498909985641\n",
      "train loss:0.09071660278251265\n",
      "train loss:0.12956650187839652\n",
      "train loss:0.06933308658722608\n",
      "train loss:0.05384045201069279\n",
      "train loss:0.10171479418249631\n",
      "train loss:0.11403941840852908\n",
      "train loss:0.12689768488738395\n",
      "train loss:0.112046112620202\n",
      "train loss:0.0475928044892814\n",
      "train loss:0.0884891608564657\n",
      "train loss:0.13957217244590636\n",
      "train loss:0.0628962555561745\n",
      "train loss:0.12113240675511312\n",
      "train loss:0.12646389796511937\n",
      "train loss:0.06283638660143435\n",
      "train loss:0.11853759252472881\n",
      "train loss:0.0874189985876113\n",
      "train loss:0.07131283646615688\n",
      "train loss:0.16226215644472297\n",
      "train loss:0.12550282407488383\n",
      "train loss:0.12397163510166348\n",
      "train loss:0.12987244074937515\n",
      "train loss:0.1078104207701126\n",
      "train loss:0.09330499217865723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.09205162850745102\n",
      "train loss:0.10585297305162479\n",
      "train loss:0.08944690458032004\n",
      "train loss:0.08457247152361884\n",
      "train loss:0.06613462938925592\n",
      "train loss:0.08410883795776206\n",
      "train loss:0.034460113019810466\n",
      "train loss:0.07778400289011837\n",
      "train loss:0.08665781641880449\n",
      "train loss:0.17032406296326877\n",
      "train loss:0.06794262509684217\n",
      "train loss:0.03204959517643513\n",
      "train loss:0.04790328597817041\n",
      "train loss:0.12666883813777108\n",
      "train loss:0.07171842521998822\n",
      "train loss:0.07430382661617935\n",
      "train loss:0.13425268652694325\n",
      "train loss:0.07045534901498433\n",
      "train loss:0.07583789914141109\n",
      "train loss:0.09707163351861389\n",
      "train loss:0.12380527431840953\n",
      "train loss:0.02830393612272375\n",
      "train loss:0.06103482592523424\n",
      "train loss:0.06167152337292743\n",
      "train loss:0.034811805094383814\n",
      "train loss:0.1082910194235524\n",
      "train loss:0.054348549236566665\n",
      "train loss:0.09682177071770132\n",
      "train loss:0.12612293239411593\n",
      "train loss:0.06473081395024251\n",
      "train loss:0.10512791456273289\n",
      "train loss:0.06711514731228677\n",
      "train loss:0.17636384727424217\n",
      "train loss:0.0727692942054517\n",
      "train loss:0.054692278542929636\n",
      "train loss:0.06604004607944793\n",
      "train loss:0.10168159635366983\n",
      "train loss:0.09222815073691688\n",
      "train loss:0.13156956522422442\n",
      "train loss:0.08794708661718281\n",
      "train loss:0.10477583536252574\n",
      "train loss:0.07830970434300798\n",
      "train loss:0.041314847504714126\n",
      "train loss:0.08983633277532459\n",
      "train loss:0.059660744094659615\n",
      "train loss:0.08170099938851014\n",
      "train loss:0.09146201834650838\n",
      "train loss:0.08120351378462899\n",
      "train loss:0.041881561986869736\n",
      "train loss:0.05194607871289809\n",
      "train loss:0.09278387370278116\n",
      "train loss:0.10888197001576755\n",
      "train loss:0.11834945808160581\n",
      "train loss:0.09868335352703425\n",
      "train loss:0.047535307127851825\n",
      "train loss:0.12888537249686668\n",
      "train loss:0.030583735110524642\n",
      "train loss:0.10077138116688628\n",
      "train loss:0.0872887310415689\n",
      "train loss:0.14443011465613004\n",
      "train loss:0.08837444582870574\n",
      "train loss:0.08765411506249265\n",
      "train loss:0.06688646561835393\n",
      "train loss:0.12517782893849017\n",
      "train loss:0.1431198821173867\n",
      "train loss:0.0588028456793112\n",
      "train loss:0.0586479475404442\n",
      "train loss:0.04342824675292897\n",
      "train loss:0.0842893370930905\n",
      "train loss:0.07727804755716397\n",
      "train loss:0.0683526434484701\n",
      "train loss:0.1143442968160083\n",
      "train loss:0.08406733538069318\n",
      "train loss:0.09203144362837615\n",
      "train loss:0.1451778989207028\n",
      "train loss:0.03559670458355735\n",
      "train loss:0.09024896275564451\n",
      "train loss:0.06675570194946658\n",
      "train loss:0.06712289191114343\n",
      "train loss:0.09932471345856005\n",
      "train loss:0.05295852049237313\n",
      "train loss:0.12119710103027909\n",
      "train loss:0.09682100485750601\n",
      "train loss:0.14230015037612742\n",
      "train loss:0.15270946033109378\n",
      "train loss:0.09557050919461814\n",
      "train loss:0.1297978656161809\n",
      "train loss:0.0845215741221711\n",
      "train loss:0.06147239726687891\n",
      "train loss:0.04979162668478671\n",
      "train loss:0.11433418275636224\n",
      "train loss:0.06385079187774427\n",
      "train loss:0.08936688989094481\n",
      "train loss:0.13488571745774935\n",
      "train loss:0.1571632056450247\n",
      "train loss:0.09450831253949192\n",
      "train loss:0.07538232658387269\n",
      "train loss:0.08868611321785774\n",
      "train loss:0.04257984695460276\n",
      "train loss:0.13145186327722633\n",
      "train loss:0.045009029770708864\n",
      "train loss:0.06362606452509613\n",
      "train loss:0.10479598269872409\n",
      "train loss:0.1461111656881221\n",
      "train loss:0.04673708066333531\n",
      "train loss:0.2086660131532063\n",
      "train loss:0.06027507538516139\n",
      "train loss:0.07472019247016774\n",
      "train loss:0.12873932164364926\n",
      "train loss:0.11374040688157247\n",
      "train loss:0.0899104338384542\n",
      "train loss:0.08900252591780938\n",
      "train loss:0.04386564529994432\n",
      "train loss:0.08703866872740867\n",
      "train loss:0.11648880326058297\n",
      "train loss:0.12528787960189391\n",
      "train loss:0.03968520595144977\n",
      "train loss:0.1377700483853139\n",
      "train loss:0.07486758597577378\n",
      "train loss:0.17117907337898086\n",
      "train loss:0.11811991053970583\n",
      "train loss:0.08097480917458404\n",
      "train loss:0.05972837011694973\n",
      "train loss:0.09915038420711157\n",
      "train loss:0.08955020581470764\n",
      "train loss:0.11594004821862557\n",
      "train loss:0.02589535718734061\n",
      "train loss:0.07344486608708299\n",
      "train loss:0.07193930834653678\n",
      "train loss:0.09597797892371082\n",
      "train loss:0.12890132400979493\n",
      "train loss:0.060716226450485376\n",
      "train loss:0.10079627826061216\n",
      "train loss:0.10127666404045682\n",
      "train loss:0.0817572098780811\n",
      "train loss:0.13050592994420693\n",
      "train loss:0.08058747240005212\n",
      "train loss:0.10734379030127618\n",
      "train loss:0.06417112402590243\n",
      "train loss:0.09578240939652474\n",
      "train loss:0.09829073301028894\n",
      "train loss:0.0901981481591756\n",
      "train loss:0.07868233083788455\n",
      "train loss:0.0977574376578576\n",
      "train loss:0.19586024844609226\n",
      "train loss:0.22296690739810054\n",
      "train loss:0.13212414121331192\n",
      "train loss:0.21101421270595988\n",
      "train loss:0.0785570828189433\n",
      "train loss:0.09263379493499108\n",
      "train loss:0.11400934763356578\n",
      "train loss:0.0929646835605454\n",
      "train loss:0.06773050877744094\n",
      "train loss:0.05983757798853212\n",
      "train loss:0.08481762703379081\n",
      "train loss:0.09018054512580764\n",
      "train loss:0.0779503570004853\n",
      "train loss:0.060058694898734125\n",
      "train loss:0.08324809107382614\n",
      "train loss:0.09962407081682413\n",
      "train loss:0.05904416603885184\n",
      "train loss:0.11812704691101038\n",
      "train loss:0.0902470066260588\n",
      "train loss:0.13491609496822307\n",
      "train loss:0.05762778559304072\n",
      "train loss:0.0781211955230192\n",
      "train loss:0.09439380500688317\n",
      "train loss:0.24967812409549978\n",
      "train loss:0.1182175213003394\n",
      "train loss:0.034049580801700105\n",
      "train loss:0.07167390814682352\n",
      "train loss:0.04317920029569437\n",
      "train loss:0.04796453966283023\n",
      "train loss:0.10409276191575588\n",
      "train loss:0.24868600774842303\n",
      "train loss:0.06493549442466463\n",
      "train loss:0.05693362992253139\n",
      "train loss:0.06880678382770401\n",
      "train loss:0.07193134247914106\n",
      "train loss:0.04202695318320208\n",
      "train loss:0.05552182298296083\n",
      "train loss:0.04272582890148568\n",
      "train loss:0.06525363708422355\n",
      "train loss:0.16473669543992003\n",
      "train loss:0.04914361951925444\n",
      "train loss:0.08444175681099814\n",
      "train loss:0.0692909955858378\n",
      "train loss:0.11641759899218862\n",
      "train loss:0.07146766481319906\n",
      "train loss:0.06637050662647874\n",
      "train loss:0.12944864280137802\n",
      "train loss:0.16748602121293962\n",
      "train loss:0.07630860487771547\n",
      "train loss:0.09225893081528794\n",
      "train loss:0.09287566200567786\n",
      "train loss:0.06882993818204991\n",
      "train loss:0.04411951360804985\n",
      "train loss:0.07670971476182052\n",
      "train loss:0.055315181350744556\n",
      "train loss:0.06622079253539608\n",
      "train loss:0.13193502059687007\n",
      "train loss:0.10037312935558945\n",
      "train loss:0.04164661232054609\n",
      "train loss:0.04250278121759334\n",
      "train loss:0.1249908393490396\n",
      "train loss:0.08321279852985705\n",
      "train loss:0.0687680302160376\n",
      "train loss:0.07819003298623523\n",
      "train loss:0.052746232339804654\n",
      "train loss:0.0688482804053613\n",
      "train loss:0.12609072375260744\n",
      "train loss:0.06071363965549493\n",
      "train loss:0.0715827186071676\n",
      "train loss:0.06507833508777006\n",
      "train loss:0.07107340413562116\n",
      "train loss:0.08737508203058184\n",
      "train loss:0.09740223388057279\n",
      "train loss:0.10285506341132862\n",
      "train loss:0.07326289494900542\n",
      "train loss:0.05156205989802615\n",
      "train loss:0.055569751592609344\n",
      "train loss:0.1003957123700458\n",
      "train loss:0.11740513209521543\n",
      "train loss:0.08258168784067442\n",
      "train loss:0.1653567899645383\n",
      "train loss:0.0436708148962086\n",
      "train loss:0.1158858603863868\n",
      "train loss:0.05994331928930746\n",
      "train loss:0.08737840611003687\n",
      "train loss:0.05949358844914369\n",
      "train loss:0.056777971378964\n",
      "train loss:0.09814595936428618\n",
      "train loss:0.11373454499669158\n",
      "train loss:0.09501784209015429\n",
      "train loss:0.09500683828137885\n",
      "train loss:0.07209420848246811\n",
      "train loss:0.07360445665863499\n",
      "train loss:0.08093699904694562\n",
      "train loss:0.11743105068513535\n",
      "train loss:0.04776397783723643\n",
      "train loss:0.07885758186268427\n",
      "train loss:0.08792162418531721\n",
      "train loss:0.04935332318113939\n",
      "=== epoch:17, train acc:0.962, test acc:0.897 ===\n",
      "train loss:0.07087942180553505\n",
      "train loss:0.08933770796788637\n",
      "train loss:0.06993021360761448\n",
      "train loss:0.10774418121014322\n",
      "train loss:0.030571300118332766\n",
      "train loss:0.15842285712025161\n",
      "train loss:0.17799993151604235\n",
      "train loss:0.10741870688385564\n",
      "train loss:0.05998806493326174\n",
      "train loss:0.059306648534961814\n",
      "train loss:0.11257950566216943\n",
      "train loss:0.058829417952623364\n",
      "train loss:0.045487728861525766\n",
      "train loss:0.09999586792467013\n",
      "train loss:0.13309143456950526\n",
      "train loss:0.11942163633586578\n",
      "train loss:0.20526511136399658\n",
      "train loss:0.053710644729793734\n",
      "train loss:0.18014714446847216\n",
      "train loss:0.0735373890329694\n",
      "train loss:0.10454490021810786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0714121728190127\n",
      "train loss:0.14960720548896886\n",
      "train loss:0.0879129736987232\n",
      "train loss:0.10888022065295155\n",
      "train loss:0.08263084411579116\n",
      "train loss:0.12479043777778548\n",
      "train loss:0.04502453354790156\n",
      "train loss:0.11086621638053985\n",
      "train loss:0.11076787108463808\n",
      "train loss:0.05273221645950268\n",
      "train loss:0.06200096073156581\n",
      "train loss:0.14616023358329586\n",
      "train loss:0.12382093571441316\n",
      "train loss:0.1080672114114452\n",
      "train loss:0.14187477250984631\n",
      "train loss:0.10558451932208124\n",
      "train loss:0.029192219549623376\n",
      "train loss:0.05637194743635704\n",
      "train loss:0.07843201807469842\n",
      "train loss:0.08868533732928251\n",
      "train loss:0.07057843638162796\n",
      "train loss:0.06662854009073249\n",
      "train loss:0.09700340317233618\n",
      "train loss:0.0905432131557947\n",
      "train loss:0.050296676209199476\n",
      "train loss:0.06329710177087412\n",
      "train loss:0.05637163541744369\n",
      "train loss:0.11187530941895166\n",
      "train loss:0.0393663151304529\n",
      "train loss:0.07865208574237033\n",
      "train loss:0.10473378915777114\n",
      "train loss:0.0864843491758969\n",
      "train loss:0.11584899444978806\n",
      "train loss:0.04039580694318909\n",
      "train loss:0.03918933233069145\n",
      "train loss:0.03807855836138613\n",
      "train loss:0.16993044680134736\n",
      "train loss:0.0715793084374784\n",
      "train loss:0.1354834198808357\n",
      "train loss:0.047739382651217556\n",
      "train loss:0.039055963522845134\n",
      "train loss:0.07697008097470552\n",
      "train loss:0.06442569030155694\n",
      "train loss:0.06721509130038275\n",
      "train loss:0.11888019585540102\n",
      "train loss:0.10173203613592376\n",
      "train loss:0.15509464578736648\n",
      "train loss:0.12094202991834774\n",
      "train loss:0.07259888972821286\n",
      "train loss:0.11348145067803227\n",
      "train loss:0.04540772870133814\n",
      "train loss:0.1156644547524153\n",
      "train loss:0.08764584736917758\n",
      "train loss:0.07752143138642048\n",
      "train loss:0.10420672924408457\n",
      "train loss:0.0543591986040871\n",
      "train loss:0.12800722134112813\n",
      "train loss:0.1266659884980151\n",
      "train loss:0.07265579111545435\n",
      "train loss:0.08267240144756631\n",
      "train loss:0.16991562627534393\n",
      "train loss:0.14208100171049412\n",
      "train loss:0.12220083212839744\n",
      "train loss:0.10724918281552538\n",
      "train loss:0.046121267092493215\n",
      "train loss:0.06409529010509965\n",
      "train loss:0.11152137058279711\n",
      "train loss:0.049604339987950025\n",
      "train loss:0.08175417169010248\n",
      "train loss:0.09152871863887702\n",
      "train loss:0.07477312744981099\n",
      "train loss:0.06595185127879619\n",
      "train loss:0.07230395537734359\n",
      "train loss:0.08529321977022983\n",
      "train loss:0.05664697630361213\n",
      "train loss:0.05787797734478563\n",
      "train loss:0.13647676266446937\n",
      "train loss:0.06305827045315976\n",
      "train loss:0.11131756730148172\n",
      "train loss:0.1217873830556479\n",
      "train loss:0.06805394846819636\n",
      "train loss:0.07770240350106668\n",
      "train loss:0.07340787877197912\n",
      "train loss:0.1358182378490032\n",
      "train loss:0.12170432760762072\n",
      "train loss:0.07647948176821392\n",
      "train loss:0.063683756588601\n",
      "train loss:0.10495898865001681\n",
      "train loss:0.04034774182204013\n",
      "train loss:0.05781397525646954\n",
      "train loss:0.13497255358262372\n",
      "train loss:0.1060165093553964\n",
      "train loss:0.06290711769140624\n",
      "train loss:0.08185743101271978\n",
      "train loss:0.11978710628728222\n",
      "train loss:0.08568561879418578\n",
      "train loss:0.05600936883114065\n",
      "train loss:0.058935218923509794\n",
      "train loss:0.07460086173924381\n",
      "train loss:0.04551661033573188\n",
      "train loss:0.08781065626775829\n",
      "train loss:0.06690333807505718\n",
      "train loss:0.08378551962225014\n",
      "train loss:0.08153125700237661\n",
      "train loss:0.052029992894371324\n",
      "train loss:0.06830864057812668\n",
      "train loss:0.07350297450428968\n",
      "train loss:0.17942280234479166\n",
      "train loss:0.0982549476406466\n",
      "train loss:0.07494981670591444\n",
      "train loss:0.04885988280950847\n",
      "train loss:0.07493382068437893\n",
      "train loss:0.1271309566070682\n",
      "train loss:0.05108173901116187\n",
      "train loss:0.05532500742422922\n",
      "train loss:0.07235373949882405\n",
      "train loss:0.06459227556051536\n",
      "train loss:0.06866790711679444\n",
      "train loss:0.05729546180936557\n",
      "train loss:0.036148376934456994\n",
      "train loss:0.09943956455936304\n",
      "train loss:0.09149500168746004\n",
      "train loss:0.050348118296398486\n",
      "train loss:0.03641919792103298\n",
      "train loss:0.11469512390099837\n",
      "train loss:0.0793480443645019\n",
      "train loss:0.04733263696449318\n",
      "train loss:0.04786914127545419\n",
      "train loss:0.118904341055861\n",
      "train loss:0.09161036496420621\n",
      "train loss:0.15677697150027817\n",
      "train loss:0.05943623401008446\n",
      "train loss:0.13828957807870773\n",
      "train loss:0.0737191703959559\n",
      "train loss:0.0356629320929679\n",
      "train loss:0.03709775901943771\n",
      "train loss:0.07295015593483165\n",
      "train loss:0.047005619394349794\n",
      "train loss:0.06338247027817458\n",
      "train loss:0.18532177411590514\n",
      "train loss:0.0898947358450404\n",
      "train loss:0.09795682194705348\n",
      "train loss:0.0617751392408334\n",
      "train loss:0.1415430600075721\n",
      "train loss:0.0867164178204797\n",
      "train loss:0.058138430195442556\n",
      "train loss:0.08017972986797775\n",
      "train loss:0.07308713046286913\n",
      "train loss:0.017285482204469137\n",
      "train loss:0.10153523802750035\n",
      "train loss:0.0831425833583353\n",
      "train loss:0.11894755824297121\n",
      "train loss:0.12173142240478879\n",
      "train loss:0.11757368277924485\n",
      "train loss:0.10481689696786484\n",
      "train loss:0.0929499339267401\n",
      "train loss:0.05582482946760004\n",
      "train loss:0.0817966143314347\n",
      "train loss:0.12748865002015436\n",
      "train loss:0.11440954972798945\n",
      "train loss:0.1001306857362849\n",
      "train loss:0.07184682794137343\n",
      "train loss:0.07490124815249709\n",
      "train loss:0.05686777020059643\n",
      "train loss:0.08839280931616074\n",
      "train loss:0.057932260274989426\n",
      "train loss:0.06908633832101811\n",
      "train loss:0.03484087926402845\n",
      "train loss:0.10086888650562742\n",
      "train loss:0.06635270116160148\n",
      "train loss:0.0849173624743877\n",
      "train loss:0.12824786451189504\n",
      "train loss:0.07167741202448952\n",
      "train loss:0.08610774435645543\n",
      "train loss:0.08644934629964428\n",
      "train loss:0.15853306007839466\n",
      "train loss:0.10213540492533754\n",
      "train loss:0.10964942751040989\n",
      "train loss:0.07298256169797501\n",
      "train loss:0.08393531987931277\n",
      "train loss:0.030241815603561064\n",
      "train loss:0.09500056987033584\n",
      "train loss:0.1427390651194438\n",
      "train loss:0.16299545705418056\n",
      "train loss:0.06538115990329561\n",
      "train loss:0.12631037775526796\n",
      "train loss:0.10806045657774106\n",
      "train loss:0.08635023921265829\n",
      "train loss:0.08095496352987325\n",
      "train loss:0.07965800180839612\n",
      "train loss:0.04494869194842396\n",
      "train loss:0.06959332374262002\n",
      "train loss:0.07854523631594992\n",
      "train loss:0.07806930650048363\n",
      "train loss:0.08648413021839241\n",
      "train loss:0.18164385273463546\n",
      "train loss:0.1154921939611743\n",
      "train loss:0.09969029343162517\n",
      "train loss:0.07391897822399113\n",
      "train loss:0.059884947206619736\n",
      "train loss:0.0585218856742951\n",
      "train loss:0.06360961948582307\n",
      "train loss:0.11223185301034508\n",
      "train loss:0.06144299100421077\n",
      "train loss:0.06519754188449876\n",
      "train loss:0.03946733632573883\n",
      "train loss:0.06709342251716546\n",
      "train loss:0.08837761528961278\n",
      "train loss:0.11013536943492891\n",
      "train loss:0.04937148388391287\n",
      "train loss:0.08658021238252608\n",
      "train loss:0.060443101135780795\n",
      "train loss:0.052221794058712814\n",
      "train loss:0.05551776752269132\n",
      "train loss:0.12330098637531868\n",
      "train loss:0.09711848279972615\n",
      "train loss:0.04837075306977783\n",
      "train loss:0.06714676800885934\n",
      "train loss:0.11082620605397306\n",
      "train loss:0.06397012115381652\n",
      "train loss:0.06305249448149661\n",
      "train loss:0.12755604907663906\n",
      "train loss:0.07257088755526057\n",
      "train loss:0.05116459198866862\n",
      "train loss:0.09117405858386368\n",
      "train loss:0.04325603686708106\n",
      "train loss:0.11380395170808617\n",
      "train loss:0.08009853815633651\n",
      "train loss:0.10257094548426098\n",
      "train loss:0.1238593636140489\n",
      "train loss:0.10858311360210171\n",
      "train loss:0.09100079074689185\n",
      "train loss:0.10527049791147558\n",
      "train loss:0.1109519997584044\n",
      "train loss:0.08104410897069854\n",
      "train loss:0.06326223952015536\n",
      "train loss:0.1162865295294061\n",
      "train loss:0.06808142149485774\n",
      "train loss:0.06037722446382731\n",
      "train loss:0.11212421231441848\n",
      "train loss:0.07621204161287268\n",
      "train loss:0.10479623086776688\n",
      "train loss:0.0861863383128323\n",
      "train loss:0.08601177197180707\n",
      "train loss:0.027637286725981824\n",
      "train loss:0.046931674728365715\n",
      "train loss:0.10578265301973099\n",
      "train loss:0.0484828040945286\n",
      "train loss:0.07112295330981362\n",
      "train loss:0.09127949703460436\n",
      "train loss:0.06793022834776946\n",
      "train loss:0.05639977446116717\n",
      "train loss:0.10167384340410665\n",
      "train loss:0.10286851820515155\n",
      "train loss:0.10496552025811633\n",
      "train loss:0.09086500598609275\n",
      "train loss:0.09548599914576997\n",
      "train loss:0.09281629969186862\n",
      "train loss:0.09313357737889871\n",
      "train loss:0.07968927274479407\n",
      "train loss:0.13850602130055442\n",
      "train loss:0.04405720757039831\n",
      "train loss:0.04064971785976519\n",
      "train loss:0.15740089774186833\n",
      "train loss:0.14994853251130397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.06813400913481231\n",
      "train loss:0.08909957152256333\n",
      "train loss:0.11604947161392762\n",
      "train loss:0.06214977819966176\n",
      "train loss:0.08095089890571266\n",
      "train loss:0.03841982383473768\n",
      "train loss:0.10061122027171457\n",
      "train loss:0.06817069811559565\n",
      "train loss:0.12222725735073377\n",
      "train loss:0.18421860545090812\n",
      "train loss:0.12239556153837365\n",
      "train loss:0.040354813602290734\n",
      "train loss:0.13601133165138282\n",
      "train loss:0.08537160823320165\n",
      "train loss:0.07220336552683258\n",
      "train loss:0.10753301645049954\n",
      "train loss:0.07130471326575705\n",
      "train loss:0.12688090109557804\n",
      "train loss:0.09590550109375001\n",
      "train loss:0.09013722845843503\n",
      "train loss:0.08111225952026238\n",
      "train loss:0.09838449614970393\n",
      "train loss:0.08170363974403495\n",
      "train loss:0.0765059705033074\n",
      "train loss:0.03288790348679166\n",
      "train loss:0.1224664913182303\n",
      "train loss:0.05239036873780969\n",
      "train loss:0.060352071270545295\n",
      "train loss:0.07307632469155162\n",
      "train loss:0.07982203432741891\n",
      "train loss:0.07743770395446749\n",
      "train loss:0.08086188679382329\n",
      "train loss:0.06487711419638036\n",
      "train loss:0.14309012507836683\n",
      "train loss:0.048458113034442515\n",
      "train loss:0.030381992983165886\n",
      "train loss:0.056030347345615725\n",
      "train loss:0.12070598386502855\n",
      "train loss:0.14101102806835286\n",
      "train loss:0.15163863975961425\n",
      "train loss:0.035360223621352986\n",
      "train loss:0.08609105367200008\n",
      "train loss:0.10253475725799037\n",
      "train loss:0.18963988446136873\n",
      "train loss:0.07043194886187662\n",
      "train loss:0.07383210094008116\n",
      "train loss:0.056868098378393815\n",
      "train loss:0.0779388136871833\n",
      "train loss:0.04337981478972008\n",
      "train loss:0.07063112713232261\n",
      "train loss:0.05538131945370228\n",
      "train loss:0.1257469976435042\n",
      "train loss:0.0483859164891773\n",
      "train loss:0.07934420509929734\n",
      "train loss:0.11452419245554463\n",
      "train loss:0.07555544917161094\n",
      "train loss:0.06406042350579728\n",
      "train loss:0.14472778607394826\n",
      "train loss:0.08477563463471956\n",
      "train loss:0.06459123406520288\n",
      "train loss:0.09712314688590508\n",
      "train loss:0.0489323186768255\n",
      "train loss:0.19751478677249032\n",
      "train loss:0.06733279226222941\n",
      "train loss:0.03658051282598985\n",
      "train loss:0.052435609114199026\n",
      "train loss:0.05860020734569735\n",
      "train loss:0.05131889032990589\n",
      "train loss:0.03434715263414831\n",
      "train loss:0.1080742954572379\n",
      "train loss:0.07239892330496593\n",
      "train loss:0.06215575384167584\n",
      "train loss:0.059610099051970254\n",
      "train loss:0.12525121948736348\n",
      "train loss:0.1663411944893441\n",
      "train loss:0.0638577228059778\n",
      "train loss:0.05325041654570109\n",
      "train loss:0.09327337146694498\n",
      "train loss:0.06346589004007339\n",
      "train loss:0.07697224659515457\n",
      "train loss:0.09006437682582832\n",
      "train loss:0.08809672487800922\n",
      "train loss:0.09602858045859194\n",
      "train loss:0.0988722773304045\n",
      "train loss:0.08426270295926575\n",
      "train loss:0.045445211871110995\n",
      "train loss:0.044937727133412535\n",
      "train loss:0.052211073574536686\n",
      "train loss:0.11018326495489215\n",
      "train loss:0.13889752290665375\n",
      "train loss:0.07265004010301522\n",
      "train loss:0.10852500957477092\n",
      "train loss:0.10524900482697548\n",
      "train loss:0.06646028696048153\n",
      "train loss:0.09379319446713347\n",
      "train loss:0.059572728116764416\n",
      "train loss:0.10463609039258706\n",
      "train loss:0.13955166605937194\n",
      "train loss:0.08986390142740865\n",
      "train loss:0.11299316676939097\n",
      "train loss:0.11194034064944679\n",
      "train loss:0.11111884368670966\n",
      "train loss:0.04309350211842859\n",
      "train loss:0.051085748867366707\n",
      "train loss:0.0592877609260306\n",
      "train loss:0.06361001575317726\n",
      "train loss:0.062496866091403876\n",
      "train loss:0.04495310711328582\n",
      "train loss:0.05344972637843035\n",
      "train loss:0.08155703736866313\n",
      "train loss:0.08618953215052734\n",
      "train loss:0.08331910588305652\n",
      "train loss:0.10149503802983333\n",
      "train loss:0.06894902478614942\n",
      "train loss:0.13797030609827596\n",
      "train loss:0.1251478300377119\n",
      "train loss:0.056759255241741906\n",
      "train loss:0.07544080831618659\n",
      "train loss:0.059353598095916026\n",
      "train loss:0.06869580300607005\n",
      "train loss:0.11496399320330448\n",
      "train loss:0.05724163158769901\n",
      "train loss:0.07402520837027031\n",
      "train loss:0.08443485579390739\n",
      "train loss:0.11916679050300123\n",
      "train loss:0.06430659910022811\n",
      "train loss:0.06353669117827797\n",
      "train loss:0.09915406548491319\n",
      "train loss:0.061511486079148706\n",
      "train loss:0.07749845378488256\n",
      "train loss:0.05279954527021604\n",
      "train loss:0.11650977605076283\n",
      "train loss:0.19616818750250034\n",
      "train loss:0.06985895731256807\n",
      "train loss:0.1345908936321159\n",
      "train loss:0.0359910043317784\n",
      "train loss:0.0944488150229918\n",
      "train loss:0.07678590008625326\n",
      "train loss:0.06709131569238248\n",
      "train loss:0.08457592043476307\n",
      "train loss:0.02774183092550153\n",
      "train loss:0.12128134194632724\n",
      "train loss:0.13119270432576638\n",
      "train loss:0.05563385020873242\n",
      "train loss:0.17507136620129185\n",
      "train loss:0.13990401818720785\n",
      "train loss:0.13790001081739517\n",
      "train loss:0.14603409570350315\n",
      "train loss:0.03275711478559244\n",
      "train loss:0.0701246596588974\n",
      "train loss:0.07756136798500789\n",
      "train loss:0.152579973753378\n",
      "train loss:0.06462177394268087\n",
      "train loss:0.06880903904128098\n",
      "train loss:0.03725602477924537\n",
      "train loss:0.09173703101854183\n",
      "train loss:0.06013295111818126\n",
      "train loss:0.11827845246288664\n",
      "train loss:0.26841519979576434\n",
      "train loss:0.07967350704294876\n",
      "train loss:0.09464182573017071\n",
      "train loss:0.06260102172786466\n",
      "train loss:0.07777536757123797\n",
      "train loss:0.059191515459499924\n",
      "train loss:0.07244999699793742\n",
      "train loss:0.0766160310355599\n",
      "train loss:0.10098767692819828\n",
      "train loss:0.098090920868389\n",
      "train loss:0.2071461991875108\n",
      "train loss:0.08501180894478581\n",
      "train loss:0.10797322460048786\n",
      "train loss:0.10385608846823302\n",
      "train loss:0.05622457619584081\n",
      "train loss:0.06949567947980782\n",
      "train loss:0.06789279660708783\n",
      "train loss:0.22347356514229857\n",
      "train loss:0.06620997288071641\n",
      "train loss:0.05340078187396772\n",
      "train loss:0.14947685287190676\n",
      "train loss:0.09454670148563965\n",
      "train loss:0.14623301877361217\n",
      "train loss:0.11147778837182534\n",
      "train loss:0.09789764232572012\n",
      "train loss:0.053402245021271035\n",
      "train loss:0.08016772292338704\n",
      "train loss:0.1219434225028053\n",
      "train loss:0.07346488616492479\n",
      "train loss:0.07108027801727919\n",
      "train loss:0.12089538498643422\n",
      "train loss:0.07362874148125435\n",
      "train loss:0.05983725340358974\n",
      "train loss:0.03214460844963408\n",
      "train loss:0.0698637143204495\n",
      "train loss:0.13229463746637\n",
      "train loss:0.0911671547574154\n",
      "train loss:0.06384668657183808\n",
      "train loss:0.08637606508258182\n",
      "train loss:0.05309893534889655\n",
      "train loss:0.1572684706609291\n",
      "train loss:0.13160108973268017\n",
      "train loss:0.05559248275023926\n",
      "train loss:0.06767334269198677\n",
      "train loss:0.1251313522707231\n",
      "train loss:0.07498521305148192\n",
      "train loss:0.0562467423478334\n",
      "train loss:0.027628964200724186\n",
      "train loss:0.0615617108979385\n",
      "train loss:0.07682344343105692\n",
      "train loss:0.06607201194915342\n",
      "train loss:0.09801432258684956\n",
      "train loss:0.10682973394322971\n",
      "train loss:0.07425804778806108\n",
      "train loss:0.154865875268461\n",
      "train loss:0.04417759363471451\n",
      "train loss:0.019683923791448038\n",
      "train loss:0.08783515813909215\n",
      "train loss:0.1781909424711152\n",
      "train loss:0.10138410649857085\n",
      "train loss:0.08322108560966075\n",
      "train loss:0.06745418988066508\n",
      "train loss:0.07841013415748692\n",
      "train loss:0.04385785556579398\n",
      "train loss:0.10226156917377739\n",
      "train loss:0.12155720700801137\n",
      "train loss:0.12993538159544768\n",
      "train loss:0.06447000150904675\n",
      "train loss:0.08544023941425591\n",
      "train loss:0.050934057214321656\n",
      "train loss:0.04830754494023834\n",
      "train loss:0.12437586007353708\n",
      "train loss:0.16370457828420168\n",
      "train loss:0.08959953824554882\n",
      "train loss:0.08149712454212267\n",
      "train loss:0.08459403348780238\n",
      "train loss:0.038695645596409416\n",
      "train loss:0.03827821027373564\n",
      "train loss:0.09114159582815619\n",
      "train loss:0.10858629168046482\n",
      "train loss:0.0912007949962763\n",
      "train loss:0.15484063130494208\n",
      "train loss:0.0920097750170401\n",
      "train loss:0.11949293871445564\n",
      "train loss:0.12601451273424388\n",
      "train loss:0.088732241620155\n",
      "train loss:0.06238183872276844\n",
      "train loss:0.07773367210302858\n",
      "train loss:0.06426510111242967\n",
      "train loss:0.06755059784723313\n",
      "train loss:0.1464080194950033\n",
      "train loss:0.09707325579018637\n",
      "train loss:0.05993355046907987\n",
      "train loss:0.11883379900238618\n",
      "train loss:0.16468812045839024\n",
      "train loss:0.08961947694973078\n",
      "train loss:0.020652777158038243\n",
      "train loss:0.09912099805536437\n",
      "train loss:0.062021977154522956\n",
      "train loss:0.08737363498146465\n",
      "train loss:0.085128860338413\n",
      "train loss:0.04949260900336812\n",
      "train loss:0.08915425392236517\n",
      "train loss:0.07090452749825532\n",
      "train loss:0.06673409738250295\n",
      "train loss:0.0718597913228907\n",
      "train loss:0.11434345022050009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.02884657982866297\n",
      "train loss:0.09729881710767574\n",
      "train loss:0.1135250338844755\n",
      "train loss:0.05775067511639222\n",
      "train loss:0.07768458930137091\n",
      "train loss:0.07468300069544802\n",
      "train loss:0.05081973347791203\n",
      "train loss:0.09931809543842039\n",
      "train loss:0.03476619911696723\n",
      "train loss:0.09414817532111529\n",
      "train loss:0.09147530508143367\n",
      "train loss:0.07747090524346265\n",
      "train loss:0.045924234730877506\n",
      "train loss:0.07819784567094323\n",
      "train loss:0.05199785605417949\n",
      "train loss:0.09129024210521548\n",
      "train loss:0.06092964752383603\n",
      "train loss:0.14915055741748412\n",
      "train loss:0.09345877244956753\n",
      "train loss:0.08750342545343534\n",
      "train loss:0.048999143839233025\n",
      "train loss:0.06702514166429259\n",
      "train loss:0.09875096327158986\n",
      "train loss:0.05856091960208701\n",
      "train loss:0.04040975492342524\n",
      "train loss:0.062038937560114346\n",
      "train loss:0.047668947918228934\n",
      "train loss:0.09380647026172947\n",
      "train loss:0.08959558961646037\n",
      "train loss:0.07498819161097839\n",
      "train loss:0.1360076338868258\n",
      "train loss:0.08984306184257056\n",
      "train loss:0.1439523475958265\n",
      "train loss:0.08039241853722495\n",
      "train loss:0.0704077239566127\n",
      "train loss:0.09723833959184867\n",
      "train loss:0.05181192706626244\n",
      "train loss:0.04099813267023519\n",
      "train loss:0.07072712447176562\n",
      "train loss:0.059826005755319225\n",
      "train loss:0.077875418392054\n",
      "train loss:0.14773052059899966\n",
      "train loss:0.057797755572183626\n",
      "train loss:0.07052934595362831\n",
      "train loss:0.08355631007612242\n",
      "train loss:0.17523113578397584\n",
      "train loss:0.0603689690817263\n",
      "train loss:0.1180455235292963\n",
      "train loss:0.09246499856425965\n",
      "=== epoch:18, train acc:0.972, test acc:0.906 ===\n",
      "train loss:0.04671469073530249\n",
      "train loss:0.08797136355844466\n",
      "train loss:0.06459245520563335\n",
      "train loss:0.06731732803946061\n",
      "train loss:0.086541927396262\n",
      "train loss:0.06463833818361235\n",
      "train loss:0.08877698953309561\n",
      "train loss:0.08956566631386222\n",
      "train loss:0.11102216010736149\n",
      "train loss:0.027158913565396105\n",
      "train loss:0.11963972811912825\n",
      "train loss:0.051399870978712396\n",
      "train loss:0.0642559566821838\n",
      "train loss:0.09885732348256882\n",
      "train loss:0.10496127163111924\n",
      "train loss:0.03780914122376873\n",
      "train loss:0.07523192139312673\n",
      "train loss:0.11783159055959797\n",
      "train loss:0.06065216884239251\n",
      "train loss:0.07910669041538981\n",
      "train loss:0.06723183966892232\n",
      "train loss:0.05559965417646496\n",
      "train loss:0.06208830578166741\n",
      "train loss:0.05370013426313456\n",
      "train loss:0.07227880379732424\n",
      "train loss:0.03546755354193781\n",
      "train loss:0.10327626550688761\n",
      "train loss:0.05659971498003375\n",
      "train loss:0.08387736835074827\n",
      "train loss:0.046272181723136636\n",
      "train loss:0.12232245553605288\n",
      "train loss:0.1289336645126762\n",
      "train loss:0.09389528362557359\n",
      "train loss:0.0545952987829797\n",
      "train loss:0.06053458361120004\n",
      "train loss:0.032437599761871584\n",
      "train loss:0.11131171143287098\n",
      "train loss:0.05462035365792013\n",
      "train loss:0.07381188439738881\n",
      "train loss:0.07678607971183825\n",
      "train loss:0.05648084582930577\n",
      "train loss:0.0485123090983206\n",
      "train loss:0.054891885277641085\n",
      "train loss:0.07664144222912746\n",
      "train loss:0.124098926263586\n",
      "train loss:0.031953359690624676\n",
      "train loss:0.11298192733174028\n",
      "train loss:0.033152496651302245\n",
      "train loss:0.048531500551054846\n",
      "train loss:0.112948602144021\n",
      "train loss:0.08133214963358357\n",
      "train loss:0.06744401398468049\n",
      "train loss:0.0895711715640337\n",
      "train loss:0.07660932750581158\n",
      "train loss:0.12068191405730624\n",
      "train loss:0.07971185246296365\n",
      "train loss:0.02330677527456791\n",
      "train loss:0.05522820990159058\n",
      "train loss:0.0614682469366148\n",
      "train loss:0.14293072089142808\n",
      "train loss:0.08817039876490539\n",
      "train loss:0.07697070297202303\n",
      "train loss:0.15665964690003564\n",
      "train loss:0.14717648037622927\n",
      "train loss:0.08747539413716765\n",
      "train loss:0.06944146008082719\n",
      "train loss:0.09128419453456964\n",
      "train loss:0.0911028364129211\n",
      "train loss:0.10876387889347548\n",
      "train loss:0.08204717098944636\n",
      "train loss:0.0397943641122974\n",
      "train loss:0.08268423833444133\n",
      "train loss:0.04544695831494458\n",
      "train loss:0.06086393758235441\n",
      "train loss:0.055211858709189494\n",
      "train loss:0.06390654472110795\n",
      "train loss:0.12289048782705367\n",
      "train loss:0.06554362241419749\n",
      "train loss:0.08851338237419998\n",
      "train loss:0.10190342141183156\n",
      "train loss:0.07755503508778575\n",
      "train loss:0.11499388030421791\n",
      "train loss:0.07274212346893578\n",
      "train loss:0.057610129532296786\n",
      "train loss:0.10668724041449919\n",
      "train loss:0.13436735244339254\n",
      "train loss:0.08445386760049338\n",
      "train loss:0.08094629514896917\n",
      "train loss:0.057826274326920564\n",
      "train loss:0.1130581978107439\n",
      "train loss:0.07268377689045062\n",
      "train loss:0.0738795281682882\n",
      "train loss:0.08975874106473317\n",
      "train loss:0.11420334364069293\n",
      "train loss:0.15306871205589745\n",
      "train loss:0.19003922283221147\n",
      "train loss:0.0386751189173753\n",
      "train loss:0.08362135258379463\n",
      "train loss:0.06444303200997936\n",
      "train loss:0.0590555477335382\n",
      "train loss:0.0787831459064769\n",
      "train loss:0.039577589436582426\n",
      "train loss:0.06051936246207786\n",
      "train loss:0.01716120583552935\n",
      "train loss:0.05251904511144335\n",
      "train loss:0.02167084743060272\n",
      "train loss:0.12742694252856965\n",
      "train loss:0.03706719718271427\n",
      "train loss:0.05479474455747062\n",
      "train loss:0.06357227699478572\n",
      "train loss:0.080877921069432\n",
      "train loss:0.03530095569207732\n",
      "train loss:0.04834892726640784\n",
      "train loss:0.09813016077917278\n",
      "train loss:0.047442028174024264\n",
      "train loss:0.02690599983223724\n",
      "train loss:0.03971045948249492\n",
      "train loss:0.06144814050222121\n",
      "train loss:0.10238726928642616\n",
      "train loss:0.12406460670248942\n",
      "train loss:0.06366238640665407\n",
      "train loss:0.03198064193954091\n",
      "train loss:0.063660622402227\n",
      "train loss:0.18574184556701767\n",
      "train loss:0.06395071566555345\n",
      "train loss:0.07484310048274324\n",
      "train loss:0.02584180885221969\n",
      "train loss:0.047596552402833836\n",
      "train loss:0.054750373090424416\n",
      "train loss:0.052778699719714425\n",
      "train loss:0.08234361777844537\n",
      "train loss:0.0246289649597577\n",
      "train loss:0.04116942645374941\n",
      "train loss:0.10307816378412495\n",
      "train loss:0.09310319758982305\n",
      "train loss:0.046715397206403886\n",
      "train loss:0.03652176422999507\n",
      "train loss:0.0866624882331904\n",
      "train loss:0.10169281788845694\n",
      "train loss:0.09310269241555609\n",
      "train loss:0.09795868097107416\n",
      "train loss:0.08851167552558603\n",
      "train loss:0.059474786033002915\n",
      "train loss:0.08881257164790421\n",
      "train loss:0.11454527104393927\n",
      "train loss:0.06341067901051813\n",
      "train loss:0.05937625465732554\n",
      "train loss:0.07788840863309968\n",
      "train loss:0.0580587514708381\n",
      "train loss:0.07431591265686079\n",
      "train loss:0.048722274594403044\n",
      "train loss:0.07175063868050455\n",
      "train loss:0.15742665123828092\n",
      "train loss:0.05480050818551967\n",
      "train loss:0.10666946877478115\n",
      "train loss:0.15307563144932504\n",
      "train loss:0.0573765822079903\n",
      "train loss:0.036603895573333885\n",
      "train loss:0.07234167170946632\n",
      "train loss:0.13669316804145806\n",
      "train loss:0.09463330397403459\n",
      "train loss:0.069870572637348\n",
      "train loss:0.09795069057045676\n",
      "train loss:0.10594545647480494\n",
      "train loss:0.07024801966780153\n",
      "train loss:0.06076547838192912\n",
      "train loss:0.11454265912284901\n",
      "train loss:0.07990514755669886\n",
      "train loss:0.0860611983969274\n",
      "train loss:0.09750649506426762\n",
      "train loss:0.05719126200992355\n",
      "train loss:0.06719469502507684\n",
      "train loss:0.15277858838714356\n",
      "train loss:0.03326297779379739\n",
      "train loss:0.03557775878370975\n",
      "train loss:0.04311655844729376\n",
      "train loss:0.10479554588256132\n",
      "train loss:0.05558613662399406\n",
      "train loss:0.15025047987659443\n",
      "train loss:0.15470469556892982\n",
      "train loss:0.09786741465838453\n",
      "train loss:0.07943706894150136\n",
      "train loss:0.061753222084060935\n",
      "train loss:0.0479930190299464\n",
      "train loss:0.03794666048101343\n",
      "train loss:0.11239706729569036\n",
      "train loss:0.03310144090522718\n",
      "train loss:0.05571843319978042\n",
      "train loss:0.06435688284713235\n",
      "train loss:0.07644273175980934\n",
      "train loss:0.02716253253317199\n",
      "train loss:0.09759864731897602\n",
      "train loss:0.11777529337692266\n",
      "train loss:0.06374491962000815\n",
      "train loss:0.06878726227085677\n",
      "train loss:0.1957254130967856\n",
      "train loss:0.09074406926196009\n",
      "train loss:0.1474892046364812\n",
      "train loss:0.09194876748799874\n",
      "train loss:0.06951036509078982\n",
      "train loss:0.1004649849543203\n",
      "train loss:0.05393489638473674\n",
      "train loss:0.08079283431608164\n",
      "train loss:0.07807290972771216\n",
      "train loss:0.06052310700491166\n",
      "train loss:0.10561981112495183\n",
      "train loss:0.1059348338883283\n",
      "train loss:0.07619208230741249\n",
      "train loss:0.09331651658122128\n",
      "train loss:0.04304328506864651\n",
      "train loss:0.07550596105729909\n",
      "train loss:0.11243742384333118\n",
      "train loss:0.12456980037381245\n",
      "train loss:0.0951675155173514\n",
      "train loss:0.08499484702209134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.08095966545510859\n",
      "train loss:0.08959593554234668\n",
      "train loss:0.13381545317803575\n",
      "train loss:0.05256804026737392\n",
      "train loss:0.06836883132817535\n",
      "train loss:0.12846164987120326\n",
      "train loss:0.13281367040327338\n",
      "train loss:0.10022387331692865\n",
      "train loss:0.17668241848829425\n",
      "train loss:0.08629260214516975\n",
      "train loss:0.08448369687290526\n",
      "train loss:0.10392918730773207\n",
      "train loss:0.05435386042721068\n",
      "train loss:0.09458708231866408\n",
      "train loss:0.08044385836648515\n",
      "train loss:0.10485784146768463\n",
      "train loss:0.027442580386927748\n",
      "train loss:0.03605571226687773\n",
      "train loss:0.06188953792282895\n",
      "train loss:0.03326858588861528\n",
      "train loss:0.08499712938736968\n",
      "train loss:0.07388015434243773\n",
      "train loss:0.041502588275453355\n",
      "train loss:0.05102158273818151\n",
      "train loss:0.07529741127296209\n",
      "train loss:0.07793809754583805\n",
      "train loss:0.05059522038735301\n",
      "train loss:0.07583639972292232\n",
      "train loss:0.08296160204417417\n",
      "train loss:0.02404046638038283\n",
      "train loss:0.09503207433966246\n",
      "train loss:0.1352393959410788\n",
      "train loss:0.08369127382299459\n",
      "train loss:0.07633435949031259\n",
      "train loss:0.04521530460055221\n",
      "train loss:0.036700509694719656\n",
      "train loss:0.029223995286925958\n",
      "train loss:0.054887231958870124\n",
      "train loss:0.0369716517153676\n",
      "train loss:0.06651070191606073\n",
      "train loss:0.12407001655892119\n",
      "train loss:0.06013745632280547\n",
      "train loss:0.1262102603920324\n",
      "train loss:0.07277464014260045\n",
      "train loss:0.07655338256713719\n",
      "train loss:0.06803822221594197\n",
      "train loss:0.07048343445193968\n",
      "train loss:0.07062820958384265\n",
      "train loss:0.06333168208450692\n",
      "train loss:0.09242739193848463\n",
      "train loss:0.03819785475368274\n",
      "train loss:0.11105922330503308\n",
      "train loss:0.0870165976461397\n",
      "train loss:0.10636672384514098\n",
      "train loss:0.05481944270907532\n",
      "train loss:0.11105869359777432\n",
      "train loss:0.14281498775217952\n",
      "train loss:0.01260091166397529\n",
      "train loss:0.09541308356851347\n",
      "train loss:0.07822391845174263\n",
      "train loss:0.06817552475416157\n",
      "train loss:0.061580583780957036\n",
      "train loss:0.1369430712580832\n",
      "train loss:0.035641536035586126\n",
      "train loss:0.07973013857296712\n",
      "train loss:0.05124804003419637\n",
      "train loss:0.08169154171396277\n",
      "train loss:0.12171790472633967\n",
      "train loss:0.06042822423398128\n",
      "train loss:0.10613270964526535\n",
      "train loss:0.0759650216024991\n",
      "train loss:0.05220244447676035\n",
      "train loss:0.10691537005584972\n",
      "train loss:0.06573964214521034\n",
      "train loss:0.16376026270225041\n",
      "train loss:0.04016506889919233\n",
      "train loss:0.08720976675884598\n",
      "train loss:0.11187502967723992\n",
      "train loss:0.09223087764114143\n",
      "train loss:0.06351383022915708\n",
      "train loss:0.0877533705985572\n",
      "train loss:0.14649108788494136\n",
      "train loss:0.07361696344820806\n",
      "train loss:0.06293581210288232\n",
      "train loss:0.06737716046258158\n",
      "train loss:0.07468924698830134\n",
      "train loss:0.09035609435332537\n",
      "train loss:0.11178599982164245\n",
      "train loss:0.034942625230047215\n",
      "train loss:0.046655782272269714\n",
      "train loss:0.04886770227816704\n",
      "train loss:0.10090979804237907\n",
      "train loss:0.06793552200140779\n",
      "train loss:0.08790696230329977\n",
      "train loss:0.09705545632360237\n",
      "train loss:0.06422684200717606\n",
      "train loss:0.09489112736240096\n",
      "train loss:0.09553469814769791\n",
      "train loss:0.05410031884173755\n",
      "train loss:0.08050397051441244\n",
      "train loss:0.06099875413408487\n",
      "train loss:0.09038792541550351\n",
      "train loss:0.07545302344973792\n",
      "train loss:0.1337086936571845\n",
      "train loss:0.0839438429492363\n",
      "train loss:0.05029357656158306\n",
      "train loss:0.11059473922735502\n",
      "train loss:0.01630850715134836\n",
      "train loss:0.10264641302672253\n",
      "train loss:0.0843697624068462\n",
      "train loss:0.09983553380486039\n",
      "train loss:0.0889299885633694\n",
      "train loss:0.07193967431622517\n",
      "train loss:0.03334152775982482\n",
      "train loss:0.12778344082535392\n",
      "train loss:0.1241159434473081\n",
      "train loss:0.07159880403058486\n",
      "train loss:0.05726342126434956\n",
      "train loss:0.030044305920715355\n",
      "train loss:0.05620534435199656\n",
      "train loss:0.12612721073665362\n",
      "train loss:0.057509908774091484\n",
      "train loss:0.08825855993281906\n",
      "train loss:0.07293101850361773\n",
      "train loss:0.042718460226528567\n",
      "train loss:0.09237414467056604\n",
      "train loss:0.05037374373356671\n",
      "train loss:0.04676858015333949\n",
      "train loss:0.030858079403788284\n",
      "train loss:0.09849301509086562\n",
      "train loss:0.08473998952283551\n",
      "train loss:0.106113765583676\n",
      "train loss:0.07414111723669448\n",
      "train loss:0.07688390906334443\n",
      "train loss:0.07291880120467834\n",
      "train loss:0.0947522092467921\n",
      "train loss:0.10390437047237491\n",
      "train loss:0.060015857774203735\n",
      "train loss:0.1256265748078579\n",
      "train loss:0.14961404865371544\n",
      "train loss:0.06411973445629524\n",
      "train loss:0.08682876912298934\n",
      "train loss:0.10232840685208115\n",
      "train loss:0.09213351264515846\n",
      "train loss:0.05062527005038372\n",
      "train loss:0.08648225199606624\n",
      "train loss:0.05457711976202396\n",
      "train loss:0.056330099002149706\n",
      "train loss:0.0495041213285245\n",
      "train loss:0.15993633275715713\n",
      "train loss:0.04306946234361138\n",
      "train loss:0.058107085717140954\n",
      "train loss:0.08704120795608981\n",
      "train loss:0.06883176418828506\n",
      "train loss:0.08306509654122671\n",
      "train loss:0.07259953108533732\n",
      "train loss:0.09719574317630197\n",
      "train loss:0.12744460720456166\n",
      "train loss:0.08495745370110919\n",
      "train loss:0.0751973600404923\n",
      "train loss:0.05775330854353562\n",
      "train loss:0.04304351599548962\n",
      "train loss:0.04758467910120178\n",
      "train loss:0.12206257410802873\n",
      "train loss:0.055226838756483924\n",
      "train loss:0.05015535577781772\n",
      "train loss:0.045858482475293096\n",
      "train loss:0.01988420550192407\n",
      "train loss:0.06107053624556535\n",
      "train loss:0.11194864524557235\n",
      "train loss:0.08593330998929259\n",
      "train loss:0.02440733779427137\n",
      "train loss:0.04224916303522479\n",
      "train loss:0.04556286303060483\n",
      "train loss:0.09547887060841699\n",
      "train loss:0.044911668009686274\n",
      "train loss:0.07606589403996054\n",
      "train loss:0.05840806385425022\n",
      "train loss:0.04194269637877829\n",
      "train loss:0.09912215583721183\n",
      "train loss:0.07774293616400792\n",
      "train loss:0.09184160965999975\n",
      "train loss:0.053261057740520375\n",
      "train loss:0.11705552875158812\n",
      "train loss:0.07278870905044879\n",
      "train loss:0.05197509903756179\n",
      "train loss:0.10679253229010671\n",
      "train loss:0.054491180082122524\n",
      "train loss:0.07755094834431644\n",
      "train loss:0.09259330694270913\n",
      "train loss:0.12871159570769677\n",
      "train loss:0.058669542980483956\n",
      "train loss:0.07340950368433123\n",
      "train loss:0.08722697283869801\n",
      "train loss:0.08713432969205831\n",
      "train loss:0.05385247963603595\n",
      "train loss:0.07566753140011487\n",
      "train loss:0.04823328839517571\n",
      "train loss:0.064702484464729\n",
      "train loss:0.16708495117610503\n",
      "train loss:0.0868378272999198\n",
      "train loss:0.05063455027985061\n",
      "train loss:0.045419368728806225\n",
      "train loss:0.046466876454091796\n",
      "train loss:0.09887439106635508\n",
      "train loss:0.11567642903821178\n",
      "train loss:0.06845636517660293\n",
      "train loss:0.05283164884740108\n",
      "train loss:0.08527870422494574\n",
      "train loss:0.10693765142965908\n",
      "train loss:0.1072859141641837\n",
      "train loss:0.04714138033391897\n",
      "train loss:0.06782658224280316\n",
      "train loss:0.08377490621638571\n",
      "train loss:0.06413250092884923\n",
      "train loss:0.05458909211111758\n",
      "train loss:0.07122032549491862\n",
      "train loss:0.06097581760906762\n",
      "train loss:0.11315695724381784\n",
      "train loss:0.04050192954578566\n",
      "train loss:0.11741348560106363\n",
      "train loss:0.11829819087069943\n",
      "train loss:0.04114346017264626\n",
      "train loss:0.10431462396819269\n",
      "train loss:0.07936977883048572\n",
      "train loss:0.07519923524480392\n",
      "train loss:0.1558426854116072\n",
      "train loss:0.05672259017241656\n",
      "train loss:0.06848139054560512\n",
      "train loss:0.14671222106143145\n",
      "train loss:0.03756386032293799\n",
      "train loss:0.06533286548966544\n",
      "train loss:0.07915763486708098\n",
      "train loss:0.10928556724671719\n",
      "train loss:0.08775309058010118\n",
      "train loss:0.06882650076599876\n",
      "train loss:0.072503964750224\n",
      "train loss:0.08080691247787623\n",
      "train loss:0.058692481436742126\n",
      "train loss:0.04060731622961419\n",
      "train loss:0.07017148452071004\n",
      "train loss:0.07553227586833161\n",
      "train loss:0.08945241520842638\n",
      "train loss:0.07687073184203373\n",
      "train loss:0.07690577472109301\n",
      "train loss:0.09378751045222584\n",
      "train loss:0.1257282809950289\n",
      "train loss:0.07690566123987012\n",
      "train loss:0.03735314765944186\n",
      "train loss:0.09421744466380072\n",
      "train loss:0.06807560094565748\n",
      "train loss:0.1946947744140326\n",
      "train loss:0.13921847431566114\n",
      "train loss:0.11020045269831792\n",
      "train loss:0.08093741716281488\n",
      "train loss:0.04198959113234954\n",
      "train loss:0.07915199127427254\n",
      "train loss:0.01730514110537093\n",
      "train loss:0.057674894581131245\n",
      "train loss:0.03446518994011726\n",
      "train loss:0.10594166757282579\n",
      "train loss:0.10255462000600239\n",
      "train loss:0.14436635492729816\n",
      "train loss:0.08244122176746944\n",
      "train loss:0.09327767370435346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.05624064414206427\n",
      "train loss:0.056272619657365484\n",
      "train loss:0.05523145970543907\n",
      "train loss:0.0654863116543636\n",
      "train loss:0.09161283661970727\n",
      "train loss:0.06274402285018241\n",
      "train loss:0.05064585538935039\n",
      "train loss:0.1205692025708054\n",
      "train loss:0.11850673820222653\n",
      "train loss:0.06815284432071256\n",
      "train loss:0.09669464922142806\n",
      "train loss:0.11724885682177376\n",
      "train loss:0.06852894378730885\n",
      "train loss:0.08268657333921996\n",
      "train loss:0.11756324562195218\n",
      "train loss:0.12492086437013655\n",
      "train loss:0.08774861171744512\n",
      "train loss:0.060373585135869316\n",
      "train loss:0.0460292037331001\n",
      "train loss:0.05075477023831277\n",
      "train loss:0.0862064811147677\n",
      "train loss:0.06992695052251544\n",
      "train loss:0.042721036518579496\n",
      "train loss:0.0687742715550246\n",
      "train loss:0.11427195797891686\n",
      "train loss:0.026158698034200564\n",
      "train loss:0.023245259312547555\n",
      "train loss:0.07525760854158228\n",
      "train loss:0.0754347627809971\n",
      "train loss:0.059457385017610026\n",
      "train loss:0.062218678936904304\n",
      "train loss:0.05214365900731229\n",
      "train loss:0.0578813901267025\n",
      "train loss:0.08497217425348716\n",
      "train loss:0.07039638195737145\n",
      "train loss:0.11303283857869623\n",
      "train loss:0.05141021808225833\n",
      "train loss:0.056673848968026304\n",
      "train loss:0.08419723748286234\n",
      "train loss:0.16388160124761098\n",
      "train loss:0.041032232510254216\n",
      "train loss:0.06285790020847642\n",
      "train loss:0.08310697113492305\n",
      "train loss:0.05380391460992987\n",
      "train loss:0.07718467852558646\n",
      "train loss:0.09919183741856279\n",
      "train loss:0.1104259370826487\n",
      "train loss:0.03171719317347706\n",
      "train loss:0.08736112163937843\n",
      "train loss:0.06514093826131756\n",
      "train loss:0.08036758250101682\n",
      "train loss:0.10174907634387724\n",
      "train loss:0.12294787078029402\n",
      "train loss:0.08266695239263074\n",
      "train loss:0.05140977069367861\n",
      "train loss:0.06116764432982449\n",
      "train loss:0.04779621630663484\n",
      "train loss:0.04928996292805482\n",
      "train loss:0.1305064269012564\n",
      "train loss:0.04397331433208361\n",
      "train loss:0.093061917134588\n",
      "train loss:0.05634653626674714\n",
      "train loss:0.027090511446034554\n",
      "train loss:0.0219198049009014\n",
      "train loss:0.08233321041793991\n",
      "train loss:0.12938137903654445\n",
      "train loss:0.15132299100336927\n",
      "train loss:0.05886096382515483\n",
      "train loss:0.06012138767784985\n",
      "train loss:0.016527216220480912\n",
      "train loss:0.07538698615964265\n",
      "train loss:0.03408139757299146\n",
      "train loss:0.07865966136829153\n",
      "train loss:0.04861597902231743\n",
      "train loss:0.07778402064463692\n",
      "train loss:0.1130727401311783\n",
      "train loss:0.08964630349870331\n",
      "train loss:0.039806348093307097\n",
      "train loss:0.09428253571564836\n",
      "train loss:0.031416291354342714\n",
      "train loss:0.0337076127372265\n",
      "train loss:0.039454482088097646\n",
      "train loss:0.05359586393099483\n",
      "train loss:0.06714513788358992\n",
      "train loss:0.09800019013932955\n",
      "train loss:0.15305620160100608\n",
      "train loss:0.13253054570981163\n",
      "train loss:0.05387268842141675\n",
      "train loss:0.08695902810212647\n",
      "train loss:0.06301032542331013\n",
      "train loss:0.06829762401236322\n",
      "train loss:0.14137776301601837\n",
      "train loss:0.044270331465475515\n",
      "train loss:0.16060974533194158\n",
      "train loss:0.051599965101333495\n",
      "train loss:0.040840630329876275\n",
      "train loss:0.034959898731434194\n",
      "train loss:0.024600420906747713\n",
      "train loss:0.04275145119544586\n",
      "train loss:0.05049927641257889\n",
      "train loss:0.07415062831327926\n",
      "train loss:0.10778288168622527\n",
      "train loss:0.07216391063296848\n",
      "train loss:0.04811644406844469\n",
      "train loss:0.07680484975565811\n",
      "train loss:0.06344299759125013\n",
      "train loss:0.06341164086087045\n",
      "train loss:0.07498499114106486\n",
      "train loss:0.07514789515892574\n",
      "train loss:0.08256063254660406\n",
      "train loss:0.04997684763738837\n",
      "train loss:0.07742431523877341\n",
      "train loss:0.09469016341353402\n",
      "train loss:0.10419500011111406\n",
      "train loss:0.03824821345582614\n",
      "train loss:0.14959599371759977\n",
      "train loss:0.03532867406150267\n",
      "train loss:0.06484004352347189\n",
      "train loss:0.03187154506039752\n",
      "train loss:0.10207310308689585\n",
      "=== epoch:19, train acc:0.968, test acc:0.914 ===\n",
      "train loss:0.0996556062699474\n",
      "train loss:0.12689138182630494\n",
      "train loss:0.04967607126037236\n",
      "train loss:0.07798048688438612\n",
      "train loss:0.046173673205972265\n",
      "train loss:0.08800135517722422\n",
      "train loss:0.05459795617109233\n",
      "train loss:0.03929829149683389\n",
      "train loss:0.05819305036331149\n",
      "train loss:0.14029698845388985\n",
      "train loss:0.16017453329205963\n",
      "train loss:0.0529543788336273\n",
      "train loss:0.06930896399266137\n",
      "train loss:0.08082484963206747\n",
      "train loss:0.03881014076035305\n",
      "train loss:0.05951369015297332\n",
      "train loss:0.057678064585150894\n",
      "train loss:0.05607920815949973\n",
      "train loss:0.03937752402715899\n",
      "train loss:0.16373963517462678\n",
      "train loss:0.08752811611660398\n",
      "train loss:0.10601343066459337\n",
      "train loss:0.04569789945081798\n",
      "train loss:0.07906716812526887\n",
      "train loss:0.10172075583929013\n",
      "train loss:0.13863308607944907\n",
      "train loss:0.04120470153682136\n",
      "train loss:0.0984327088169476\n",
      "train loss:0.05981869106061808\n",
      "train loss:0.03390860849266439\n",
      "train loss:0.09457779627294734\n",
      "train loss:0.09895675588896305\n",
      "train loss:0.09458163148601391\n",
      "train loss:0.06116764588040953\n",
      "train loss:0.10483760982955274\n",
      "train loss:0.10954196770283961\n",
      "train loss:0.025998594160706812\n",
      "train loss:0.1429148104511105\n",
      "train loss:0.0651648054258755\n",
      "train loss:0.0716681695332706\n",
      "train loss:0.10180729464146643\n",
      "train loss:0.04464654160144892\n",
      "train loss:0.04709673066901814\n",
      "train loss:0.07795524983530994\n",
      "train loss:0.06137202584571288\n",
      "train loss:0.033382192043567425\n",
      "train loss:0.09203973434999549\n",
      "train loss:0.07026594061427285\n",
      "train loss:0.040330303855463566\n",
      "train loss:0.07654304329659728\n",
      "train loss:0.12327628120348995\n",
      "train loss:0.03169394126094229\n",
      "train loss:0.05570994167527138\n",
      "train loss:0.12381584425247766\n",
      "train loss:0.08889673345134186\n",
      "train loss:0.055150125639221025\n",
      "train loss:0.0625077105769586\n",
      "train loss:0.04052035167128285\n",
      "train loss:0.10343955783488104\n",
      "train loss:0.04177892806407143\n",
      "train loss:0.043023135038014\n",
      "train loss:0.05827851217858338\n",
      "train loss:0.06124750614169445\n",
      "train loss:0.11601998175677304\n",
      "train loss:0.05744128624283041\n",
      "train loss:0.07986628713809571\n",
      "train loss:0.06076687701732974\n",
      "train loss:0.07215564537740152\n",
      "train loss:0.06213919285741462\n",
      "train loss:0.04050984275584036\n",
      "train loss:0.18066812498908397\n",
      "train loss:0.05043843511381029\n",
      "train loss:0.052538717657063874\n",
      "train loss:0.08310257858251571\n",
      "train loss:0.028080815196281552\n",
      "train loss:0.09482984186029408\n",
      "train loss:0.1436828567890829\n",
      "train loss:0.077630094789198\n",
      "train loss:0.09872191331400812\n",
      "train loss:0.07378222510361343\n",
      "train loss:0.05492124824450853\n",
      "train loss:0.059378013284382254\n",
      "train loss:0.05829801378395206\n",
      "train loss:0.04578733176980288\n",
      "train loss:0.04363364193468469\n",
      "train loss:0.06234961101109295\n",
      "train loss:0.06291079327461685\n",
      "train loss:0.050812149376228855\n",
      "train loss:0.02721887641545243\n",
      "train loss:0.06531017672616214\n",
      "train loss:0.060052410325114484\n",
      "train loss:0.07039276696795758\n",
      "train loss:0.06947123899661993\n",
      "train loss:0.09796092911363441\n",
      "train loss:0.0452325751693532\n",
      "train loss:0.08522277608255008\n",
      "train loss:0.08093083485344806\n",
      "train loss:0.07506577341839892\n",
      "train loss:0.035156405029976544\n",
      "train loss:0.08112725511805906\n",
      "train loss:0.08080193682399212\n",
      "train loss:0.03701228171491066\n",
      "train loss:0.07203141759940555\n",
      "train loss:0.07200024955545878\n",
      "train loss:0.08189006439670282\n",
      "train loss:0.05290283657218661\n",
      "train loss:0.03940987818257122\n",
      "train loss:0.0766508648527123\n",
      "train loss:0.015658118781156215\n",
      "train loss:0.04578850398239058\n",
      "train loss:0.07858190966478974\n",
      "train loss:0.032603320329113186\n",
      "train loss:0.0849824216478048\n",
      "train loss:0.16814336591538115\n",
      "train loss:0.06846339818210775\n",
      "train loss:0.08819289566193947\n",
      "train loss:0.045199535781576455\n",
      "train loss:0.028798801736302095\n",
      "train loss:0.09060115719005435\n",
      "train loss:0.054181206258836705\n",
      "train loss:0.06693835358115653\n",
      "train loss:0.06585690643789559\n",
      "train loss:0.07248925768333774\n",
      "train loss:0.05245101632638301\n",
      "train loss:0.09837413002857863\n",
      "train loss:0.10129626464580374\n",
      "train loss:0.07885359799094281\n",
      "train loss:0.05454451904666503\n",
      "train loss:0.06085916059419892\n",
      "train loss:0.059194191906698564\n",
      "train loss:0.06843357276952566\n",
      "train loss:0.05709177430327002\n",
      "train loss:0.12062232867358778\n",
      "train loss:0.06288777824143421\n",
      "train loss:0.061329966930562974\n",
      "train loss:0.06067650443492446\n",
      "train loss:0.05595824438940359\n",
      "train loss:0.06202745939300861\n",
      "train loss:0.10195901176583369\n",
      "train loss:0.06101738443980564\n",
      "train loss:0.04257853139713618\n",
      "train loss:0.10993165664153345\n",
      "train loss:0.08753135117706973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.11886524414453216\n",
      "train loss:0.10583592091812814\n",
      "train loss:0.10755942088929746\n",
      "train loss:0.08026084169125511\n",
      "train loss:0.11559995176792949\n",
      "train loss:0.02825150994340118\n",
      "train loss:0.10130872755967489\n",
      "train loss:0.05718172998706574\n",
      "train loss:0.08058938178917355\n",
      "train loss:0.14338822658569417\n",
      "train loss:0.0750388460201699\n",
      "train loss:0.0546175238444662\n",
      "train loss:0.09870183301646879\n",
      "train loss:0.08388907350668547\n",
      "train loss:0.06453283974078836\n",
      "train loss:0.09985181333464922\n",
      "train loss:0.08777919377782953\n",
      "train loss:0.05979557875696772\n",
      "train loss:0.10732370281746416\n",
      "train loss:0.041597978560767544\n",
      "train loss:0.08932128235342446\n",
      "train loss:0.06333443554052785\n",
      "train loss:0.07878583499002483\n",
      "train loss:0.09287531814749181\n",
      "train loss:0.05717950639891714\n",
      "train loss:0.06398382163703914\n",
      "train loss:0.06232906023994081\n",
      "train loss:0.060074707488643034\n",
      "train loss:0.042482923363997366\n",
      "train loss:0.05955087169026764\n",
      "train loss:0.052842802308461466\n",
      "train loss:0.06286591730929528\n",
      "train loss:0.05746155014079325\n",
      "train loss:0.046206268951250455\n",
      "train loss:0.036579693639795866\n",
      "train loss:0.05562949285242195\n",
      "train loss:0.14997771075266722\n",
      "train loss:0.1292521199516303\n",
      "train loss:0.07848205006451704\n",
      "train loss:0.0842669075501734\n",
      "train loss:0.0237646772620658\n",
      "train loss:0.040412615761685124\n",
      "train loss:0.07560583920311928\n",
      "train loss:0.0618935360626192\n",
      "train loss:0.0678733429166226\n",
      "train loss:0.061365895649419924\n",
      "train loss:0.048022847472779615\n",
      "train loss:0.06432116721351712\n",
      "train loss:0.03649455972743031\n",
      "train loss:0.033362238661607445\n",
      "train loss:0.035219851656923325\n",
      "train loss:0.07188643514664059\n",
      "train loss:0.04676187134311093\n",
      "train loss:0.13351877886363858\n",
      "train loss:0.06356124367614231\n",
      "train loss:0.0613180630813429\n",
      "train loss:0.045658038988513824\n",
      "train loss:0.13700313359162317\n",
      "train loss:0.05721659235406133\n",
      "train loss:0.03288486849088587\n",
      "train loss:0.05352856128522939\n",
      "train loss:0.06012210496063165\n",
      "train loss:0.05862400745622821\n",
      "train loss:0.061868435298507295\n",
      "train loss:0.10501101142721422\n",
      "train loss:0.05273988032635149\n",
      "train loss:0.05520433875783425\n",
      "train loss:0.05311954092767685\n",
      "train loss:0.08703450297723084\n",
      "train loss:0.04214044903590247\n",
      "train loss:0.0307358636431365\n",
      "train loss:0.04444266854298724\n",
      "train loss:0.04558364719580922\n",
      "train loss:0.10109408362043865\n",
      "train loss:0.11642873774301692\n",
      "train loss:0.07717751540012059\n",
      "train loss:0.11402991564115725\n",
      "train loss:0.06843858039966111\n",
      "train loss:0.08113090500797623\n",
      "train loss:0.07522498652945728\n",
      "train loss:0.03963095779696974\n",
      "train loss:0.10979934250659142\n",
      "train loss:0.056193901937372226\n",
      "train loss:0.05640805293743809\n",
      "train loss:0.04812741835816465\n",
      "train loss:0.1252183833037343\n",
      "train loss:0.018133896199433907\n",
      "train loss:0.041010666013589644\n",
      "train loss:0.054522793200839664\n",
      "train loss:0.09025813730721147\n",
      "train loss:0.04132891685085067\n",
      "train loss:0.07400820604198372\n",
      "train loss:0.061119493091689174\n",
      "train loss:0.19890029314556035\n",
      "train loss:0.03913479982610124\n",
      "train loss:0.03861042136230873\n",
      "train loss:0.1199999936798467\n",
      "train loss:0.0573663399099807\n",
      "train loss:0.13540177501592002\n",
      "train loss:0.07044795444200708\n",
      "train loss:0.048053788073158826\n",
      "train loss:0.08770258387097778\n",
      "train loss:0.05843015362667199\n",
      "train loss:0.09067076929500374\n",
      "train loss:0.055076945169322954\n",
      "train loss:0.07576343328197324\n",
      "train loss:0.08726033174128071\n",
      "train loss:0.08842625049479587\n",
      "train loss:0.07547658552764408\n",
      "train loss:0.07619580832758438\n",
      "train loss:0.04806075115838089\n",
      "train loss:0.043379095804023445\n",
      "train loss:0.1384056699555608\n",
      "train loss:0.06956218947806006\n",
      "train loss:0.10305642706819264\n",
      "train loss:0.05936664451524683\n",
      "train loss:0.0861875112204888\n",
      "train loss:0.09660659810874676\n",
      "train loss:0.06689848618472011\n",
      "train loss:0.047842316673572235\n",
      "train loss:0.0826907136226845\n",
      "train loss:0.13301841846713988\n",
      "train loss:0.12222997036843669\n",
      "train loss:0.09170394021066848\n",
      "train loss:0.08323539093087008\n",
      "train loss:0.12024689893263706\n",
      "train loss:0.032206055447538164\n",
      "train loss:0.05462311001071129\n",
      "train loss:0.09171205294880627\n",
      "train loss:0.1203258128349736\n",
      "train loss:0.03432266673034472\n",
      "train loss:0.02501303618116748\n",
      "train loss:0.08417010646689409\n",
      "train loss:0.13229511246806497\n",
      "train loss:0.12630254501524213\n",
      "train loss:0.047006075185774016\n",
      "train loss:0.08579402822944626\n",
      "train loss:0.1178453050807185\n",
      "train loss:0.06949189184014362\n",
      "train loss:0.06970838891462061\n",
      "train loss:0.03879490255465494\n",
      "train loss:0.036693928304396696\n",
      "train loss:0.0962823847672205\n",
      "train loss:0.051515229488809065\n",
      "train loss:0.10014758174066138\n",
      "train loss:0.15390020381999706\n",
      "train loss:0.024873652331962502\n",
      "train loss:0.03462628345170482\n",
      "train loss:0.1704106445253601\n",
      "train loss:0.17962180618138998\n",
      "train loss:0.16664090519671987\n",
      "train loss:0.04954546475778885\n",
      "train loss:0.11810616874851347\n",
      "train loss:0.0535514647610015\n",
      "train loss:0.0919135715581357\n",
      "train loss:0.11826930861152872\n",
      "train loss:0.07316389216590036\n",
      "train loss:0.03904919216987072\n",
      "train loss:0.09416685658749234\n",
      "train loss:0.13103315599975446\n",
      "train loss:0.10080410306299409\n",
      "train loss:0.05216684211240546\n",
      "train loss:0.07346537216760822\n",
      "train loss:0.05759877072432136\n",
      "train loss:0.07901852376034618\n",
      "train loss:0.040836992008181555\n",
      "train loss:0.06294797754276243\n",
      "train loss:0.060876776358931295\n",
      "train loss:0.03174037199777092\n",
      "train loss:0.04178674910591326\n",
      "train loss:0.042470084481385034\n",
      "train loss:0.12390576305636623\n",
      "train loss:0.05541864530170296\n",
      "train loss:0.05531796424948394\n",
      "train loss:0.0709153708121675\n",
      "train loss:0.05052285008398863\n",
      "train loss:0.04045897801669363\n",
      "train loss:0.04247684420541236\n",
      "train loss:0.039162236922670186\n",
      "train loss:0.017286113860598827\n",
      "train loss:0.06462576582523291\n",
      "train loss:0.10615497631064925\n",
      "train loss:0.07244628131921188\n",
      "train loss:0.09999900671363322\n",
      "train loss:0.11764089345043698\n",
      "train loss:0.130003485056971\n",
      "train loss:0.028633723141260753\n",
      "train loss:0.05445924327639957\n",
      "train loss:0.038965921935697645\n",
      "train loss:0.10261692154383333\n",
      "train loss:0.06363911697825252\n",
      "train loss:0.07649581261956397\n",
      "train loss:0.0737159901829883\n",
      "train loss:0.09625019887080281\n",
      "train loss:0.06627751688030653\n",
      "train loss:0.035059282379343956\n",
      "train loss:0.08797068441885328\n",
      "train loss:0.04979122157664145\n",
      "train loss:0.0763464732882605\n",
      "train loss:0.05686459392755333\n",
      "train loss:0.10839399917925671\n",
      "train loss:0.1012797289064781\n",
      "train loss:0.03500638766209849\n",
      "train loss:0.07833293788714346\n",
      "train loss:0.056571290249788915\n",
      "train loss:0.059357434559454816\n",
      "train loss:0.08530969340730205\n",
      "train loss:0.06901897791542268\n",
      "train loss:0.09410947786928041\n",
      "train loss:0.0566568510266692\n",
      "train loss:0.07319598034070689\n",
      "train loss:0.02127696550989043\n",
      "train loss:0.08935999087659412\n",
      "train loss:0.07068552376220244\n",
      "train loss:0.06069270327437321\n",
      "train loss:0.04629017528690892\n",
      "train loss:0.0299178642203944\n",
      "train loss:0.11139496677840216\n",
      "train loss:0.07615747393407872\n",
      "train loss:0.045495590584529406\n",
      "train loss:0.07117731377297513\n",
      "train loss:0.08595602707559583\n",
      "train loss:0.021716431910205718\n",
      "train loss:0.06576891353274109\n",
      "train loss:0.09238848281655704\n",
      "train loss:0.07087083565637095\n",
      "train loss:0.09021951228105418\n",
      "train loss:0.025606000426169097\n",
      "train loss:0.03281013690143793\n",
      "train loss:0.027155428045804272\n",
      "train loss:0.07978582233528901\n",
      "train loss:0.06588906645743578\n",
      "train loss:0.03448325284820445\n",
      "train loss:0.11560248350223722\n",
      "train loss:0.048255711104927906\n",
      "train loss:0.052332240510495176\n",
      "train loss:0.06756871033422417\n",
      "train loss:0.09266036837551656\n",
      "train loss:0.12328093602215119\n",
      "train loss:0.04465313558411708\n",
      "train loss:0.07246561186560706\n",
      "train loss:0.0652655973725355\n",
      "train loss:0.06522888121592377\n",
      "train loss:0.04419613706595211\n",
      "train loss:0.09456520371423306\n",
      "train loss:0.08165095730637702\n",
      "train loss:0.08641621481757716\n",
      "train loss:0.08717818371467324\n",
      "train loss:0.06217513093223571\n",
      "train loss:0.03650575400138187\n",
      "train loss:0.10426556288684077\n",
      "train loss:0.061951842763990274\n",
      "train loss:0.09722828224275817\n",
      "train loss:0.1276786502186765\n",
      "train loss:0.07815450854053757\n",
      "train loss:0.02673903037365567\n",
      "train loss:0.033896778771136754\n",
      "train loss:0.06562422979132503\n",
      "train loss:0.04641932459573633\n",
      "train loss:0.07662107836093283\n",
      "train loss:0.029042253591548935\n",
      "train loss:0.07024844304740208\n",
      "train loss:0.04337172922931485\n",
      "train loss:0.09466835038662973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.05225420073460668\n",
      "train loss:0.07319525981559899\n",
      "train loss:0.04039373349573114\n",
      "train loss:0.084816381016545\n",
      "train loss:0.07866131643677134\n",
      "train loss:0.05221698873327938\n",
      "train loss:0.04814221851334839\n",
      "train loss:0.04502254998895598\n",
      "train loss:0.06853819090084691\n",
      "train loss:0.04798741478981107\n",
      "train loss:0.1998811239052657\n",
      "train loss:0.04193314415063679\n",
      "train loss:0.06172996451838341\n",
      "train loss:0.12275238740761366\n",
      "train loss:0.03478838778862445\n",
      "train loss:0.1052745652119857\n",
      "train loss:0.1173609469098509\n",
      "train loss:0.036051988023159384\n",
      "train loss:0.09822760141270065\n",
      "train loss:0.03572102567472882\n",
      "train loss:0.044988710756269014\n",
      "train loss:0.05208200820900764\n",
      "train loss:0.08561829380164003\n",
      "train loss:0.05267015194643108\n",
      "train loss:0.057595021176114126\n",
      "train loss:0.08028738935916153\n",
      "train loss:0.055956211667484636\n",
      "train loss:0.10795990852509346\n",
      "train loss:0.05763970278524927\n",
      "train loss:0.07612390701570829\n",
      "train loss:0.07434148205638745\n",
      "train loss:0.06517564271804355\n",
      "train loss:0.07918430495016014\n",
      "train loss:0.06583082408605265\n",
      "train loss:0.11312461685607024\n",
      "train loss:0.021461838300617854\n",
      "train loss:0.10281111334719345\n",
      "train loss:0.03982849038404665\n",
      "train loss:0.0656338233898552\n",
      "train loss:0.07955579887652411\n",
      "train loss:0.0753501482178282\n",
      "train loss:0.05410111626784761\n",
      "train loss:0.03889785570232022\n",
      "train loss:0.09881603937139499\n",
      "train loss:0.045548004003178925\n",
      "train loss:0.03325952873346952\n",
      "train loss:0.10121172730236992\n",
      "train loss:0.03413750454371401\n",
      "train loss:0.04459378875813895\n",
      "train loss:0.09205671803934905\n",
      "train loss:0.04729672391049416\n",
      "train loss:0.04843277493902397\n",
      "train loss:0.04683025467727066\n",
      "train loss:0.0894193892997523\n",
      "train loss:0.037800096007626474\n",
      "train loss:0.12648183431827886\n",
      "train loss:0.037831360984321105\n",
      "train loss:0.06466092318098775\n",
      "train loss:0.10912436501877856\n",
      "train loss:0.14952775763066295\n",
      "train loss:0.03403243144694134\n",
      "train loss:0.035058327547494904\n",
      "train loss:0.05403263877914676\n",
      "train loss:0.1308572048315433\n",
      "train loss:0.051715674695100154\n",
      "train loss:0.061777081141800666\n",
      "train loss:0.14533421982428932\n",
      "train loss:0.03386487977367763\n",
      "train loss:0.09769461955511324\n",
      "train loss:0.05060577951221805\n",
      "train loss:0.08186954314414978\n",
      "train loss:0.09607740976186603\n",
      "train loss:0.052029516861685055\n",
      "train loss:0.08883300271021366\n",
      "train loss:0.035446303435849355\n",
      "train loss:0.06218527262956175\n",
      "train loss:0.047279549575159535\n",
      "train loss:0.08885694605113731\n",
      "train loss:0.08200135499318073\n",
      "train loss:0.13815643975862413\n",
      "train loss:0.1216025834980874\n",
      "train loss:0.16204291011726452\n",
      "train loss:0.15037909291561521\n",
      "train loss:0.03671481453270733\n",
      "train loss:0.04998302332463549\n",
      "train loss:0.04883655184553743\n",
      "train loss:0.07336661737731641\n",
      "train loss:0.06031113914987838\n",
      "train loss:0.10151738991541231\n",
      "train loss:0.13097227515482213\n",
      "train loss:0.07775353638377676\n",
      "train loss:0.09331404128846608\n",
      "train loss:0.08050509026031437\n",
      "train loss:0.05922902838205319\n",
      "train loss:0.04482750740806798\n",
      "train loss:0.07532005894861876\n",
      "train loss:0.02811006775680044\n",
      "train loss:0.09009504483889669\n",
      "train loss:0.03284072107607687\n",
      "train loss:0.052729931274400815\n",
      "train loss:0.057942414814626766\n",
      "train loss:0.10868890564819028\n",
      "train loss:0.07438225502402168\n",
      "train loss:0.15450889468983525\n",
      "train loss:0.0832159582208341\n",
      "train loss:0.043099168856366485\n",
      "train loss:0.06098094642316723\n",
      "train loss:0.07707814750570596\n",
      "train loss:0.041037810469996\n",
      "train loss:0.07800092223633638\n",
      "train loss:0.05876642828775484\n",
      "train loss:0.09173879257252762\n",
      "train loss:0.0717927707222574\n",
      "train loss:0.13721587690425674\n",
      "train loss:0.08264846880544431\n",
      "train loss:0.027471075473293912\n",
      "train loss:0.04473792398492228\n",
      "train loss:0.1029553526749471\n",
      "train loss:0.05687450724930523\n",
      "train loss:0.07918702548805863\n",
      "train loss:0.1271018488559383\n",
      "train loss:0.03671254774310941\n",
      "train loss:0.07521333463782809\n",
      "train loss:0.03140556512431069\n",
      "train loss:0.050400748828120345\n",
      "train loss:0.03595541698777217\n",
      "train loss:0.020145540466107767\n",
      "train loss:0.04370791808342253\n",
      "train loss:0.086175739910248\n",
      "train loss:0.10641463461362402\n",
      "train loss:0.059775753447752\n",
      "train loss:0.060498633942245396\n",
      "train loss:0.032837520106609626\n",
      "train loss:0.0914548340684867\n",
      "train loss:0.06852449914182678\n",
      "train loss:0.05797766698792751\n",
      "train loss:0.055671696186456614\n",
      "train loss:0.05271650140757395\n",
      "train loss:0.07788443985850167\n",
      "train loss:0.06422652955297133\n",
      "train loss:0.03764066992127137\n",
      "train loss:0.040009776963452426\n",
      "train loss:0.03857819291558033\n",
      "train loss:0.049610903300744094\n",
      "train loss:0.08633073511172894\n",
      "train loss:0.06825285240905167\n",
      "train loss:0.06767310696274335\n",
      "train loss:0.03184113239637917\n",
      "train loss:0.14663105718642\n",
      "train loss:0.08570947142325387\n",
      "train loss:0.05162043496801344\n",
      "train loss:0.04967694471263888\n",
      "train loss:0.06492696478466929\n",
      "train loss:0.060358241176946895\n",
      "train loss:0.08198868578179667\n",
      "train loss:0.09254022199574387\n",
      "train loss:0.04860132885696932\n",
      "train loss:0.055687872291799716\n",
      "train loss:0.02252229957125058\n",
      "train loss:0.06286754055443286\n",
      "train loss:0.037912663610075475\n",
      "train loss:0.014855552922189687\n",
      "train loss:0.038189168863922526\n",
      "train loss:0.04995606357497444\n",
      "train loss:0.025515803239104275\n",
      "train loss:0.06210604909719992\n",
      "train loss:0.11727315876123195\n",
      "train loss:0.04089378605321697\n",
      "train loss:0.06906070218885053\n",
      "train loss:0.028104693150802364\n",
      "train loss:0.0341577549171257\n",
      "train loss:0.0456623012968586\n",
      "train loss:0.047893525048360176\n",
      "train loss:0.06695549881592594\n",
      "train loss:0.04369950158057104\n",
      "train loss:0.0696498679584847\n",
      "train loss:0.057481291720233745\n",
      "train loss:0.13173752370917055\n",
      "train loss:0.04474926461289713\n",
      "train loss:0.038137677677031225\n",
      "train loss:0.057482758775031215\n",
      "train loss:0.0987437717392841\n",
      "train loss:0.10154257035197696\n",
      "train loss:0.10143237953956576\n",
      "train loss:0.03570976367208658\n",
      "train loss:0.06037398521083978\n",
      "train loss:0.03616972729100494\n",
      "train loss:0.03834038534312718\n",
      "train loss:0.06625019290291966\n",
      "train loss:0.1447251166767246\n",
      "train loss:0.04034527370830483\n",
      "train loss:0.08369375232586625\n",
      "train loss:0.1176800883955543\n",
      "=== epoch:20, train acc:0.979, test acc:0.907 ===\n",
      "train loss:0.02451943509968184\n",
      "train loss:0.05252347358474146\n",
      "train loss:0.046416819177214956\n",
      "train loss:0.06218248435922663\n",
      "train loss:0.09076846328696977\n",
      "train loss:0.06144675880499016\n",
      "train loss:0.1155544283430918\n",
      "train loss:0.07383831800465866\n",
      "train loss:0.08172515826129109\n",
      "train loss:0.13663069941815492\n",
      "train loss:0.06956786502169364\n",
      "train loss:0.03247200732352242\n",
      "train loss:0.06343833221633619\n",
      "train loss:0.06507327685344688\n",
      "train loss:0.049550882171466075\n",
      "train loss:0.07972722611422095\n",
      "train loss:0.0718653831852923\n",
      "train loss:0.04027748592652377\n",
      "train loss:0.04018947811145948\n",
      "train loss:0.05692489648355058\n",
      "train loss:0.045209857157588226\n",
      "train loss:0.18126800969972107\n",
      "train loss:0.04181788254418959\n",
      "train loss:0.14070809301133716\n",
      "train loss:0.026319515002489302\n",
      "train loss:0.11627565396734388\n",
      "train loss:0.05160724280459221\n",
      "train loss:0.020259596959140983\n",
      "train loss:0.056175960701012884\n",
      "train loss:0.1449899691284397\n",
      "train loss:0.04759065781340823\n",
      "train loss:0.05812764884525227\n",
      "train loss:0.08470820310896046\n",
      "train loss:0.0811262063386787\n",
      "train loss:0.045382811228607094\n",
      "train loss:0.06947150815098228\n",
      "train loss:0.08047203170809858\n",
      "train loss:0.08713254006089008\n",
      "train loss:0.09348737877633856\n",
      "train loss:0.07420630032017207\n",
      "train loss:0.08091156907086589\n",
      "train loss:0.06489779553056535\n",
      "train loss:0.06031744641176738\n",
      "train loss:0.07397185764975805\n",
      "train loss:0.05058461222263036\n",
      "train loss:0.1510627051068879\n",
      "train loss:0.0640858774445136\n",
      "train loss:0.11895482466312965\n",
      "train loss:0.09059864156740524\n",
      "train loss:0.06231903990240825\n",
      "train loss:0.09555699165980064\n",
      "train loss:0.048781385567212586\n",
      "train loss:0.08845760028133004\n",
      "train loss:0.03500694166145924\n",
      "train loss:0.052785268986903666\n",
      "train loss:0.11149235221524463\n",
      "train loss:0.09196681642884057\n",
      "train loss:0.10196138395014032\n",
      "train loss:0.037946910852567156\n",
      "train loss:0.04590052517165422\n",
      "train loss:0.09320096098625218\n",
      "train loss:0.0892474492988925\n",
      "train loss:0.05980050156963683\n",
      "train loss:0.048689562010331595\n",
      "train loss:0.06148985943222896\n",
      "train loss:0.05226540373265653\n",
      "train loss:0.050016200523000355\n",
      "train loss:0.026927174884616788\n",
      "train loss:0.10963928644348736\n",
      "train loss:0.12179918892970398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.04198729217657246\n",
      "train loss:0.014173674251554096\n",
      "train loss:0.04222551311847116\n",
      "train loss:0.11491292115531433\n",
      "train loss:0.10826973796750154\n",
      "train loss:0.0809538226197183\n",
      "train loss:0.0729848115003242\n",
      "train loss:0.05045133710567014\n",
      "train loss:0.11309920773000208\n",
      "train loss:0.05147991336636465\n",
      "train loss:0.09920173912498825\n",
      "train loss:0.05944818327666133\n",
      "train loss:0.07299300772577819\n",
      "train loss:0.12083943893273584\n",
      "train loss:0.10234658568630461\n",
      "train loss:0.16400664945121032\n",
      "train loss:0.10804604001286307\n",
      "train loss:0.08414149034596048\n",
      "train loss:0.0349985324771795\n",
      "train loss:0.09797510661882847\n",
      "train loss:0.02956361422058821\n",
      "train loss:0.07425197886820518\n",
      "train loss:0.08645398173875851\n",
      "train loss:0.10159473180213548\n",
      "train loss:0.07978701176322346\n",
      "train loss:0.07461996525963888\n",
      "train loss:0.059941720354394316\n",
      "train loss:0.038632212631377214\n",
      "train loss:0.051904945544436656\n",
      "train loss:0.03771315592863165\n",
      "train loss:0.03536845463253896\n",
      "train loss:0.04019926899115274\n",
      "train loss:0.04795943857915934\n",
      "train loss:0.025382481811390724\n",
      "train loss:0.04566989580606926\n",
      "train loss:0.03880085225359992\n",
      "train loss:0.061521192902197985\n",
      "train loss:0.07094509332744273\n",
      "train loss:0.06856027561149292\n",
      "train loss:0.0245313624529633\n",
      "train loss:0.06986587734716107\n",
      "train loss:0.031748473405843095\n",
      "train loss:0.060667473933102366\n",
      "train loss:0.08090931091790424\n",
      "train loss:0.030394468490297494\n",
      "train loss:0.051988383327181094\n",
      "train loss:0.0558790841297073\n",
      "train loss:0.05337153600807834\n",
      "train loss:0.04415037649778257\n",
      "train loss:0.04691375756002765\n",
      "train loss:0.10439206853245903\n",
      "train loss:0.10324468668125016\n",
      "train loss:0.052587930770635685\n",
      "train loss:0.12835671912496888\n",
      "train loss:0.06093850301021928\n",
      "train loss:0.05068230714235269\n",
      "train loss:0.016880973099909415\n",
      "train loss:0.0775611841371639\n",
      "train loss:0.08272958316165525\n",
      "train loss:0.040584871738256985\n",
      "train loss:0.07679836151879454\n",
      "train loss:0.15038027410299182\n",
      "train loss:0.03551285416100281\n",
      "train loss:0.09187951300302657\n",
      "train loss:0.06507280647521616\n",
      "train loss:0.04154998394233439\n",
      "train loss:0.06222653586139782\n",
      "train loss:0.030899874003033876\n",
      "train loss:0.06313215672096009\n",
      "train loss:0.041787268689718715\n",
      "train loss:0.10680002314498072\n",
      "train loss:0.06295382969211669\n",
      "train loss:0.04384198853236485\n",
      "train loss:0.05231817230771863\n",
      "train loss:0.041078234058383956\n",
      "train loss:0.051937965127272986\n",
      "train loss:0.051591917971727144\n",
      "train loss:0.040304414783927045\n",
      "train loss:0.04850155205287641\n",
      "train loss:0.041456650288031825\n",
      "train loss:0.06253518033488406\n",
      "train loss:0.04714303510679288\n",
      "train loss:0.09168876425542219\n",
      "train loss:0.05275020629503493\n",
      "train loss:0.09069207768796085\n",
      "train loss:0.03369348780419699\n",
      "train loss:0.04887082536265939\n",
      "train loss:0.05345496524750132\n",
      "train loss:0.049146839051043736\n",
      "train loss:0.11470893090260377\n",
      "train loss:0.05108134854509142\n",
      "train loss:0.10139498726806355\n",
      "train loss:0.0798718312381063\n",
      "train loss:0.08654953047797859\n",
      "train loss:0.045399340355832235\n",
      "train loss:0.07011778811077081\n",
      "train loss:0.019279982523331563\n",
      "train loss:0.08313899083246694\n",
      "train loss:0.07149893270726322\n",
      "train loss:0.048557666110684065\n",
      "train loss:0.12195937185745206\n",
      "train loss:0.07980203554682025\n",
      "train loss:0.028578481953229828\n",
      "train loss:0.07436277587769234\n",
      "train loss:0.07518039822581452\n",
      "train loss:0.07960393143957434\n",
      "train loss:0.13873191589622205\n",
      "train loss:0.06220807227205265\n",
      "train loss:0.02568087729723457\n",
      "train loss:0.0692727028146425\n",
      "train loss:0.06353604887789223\n",
      "train loss:0.11470053340250033\n",
      "train loss:0.07822258798604806\n",
      "train loss:0.11836726159886625\n",
      "train loss:0.05196828123511251\n",
      "train loss:0.0800315902576334\n",
      "train loss:0.06396513205360442\n",
      "train loss:0.0728155295386153\n",
      "train loss:0.09229854650476392\n",
      "train loss:0.07595476502481534\n",
      "train loss:0.06980963075277594\n",
      "train loss:0.05074963642311969\n",
      "train loss:0.04868339453274161\n",
      "train loss:0.08250433992290146\n",
      "train loss:0.11427501253847151\n",
      "train loss:0.06786910055646796\n",
      "train loss:0.0934115588353113\n",
      "train loss:0.08395635558668701\n",
      "train loss:0.08679888825299824\n",
      "train loss:0.0859828661686979\n",
      "train loss:0.07944795075054158\n",
      "train loss:0.0895900684606082\n",
      "train loss:0.11156995119464055\n",
      "train loss:0.04733339525658254\n",
      "train loss:0.08752176689442781\n",
      "train loss:0.1008996951740834\n",
      "train loss:0.04616576512388737\n",
      "train loss:0.0641189322795336\n",
      "train loss:0.11790286974766687\n",
      "train loss:0.06100221781590562\n",
      "train loss:0.1150068292667434\n",
      "train loss:0.047343415246897155\n",
      "train loss:0.03663156000871219\n",
      "train loss:0.09406013495772234\n",
      "train loss:0.12157295468404455\n",
      "train loss:0.052585668229343824\n",
      "train loss:0.09914592371707125\n",
      "train loss:0.07327815249555739\n",
      "train loss:0.04406804145209657\n",
      "train loss:0.0632326400962541\n",
      "train loss:0.026941046818947524\n",
      "train loss:0.04419474563842507\n",
      "train loss:0.07351562081338024\n",
      "train loss:0.1720892360228537\n",
      "train loss:0.11228227205714125\n",
      "train loss:0.04446370728819676\n",
      "train loss:0.02751564750307395\n",
      "train loss:0.02911183076628936\n",
      "train loss:0.0710119570582952\n",
      "train loss:0.028245546921451106\n",
      "train loss:0.05444522921359279\n",
      "train loss:0.09247190465475941\n",
      "train loss:0.05762945783906215\n",
      "train loss:0.04610473599399402\n",
      "train loss:0.06610424983648511\n",
      "train loss:0.08279352427177955\n",
      "train loss:0.02927925615775092\n",
      "train loss:0.07637245488958025\n",
      "train loss:0.11403611103864396\n",
      "train loss:0.05437552633528871\n",
      "train loss:0.10410650702387544\n",
      "train loss:0.09149200716355016\n",
      "train loss:0.04042127253282461\n",
      "train loss:0.06692581635343284\n",
      "train loss:0.06497685523155326\n",
      "train loss:0.07280238543275573\n",
      "train loss:0.04714721159716289\n",
      "train loss:0.04228770608452097\n",
      "train loss:0.026794353550013167\n",
      "train loss:0.07926102025545098\n",
      "train loss:0.0442773692300622\n",
      "train loss:0.0347918809368866\n",
      "train loss:0.023778681636140483\n",
      "train loss:0.03679496786173574\n",
      "train loss:0.041113172589902804\n",
      "train loss:0.02668393834631991\n",
      "train loss:0.043459418226872784\n",
      "train loss:0.08445808282121227\n",
      "train loss:0.01962997281806854\n",
      "train loss:0.05451498130182829\n",
      "train loss:0.041031439627597234\n",
      "train loss:0.08441646835384936\n",
      "train loss:0.027554274020833644\n",
      "train loss:0.048417016456782626\n",
      "train loss:0.0784751988670196\n",
      "train loss:0.048550342254508896\n",
      "train loss:0.0374988300392293\n",
      "train loss:0.07675594832654714\n",
      "train loss:0.07063466730295241\n",
      "train loss:0.08714369567787221\n",
      "train loss:0.0964039929805562\n",
      "train loss:0.06391124876898313\n",
      "train loss:0.11811378746969042\n",
      "train loss:0.0737448800413775\n",
      "train loss:0.06922024101388011\n",
      "train loss:0.12084410686672246\n",
      "train loss:0.09984483671546533\n",
      "train loss:0.03399638806890141\n",
      "train loss:0.07763929762739943\n",
      "train loss:0.09530835203520174\n",
      "train loss:0.04662868994773692\n",
      "train loss:0.0979101009523832\n",
      "train loss:0.04201421801119537\n",
      "train loss:0.03714113760516947\n",
      "train loss:0.07534920865390837\n",
      "train loss:0.06513754934608426\n",
      "train loss:0.05856476156823707\n",
      "train loss:0.04746991899244565\n",
      "train loss:0.026254233587304526\n",
      "train loss:0.062335367815879825\n",
      "train loss:0.061163111414289734\n",
      "train loss:0.09957481317758576\n",
      "train loss:0.07395106381101874\n",
      "train loss:0.04277013830647946\n",
      "train loss:0.04775046726945705\n",
      "train loss:0.08462798361963535\n",
      "train loss:0.07071839571160123\n",
      "train loss:0.08987182284990482\n",
      "train loss:0.14126401077803197\n",
      "train loss:0.021829098502316083\n",
      "train loss:0.04600403280769808\n",
      "train loss:0.032793695973093444\n",
      "train loss:0.0705397488753015\n",
      "train loss:0.03951095669425166\n",
      "train loss:0.040084870757359725\n",
      "train loss:0.052858331299926606\n",
      "train loss:0.10844365810500702\n",
      "train loss:0.15234467258442697\n",
      "train loss:0.09307003612876745\n",
      "train loss:0.10817272350611763\n",
      "train loss:0.048157805014752704\n",
      "train loss:0.04900952895733144\n",
      "train loss:0.03473842696796802\n",
      "train loss:0.0695050926832642\n",
      "train loss:0.04846003800747225\n",
      "train loss:0.1490763454683257\n",
      "train loss:0.1212371560818998\n",
      "train loss:0.09964874707424168\n",
      "train loss:0.08651459658327103\n",
      "train loss:0.13617402532464387\n",
      "train loss:0.05634193101947549\n",
      "train loss:0.07752185399042544\n",
      "train loss:0.03679184249204434\n",
      "train loss:0.05089860771495317\n",
      "train loss:0.06089821215835498\n",
      "train loss:0.05296055419763297\n",
      "train loss:0.06347912423819982\n",
      "train loss:0.08085850973530008\n",
      "train loss:0.06643351593666963\n",
      "train loss:0.053504937184036774\n",
      "train loss:0.06495556335925019\n",
      "train loss:0.02904886085902002\n",
      "train loss:0.06151777973747756\n",
      "train loss:0.08392229786493786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.10924264531879174\n",
      "train loss:0.05688617772932706\n",
      "train loss:0.057323951643558635\n",
      "train loss:0.0653322170862439\n",
      "train loss:0.1028682845909191\n",
      "train loss:0.09621534610949999\n",
      "train loss:0.04733846189328974\n",
      "train loss:0.03991575436888707\n",
      "train loss:0.08260861921468422\n",
      "train loss:0.07683315932340766\n",
      "train loss:0.09320994622495991\n",
      "train loss:0.10401046627380499\n",
      "train loss:0.1174678051300515\n",
      "train loss:0.03572488674144513\n",
      "train loss:0.0500613006425706\n",
      "train loss:0.043012485364142095\n",
      "train loss:0.04452412132479684\n",
      "train loss:0.07670272017628997\n",
      "train loss:0.05486360833714584\n",
      "train loss:0.05666190952775919\n",
      "train loss:0.07370335392374674\n",
      "train loss:0.10571211241653572\n",
      "train loss:0.13700918114858232\n",
      "train loss:0.057692328069964986\n",
      "train loss:0.032308374918486614\n",
      "train loss:0.04885357172847781\n",
      "train loss:0.06028055450791352\n",
      "train loss:0.07765854754296657\n",
      "train loss:0.0494535758870229\n",
      "train loss:0.0693930724909754\n",
      "train loss:0.07398421836352502\n",
      "train loss:0.07737273185083461\n",
      "train loss:0.03786142270309052\n",
      "train loss:0.07480814153399523\n",
      "train loss:0.07230977921138798\n",
      "train loss:0.038472939985510164\n",
      "train loss:0.11620489731820596\n",
      "train loss:0.059703202168204086\n",
      "train loss:0.10042398584882668\n",
      "train loss:0.049113169484090745\n",
      "train loss:0.08374513704707263\n",
      "train loss:0.04839691824064975\n",
      "train loss:0.04637456737073963\n",
      "train loss:0.07935072447859028\n",
      "train loss:0.05413983639967527\n",
      "train loss:0.027823814814686192\n",
      "train loss:0.054887370923342296\n",
      "train loss:0.06646612169863271\n",
      "train loss:0.06347883337448106\n",
      "train loss:0.0691733701764063\n",
      "train loss:0.09661950087902758\n",
      "train loss:0.042168468385065855\n",
      "train loss:0.03899058198376197\n",
      "train loss:0.1363001540086753\n",
      "train loss:0.07449361824496886\n",
      "train loss:0.051451783704828176\n",
      "train loss:0.041078068939652254\n",
      "train loss:0.016637401133465003\n",
      "train loss:0.09119681038560654\n",
      "train loss:0.03698348937583164\n",
      "train loss:0.06602587790557342\n",
      "train loss:0.09613806333405382\n",
      "train loss:0.05562421586272238\n",
      "train loss:0.14334731305752876\n",
      "train loss:0.049431899156020906\n",
      "train loss:0.0656083983594352\n",
      "train loss:0.09396907798714492\n",
      "train loss:0.07912500767679244\n",
      "train loss:0.12096614499135841\n",
      "train loss:0.11220368670025978\n",
      "train loss:0.0641269396881583\n",
      "train loss:0.041074584525139464\n",
      "train loss:0.12841944137791217\n",
      "train loss:0.062218138893858264\n",
      "train loss:0.11074676079356482\n",
      "train loss:0.08332115766133237\n",
      "train loss:0.09595944992743848\n",
      "train loss:0.06204530605859593\n",
      "train loss:0.029245527505910123\n",
      "train loss:0.12513020412262965\n",
      "train loss:0.12216765109093836\n",
      "train loss:0.12929897981314467\n",
      "train loss:0.09010908677342547\n",
      "train loss:0.06411718862518509\n",
      "train loss:0.0959916488692319\n",
      "train loss:0.02203009080586562\n",
      "train loss:0.13959471385027064\n",
      "train loss:0.06579506164294151\n",
      "train loss:0.06001604061995133\n",
      "train loss:0.07772155997889856\n",
      "train loss:0.05353845607150986\n",
      "train loss:0.10707085595388931\n",
      "train loss:0.035231856473924614\n",
      "train loss:0.05276143840589748\n",
      "train loss:0.08378480239124057\n",
      "train loss:0.04153639512807882\n",
      "train loss:0.05091689480463229\n",
      "train loss:0.06764961357052605\n",
      "train loss:0.10179358905054771\n",
      "train loss:0.07423812697189297\n",
      "train loss:0.024591053414767444\n",
      "train loss:0.08424068167837556\n",
      "train loss:0.06444181023561682\n",
      "train loss:0.10819272494335325\n",
      "train loss:0.05782156379043501\n",
      "train loss:0.036635186700013686\n",
      "train loss:0.08315983447414486\n",
      "train loss:0.19093041579600953\n",
      "train loss:0.04376245142518334\n",
      "train loss:0.09355280540876791\n",
      "train loss:0.054761847457657276\n",
      "train loss:0.03225645751062409\n",
      "train loss:0.043176799169276345\n",
      "train loss:0.07656638922978881\n",
      "train loss:0.030760698470774166\n",
      "train loss:0.07358243899332403\n",
      "train loss:0.07129194590832888\n",
      "train loss:0.03349254654147013\n",
      "train loss:0.121255185509179\n",
      "train loss:0.04939086484427832\n",
      "train loss:0.042887198496561835\n",
      "train loss:0.05871755481707667\n",
      "train loss:0.0735704210051988\n",
      "train loss:0.06453023961951615\n",
      "train loss:0.05526186043310268\n",
      "train loss:0.04775594138105976\n",
      "train loss:0.06540806258836686\n",
      "train loss:0.053329520154448716\n",
      "train loss:0.0975515560144059\n",
      "train loss:0.023796204765591585\n",
      "train loss:0.11885264948444911\n",
      "train loss:0.02980898031670728\n",
      "train loss:0.07787952927760448\n",
      "train loss:0.02816173146070316\n",
      "train loss:0.06301648544529792\n",
      "train loss:0.04410351356067738\n",
      "train loss:0.07443451415433681\n",
      "train loss:0.06826106298387451\n",
      "train loss:0.049289029708027725\n",
      "train loss:0.0532897723686258\n",
      "train loss:0.05401991455180968\n",
      "train loss:0.11580978060795304\n",
      "train loss:0.027752252073264247\n",
      "train loss:0.0875130246629251\n",
      "train loss:0.08992798206783408\n",
      "train loss:0.049867789022234724\n",
      "train loss:0.052765167613189445\n",
      "train loss:0.11043116008564507\n",
      "train loss:0.07623745222847891\n",
      "train loss:0.06915407569960041\n",
      "train loss:0.08785924347372041\n",
      "train loss:0.05660728251743385\n",
      "train loss:0.05606851188989553\n",
      "train loss:0.06781227816444799\n",
      "train loss:0.027445501164608654\n",
      "train loss:0.06096209265807786\n",
      "train loss:0.08375795734710048\n",
      "train loss:0.09871073760146669\n",
      "train loss:0.0338830200419921\n",
      "train loss:0.035338874734782026\n",
      "train loss:0.11217412300079055\n",
      "train loss:0.06939825889766799\n",
      "train loss:0.037880437498376995\n",
      "train loss:0.06479962537687409\n",
      "train loss:0.07404815045754364\n",
      "train loss:0.06255179250190804\n",
      "train loss:0.1404188792586252\n",
      "train loss:0.019067882023074346\n",
      "train loss:0.06740975438684384\n",
      "train loss:0.0534054243493471\n",
      "train loss:0.041219341606112625\n",
      "train loss:0.06370746650972735\n",
      "train loss:0.04761775051475046\n",
      "train loss:0.09059014025891754\n",
      "train loss:0.03297876958427668\n",
      "train loss:0.08397104865094934\n",
      "train loss:0.020892016966777845\n",
      "train loss:0.06933027462960634\n",
      "train loss:0.04331192455558038\n",
      "train loss:0.06334526137136962\n",
      "train loss:0.057967156410593405\n",
      "train loss:0.03634173126972377\n",
      "train loss:0.017714167189550996\n",
      "train loss:0.02265289607646334\n",
      "train loss:0.07966580631004307\n",
      "train loss:0.02326211680517457\n",
      "train loss:0.11892314132507793\n",
      "train loss:0.06859492246806907\n",
      "train loss:0.05993968968453985\n",
      "train loss:0.02904645708441665\n",
      "train loss:0.05248125038784785\n",
      "train loss:0.0375903330314378\n",
      "train loss:0.05721307550029655\n",
      "train loss:0.06228047715086964\n",
      "train loss:0.04398830676296594\n",
      "train loss:0.02982428342925205\n",
      "train loss:0.05084950878040287\n",
      "train loss:0.030807722935684963\n",
      "train loss:0.030150528447347235\n",
      "train loss:0.09446602223214494\n",
      "train loss:0.044829049916298915\n",
      "train loss:0.06884725762512516\n",
      "train loss:0.06354394816539694\n",
      "train loss:0.06107724789501491\n",
      "train loss:0.05480240757815831\n",
      "train loss:0.03715477699868726\n",
      "train loss:0.04068384533053988\n",
      "train loss:0.11826165925859283\n",
      "train loss:0.05489390442188172\n",
      "train loss:0.058315792523891685\n",
      "train loss:0.06478560945715132\n",
      "train loss:0.047781836015817473\n",
      "train loss:0.03252637535686348\n",
      "train loss:0.05315335154724132\n",
      "train loss:0.025477555161421403\n",
      "train loss:0.05059182857004352\n",
      "train loss:0.08217471547982765\n",
      "train loss:0.04155229798450923\n",
      "train loss:0.04018862977802915\n",
      "train loss:0.0961140292744576\n",
      "train loss:0.019598722741610997\n",
      "train loss:0.0559328452621222\n",
      "train loss:0.05322752036202967\n",
      "train loss:0.031630723912838034\n",
      "train loss:0.05063894551404823\n",
      "train loss:0.02230813933611493\n",
      "train loss:0.07803270529580093\n",
      "train loss:0.06886265699213409\n",
      "train loss:0.03595619642656406\n",
      "train loss:0.02978685242000958\n",
      "train loss:0.07693755924951336\n",
      "train loss:0.027906224911264977\n",
      "train loss:0.020869038516966282\n",
      "train loss:0.059001941070975485\n",
      "train loss:0.058239982742826595\n",
      "train loss:0.1582276051398902\n",
      "train loss:0.0332798209425579\n",
      "train loss:0.043539413239422675\n",
      "train loss:0.049970717313758926\n",
      "train loss:0.09355095674645879\n",
      "train loss:0.07626432314103827\n",
      "train loss:0.08020947748068297\n",
      "train loss:0.06219745206200576\n",
      "train loss:0.06372288315834206\n",
      "train loss:0.053008962473635644\n",
      "train loss:0.06822079663009573\n",
      "train loss:0.09025945708859398\n",
      "train loss:0.04841478846774023\n",
      "train loss:0.054778784247863\n",
      "train loss:0.051371508426879264\n",
      "train loss:0.06525130085782642\n",
      "train loss:0.042914494304308104\n",
      "train loss:0.06842532495317444\n",
      "train loss:0.026413398141979214\n",
      "train loss:0.029228794172300985\n",
      "train loss:0.20942740091055279\n",
      "train loss:0.01996873154120285\n",
      "train loss:0.06041465865264718\n",
      "train loss:0.03494850304161078\n",
      "train loss:0.0271410189491598\n",
      "train loss:0.06618484143590268\n",
      "train loss:0.05194259780701341\n",
      "train loss:0.0508559198518635\n",
      "train loss:0.10335521869963017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.06837640298393342\n",
      "train loss:0.06769429471154166\n",
      "=== epoch:21, train acc:0.978, test acc:0.908 ===\n",
      "train loss:0.0815425344862688\n",
      "train loss:0.052698870986042444\n",
      "train loss:0.015623799231289535\n",
      "train loss:0.03282426508768742\n",
      "train loss:0.04555362132400884\n",
      "train loss:0.12150222600924232\n",
      "train loss:0.061313184664542664\n",
      "train loss:0.06768864503532016\n",
      "train loss:0.0838019546472383\n",
      "train loss:0.080837526382131\n",
      "train loss:0.05093187966435101\n",
      "train loss:0.04802735497545964\n",
      "train loss:0.06878585908811816\n",
      "train loss:0.09689145842918424\n",
      "train loss:0.07458832654039735\n",
      "train loss:0.024950240082576024\n",
      "train loss:0.16557153302887964\n",
      "train loss:0.040120772169707344\n",
      "train loss:0.09934376470056155\n",
      "train loss:0.1248134159983031\n",
      "train loss:0.06169217149690223\n",
      "train loss:0.07764524317469766\n",
      "train loss:0.048147500351264395\n",
      "train loss:0.062433269635004916\n",
      "train loss:0.026701481276498185\n",
      "train loss:0.10340282969816289\n",
      "train loss:0.036707517978976534\n",
      "train loss:0.07648290721765584\n",
      "train loss:0.027916457287032685\n",
      "train loss:0.04042741303280217\n",
      "train loss:0.04988884739095563\n",
      "train loss:0.038372463835771836\n",
      "train loss:0.09774275633763972\n",
      "train loss:0.047121696653856925\n",
      "train loss:0.04796473868814078\n",
      "train loss:0.044523093732553747\n",
      "train loss:0.052773121278265694\n",
      "train loss:0.14060665669482061\n",
      "train loss:0.03436552741822806\n",
      "train loss:0.032833979776231786\n",
      "train loss:0.06170741019034734\n",
      "train loss:0.06778101439805637\n",
      "train loss:0.08360275518945447\n",
      "train loss:0.053965288513304205\n",
      "train loss:0.056694632106909906\n",
      "train loss:0.031418784975074415\n",
      "train loss:0.11586485484160049\n",
      "train loss:0.09571648762580395\n",
      "train loss:0.11862672823918073\n",
      "train loss:0.05132636746600791\n",
      "train loss:0.10487582502820705\n",
      "train loss:0.03739879063203575\n",
      "train loss:0.08953928070695788\n",
      "train loss:0.046430479069001745\n",
      "train loss:0.04377552171644657\n",
      "train loss:0.0774198655485846\n",
      "train loss:0.04160103827255654\n",
      "train loss:0.06410652858067663\n",
      "train loss:0.04010049493840964\n",
      "train loss:0.034708521350278077\n",
      "train loss:0.06403513929151244\n",
      "train loss:0.08940554898702907\n",
      "train loss:0.0701534271482382\n",
      "train loss:0.07432874222511025\n",
      "train loss:0.09962783138101917\n",
      "train loss:0.03648542863208756\n",
      "train loss:0.06294621620110051\n",
      "train loss:0.04117318419700415\n",
      "train loss:0.041883255062106314\n",
      "train loss:0.025439877559771715\n",
      "train loss:0.103822848673685\n",
      "train loss:0.02824757198793128\n",
      "train loss:0.05162056778828917\n",
      "train loss:0.05292830493293951\n",
      "train loss:0.056251278303916435\n",
      "train loss:0.09475041684231242\n",
      "train loss:0.14520410895829716\n",
      "train loss:0.02177937528144404\n",
      "train loss:0.03189573425101743\n",
      "train loss:0.072242534374206\n",
      "train loss:0.03051265489733079\n",
      "train loss:0.18509061433408808\n",
      "train loss:0.09239350575826265\n",
      "train loss:0.038313993050151735\n",
      "train loss:0.03154447145569577\n",
      "train loss:0.04312068177358391\n",
      "train loss:0.10129636706204953\n",
      "train loss:0.02613265155135709\n",
      "train loss:0.06028997486143244\n",
      "train loss:0.055872265103043856\n",
      "train loss:0.08821855082762964\n",
      "train loss:0.04262338349172308\n",
      "train loss:0.05298509724208796\n",
      "train loss:0.039709252060429905\n",
      "train loss:0.06579460209114701\n",
      "train loss:0.05949865082541853\n",
      "train loss:0.07654927942280397\n",
      "train loss:0.0467377945513543\n",
      "train loss:0.0719941803210544\n",
      "train loss:0.09841830031249214\n",
      "train loss:0.031124962866214804\n",
      "train loss:0.039754758484836956\n",
      "train loss:0.034854967424095856\n",
      "train loss:0.07431509897377409\n",
      "train loss:0.08224835333653667\n",
      "train loss:0.04761887448045085\n",
      "train loss:0.05859951256031873\n",
      "train loss:0.028177707169082432\n",
      "train loss:0.02418614045860549\n",
      "train loss:0.09875514193000204\n",
      "train loss:0.08669787372265172\n",
      "train loss:0.09085533709531711\n",
      "train loss:0.019961580014460467\n",
      "train loss:0.04836048069745246\n",
      "train loss:0.044350928200715546\n",
      "train loss:0.047540447851823264\n",
      "train loss:0.05194508782666018\n",
      "train loss:0.020622702316852037\n",
      "train loss:0.10935597299291427\n",
      "train loss:0.0349959489890776\n",
      "train loss:0.0501736461249013\n",
      "train loss:0.14282759504613846\n",
      "train loss:0.04278033016912414\n",
      "train loss:0.03971685432741647\n",
      "train loss:0.05735879154028419\n",
      "train loss:0.1019952641259717\n",
      "train loss:0.026494625507564512\n",
      "train loss:0.0448246355189295\n",
      "train loss:0.05702359138215888\n",
      "train loss:0.0629639337543518\n",
      "train loss:0.09537285277882161\n",
      "train loss:0.06671573652813616\n",
      "train loss:0.032564776203092054\n",
      "train loss:0.05824270894195825\n",
      "train loss:0.026946564205438304\n",
      "train loss:0.02688761490532502\n",
      "train loss:0.08918528680157363\n",
      "train loss:0.037369211108094824\n",
      "train loss:0.12846388030209038\n",
      "train loss:0.053050240671211155\n",
      "train loss:0.04680036363669176\n",
      "train loss:0.06917614500885728\n",
      "train loss:0.08548311689690152\n",
      "train loss:0.044232102375814854\n",
      "train loss:0.06330548733394484\n",
      "train loss:0.02079146160514215\n",
      "train loss:0.060870603743657846\n",
      "train loss:0.045794406033528696\n",
      "train loss:0.10450590003879577\n",
      "train loss:0.04369650378557315\n",
      "train loss:0.03607620734325337\n",
      "train loss:0.15389965927375265\n",
      "train loss:0.09609071603187216\n",
      "train loss:0.09351394601678749\n",
      "train loss:0.06798746547429725\n",
      "train loss:0.02620454791982445\n",
      "train loss:0.024731144066748225\n",
      "train loss:0.05890439182539117\n",
      "train loss:0.07958348575463779\n",
      "train loss:0.08335623585251421\n",
      "train loss:0.1410502002119189\n",
      "train loss:0.022937442878043012\n",
      "train loss:0.0792520652203297\n",
      "train loss:0.022159463530782148\n",
      "train loss:0.06421331342977701\n",
      "train loss:0.08258031097159907\n",
      "train loss:0.042413854503055334\n",
      "train loss:0.04633189641957391\n",
      "train loss:0.036809739483463805\n",
      "train loss:0.0385568793619609\n",
      "train loss:0.16111836017824469\n",
      "train loss:0.07014327109952817\n",
      "train loss:0.02692000646802814\n",
      "train loss:0.060603468144629004\n",
      "train loss:0.06809987596945899\n",
      "train loss:0.04966693253115331\n",
      "train loss:0.03699406196900389\n",
      "train loss:0.038612881649311113\n",
      "train loss:0.06122094751810172\n",
      "train loss:0.04538300124708966\n",
      "train loss:0.06870000327902834\n",
      "train loss:0.06537820223594273\n",
      "train loss:0.05943372863390348\n",
      "train loss:0.04042014878466576\n",
      "train loss:0.03279668845438336\n",
      "train loss:0.06297741267580503\n",
      "train loss:0.0655604903593474\n",
      "train loss:0.0657955181294836\n",
      "train loss:0.055498323472872764\n",
      "train loss:0.07561183993010342\n",
      "train loss:0.0201808042423027\n",
      "train loss:0.03015078944135074\n",
      "train loss:0.029584366596195354\n",
      "train loss:0.10703015632519465\n",
      "train loss:0.04275563836063473\n",
      "train loss:0.04553538692701549\n",
      "train loss:0.07133317259446327\n",
      "train loss:0.05982746460667726\n",
      "train loss:0.042979719414165805\n",
      "train loss:0.03204438337905027\n",
      "train loss:0.053150930485779596\n",
      "train loss:0.06822594710604857\n",
      "train loss:0.05911521738021367\n",
      "train loss:0.14880754598472956\n",
      "train loss:0.0827803558944168\n",
      "train loss:0.040659570670452956\n",
      "train loss:0.0712421060893662\n",
      "train loss:0.090359814911539\n",
      "train loss:0.047734467432746744\n",
      "train loss:0.039853239921963365\n",
      "train loss:0.08141152762718501\n",
      "train loss:0.03321831393160237\n",
      "train loss:0.0959098956712455\n",
      "train loss:0.05733659797678179\n",
      "train loss:0.05478033612001003\n",
      "train loss:0.17475163243400524\n",
      "train loss:0.04972162544987611\n",
      "train loss:0.0580009654125137\n",
      "train loss:0.11244204182410765\n",
      "train loss:0.043130813165546844\n",
      "train loss:0.04622946464742534\n",
      "train loss:0.05600846395828916\n",
      "train loss:0.07031306459096183\n",
      "train loss:0.04876394658022088\n",
      "train loss:0.02533446468924427\n",
      "train loss:0.060482610863372734\n",
      "train loss:0.014860495591599894\n",
      "train loss:0.04508480066497101\n",
      "train loss:0.08405244048985228\n",
      "train loss:0.11836705849037976\n",
      "train loss:0.05898193880582547\n",
      "train loss:0.05125384713874841\n",
      "train loss:0.08974143584369827\n",
      "train loss:0.05189768490865092\n",
      "train loss:0.03742918325936885\n",
      "train loss:0.03901536036772867\n",
      "train loss:0.0850958520531845\n",
      "train loss:0.04683029256491517\n",
      "train loss:0.02999639484586002\n",
      "train loss:0.1556614062116571\n",
      "train loss:0.031887000992458364\n",
      "train loss:0.04134517062987604\n",
      "train loss:0.05284759225060639\n",
      "train loss:0.044404160473541295\n",
      "train loss:0.05946849623491266\n",
      "train loss:0.025114045190782044\n",
      "train loss:0.07240032696648052\n",
      "train loss:0.054152184594454714\n",
      "train loss:0.0992124381471649\n",
      "train loss:0.0588382819557626\n",
      "train loss:0.04440695029555032\n",
      "train loss:0.058128685424982916\n",
      "train loss:0.08358560040782714\n",
      "train loss:0.12433979014337464\n",
      "train loss:0.08079883324507248\n",
      "train loss:0.03129142125362091\n",
      "train loss:0.07047533242879189\n",
      "train loss:0.05754468613120687\n",
      "train loss:0.06634192018384402\n",
      "train loss:0.03022239069373461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.08490294488150858\n",
      "train loss:0.023216246240085177\n",
      "train loss:0.10514162375786378\n",
      "train loss:0.03754980715288695\n",
      "train loss:0.08194044409661631\n",
      "train loss:0.10790826723096857\n",
      "train loss:0.03751243984004133\n",
      "train loss:0.08545519921841532\n",
      "train loss:0.014426465825567865\n",
      "train loss:0.03806343474888948\n",
      "train loss:0.08639613244542144\n",
      "train loss:0.059630663935585436\n",
      "train loss:0.06050029730295952\n",
      "train loss:0.030915527790113\n",
      "train loss:0.053032210916120474\n",
      "train loss:0.09336846241579064\n",
      "train loss:0.04205188690649709\n",
      "train loss:0.07517307437328825\n",
      "train loss:0.04319076242288314\n",
      "train loss:0.07068638722553343\n",
      "train loss:0.015464002772611967\n",
      "train loss:0.0584874922726186\n",
      "train loss:0.07880838741560207\n",
      "train loss:0.09456367826113725\n",
      "train loss:0.04677915164827758\n",
      "train loss:0.06148968138409344\n",
      "train loss:0.06030153259538036\n",
      "train loss:0.05684508139328335\n",
      "train loss:0.02609367492176852\n",
      "train loss:0.044443016307434906\n",
      "train loss:0.08692037082272577\n",
      "train loss:0.04163434455309563\n",
      "train loss:0.05748532081324608\n",
      "train loss:0.1254745950295193\n",
      "train loss:0.09788516881765606\n",
      "train loss:0.032328206643572804\n",
      "train loss:0.09922057767095292\n",
      "train loss:0.02506991036643212\n",
      "train loss:0.060545097660599526\n",
      "train loss:0.10417162195648438\n",
      "train loss:0.03810448948548043\n",
      "train loss:0.09161025593578928\n",
      "train loss:0.09648852837877776\n",
      "train loss:0.09157149630192934\n",
      "train loss:0.12277518938647111\n",
      "train loss:0.062119992904352\n",
      "train loss:0.06353411735576849\n",
      "train loss:0.028149536886672405\n",
      "train loss:0.052159947963567384\n",
      "train loss:0.0573719407796608\n",
      "train loss:0.07332312703505452\n",
      "train loss:0.06368379964699543\n",
      "train loss:0.0990592105415342\n",
      "train loss:0.02655501107344294\n",
      "train loss:0.021617092166402823\n",
      "train loss:0.030086602314503882\n",
      "train loss:0.0405114434423572\n",
      "train loss:0.09664244106456313\n",
      "train loss:0.05920711011493381\n",
      "train loss:0.052601976806714086\n",
      "train loss:0.07749146299581712\n",
      "train loss:0.014219072595559303\n",
      "train loss:0.04405710023477547\n",
      "train loss:0.10362167992958553\n",
      "train loss:0.033228544714974856\n",
      "train loss:0.01844513853621348\n",
      "train loss:0.03775874937054905\n",
      "train loss:0.029814200376273758\n",
      "train loss:0.10009990217472493\n",
      "train loss:0.03584631737610963\n",
      "train loss:0.037461022373249594\n",
      "train loss:0.034547796932854286\n",
      "train loss:0.018034066540042793\n",
      "train loss:0.034571023207982464\n",
      "train loss:0.08982241137536683\n",
      "train loss:0.06516926783202297\n",
      "train loss:0.07875629488259688\n",
      "train loss:0.12078044873958667\n",
      "train loss:0.0761550977490594\n",
      "train loss:0.021006607424147082\n",
      "train loss:0.03951906101183343\n",
      "train loss:0.07853487283623296\n",
      "train loss:0.03686126299359533\n",
      "train loss:0.06067520575467917\n",
      "train loss:0.04374579522246817\n",
      "train loss:0.018872227563933548\n",
      "train loss:0.06204727227817102\n",
      "train loss:0.06710009208551368\n",
      "train loss:0.048718920619188914\n",
      "train loss:0.04293433181687512\n",
      "train loss:0.0743045284746428\n",
      "train loss:0.06542292070306473\n",
      "train loss:0.01947326711786095\n",
      "train loss:0.0537006434630423\n",
      "train loss:0.03332157645391447\n",
      "train loss:0.07385475530519997\n",
      "train loss:0.04015455184154474\n",
      "train loss:0.06615338524524313\n",
      "train loss:0.03816335003947009\n",
      "train loss:0.08184924421520451\n",
      "train loss:0.0720644324989466\n",
      "train loss:0.037099052581250125\n",
      "train loss:0.03455570470441142\n",
      "train loss:0.04551095163591568\n",
      "train loss:0.03391363227907054\n",
      "train loss:0.020813520886647188\n",
      "train loss:0.1271549139771973\n",
      "train loss:0.06316581771560016\n",
      "train loss:0.03676803465224866\n",
      "train loss:0.057778357375011906\n",
      "train loss:0.07221414491240294\n",
      "train loss:0.027123338637504078\n",
      "train loss:0.04610052497328046\n",
      "train loss:0.05155877407322536\n",
      "train loss:0.039997457284808115\n",
      "train loss:0.031242904594407497\n",
      "train loss:0.02851385382272292\n",
      "train loss:0.07287421555449992\n",
      "train loss:0.12443727494059535\n",
      "train loss:0.03388644472047185\n",
      "train loss:0.04831033095850424\n",
      "train loss:0.030601608774748854\n",
      "train loss:0.019000199525907757\n",
      "train loss:0.05698921450758958\n",
      "train loss:0.07756447483898808\n",
      "train loss:0.04743584324193708\n",
      "train loss:0.03716405282305508\n",
      "train loss:0.02555035453790996\n",
      "train loss:0.037664663762555464\n",
      "train loss:0.03617549545155249\n",
      "train loss:0.016895222926331475\n",
      "train loss:0.0965081373945253\n",
      "train loss:0.02995951079623318\n",
      "train loss:0.018550061421430876\n",
      "train loss:0.06144697312640854\n",
      "train loss:0.06705137062219407\n",
      "train loss:0.037689388028551284\n",
      "train loss:0.029205475922736653\n",
      "train loss:0.07153311032149932\n",
      "train loss:0.07132959965937861\n",
      "train loss:0.029707346545123556\n",
      "train loss:0.1059726952781169\n",
      "train loss:0.06304787500892756\n",
      "train loss:0.05662905094976284\n",
      "train loss:0.08792100504089026\n",
      "train loss:0.04860900071410239\n",
      "train loss:0.08873186073173032\n",
      "train loss:0.05078205041982466\n",
      "train loss:0.03298452178967334\n",
      "train loss:0.04863345594284267\n",
      "train loss:0.018720709470279127\n",
      "train loss:0.028793028872702995\n",
      "train loss:0.12208218652342497\n",
      "train loss:0.060203113120621196\n",
      "train loss:0.1354373892024495\n",
      "train loss:0.04031613282223716\n",
      "train loss:0.09182881880028605\n",
      "train loss:0.03536004162522251\n",
      "train loss:0.035301375204678395\n",
      "train loss:0.0399838619152441\n",
      "train loss:0.04961739316162443\n",
      "train loss:0.040604220197287245\n",
      "train loss:0.10889986694988142\n",
      "train loss:0.065063189694582\n",
      "train loss:0.054109029410589767\n",
      "train loss:0.02125649135835774\n",
      "train loss:0.0579210315053362\n",
      "train loss:0.05692629194122803\n",
      "train loss:0.06366850474457611\n",
      "train loss:0.06491997453555821\n",
      "train loss:0.02611659046697125\n",
      "train loss:0.028116936830539042\n",
      "train loss:0.07689869372970952\n",
      "train loss:0.06126630398107942\n",
      "train loss:0.030027904332590723\n",
      "train loss:0.027215625583611586\n",
      "train loss:0.07014130253737749\n",
      "train loss:0.06588579950064258\n",
      "train loss:0.06415628398692622\n",
      "train loss:0.04023422746023776\n",
      "train loss:0.04491017086841421\n",
      "train loss:0.08794644185531986\n",
      "train loss:0.03522492724517497\n",
      "train loss:0.06925509891461298\n",
      "train loss:0.033227464880627194\n",
      "train loss:0.04633120395138816\n",
      "train loss:0.1014100707436506\n",
      "train loss:0.03793389518882176\n",
      "train loss:0.03200656060249021\n",
      "train loss:0.04174354707221908\n",
      "train loss:0.027360636124810343\n",
      "train loss:0.04501947361649273\n",
      "train loss:0.054009779927494304\n",
      "train loss:0.07493636927669454\n",
      "train loss:0.11204345523103715\n",
      "train loss:0.030713464326415068\n",
      "train loss:0.05764698542651593\n",
      "train loss:0.03265563913945882\n",
      "train loss:0.023697570383334553\n",
      "train loss:0.07500732160769133\n",
      "train loss:0.08416324685451966\n",
      "train loss:0.07463598367912692\n",
      "train loss:0.060726085147631066\n",
      "train loss:0.049963514788749545\n",
      "train loss:0.09518312113465578\n",
      "train loss:0.039082246622032926\n",
      "train loss:0.05117535253588251\n",
      "train loss:0.08242246747968723\n",
      "train loss:0.06233209351716566\n",
      "train loss:0.06091956478161296\n",
      "train loss:0.06522092366219215\n",
      "train loss:0.054052538966620274\n",
      "train loss:0.12853563578129112\n",
      "train loss:0.09498269999215424\n",
      "train loss:0.04705383350706816\n",
      "train loss:0.06468070108587196\n",
      "train loss:0.02247299373605452\n",
      "train loss:0.09551119366572002\n",
      "train loss:0.02653996359507568\n",
      "train loss:0.0930658508562851\n",
      "train loss:0.07487818295290027\n",
      "train loss:0.05599619017832123\n",
      "train loss:0.03772760912830335\n",
      "train loss:0.03203699092189625\n",
      "train loss:0.04028133065019037\n",
      "train loss:0.03383442873575855\n",
      "train loss:0.034469147534620055\n",
      "train loss:0.017157671022070085\n",
      "train loss:0.042253933007562056\n",
      "train loss:0.06848932527362858\n",
      "train loss:0.07358807471521878\n",
      "train loss:0.012149138610410478\n",
      "train loss:0.055262288468776725\n",
      "train loss:0.04347310141314486\n",
      "train loss:0.0316544761113189\n",
      "train loss:0.03873800748187172\n",
      "train loss:0.05140810293683363\n",
      "train loss:0.04091350482489116\n",
      "train loss:0.09649802425619733\n",
      "train loss:0.07079673831851788\n",
      "train loss:0.07495697211384247\n",
      "train loss:0.036644583675495876\n",
      "train loss:0.07782510351138666\n",
      "train loss:0.024009642617195057\n",
      "train loss:0.06495812371858499\n",
      "train loss:0.04033891313059944\n",
      "train loss:0.0451801696052869\n",
      "train loss:0.06016100616282737\n",
      "train loss:0.049778163376751526\n",
      "train loss:0.13455613437876623\n",
      "train loss:0.048746777181123004\n",
      "train loss:0.06486402407851688\n",
      "train loss:0.06273876053502664\n",
      "train loss:0.02677867844355484\n",
      "train loss:0.04519617732973409\n",
      "train loss:0.04943856058702119\n",
      "train loss:0.04670785836004824\n",
      "train loss:0.06708172849410342\n",
      "train loss:0.10229022601468228\n",
      "train loss:0.03694223099515092\n",
      "train loss:0.0594342325729924\n",
      "train loss:0.04839781526454237\n",
      "train loss:0.03170440490879583\n",
      "train loss:0.05408845912725509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.06438976059269125\n",
      "train loss:0.036900820638298235\n",
      "train loss:0.0647589318615167\n",
      "train loss:0.05981181083965328\n",
      "train loss:0.062167782661971434\n",
      "train loss:0.062331755389601146\n",
      "train loss:0.034590170462450984\n",
      "train loss:0.021057033990483115\n",
      "train loss:0.11248202406626612\n",
      "train loss:0.03025074507151639\n",
      "train loss:0.03508337392560523\n",
      "train loss:0.0441804174828335\n",
      "train loss:0.015477968247048546\n",
      "train loss:0.036376212632746624\n",
      "train loss:0.0669753764775248\n",
      "train loss:0.03113445281778047\n",
      "train loss:0.03208269759553741\n",
      "train loss:0.04832395751704304\n",
      "train loss:0.018122420133049082\n",
      "train loss:0.07625794015781033\n",
      "train loss:0.05093571155345922\n",
      "train loss:0.04051333645388195\n",
      "train loss:0.04928540468034566\n",
      "train loss:0.035312307538078326\n",
      "train loss:0.03206187347063752\n",
      "train loss:0.04005577550719197\n",
      "train loss:0.03126556213215173\n",
      "train loss:0.059676006057772124\n",
      "train loss:0.02682386556020865\n",
      "train loss:0.03444096206811059\n",
      "train loss:0.02815242935084794\n",
      "train loss:0.0598611441009551\n",
      "train loss:0.03368964927438717\n",
      "train loss:0.052441880961488566\n",
      "train loss:0.02803750630010729\n",
      "train loss:0.03239894638196948\n",
      "train loss:0.12961999292776893\n",
      "train loss:0.06312655743049347\n",
      "train loss:0.01731442166854459\n",
      "train loss:0.01775537952874187\n",
      "train loss:0.07154388651386623\n",
      "train loss:0.04096210169051696\n",
      "train loss:0.06187058958526101\n",
      "train loss:0.07229173973220193\n",
      "train loss:0.030524585142747574\n",
      "train loss:0.05417485094903718\n",
      "train loss:0.03855772867067573\n",
      "train loss:0.05536071191511387\n",
      "train loss:0.0442018751678015\n",
      "train loss:0.06609025629851079\n",
      "train loss:0.03659008408276849\n",
      "train loss:0.08533052431045561\n",
      "train loss:0.021896541203363956\n",
      "train loss:0.051466300338158355\n",
      "train loss:0.04059027358431951\n",
      "train loss:0.04429808776894166\n",
      "train loss:0.09143108643559422\n",
      "train loss:0.03133377039779859\n",
      "train loss:0.013090941593735668\n",
      "train loss:0.06971752112380945\n",
      "train loss:0.04201342234709507\n",
      "train loss:0.04595255422592576\n",
      "train loss:0.05130250135287596\n",
      "train loss:0.09367332550095087\n",
      "train loss:0.04054126497937749\n",
      "train loss:0.1338025730471121\n",
      "train loss:0.03658059734006919\n",
      "train loss:0.09722102973386866\n",
      "train loss:0.07135990344530767\n",
      "train loss:0.07200285178640614\n",
      "train loss:0.05078871916809435\n",
      "train loss:0.046519465948191244\n",
      "train loss:0.0565253581612542\n",
      "train loss:0.03870500673095995\n",
      "train loss:0.09855476188645777\n",
      "train loss:0.019954032303049297\n",
      "=== epoch:22, train acc:0.982, test acc:0.91 ===\n",
      "train loss:0.0680045736251746\n",
      "train loss:0.021000375057423824\n",
      "train loss:0.06739960814260879\n",
      "train loss:0.05815184447269015\n",
      "train loss:0.03881566590525316\n",
      "train loss:0.03887674030819604\n",
      "train loss:0.04492115883692985\n",
      "train loss:0.11895181435937091\n",
      "train loss:0.037167821444656676\n",
      "train loss:0.04734190076834819\n",
      "train loss:0.025089745423682405\n",
      "train loss:0.04636786056133485\n",
      "train loss:0.03930366585911731\n",
      "train loss:0.05283406225379925\n",
      "train loss:0.04115639292306291\n",
      "train loss:0.029654480644247326\n",
      "train loss:0.039583624119933034\n",
      "train loss:0.03365332078290185\n",
      "train loss:0.013122747637837329\n",
      "train loss:0.04521720888363409\n",
      "train loss:0.09640517655241997\n",
      "train loss:0.05966585859891199\n",
      "train loss:0.021993729539118524\n",
      "train loss:0.04095212467026373\n",
      "train loss:0.05653337991740977\n",
      "train loss:0.028296396646847827\n",
      "train loss:0.09468926859624477\n",
      "train loss:0.04041820697929432\n",
      "train loss:0.06816579588251448\n",
      "train loss:0.08163291854389394\n",
      "train loss:0.04641701927768307\n",
      "train loss:0.04413394329142933\n",
      "train loss:0.04753260473962561\n",
      "train loss:0.04419523784398341\n",
      "train loss:0.07656936413882798\n",
      "train loss:0.08589381976763587\n",
      "train loss:0.05262351686904997\n",
      "train loss:0.02470589871533094\n",
      "train loss:0.024335832381002315\n",
      "train loss:0.0819877478591334\n",
      "train loss:0.06370762517522859\n",
      "train loss:0.037371380906705214\n",
      "train loss:0.04381051743577787\n",
      "train loss:0.06898019274219708\n",
      "train loss:0.09277487540195078\n",
      "train loss:0.07765237609445351\n",
      "train loss:0.06670029468325724\n",
      "train loss:0.027272264323212676\n",
      "train loss:0.04232613387450585\n",
      "train loss:0.06431685816089597\n",
      "train loss:0.04626099371733523\n",
      "train loss:0.07158730930576816\n",
      "train loss:0.04635160337570917\n",
      "train loss:0.09151840580039121\n",
      "train loss:0.10777491093649091\n",
      "train loss:0.016432097890065764\n",
      "train loss:0.07279256719110846\n",
      "train loss:0.0316006694653258\n",
      "train loss:0.043950042491412294\n",
      "train loss:0.06737901363763592\n",
      "train loss:0.03520271872497337\n",
      "train loss:0.0779896092658521\n",
      "train loss:0.06586851848451893\n",
      "train loss:0.02382558043420089\n",
      "train loss:0.0862560377357899\n",
      "train loss:0.029558616882343333\n",
      "train loss:0.05314845471096759\n",
      "train loss:0.060410150468801514\n",
      "train loss:0.0450750653377409\n",
      "train loss:0.05947322216289885\n",
      "train loss:0.0842048703880737\n",
      "train loss:0.05393123229832501\n",
      "train loss:0.0487683081731977\n",
      "train loss:0.02725575540535535\n",
      "train loss:0.1072950132575354\n",
      "train loss:0.08696828006825387\n",
      "train loss:0.01969990868345521\n",
      "train loss:0.04810903105582105\n",
      "train loss:0.05322713578254693\n",
      "train loss:0.06025430876256423\n",
      "train loss:0.013611094415258302\n",
      "train loss:0.021516546437114106\n",
      "train loss:0.058082521785009854\n",
      "train loss:0.03836136595951143\n",
      "train loss:0.06870979477338289\n",
      "train loss:0.04372182482511336\n",
      "train loss:0.04818446600789991\n",
      "train loss:0.040557292793726225\n",
      "train loss:0.096563036090282\n",
      "train loss:0.06022221778211779\n",
      "train loss:0.09986490155518565\n",
      "train loss:0.019763066640139996\n",
      "train loss:0.045130012960463324\n",
      "train loss:0.021278843659704175\n",
      "train loss:0.04804826723084253\n",
      "train loss:0.0669405131728788\n",
      "train loss:0.025322645805076042\n",
      "train loss:0.03135167609159946\n",
      "train loss:0.08439475769758825\n",
      "train loss:0.039407836820979064\n",
      "train loss:0.09191391355967946\n",
      "train loss:0.029563872952792326\n",
      "train loss:0.11366271380557284\n",
      "train loss:0.01961654138014406\n",
      "train loss:0.059441304419088375\n",
      "train loss:0.035972984126366285\n",
      "train loss:0.03848358028307994\n",
      "train loss:0.032384002467705474\n",
      "train loss:0.07139190792450349\n",
      "train loss:0.04671927876923052\n",
      "train loss:0.022399443149074695\n",
      "train loss:0.03471226370470733\n",
      "train loss:0.027524456819544244\n",
      "train loss:0.04104390616535917\n",
      "train loss:0.10749450564492757\n",
      "train loss:0.05750736420229018\n",
      "train loss:0.012424820475975533\n",
      "train loss:0.07107458715822042\n",
      "train loss:0.03741768981690793\n",
      "train loss:0.07970545750138552\n",
      "train loss:0.0180872167119402\n",
      "train loss:0.031101057928658343\n",
      "train loss:0.04316079519468295\n",
      "train loss:0.0436897781961392\n",
      "train loss:0.02532023255471101\n",
      "train loss:0.04455441461074273\n",
      "train loss:0.14184274958424767\n",
      "train loss:0.04651953589851985\n",
      "train loss:0.033422196254836944\n",
      "train loss:0.08153035152515914\n",
      "train loss:0.027446959574782027\n",
      "train loss:0.09687229817919013\n",
      "train loss:0.047575797199618214\n",
      "train loss:0.02979652899295529\n",
      "train loss:0.08057184250578979\n",
      "train loss:0.0969397780611613\n",
      "train loss:0.027464371979681778\n",
      "train loss:0.06406790894380625\n",
      "train loss:0.05566686850745382\n",
      "train loss:0.05058191344622033\n",
      "train loss:0.05002858418318169\n",
      "train loss:0.06306555208496452\n",
      "train loss:0.04013471714689801\n",
      "train loss:0.018105645493695297\n",
      "train loss:0.07342309838894509\n",
      "train loss:0.05816669212651305\n",
      "train loss:0.05634017343764157\n",
      "train loss:0.03577023306485742\n",
      "train loss:0.03913820116528441\n",
      "train loss:0.06003694118933704\n",
      "train loss:0.0925549576255017\n",
      "train loss:0.07771547485072144\n",
      "train loss:0.07113468007674299\n",
      "train loss:0.10860325461621446\n",
      "train loss:0.078115047653321\n",
      "train loss:0.04849643152485864\n",
      "train loss:0.06527280189497164\n",
      "train loss:0.042455666457102144\n",
      "train loss:0.04197085205839071\n",
      "train loss:0.03531394807705709\n",
      "train loss:0.029979841608310555\n",
      "train loss:0.05361753676700501\n",
      "train loss:0.0921770044534695\n",
      "train loss:0.10431821468580296\n",
      "train loss:0.04323271346399601\n",
      "train loss:0.07517197858146828\n",
      "train loss:0.051438446497906895\n",
      "train loss:0.08655197437701868\n",
      "train loss:0.016087101893698323\n",
      "train loss:0.059245342574815535\n",
      "train loss:0.04007044594670557\n",
      "train loss:0.06506613752754538\n",
      "train loss:0.07058808078276335\n",
      "train loss:0.06479465858042283\n",
      "train loss:0.02735555240118262\n",
      "train loss:0.08462140629856804\n",
      "train loss:0.058436861051058386\n",
      "train loss:0.028478612253078826\n",
      "train loss:0.03835480454309134\n",
      "train loss:0.03492796591445983\n",
      "train loss:0.0884596848429341\n",
      "train loss:0.08284092786771322\n",
      "train loss:0.03297101821376567\n",
      "train loss:0.02079934568919295\n",
      "train loss:0.09658862641102763\n",
      "train loss:0.08987888082701323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.08677714495881983\n",
      "train loss:0.04433166393299139\n",
      "train loss:0.02463440862469716\n",
      "train loss:0.10343950983709922\n",
      "train loss:0.04781606155869409\n",
      "train loss:0.08929280256584217\n",
      "train loss:0.05893630001935552\n",
      "train loss:0.022697872886659982\n",
      "train loss:0.06523966264143712\n",
      "train loss:0.03237794890981467\n",
      "train loss:0.03162329064247378\n",
      "train loss:0.12152172523628264\n",
      "train loss:0.07829643949556257\n",
      "train loss:0.04407222160682951\n",
      "train loss:0.06633300017755857\n",
      "train loss:0.04826196359827908\n",
      "train loss:0.09823368120236531\n",
      "train loss:0.07994959338056776\n",
      "train loss:0.025715918131820188\n",
      "train loss:0.04103265893674634\n",
      "train loss:0.06407362226783606\n",
      "train loss:0.04721744015801794\n",
      "train loss:0.04030561141892672\n",
      "train loss:0.04145916422466049\n",
      "train loss:0.053680332846043184\n",
      "train loss:0.03447005685955825\n",
      "train loss:0.06774106289848804\n",
      "train loss:0.09188930660741176\n",
      "train loss:0.023068385472859297\n",
      "train loss:0.035744394283554325\n",
      "train loss:0.04056091053007927\n",
      "train loss:0.04041146102618667\n",
      "train loss:0.10483409448102358\n",
      "train loss:0.059197480379504036\n",
      "train loss:0.06569145716053286\n",
      "train loss:0.052669041264352706\n",
      "train loss:0.0506569362720117\n",
      "train loss:0.04646617162915305\n",
      "train loss:0.05399003715931936\n",
      "train loss:0.032032234449691714\n",
      "train loss:0.07194912848897678\n",
      "train loss:0.05895606903240111\n",
      "train loss:0.04564117547562288\n",
      "train loss:0.1045165385760436\n",
      "train loss:0.07714101790535027\n",
      "train loss:0.0546417953004343\n",
      "train loss:0.08418410621316845\n",
      "train loss:0.03382470732436288\n",
      "train loss:0.025956192297492353\n",
      "train loss:0.10378243014726175\n",
      "train loss:0.05761271707747179\n",
      "train loss:0.03562789446505023\n",
      "train loss:0.06620507752629587\n",
      "train loss:0.09860071887813046\n",
      "train loss:0.08036986212135055\n",
      "train loss:0.04719388280694161\n",
      "train loss:0.038717150446371945\n",
      "train loss:0.032843147519692265\n",
      "train loss:0.06817136399938749\n",
      "train loss:0.08364297332997087\n",
      "train loss:0.06486623068729955\n",
      "train loss:0.07521661712432498\n",
      "train loss:0.023177391471294037\n",
      "train loss:0.034289107890603465\n",
      "train loss:0.055700644842011995\n",
      "train loss:0.06393045996217402\n",
      "train loss:0.09919147953239943\n",
      "train loss:0.04862280115007226\n",
      "train loss:0.029805602973745248\n",
      "train loss:0.08880823440260757\n",
      "train loss:0.05583726653701729\n",
      "train loss:0.0552945680252975\n",
      "train loss:0.17344086264730904\n",
      "train loss:0.048616701420119944\n",
      "train loss:0.04360817197005114\n",
      "train loss:0.07016812021094257\n",
      "train loss:0.07394941327170376\n",
      "train loss:0.04447422856059547\n",
      "train loss:0.028681982521563117\n",
      "train loss:0.061337876824957116\n",
      "train loss:0.060842179304838796\n",
      "train loss:0.04290204870742967\n",
      "train loss:0.01736178061816173\n",
      "train loss:0.060458901199697664\n",
      "train loss:0.10815783373194085\n",
      "train loss:0.05823792594464788\n",
      "train loss:0.04180455221419459\n",
      "train loss:0.07604209054252795\n",
      "train loss:0.030671933353361946\n",
      "train loss:0.14400550942742965\n",
      "train loss:0.03542453032156539\n",
      "train loss:0.09039221926042627\n",
      "train loss:0.048668256445746634\n",
      "train loss:0.02692319231226766\n",
      "train loss:0.11967666606954343\n",
      "train loss:0.036953761049128356\n",
      "train loss:0.030767137684083293\n",
      "train loss:0.017616260723902728\n",
      "train loss:0.030821716951150515\n",
      "train loss:0.013151146135152076\n",
      "train loss:0.05166992083225824\n",
      "train loss:0.044229915435382273\n",
      "train loss:0.07471790041007945\n",
      "train loss:0.049880109961981105\n",
      "train loss:0.027104214493763514\n",
      "train loss:0.029133745523915282\n",
      "train loss:0.007229090474404474\n",
      "train loss:0.11581211581144463\n",
      "train loss:0.01807653740942666\n",
      "train loss:0.05329137176270739\n",
      "train loss:0.09029691799411939\n",
      "train loss:0.07008731420224021\n",
      "train loss:0.047044404500171604\n",
      "train loss:0.10273797682231028\n",
      "train loss:0.09836542057993997\n",
      "train loss:0.08513317828057787\n",
      "train loss:0.04825503691604856\n",
      "train loss:0.023056788249724805\n",
      "train loss:0.040274439670416357\n",
      "train loss:0.03514911870888244\n",
      "train loss:0.030860184638613078\n",
      "train loss:0.12019624323520733\n",
      "train loss:0.061075285011807354\n",
      "train loss:0.05571209902320861\n",
      "train loss:0.05578472652131567\n",
      "train loss:0.04294713795262732\n",
      "train loss:0.053072339189010886\n",
      "train loss:0.05275573453179925\n",
      "train loss:0.02297242989857767\n",
      "train loss:0.03308196064356917\n",
      "train loss:0.03583845318458526\n",
      "train loss:0.11647802017226284\n",
      "train loss:0.04322012837686881\n",
      "train loss:0.08614489199837504\n",
      "train loss:0.03347502278104478\n",
      "train loss:0.02909575849343626\n",
      "train loss:0.02896329062427085\n",
      "train loss:0.023932700066622556\n",
      "train loss:0.0173256518959904\n",
      "train loss:0.041242725710659886\n",
      "train loss:0.03628180483494469\n",
      "train loss:0.015957286333088253\n",
      "train loss:0.06873319022492048\n",
      "train loss:0.046899863208402566\n",
      "train loss:0.02595732124528086\n",
      "train loss:0.02564528681282807\n",
      "train loss:0.08828895738751096\n",
      "train loss:0.04731784843611511\n",
      "train loss:0.06084099143632631\n",
      "train loss:0.02630972935154149\n",
      "train loss:0.051932245573131024\n",
      "train loss:0.02141310166809907\n",
      "train loss:0.05225115732741772\n",
      "train loss:0.0649260711997855\n",
      "train loss:0.033961209436980104\n",
      "train loss:0.08105094384597086\n",
      "train loss:0.029918504630509903\n",
      "train loss:0.029087966399815705\n",
      "train loss:0.031084016160204002\n",
      "train loss:0.06789803142772953\n",
      "train loss:0.08932768229446308\n",
      "train loss:0.07597457419732372\n",
      "train loss:0.03980391924849969\n",
      "train loss:0.012022536658403938\n",
      "train loss:0.03479035527388272\n",
      "train loss:0.055202923342473766\n",
      "train loss:0.022861796687025832\n",
      "train loss:0.03940496097435113\n",
      "train loss:0.023213426393286635\n",
      "train loss:0.03224888630440946\n",
      "train loss:0.04419376746366632\n",
      "train loss:0.026802988108944565\n",
      "train loss:0.04166455388006815\n",
      "train loss:0.05763529684507546\n",
      "train loss:0.06457441043615128\n",
      "train loss:0.03062202992479435\n",
      "train loss:0.02469766103101224\n",
      "train loss:0.06475398151887793\n",
      "train loss:0.03738827624265779\n",
      "train loss:0.016236385899121786\n",
      "train loss:0.08759736524051151\n",
      "train loss:0.0403164047817015\n",
      "train loss:0.0589088428376072\n",
      "train loss:0.06787182737938863\n",
      "train loss:0.02538651120274257\n",
      "train loss:0.09494530622543465\n",
      "train loss:0.018132952460395882\n",
      "train loss:0.08778112051514234\n",
      "train loss:0.05293359539658131\n",
      "train loss:0.06638814632509255\n",
      "train loss:0.023149322742570796\n",
      "train loss:0.054589753620680345\n",
      "train loss:0.041369635304694244\n",
      "train loss:0.010313027651773807\n",
      "train loss:0.05687682001584848\n",
      "train loss:0.052577572726537715\n",
      "train loss:0.09094210369997675\n",
      "train loss:0.022186355373904166\n",
      "train loss:0.03308617084704812\n",
      "train loss:0.05161418733114027\n",
      "train loss:0.09377583670861105\n",
      "train loss:0.044524736608376976\n",
      "train loss:0.08538500588129017\n",
      "train loss:0.03431105126717718\n",
      "train loss:0.03330023740434882\n",
      "train loss:0.03142822229700422\n",
      "train loss:0.028780814364105484\n",
      "train loss:0.046801474549551324\n",
      "train loss:0.04194226002464494\n",
      "train loss:0.06094755237220386\n",
      "train loss:0.0898910292772901\n",
      "train loss:0.03417735120332701\n",
      "train loss:0.09043645021257264\n",
      "train loss:0.052074775448030186\n",
      "train loss:0.009143927858473563\n",
      "train loss:0.0177196689963192\n",
      "train loss:0.046826755037533384\n",
      "train loss:0.03304962750302083\n",
      "train loss:0.05325946326711559\n",
      "train loss:0.05794249176817809\n",
      "train loss:0.11319040598881176\n",
      "train loss:0.05654927821670955\n",
      "train loss:0.045694232648705396\n",
      "train loss:0.02571631610843561\n",
      "train loss:0.040291037368556555\n",
      "train loss:0.11525380308010162\n",
      "train loss:0.020417523430121265\n",
      "train loss:0.03829248585579384\n",
      "train loss:0.12588964601032243\n",
      "train loss:0.02657238765095317\n",
      "train loss:0.03182391296370437\n",
      "train loss:0.06449626988427673\n",
      "train loss:0.033684930301522115\n",
      "train loss:0.025545438541898155\n",
      "train loss:0.06275420937968484\n",
      "train loss:0.06400713116318103\n",
      "train loss:0.029774874958011028\n",
      "train loss:0.054441128639273334\n",
      "train loss:0.07365254406470714\n",
      "train loss:0.02482176258545608\n",
      "train loss:0.03428153174777551\n",
      "train loss:0.04407829828844847\n",
      "train loss:0.06115243904918694\n",
      "train loss:0.02006875305722626\n",
      "train loss:0.028248663075001804\n",
      "train loss:0.030489410123142772\n",
      "train loss:0.0512978362399375\n",
      "train loss:0.06075842814901116\n",
      "train loss:0.044985186081994394\n",
      "train loss:0.05185530594930767\n",
      "train loss:0.036943778305265844\n",
      "train loss:0.054095645417451585\n",
      "train loss:0.03063496693595626\n",
      "train loss:0.026598538188944518\n",
      "train loss:0.06968309251008509\n",
      "train loss:0.04508995341074333\n",
      "train loss:0.0501173159861949\n",
      "train loss:0.0388174985841311\n",
      "train loss:0.024112860237382613\n",
      "train loss:0.03983909760537529\n",
      "train loss:0.051112136306873515\n",
      "train loss:0.059343955236491226\n",
      "train loss:0.033206645138478735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.06247371783674299\n",
      "train loss:0.04699416226405027\n",
      "train loss:0.090623232753137\n",
      "train loss:0.056374785094531345\n",
      "train loss:0.017263963978938382\n",
      "train loss:0.0964915281129297\n",
      "train loss:0.04361072417522133\n",
      "train loss:0.03334361276164543\n",
      "train loss:0.05967685094758723\n",
      "train loss:0.043210188180005674\n",
      "train loss:0.05639467733923923\n",
      "train loss:0.04882543385408436\n",
      "train loss:0.036348514340833915\n",
      "train loss:0.023168961858793975\n",
      "train loss:0.0661927377660846\n",
      "train loss:0.0458397574836485\n",
      "train loss:0.07051108256611685\n",
      "train loss:0.04223110286439751\n",
      "train loss:0.0493059976428791\n",
      "train loss:0.03582140707205838\n",
      "train loss:0.03420105012175228\n",
      "train loss:0.06470558967524807\n",
      "train loss:0.055109079722801574\n",
      "train loss:0.02122152673394213\n",
      "train loss:0.04188700501085879\n",
      "train loss:0.051464884014803314\n",
      "train loss:0.03783752617382667\n",
      "train loss:0.03850673151203655\n",
      "train loss:0.04666284671016698\n",
      "train loss:0.06778356853296275\n",
      "train loss:0.1338601293610998\n",
      "train loss:0.03355159910635211\n",
      "train loss:0.07405434917211981\n",
      "train loss:0.05534895922853553\n",
      "train loss:0.046060534267486235\n",
      "train loss:0.01687688734079668\n",
      "train loss:0.04016966854383743\n",
      "train loss:0.035243011773753864\n",
      "train loss:0.06770735633309194\n",
      "train loss:0.06817295562108579\n",
      "train loss:0.052394183753899475\n",
      "train loss:0.030367616905972786\n",
      "train loss:0.04366866817603147\n",
      "train loss:0.028520925843704227\n",
      "train loss:0.11830311746552508\n",
      "train loss:0.023684524789633333\n",
      "train loss:0.02613862837267108\n",
      "train loss:0.03166373829687583\n",
      "train loss:0.04232109410414733\n",
      "train loss:0.05633200744179654\n",
      "train loss:0.0245726661683323\n",
      "train loss:0.021652715357798183\n",
      "train loss:0.0356951801818632\n",
      "train loss:0.044706712433957956\n",
      "train loss:0.022384409247147467\n",
      "train loss:0.06026005632462446\n",
      "train loss:0.03902338537796011\n",
      "train loss:0.031249578187456942\n",
      "train loss:0.07603651081836821\n",
      "train loss:0.03537298989141291\n",
      "train loss:0.06049663101157978\n",
      "train loss:0.08751639156072147\n",
      "train loss:0.04741286399988913\n",
      "train loss:0.025221289614089804\n",
      "train loss:0.038391535056052806\n",
      "train loss:0.048325186992175216\n",
      "train loss:0.03327913660292633\n",
      "train loss:0.053981650415918715\n",
      "train loss:0.024652069780635496\n",
      "train loss:0.08154322476727233\n",
      "train loss:0.02483459478771473\n",
      "train loss:0.029735468751506663\n",
      "train loss:0.03534885852567618\n",
      "train loss:0.07620450176956166\n",
      "train loss:0.03240622821439118\n",
      "train loss:0.04358726848576601\n",
      "train loss:0.08150571229977828\n",
      "train loss:0.03224607076403881\n",
      "train loss:0.04802475523414057\n",
      "train loss:0.03803399137166407\n",
      "train loss:0.07916972351677504\n",
      "train loss:0.054040363153472215\n",
      "train loss:0.08262796221182592\n",
      "train loss:0.026257343185562942\n",
      "train loss:0.04234711098957651\n",
      "train loss:0.045062052810508624\n",
      "train loss:0.12433227318207539\n",
      "train loss:0.022837125065588233\n",
      "train loss:0.0482189457707289\n",
      "train loss:0.02693444750621286\n",
      "train loss:0.03195605983569691\n",
      "train loss:0.0362681564597858\n",
      "train loss:0.06622820743109227\n",
      "train loss:0.027284716829372436\n",
      "train loss:0.0356302413662204\n",
      "train loss:0.054079369684162534\n",
      "train loss:0.05645911297854453\n",
      "train loss:0.03426744370922677\n",
      "train loss:0.057955858386192965\n",
      "train loss:0.027083967759718882\n",
      "train loss:0.05327250849467538\n",
      "train loss:0.06218994486592325\n",
      "train loss:0.07594915949177715\n",
      "train loss:0.0327306010485643\n",
      "train loss:0.07878964822951028\n",
      "train loss:0.047881325048796476\n",
      "train loss:0.03909927060714857\n",
      "train loss:0.08907941318403102\n",
      "train loss:0.06861283167520721\n",
      "train loss:0.035069838400453246\n",
      "train loss:0.029293726931699755\n",
      "train loss:0.07368216693548459\n",
      "train loss:0.024998449920500387\n",
      "train loss:0.018841416801106337\n",
      "train loss:0.037466477339396544\n",
      "train loss:0.06666955923138648\n",
      "train loss:0.034371911219614\n",
      "train loss:0.06650841676732334\n",
      "train loss:0.06566241080166342\n",
      "train loss:0.0286727270254144\n",
      "train loss:0.0654256800388536\n",
      "train loss:0.027060445588007707\n",
      "train loss:0.0683950938033135\n",
      "train loss:0.02454407986179788\n",
      "train loss:0.08056120198146019\n",
      "train loss:0.10607886690593712\n",
      "train loss:0.08789282019913322\n",
      "train loss:0.05843191529857306\n",
      "train loss:0.02140031161073573\n",
      "train loss:0.053807480931984585\n",
      "train loss:0.042818019080543765\n",
      "train loss:0.0511331877639635\n",
      "train loss:0.13775564178769398\n",
      "train loss:0.05055787872025612\n",
      "train loss:0.15983310338587242\n",
      "train loss:0.08701904302871226\n",
      "train loss:0.09823465296819682\n",
      "train loss:0.04030340888660029\n",
      "train loss:0.07220455314479107\n",
      "train loss:0.01869572142608469\n",
      "train loss:0.09436437257253218\n",
      "train loss:0.04220135559617105\n",
      "train loss:0.06374348863094301\n",
      "train loss:0.05637000894397553\n",
      "train loss:0.03260684623759089\n",
      "train loss:0.10777442346296719\n",
      "train loss:0.06719007288547567\n",
      "train loss:0.03715290696771098\n",
      "train loss:0.04408405843436824\n",
      "train loss:0.0685294615340329\n",
      "train loss:0.035805339948946906\n",
      "=== epoch:23, train acc:0.981, test acc:0.904 ===\n",
      "train loss:0.08236379005376504\n",
      "train loss:0.034368948037652086\n",
      "train loss:0.02781428427796346\n",
      "train loss:0.04098078955376587\n",
      "train loss:0.05390468988943357\n",
      "train loss:0.04505478139010851\n",
      "train loss:0.025664402884761173\n",
      "train loss:0.03621647551306208\n",
      "train loss:0.034468135657395135\n",
      "train loss:0.01776804902509772\n",
      "train loss:0.047600233806759554\n",
      "train loss:0.0327927315888715\n",
      "train loss:0.027578667341120293\n",
      "train loss:0.07420468415026439\n",
      "train loss:0.04897306015364961\n",
      "train loss:0.02251077913546893\n",
      "train loss:0.04126118419469458\n",
      "train loss:0.027593285546774596\n",
      "train loss:0.07214863066437549\n",
      "train loss:0.0145237805282808\n",
      "train loss:0.13122136251719604\n",
      "train loss:0.10164221383955617\n",
      "train loss:0.01018018323775217\n",
      "train loss:0.0488409374012026\n",
      "train loss:0.056219950322536356\n",
      "train loss:0.05014288611369258\n",
      "train loss:0.1073762698975368\n",
      "train loss:0.023919247936691465\n",
      "train loss:0.06912828814452184\n",
      "train loss:0.05268518969676724\n",
      "train loss:0.04521816491879716\n",
      "train loss:0.03877250782079991\n",
      "train loss:0.035920229669809366\n",
      "train loss:0.0168779429429013\n",
      "train loss:0.03313799799684564\n",
      "train loss:0.03809269801837807\n",
      "train loss:0.050347898045915586\n",
      "train loss:0.03645760719584367\n",
      "train loss:0.08847429352589647\n",
      "train loss:0.05779777187304748\n",
      "train loss:0.015694526554431584\n",
      "train loss:0.03306062730247226\n",
      "train loss:0.0294554903968469\n",
      "train loss:0.026980877719740212\n",
      "train loss:0.03673713922551357\n",
      "train loss:0.04065195989076896\n",
      "train loss:0.15904829585644242\n",
      "train loss:0.049013995460253035\n",
      "train loss:0.046437634211807514\n",
      "train loss:0.06779607610515517\n",
      "train loss:0.027031761762561186\n",
      "train loss:0.031248601026520904\n",
      "train loss:0.03375816105903533\n",
      "train loss:0.02700993333198825\n",
      "train loss:0.07206520163290325\n",
      "train loss:0.06774615823608067\n",
      "train loss:0.05408894603483536\n",
      "train loss:0.07514459389020041\n",
      "train loss:0.046766315342855386\n",
      "train loss:0.06626029266943735\n",
      "train loss:0.052141668200130394\n",
      "train loss:0.04796873174748392\n",
      "train loss:0.049781284185746004\n",
      "train loss:0.05464765834524824\n",
      "train loss:0.05571714360154772\n",
      "train loss:0.027805838663233398\n",
      "train loss:0.04237015273851176\n",
      "train loss:0.12728762589174905\n",
      "train loss:0.0422058859437075\n",
      "train loss:0.0834816306561507\n",
      "train loss:0.09558580095055422\n",
      "train loss:0.044528813236044046\n",
      "train loss:0.07174036893109745\n",
      "train loss:0.03682352068398658\n",
      "train loss:0.017125682264372968\n",
      "train loss:0.043118640530469356\n",
      "train loss:0.10340574634918095\n",
      "train loss:0.03457934215652074\n",
      "train loss:0.07849195535490955\n",
      "train loss:0.035378372705574625\n",
      "train loss:0.04234490962404857\n",
      "train loss:0.020555900654263947\n",
      "train loss:0.05497831408581935\n",
      "train loss:0.05448431218813485\n",
      "train loss:0.11016945470598985\n",
      "train loss:0.12579598502844608\n",
      "train loss:0.03674764879645565\n",
      "train loss:0.05441101110776474\n",
      "train loss:0.016372986456549134\n",
      "train loss:0.04313531873948323\n",
      "train loss:0.087993758367955\n",
      "train loss:0.1200591510975651\n",
      "train loss:0.07679566859175324\n",
      "train loss:0.06759352346906505\n",
      "train loss:0.01993478941433445\n",
      "train loss:0.06517588539578688\n",
      "train loss:0.05261457172228324\n",
      "train loss:0.037872951089013805\n",
      "train loss:0.037116915508090605\n",
      "train loss:0.02273774497033612\n",
      "train loss:0.06028762097806042\n",
      "train loss:0.040711365669021254\n",
      "train loss:0.05435011272231726\n",
      "train loss:0.038101049868268455\n",
      "train loss:0.03836550112504819\n",
      "train loss:0.03275930244778172\n",
      "train loss:0.02447913460184728\n",
      "train loss:0.06125613375980442\n",
      "train loss:0.05680182610247114\n",
      "train loss:0.0760803179031859\n",
      "train loss:0.044719184648682006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.017983046055386264\n",
      "train loss:0.05338081647905066\n",
      "train loss:0.030611599362669772\n",
      "train loss:0.036826236779399474\n",
      "train loss:0.08286742358901\n",
      "train loss:0.05001658427239989\n",
      "train loss:0.04226780959386592\n",
      "train loss:0.061163953518677025\n",
      "train loss:0.04696906338992348\n",
      "train loss:0.023706895369012018\n",
      "train loss:0.03556171892004802\n",
      "train loss:0.036884118158013915\n",
      "train loss:0.029135080467058233\n",
      "train loss:0.030796436111958533\n",
      "train loss:0.02485832964150016\n",
      "train loss:0.03681863977484606\n",
      "train loss:0.02523604091015853\n",
      "train loss:0.028522468836397193\n",
      "train loss:0.053955618163407486\n",
      "train loss:0.03669164259890912\n",
      "train loss:0.03434895991958611\n",
      "train loss:0.04957795418204529\n",
      "train loss:0.0323494897125538\n",
      "train loss:0.04540610420876178\n",
      "train loss:0.036750058851774674\n",
      "train loss:0.08691102198481471\n",
      "train loss:0.02519055219108947\n",
      "train loss:0.030793928358487134\n",
      "train loss:0.03644349863733046\n",
      "train loss:0.0225327221624105\n",
      "train loss:0.1362340477431462\n",
      "train loss:0.05479557428219941\n",
      "train loss:0.029609814661641608\n",
      "train loss:0.042621963822150236\n",
      "train loss:0.055059050956525496\n",
      "train loss:0.02690775394530722\n",
      "train loss:0.02903074814153094\n",
      "train loss:0.02320340038366887\n",
      "train loss:0.04652273115362819\n",
      "train loss:0.029767499007193145\n",
      "train loss:0.03341260542794659\n",
      "train loss:0.06404961744958396\n",
      "train loss:0.04976486876194767\n",
      "train loss:0.02407560187786956\n",
      "train loss:0.04095083579798706\n",
      "train loss:0.06852130114697194\n",
      "train loss:0.04031953161040455\n",
      "train loss:0.044230288382627665\n",
      "train loss:0.047208792268888564\n",
      "train loss:0.06306292186347177\n",
      "train loss:0.07915104735869279\n",
      "train loss:0.042601926536203774\n",
      "train loss:0.05974376697789777\n",
      "train loss:0.04332086760120862\n",
      "train loss:0.08346121798046922\n",
      "train loss:0.03306142234877369\n",
      "train loss:0.055734909339504514\n",
      "train loss:0.13916321518335228\n",
      "train loss:0.0920727489709178\n",
      "train loss:0.040969646827996475\n",
      "train loss:0.0663013876375246\n",
      "train loss:0.024759261113195583\n",
      "train loss:0.025818865246904025\n",
      "train loss:0.10262162911651704\n",
      "train loss:0.058045292973439404\n",
      "train loss:0.06553407158429415\n",
      "train loss:0.04384458124276922\n",
      "train loss:0.062026245244794505\n",
      "train loss:0.07189589606682305\n",
      "train loss:0.07344472629463669\n",
      "train loss:0.05154386137803108\n",
      "train loss:0.03546207068546639\n",
      "train loss:0.0668221317233563\n",
      "train loss:0.07756654199607796\n",
      "train loss:0.03674302778089894\n",
      "train loss:0.03307442216979441\n",
      "train loss:0.020972890931934073\n",
      "train loss:0.05360694720260905\n",
      "train loss:0.014074993001602039\n",
      "train loss:0.07165090578469323\n",
      "train loss:0.01582361743924446\n",
      "train loss:0.04994857212264511\n",
      "train loss:0.03112270034263116\n",
      "train loss:0.07065618024372126\n",
      "train loss:0.06805927522486283\n",
      "train loss:0.031124977931506415\n",
      "train loss:0.021652931191145905\n",
      "train loss:0.07351312239228747\n",
      "train loss:0.059887292591109406\n",
      "train loss:0.025415121181978223\n",
      "train loss:0.03238924808301318\n",
      "train loss:0.08302486303194906\n",
      "train loss:0.05365273664286191\n",
      "train loss:0.04248412887730609\n",
      "train loss:0.03273786801813005\n",
      "train loss:0.056244346734085\n",
      "train loss:0.023368587436294504\n",
      "train loss:0.04137050942110463\n",
      "train loss:0.06387445765874195\n",
      "train loss:0.06896666729527552\n",
      "train loss:0.18408948208065895\n",
      "train loss:0.043057087454514614\n",
      "train loss:0.031772566030507356\n",
      "train loss:0.09914166377193237\n",
      "train loss:0.052492704209683175\n",
      "train loss:0.0507226498543582\n",
      "train loss:0.016609026974105347\n",
      "train loss:0.025522486253059105\n",
      "train loss:0.06074172616916369\n",
      "train loss:0.08141430639460047\n",
      "train loss:0.04218639843821457\n",
      "train loss:0.024946050430102038\n",
      "train loss:0.06792096955324645\n",
      "train loss:0.027053171270765394\n",
      "train loss:0.03766269108107404\n",
      "train loss:0.05784874569037658\n",
      "train loss:0.09108406218225655\n",
      "train loss:0.07722709313990071\n",
      "train loss:0.07069330045731846\n",
      "train loss:0.04276411422871268\n",
      "train loss:0.030898253395789315\n",
      "train loss:0.0234580584581905\n",
      "train loss:0.029025582815595977\n",
      "train loss:0.05334392497017669\n",
      "train loss:0.014494144612780015\n",
      "train loss:0.03124304437222872\n",
      "train loss:0.05221324557770858\n",
      "train loss:0.0336812912133359\n",
      "train loss:0.06316316703224288\n",
      "train loss:0.02086134560277375\n",
      "train loss:0.053244278606538485\n",
      "train loss:0.030526041727424645\n",
      "train loss:0.04097087759898931\n",
      "train loss:0.02379428253853658\n",
      "train loss:0.016520321995491888\n",
      "train loss:0.02766232609062488\n",
      "train loss:0.027967596918345314\n",
      "train loss:0.09640945040626585\n",
      "train loss:0.08135627602555948\n",
      "train loss:0.028810086783864552\n",
      "train loss:0.03595494228333993\n",
      "train loss:0.0347480626842461\n",
      "train loss:0.03839762406016911\n",
      "train loss:0.01720131327992938\n",
      "train loss:0.038949039378815616\n",
      "train loss:0.07918472352242961\n",
      "train loss:0.03589472606542382\n",
      "train loss:0.04417068738664181\n",
      "train loss:0.05250826007796926\n",
      "train loss:0.0479662841723656\n",
      "train loss:0.06127571698843031\n",
      "train loss:0.03442094670080538\n",
      "train loss:0.02173509179046433\n",
      "train loss:0.016708366706304482\n",
      "train loss:0.04476274138865558\n",
      "train loss:0.06995985611594496\n",
      "train loss:0.03979972816922543\n",
      "train loss:0.0630682605050609\n",
      "train loss:0.03568269296267404\n",
      "train loss:0.05244876697124251\n",
      "train loss:0.038800452885510664\n",
      "train loss:0.03488326370347852\n",
      "train loss:0.029611210842199087\n",
      "train loss:0.034874516298775624\n",
      "train loss:0.04923128588618678\n",
      "train loss:0.026001017881410248\n",
      "train loss:0.03340938897354964\n",
      "train loss:0.05860312722474896\n",
      "train loss:0.04519894581073962\n",
      "train loss:0.02544702109065124\n",
      "train loss:0.051890330883175156\n",
      "train loss:0.06849604667666095\n",
      "train loss:0.06886508173151397\n",
      "train loss:0.02728770268331495\n",
      "train loss:0.02266683320355428\n",
      "train loss:0.06847704605293724\n",
      "train loss:0.020834019179258537\n",
      "train loss:0.03414758785125072\n",
      "train loss:0.09282609610739043\n",
      "train loss:0.04131492495071489\n",
      "train loss:0.028519308473628095\n",
      "train loss:0.05751806329586444\n",
      "train loss:0.04235226879629438\n",
      "train loss:0.0446500938813239\n",
      "train loss:0.05897409105103253\n",
      "train loss:0.016142313234026696\n",
      "train loss:0.020248556655999218\n",
      "train loss:0.0872390179989397\n",
      "train loss:0.050575202563556125\n",
      "train loss:0.027432093192802143\n",
      "train loss:0.05696839413336572\n",
      "train loss:0.04914566147816612\n",
      "train loss:0.042701008840430134\n",
      "train loss:0.05381713589653152\n",
      "train loss:0.028259454847997564\n",
      "train loss:0.0418699145252795\n",
      "train loss:0.10676885133588886\n",
      "train loss:0.0550337474108189\n",
      "train loss:0.048936428401775284\n",
      "train loss:0.04371417446599296\n",
      "train loss:0.021046808041749285\n",
      "train loss:0.10968779348010464\n",
      "train loss:0.034066423851053435\n",
      "train loss:0.0355199255373539\n",
      "train loss:0.07026753194620013\n",
      "train loss:0.04713451587380425\n",
      "train loss:0.022805669279144406\n",
      "train loss:0.05536226877860245\n",
      "train loss:0.022133728218588115\n",
      "train loss:0.03379482289095224\n",
      "train loss:0.03833068915771486\n",
      "train loss:0.04090287072011934\n",
      "train loss:0.036737680305016736\n",
      "train loss:0.02553134928407695\n",
      "train loss:0.06389330975992405\n",
      "train loss:0.00908038709885891\n",
      "train loss:0.03610511970838812\n",
      "train loss:0.05313779527491979\n",
      "train loss:0.02415802860262393\n",
      "train loss:0.06543934381882871\n",
      "train loss:0.05464172390856683\n",
      "train loss:0.020718439021018536\n",
      "train loss:0.019466059357303486\n",
      "train loss:0.07200831397532628\n",
      "train loss:0.06056200889062379\n",
      "train loss:0.024269544468813752\n",
      "train loss:0.027288175713361645\n",
      "train loss:0.01620177123913597\n",
      "train loss:0.0233468083322839\n",
      "train loss:0.035964127612827655\n",
      "train loss:0.03632496662881836\n",
      "train loss:0.0635734966343399\n",
      "train loss:0.022474515585732758\n",
      "train loss:0.01318048773928278\n",
      "train loss:0.02892818580998783\n",
      "train loss:0.05042858877882574\n",
      "train loss:0.042682521406944424\n",
      "train loss:0.012148269900625723\n",
      "train loss:0.04606564417325442\n",
      "train loss:0.16713246456824243\n",
      "train loss:0.08779900711699672\n",
      "train loss:0.022075117462858732\n",
      "train loss:0.036462496470680554\n",
      "train loss:0.012010829831355332\n",
      "train loss:0.04924033847740491\n",
      "train loss:0.08314916032079368\n",
      "train loss:0.09304654509963277\n",
      "train loss:0.0556289599539848\n",
      "train loss:0.01472735883998333\n",
      "train loss:0.06740358619328307\n",
      "train loss:0.023718959511617937\n",
      "train loss:0.04163743971064929\n",
      "train loss:0.021249213585162307\n",
      "train loss:0.02892459977895916\n",
      "train loss:0.0209467302376907\n",
      "train loss:0.026476196820304342\n",
      "train loss:0.06487640991584986\n",
      "train loss:0.03872245216955381\n",
      "train loss:0.031557029723935384\n",
      "train loss:0.04025801266956271\n",
      "train loss:0.018684402822860043\n",
      "train loss:0.021008680138572967\n",
      "train loss:0.038377459322111285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.023724384309867026\n",
      "train loss:0.01802995069794522\n",
      "train loss:0.03272742740969805\n",
      "train loss:0.055611375943183744\n",
      "train loss:0.03234765611505079\n",
      "train loss:0.03286460603805861\n",
      "train loss:0.04269528234726718\n",
      "train loss:0.062365482982674546\n",
      "train loss:0.04790786523088709\n",
      "train loss:0.03321299320285496\n",
      "train loss:0.05051218988891768\n",
      "train loss:0.06775159809748611\n",
      "train loss:0.029608120008070133\n",
      "train loss:0.11311106586000562\n",
      "train loss:0.09544747979539377\n",
      "train loss:0.15540209026306034\n",
      "train loss:0.05151103951914642\n",
      "train loss:0.05261260703098122\n",
      "train loss:0.0255459986042125\n",
      "train loss:0.06713327079679778\n",
      "train loss:0.03715816380932845\n",
      "train loss:0.05082061008082886\n",
      "train loss:0.031173977921411612\n",
      "train loss:0.0492980956867082\n",
      "train loss:0.054431016856612995\n",
      "train loss:0.04201362216444845\n",
      "train loss:0.04060884002260372\n",
      "train loss:0.03678738169616244\n",
      "train loss:0.03680006649349202\n",
      "train loss:0.026106275356452106\n",
      "train loss:0.029980453787290993\n",
      "train loss:0.02362913469463351\n",
      "train loss:0.02977135771811168\n",
      "train loss:0.0978192802291786\n",
      "train loss:0.014290504895490172\n",
      "train loss:0.07579779971564148\n",
      "train loss:0.050077670383622104\n",
      "train loss:0.041994527083254046\n",
      "train loss:0.017784456737233577\n",
      "train loss:0.015298665156753844\n",
      "train loss:0.03988111231757887\n",
      "train loss:0.030211474045852126\n",
      "train loss:0.048204207645487995\n",
      "train loss:0.04522889988260895\n",
      "train loss:0.018068434444038814\n",
      "train loss:0.06667752627571186\n",
      "train loss:0.029609134424733775\n",
      "train loss:0.06464299783672821\n",
      "train loss:0.11692181240069843\n",
      "train loss:0.03103637264387712\n",
      "train loss:0.02479487810379327\n",
      "train loss:0.025598910240496254\n",
      "train loss:0.02459482180466485\n",
      "train loss:0.054162149359415886\n",
      "train loss:0.05462581834472385\n",
      "train loss:0.02679508217254687\n",
      "train loss:0.028638152593557377\n",
      "train loss:0.042595165650195346\n",
      "train loss:0.04234132779905335\n",
      "train loss:0.02738158667172198\n",
      "train loss:0.022971183779519327\n",
      "train loss:0.06028924186546673\n",
      "train loss:0.045828463065172666\n",
      "train loss:0.09052306744867478\n",
      "train loss:0.04376102673365186\n",
      "train loss:0.02495229740159839\n",
      "train loss:0.05023637067765015\n",
      "train loss:0.03345680278037618\n",
      "train loss:0.040223677811723604\n",
      "train loss:0.0320218926948926\n",
      "train loss:0.0324712854832441\n",
      "train loss:0.04628658361184086\n",
      "train loss:0.03756087022194344\n",
      "train loss:0.07028830288854171\n",
      "train loss:0.04858672069809826\n",
      "train loss:0.04446217800336196\n",
      "train loss:0.07207518682476372\n",
      "train loss:0.09519360095146294\n",
      "train loss:0.01590763566809945\n",
      "train loss:0.01788188399059249\n",
      "train loss:0.027245224069223698\n",
      "train loss:0.07454262336088728\n",
      "train loss:0.11739758173608784\n",
      "train loss:0.04849779117185733\n",
      "train loss:0.10643782373065483\n",
      "train loss:0.0659907976377522\n",
      "train loss:0.0476417681452086\n",
      "train loss:0.08815683560182752\n",
      "train loss:0.049424202580667\n",
      "train loss:0.05890606184865496\n",
      "train loss:0.08062083756624894\n",
      "train loss:0.12090421287773227\n",
      "train loss:0.11721928427278495\n",
      "train loss:0.04018143064454348\n",
      "train loss:0.11940275891165063\n",
      "train loss:0.07726911636796607\n",
      "train loss:0.1113949918321888\n",
      "train loss:0.01305707323565722\n",
      "train loss:0.07176109635249271\n",
      "train loss:0.05979208034023478\n",
      "train loss:0.05046850794443982\n",
      "train loss:0.061614743234136536\n",
      "train loss:0.039931765818258455\n",
      "train loss:0.03768819178894173\n",
      "train loss:0.14229215071759208\n",
      "train loss:0.08397683310985318\n",
      "train loss:0.07134495353414591\n",
      "train loss:0.033995707788033735\n",
      "train loss:0.03010048629150296\n",
      "train loss:0.05551495346897889\n",
      "train loss:0.0806184044689838\n",
      "train loss:0.025185682076175046\n",
      "train loss:0.09838967096569075\n",
      "train loss:0.057095233922825284\n",
      "train loss:0.06928143649051008\n",
      "train loss:0.02457119594512893\n",
      "train loss:0.12901589925504292\n",
      "train loss:0.08659167081400215\n",
      "train loss:0.021590133008329432\n",
      "train loss:0.06771971113315854\n",
      "train loss:0.04217938444996583\n",
      "train loss:0.038328710816350565\n",
      "train loss:0.02549974975241268\n",
      "train loss:0.08738607361449054\n",
      "train loss:0.028561109315226728\n",
      "train loss:0.08204795523719383\n",
      "train loss:0.022794016185137086\n",
      "train loss:0.0701961111893654\n",
      "train loss:0.023183615327906394\n",
      "train loss:0.04989793033612351\n",
      "train loss:0.07221034423932896\n",
      "train loss:0.04208808428565007\n",
      "train loss:0.09480512667367949\n",
      "train loss:0.05195578604579043\n",
      "train loss:0.04754392070032999\n",
      "train loss:0.038972762842819406\n",
      "train loss:0.041985657836753065\n",
      "train loss:0.03559775682490465\n",
      "train loss:0.024624782680225214\n",
      "train loss:0.053702425443649913\n",
      "train loss:0.052655420188726626\n",
      "train loss:0.055087873254942535\n",
      "train loss:0.06426752107930339\n",
      "train loss:0.04191389241126694\n",
      "train loss:0.053001161945357075\n",
      "train loss:0.01914256535208629\n",
      "train loss:0.050464061690582845\n",
      "train loss:0.024355086142218436\n",
      "train loss:0.05454260437996647\n",
      "train loss:0.10851975553164273\n",
      "train loss:0.04929903446979599\n",
      "train loss:0.06919677547235258\n",
      "train loss:0.08081852464409003\n",
      "train loss:0.041510289832895814\n",
      "train loss:0.08529195558423051\n",
      "train loss:0.060789860627527\n",
      "train loss:0.0475462702131796\n",
      "train loss:0.07421081625132037\n",
      "train loss:0.019914780602021325\n",
      "train loss:0.04212145060933301\n",
      "train loss:0.037013818155123335\n",
      "train loss:0.04017839853415235\n",
      "train loss:0.04862277351819336\n",
      "train loss:0.03068640812453955\n",
      "train loss:0.06514190034354489\n",
      "train loss:0.04208396117147407\n",
      "train loss:0.03365679667849664\n",
      "train loss:0.026357455263215618\n",
      "train loss:0.03922895033598716\n",
      "train loss:0.03509809693820221\n",
      "train loss:0.08335253341793887\n",
      "train loss:0.04042214846369438\n",
      "train loss:0.06038422911649115\n",
      "train loss:0.06754832591869377\n",
      "train loss:0.04538584943572419\n",
      "train loss:0.048641674564616356\n",
      "train loss:0.033624774466530824\n",
      "train loss:0.030444815305015385\n",
      "train loss:0.03230917418981799\n",
      "train loss:0.05674750651213776\n",
      "train loss:0.10237863416121995\n",
      "train loss:0.04078125375807685\n",
      "train loss:0.06159475529835744\n",
      "train loss:0.024257678246821773\n",
      "train loss:0.030741795770292523\n",
      "train loss:0.03280593287872872\n",
      "train loss:0.01900872111602537\n",
      "train loss:0.05230404215379741\n",
      "train loss:0.02713012795496328\n",
      "train loss:0.040697835266209126\n",
      "train loss:0.017574297304660348\n",
      "train loss:0.08699866893775822\n",
      "train loss:0.03622434084690342\n",
      "train loss:0.059743261799807185\n",
      "train loss:0.027965931490138696\n",
      "train loss:0.051043899029770995\n",
      "train loss:0.05997868918656602\n",
      "train loss:0.059750982020469266\n",
      "train loss:0.0695327538166025\n",
      "train loss:0.043576107891415215\n",
      "train loss:0.0271103702095365\n",
      "train loss:0.028733100571651068\n",
      "train loss:0.06153152624939597\n",
      "train loss:0.04731628330050526\n",
      "train loss:0.035641376991983484\n",
      "train loss:0.025876325985055765\n",
      "train loss:0.026415587201047894\n",
      "train loss:0.04454890321588165\n",
      "train loss:0.04552852912563836\n",
      "train loss:0.07479600090882736\n",
      "train loss:0.03358466599229979\n",
      "train loss:0.048240834012919495\n",
      "train loss:0.052313468619790277\n",
      "train loss:0.12256654337853835\n",
      "train loss:0.014900885735282138\n",
      "train loss:0.038585059446404855\n",
      "train loss:0.06334169991366106\n",
      "train loss:0.016071214843325\n",
      "train loss:0.021484463094959962\n",
      "train loss:0.027310373296050957\n",
      "train loss:0.03535776375172511\n",
      "train loss:0.03468238712405034\n",
      "train loss:0.05085807900758057\n",
      "train loss:0.0423744545124636\n",
      "train loss:0.041279040415191044\n",
      "train loss:0.028490301439849798\n",
      "=== epoch:24, train acc:0.981, test acc:0.904 ===\n",
      "train loss:0.029197998659478877\n",
      "train loss:0.06836479862651709\n",
      "train loss:0.039584970357987824\n",
      "train loss:0.09289872806326203\n",
      "train loss:0.04419132130394952\n",
      "train loss:0.11916839135014405\n",
      "train loss:0.05549802282098483\n",
      "train loss:0.05868586184435893\n",
      "train loss:0.01682640650861137\n",
      "train loss:0.04810741049422492\n",
      "train loss:0.06038310668780832\n",
      "train loss:0.040661276001510246\n",
      "train loss:0.05132573012200829\n",
      "train loss:0.026169675868974306\n",
      "train loss:0.03338013905036733\n",
      "train loss:0.06512911577471264\n",
      "train loss:0.04380057089568432\n",
      "train loss:0.020070418657424136\n",
      "train loss:0.02556367693113745\n",
      "train loss:0.09587920387721559\n",
      "train loss:0.06667882200698065\n",
      "train loss:0.011891440231707932\n",
      "train loss:0.015734459258786134\n",
      "train loss:0.0655702651765831\n",
      "train loss:0.09051921510765369\n",
      "train loss:0.02586871292360425\n",
      "train loss:0.029844918777638178\n",
      "train loss:0.04848026865276309\n",
      "train loss:0.02545142562369613\n",
      "train loss:0.05469927067883306\n",
      "train loss:0.07012742729813323\n",
      "train loss:0.05426504742375214\n",
      "train loss:0.013001984912168476\n",
      "train loss:0.06218414148036323\n",
      "train loss:0.03468473650619353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.030912012693977645\n",
      "train loss:0.03208734097012942\n",
      "train loss:0.03284283127241352\n",
      "train loss:0.02841875276454949\n",
      "train loss:0.04680410017253411\n",
      "train loss:0.046052313105037504\n",
      "train loss:0.02972305011557351\n",
      "train loss:0.034858296315961275\n",
      "train loss:0.0527397213919061\n",
      "train loss:0.031054178141561545\n",
      "train loss:0.04036111526455119\n",
      "train loss:0.029131302957667814\n",
      "train loss:0.10107597645070536\n",
      "train loss:0.06638451208699024\n",
      "train loss:0.08786387889164708\n",
      "train loss:0.04313911542277436\n",
      "train loss:0.06361703314145067\n",
      "train loss:0.04360090748967454\n",
      "train loss:0.044042407680615625\n",
      "train loss:0.021584416831403157\n",
      "train loss:0.03148394872312691\n",
      "train loss:0.027842588272180478\n",
      "train loss:0.06202899969325712\n",
      "train loss:0.0434233899403646\n",
      "train loss:0.04009680444172409\n",
      "train loss:0.028828520333853774\n",
      "train loss:0.01760200214777563\n",
      "train loss:0.03673533096741121\n",
      "train loss:0.029661564125192035\n",
      "train loss:0.052139255720203496\n",
      "train loss:0.024815434314696117\n",
      "train loss:0.018799636683904407\n",
      "train loss:0.08108425648721757\n",
      "train loss:0.016611017543179313\n",
      "train loss:0.03818991804152872\n",
      "train loss:0.0275318153499557\n",
      "train loss:0.04717028650983897\n",
      "train loss:0.06866238897706221\n",
      "train loss:0.02543651166623162\n",
      "train loss:0.0175456415761076\n",
      "train loss:0.028471612040481094\n",
      "train loss:0.03769041443803368\n",
      "train loss:0.04149474418453769\n",
      "train loss:0.05210885144942376\n",
      "train loss:0.014661384947234768\n",
      "train loss:0.04285151047349897\n",
      "train loss:0.0557049252386873\n",
      "train loss:0.07070347728219668\n",
      "train loss:0.028454788050423084\n",
      "train loss:0.0582889362376303\n",
      "train loss:0.027561242123262084\n",
      "train loss:0.03056549955256554\n",
      "train loss:0.04209730293827298\n",
      "train loss:0.02981850084333948\n",
      "train loss:0.06085555675728042\n",
      "train loss:0.02673447775111932\n",
      "train loss:0.033340746334964984\n",
      "train loss:0.02760129813805742\n",
      "train loss:0.04402818902085521\n",
      "train loss:0.041630521674926396\n",
      "train loss:0.06454462473803253\n",
      "train loss:0.007721871586389207\n",
      "train loss:0.027234210841005704\n",
      "train loss:0.09105184872516818\n",
      "train loss:0.08486041350986916\n",
      "train loss:0.04414934725426895\n",
      "train loss:0.06417243983470096\n",
      "train loss:0.022834356027615074\n",
      "train loss:0.02600829097173762\n",
      "train loss:0.05821063638673926\n",
      "train loss:0.04351417600354315\n",
      "train loss:0.0455330171110388\n",
      "train loss:0.03281955637754469\n",
      "train loss:0.04682130473063113\n",
      "train loss:0.03656041556739208\n",
      "train loss:0.03009740754038852\n",
      "train loss:0.02566259301096242\n",
      "train loss:0.058190666972226274\n",
      "train loss:0.11178987931497816\n",
      "train loss:0.029432566686274947\n",
      "train loss:0.035081770733931726\n",
      "train loss:0.05357084056181373\n",
      "train loss:0.04029699372874001\n",
      "train loss:0.02863028463860696\n",
      "train loss:0.07175777538875111\n",
      "train loss:0.04482741899476543\n",
      "train loss:0.04112765174888182\n",
      "train loss:0.10319419394305342\n",
      "train loss:0.017752367769350148\n",
      "train loss:0.09213904679916045\n",
      "train loss:0.023244754753000352\n",
      "train loss:0.015117267357204024\n",
      "train loss:0.021426470362730942\n",
      "train loss:0.05632533035693612\n",
      "train loss:0.07194233956312329\n",
      "train loss:0.04441974145701012\n",
      "train loss:0.0382117682548313\n",
      "train loss:0.020010121312325442\n",
      "train loss:0.05103105733060212\n",
      "train loss:0.06529931265753605\n",
      "train loss:0.02602248902025757\n",
      "train loss:0.01866281725805621\n",
      "train loss:0.01757823897966211\n",
      "train loss:0.03649059552126401\n",
      "train loss:0.03313661925083902\n",
      "train loss:0.012333642892957176\n",
      "train loss:0.023772141362771834\n",
      "train loss:0.009670041848057215\n",
      "train loss:0.05152118696589253\n",
      "train loss:0.12150966458775313\n",
      "train loss:0.06935251523032954\n",
      "train loss:0.05263902551144197\n",
      "train loss:0.022226661448228553\n",
      "train loss:0.06257965784973524\n",
      "train loss:0.040426799884544416\n",
      "train loss:0.03558215050467568\n",
      "train loss:0.02624552703095519\n",
      "train loss:0.030014071013692595\n",
      "train loss:0.024231567441505463\n",
      "train loss:0.04472428313662463\n",
      "train loss:0.029510805250383756\n",
      "train loss:0.11459850144978066\n",
      "train loss:0.03936676859542245\n",
      "train loss:0.046459185809125725\n",
      "train loss:0.053947882334160556\n",
      "train loss:0.08085454992231313\n",
      "train loss:0.05830107362464325\n",
      "train loss:0.028277654264007978\n",
      "train loss:0.04926624284525926\n",
      "train loss:0.018992430745624952\n",
      "train loss:0.05484531930431504\n",
      "train loss:0.08293275526756394\n",
      "train loss:0.03944292821655627\n",
      "train loss:0.04503735715001759\n",
      "train loss:0.035101326714752606\n",
      "train loss:0.04121747576368448\n",
      "train loss:0.04623577014247112\n",
      "train loss:0.013608772146816028\n",
      "train loss:0.020047253258153\n",
      "train loss:0.11765402630688009\n",
      "train loss:0.031047267743725758\n",
      "train loss:0.01840878683836799\n",
      "train loss:0.03864028254020649\n",
      "train loss:0.0932596381230888\n",
      "train loss:0.035614766212481275\n",
      "train loss:0.015732184977792017\n",
      "train loss:0.058700451217400834\n",
      "train loss:0.03208522932465093\n",
      "train loss:0.07847322346836327\n",
      "train loss:0.02603516153622433\n",
      "train loss:0.0801868612757997\n",
      "train loss:0.021128896694838733\n",
      "train loss:0.049158804596850965\n",
      "train loss:0.012801397684138696\n",
      "train loss:0.036132368344549956\n",
      "train loss:0.024492263900463027\n",
      "train loss:0.07085018421715285\n",
      "train loss:0.034475042410241546\n",
      "train loss:0.0345701218091484\n",
      "train loss:0.10315914988593397\n",
      "train loss:0.012465918972385099\n",
      "train loss:0.07212754954674595\n",
      "train loss:0.04976298611392989\n",
      "train loss:0.03330428717809722\n",
      "train loss:0.048402513821871065\n",
      "train loss:0.042397438466797645\n",
      "train loss:0.023475869807569782\n",
      "train loss:0.08305797673152578\n",
      "train loss:0.039580911498398146\n",
      "train loss:0.03164049799287316\n",
      "train loss:0.03789513080940011\n",
      "train loss:0.026925804286799308\n",
      "train loss:0.029107499987834674\n",
      "train loss:0.040575549471595106\n",
      "train loss:0.07238414588531619\n",
      "train loss:0.13504419711590487\n",
      "train loss:0.07390012487522922\n",
      "train loss:0.016877052794728162\n",
      "train loss:0.07068690268170434\n",
      "train loss:0.04578507731526196\n",
      "train loss:0.03542209884290839\n",
      "train loss:0.1387508147266968\n",
      "train loss:0.036940047758127585\n",
      "train loss:0.030199467591181427\n",
      "train loss:0.018163202259218247\n",
      "train loss:0.02036802036825001\n",
      "train loss:0.02378119151343155\n",
      "train loss:0.03674402585289909\n",
      "train loss:0.014886484255094637\n",
      "train loss:0.03787296720082942\n",
      "train loss:0.03786570890640462\n",
      "train loss:0.04150412476110518\n",
      "train loss:0.07014144643812442\n",
      "train loss:0.05654742299976315\n",
      "train loss:0.022145492054731222\n",
      "train loss:0.04738172284341289\n",
      "train loss:0.028816384561050908\n",
      "train loss:0.030559881243468624\n",
      "train loss:0.029961002362104763\n",
      "train loss:0.046862856096828456\n",
      "train loss:0.03514541269366333\n",
      "train loss:0.03823322434477871\n",
      "train loss:0.02177563867395\n",
      "train loss:0.06111322098228012\n",
      "train loss:0.05557491108510021\n",
      "train loss:0.0525835188783514\n",
      "train loss:0.053375231606196206\n",
      "train loss:0.05022548732869829\n",
      "train loss:0.03505652904966738\n",
      "train loss:0.044478856597888375\n",
      "train loss:0.037513558594410606\n",
      "train loss:0.02397588298713071\n",
      "train loss:0.056602258615132406\n",
      "train loss:0.02814494008015681\n",
      "train loss:0.04207351102541259\n",
      "train loss:0.1193831827630682\n",
      "train loss:0.03477207584698672\n",
      "train loss:0.028424471306959985\n",
      "train loss:0.04688306095619384\n",
      "train loss:0.011862961549381308\n",
      "train loss:0.045659510430110274\n",
      "train loss:0.09442524836381504\n",
      "train loss:0.02313210850945978\n",
      "train loss:0.04611759223492796\n",
      "train loss:0.0157980744739488\n",
      "train loss:0.05196673239242152\n",
      "train loss:0.021922426695200455\n",
      "train loss:0.03873855952685701\n",
      "train loss:0.038863620103754\n",
      "train loss:0.048733699525258516\n",
      "train loss:0.06322984548352192\n",
      "train loss:0.03655577357904512\n",
      "train loss:0.025737567613930697\n",
      "train loss:0.053493282919405465\n",
      "train loss:0.03173500121254161\n",
      "train loss:0.02295377049813549\n",
      "train loss:0.11637558069520763\n",
      "train loss:0.04959468039805109\n",
      "train loss:0.0378238956995432\n",
      "train loss:0.038254313141164634\n",
      "train loss:0.06460328706752805\n",
      "train loss:0.030626213988017\n",
      "train loss:0.0640352404871877\n",
      "train loss:0.023016544214342655\n",
      "train loss:0.03479033358489683\n",
      "train loss:0.04216345494814977\n",
      "train loss:0.03457131809296113\n",
      "train loss:0.034621523460456397\n",
      "train loss:0.019672202837656215\n",
      "train loss:0.007191246872702819\n",
      "train loss:0.013772781418646218\n",
      "train loss:0.04152635721253154\n",
      "train loss:0.09190015360264567\n",
      "train loss:0.02172543462534061\n",
      "train loss:0.07313375983576259\n",
      "train loss:0.08008541037369797\n",
      "train loss:0.010272701692846109\n",
      "train loss:0.025692459066489676\n",
      "train loss:0.052720293874374574\n",
      "train loss:0.025657054936527188\n",
      "train loss:0.0472995739261226\n",
      "train loss:0.05471761951067255\n",
      "train loss:0.026512173289442168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.013565767271104508\n",
      "train loss:0.07937072164469644\n",
      "train loss:0.04524639413881304\n",
      "train loss:0.05818403064154992\n",
      "train loss:0.057295476310821186\n",
      "train loss:0.1186657351958698\n",
      "train loss:0.05143855845567416\n",
      "train loss:0.050255368261689234\n",
      "train loss:0.02131864293319804\n",
      "train loss:0.02159792665035286\n",
      "train loss:0.12200784986038156\n",
      "train loss:0.04178834072067042\n",
      "train loss:0.03447728011189227\n",
      "train loss:0.03449762428641927\n",
      "train loss:0.05310613163464186\n",
      "train loss:0.02220088559657761\n",
      "train loss:0.03532868482205221\n",
      "train loss:0.0698970429191414\n",
      "train loss:0.09185392270769595\n",
      "train loss:0.10393557071713184\n",
      "train loss:0.03336945469600755\n",
      "train loss:0.037425653276043955\n",
      "train loss:0.03256498338663636\n",
      "train loss:0.0741454074448241\n",
      "train loss:0.0698094635697052\n",
      "train loss:0.011684320544028433\n",
      "train loss:0.021536778254025602\n",
      "train loss:0.08547789874077263\n",
      "train loss:0.041411610841572195\n",
      "train loss:0.09841432829256196\n",
      "train loss:0.048379074162857895\n",
      "train loss:0.033731652872430615\n",
      "train loss:0.02578933501024107\n",
      "train loss:0.04851964676021291\n",
      "train loss:0.024984428479366046\n",
      "train loss:0.010181539364111782\n",
      "train loss:0.04272582678496865\n",
      "train loss:0.017311682199206438\n",
      "train loss:0.030177467593337903\n",
      "train loss:0.05255843235577615\n",
      "train loss:0.03513989079500355\n",
      "train loss:0.07581417172249469\n",
      "train loss:0.07092193168339146\n",
      "train loss:0.02030888244940619\n",
      "train loss:0.05396589551324538\n",
      "train loss:0.017565150709359514\n",
      "train loss:0.01960394595151532\n",
      "train loss:0.07934409514106423\n",
      "train loss:0.039025357935092056\n",
      "train loss:0.042176568588815355\n",
      "train loss:0.03188635544174021\n",
      "train loss:0.1373819847769381\n",
      "train loss:0.04124420195805898\n",
      "train loss:0.01922651645323292\n",
      "train loss:0.034438472748565256\n",
      "train loss:0.0415619934885227\n",
      "train loss:0.06237316876236756\n",
      "train loss:0.06053186981165472\n",
      "train loss:0.04674632945405117\n",
      "train loss:0.021875970233758424\n",
      "train loss:0.021012215673977045\n",
      "train loss:0.1235114666722838\n",
      "train loss:0.04179628095221071\n",
      "train loss:0.0524758359788224\n",
      "train loss:0.017113858533280693\n",
      "train loss:0.03575530987741469\n",
      "train loss:0.023548659688586434\n",
      "train loss:0.08690763660627654\n",
      "train loss:0.020960635366809307\n",
      "train loss:0.13088858076323473\n",
      "train loss:0.08684536274308156\n",
      "train loss:0.04605841069120536\n",
      "train loss:0.014929688672824635\n",
      "train loss:0.01810809907584255\n",
      "train loss:0.014307628711739842\n",
      "train loss:0.09522556687783623\n",
      "train loss:0.02045821237837917\n",
      "train loss:0.03457514783451796\n",
      "train loss:0.03284694539095152\n",
      "train loss:0.027710666084495624\n",
      "train loss:0.023418913499053864\n",
      "train loss:0.05847213801621867\n",
      "train loss:0.022061176233921776\n",
      "train loss:0.026997489897075084\n",
      "train loss:0.03651432394309704\n",
      "train loss:0.045160879800935694\n",
      "train loss:0.0768703628515814\n",
      "train loss:0.028653760888859275\n",
      "train loss:0.025671110335953172\n",
      "train loss:0.01584705950805826\n",
      "train loss:0.017806657865806146\n",
      "train loss:0.05225303129243328\n",
      "train loss:0.05437268656949535\n",
      "train loss:0.10049797721279347\n",
      "train loss:0.008835112044185044\n",
      "train loss:0.06391225144064036\n",
      "train loss:0.017052524523005704\n",
      "train loss:0.053576065458183254\n",
      "train loss:0.016516003892804228\n",
      "train loss:0.0710838358369789\n",
      "train loss:0.039518880383128695\n",
      "train loss:0.020955699117969143\n",
      "train loss:0.04613526149492172\n",
      "train loss:0.04195955306588149\n",
      "train loss:0.06179392852917986\n",
      "train loss:0.07939308100356206\n",
      "train loss:0.09141868205367715\n",
      "train loss:0.029660533926275417\n",
      "train loss:0.0388193071282131\n",
      "train loss:0.03292202735062823\n",
      "train loss:0.02849967967625327\n",
      "train loss:0.029090667896415942\n",
      "train loss:0.05409794776006498\n",
      "train loss:0.05647061781292047\n",
      "train loss:0.03120730803992544\n",
      "train loss:0.03495933789723034\n",
      "train loss:0.008288385783605247\n",
      "train loss:0.09789458893821712\n",
      "train loss:0.01567629580542117\n",
      "train loss:0.03286252041918092\n",
      "train loss:0.03825752290004025\n",
      "train loss:0.02276035026555047\n",
      "train loss:0.03661149770103726\n",
      "train loss:0.03763831263475627\n",
      "train loss:0.06101208056982327\n",
      "train loss:0.0334453868956517\n",
      "train loss:0.058666510765996494\n",
      "train loss:0.018137042665438877\n",
      "train loss:0.010965953364529317\n",
      "train loss:0.04349517805696721\n",
      "train loss:0.033118323553239445\n",
      "train loss:0.042293310882309705\n",
      "train loss:0.02944354295751543\n",
      "train loss:0.019864451178599498\n",
      "train loss:0.03263409880446749\n",
      "train loss:0.05281563820111214\n",
      "train loss:0.0181714658040271\n",
      "train loss:0.04020431369393947\n",
      "train loss:0.02306859243955841\n",
      "train loss:0.022801526987799036\n",
      "train loss:0.042196417709249416\n",
      "train loss:0.04425596898917087\n",
      "train loss:0.022046814736123667\n",
      "train loss:0.03984627677652549\n",
      "train loss:0.03043360884968576\n",
      "train loss:0.020575638672123763\n",
      "train loss:0.06895179304620015\n",
      "train loss:0.03706849759823659\n",
      "train loss:0.039875245906956666\n",
      "train loss:0.033985264092906885\n",
      "train loss:0.029092446872643663\n",
      "train loss:0.04531826238801698\n",
      "train loss:0.02382197529504033\n",
      "train loss:0.019757139313049125\n",
      "train loss:0.03366852490195682\n",
      "train loss:0.03746479671809131\n",
      "train loss:0.02352415513006726\n",
      "train loss:0.04044673491793246\n",
      "train loss:0.03589435993990751\n",
      "train loss:0.035567630201450866\n",
      "train loss:0.012347880928957554\n",
      "train loss:0.028042138491484417\n",
      "train loss:0.018797321026737077\n",
      "train loss:0.011117827817930592\n",
      "train loss:0.022787747094228216\n",
      "train loss:0.041719714196447884\n",
      "train loss:0.05057120578644542\n",
      "train loss:0.03121426613069092\n",
      "train loss:0.03841841556000669\n",
      "train loss:0.03838888836380398\n",
      "train loss:0.0097415346784776\n",
      "train loss:0.02245750685733621\n",
      "train loss:0.022126197038666723\n",
      "train loss:0.025107229611386762\n",
      "train loss:0.06835439588471465\n",
      "train loss:0.05481937113358973\n",
      "train loss:0.031418801730270014\n",
      "train loss:0.01760990496521676\n",
      "train loss:0.03847006274570471\n",
      "train loss:0.018210030003249746\n",
      "train loss:0.02929519976210563\n",
      "train loss:0.01865323968723988\n",
      "train loss:0.015501188484189011\n",
      "train loss:0.028976047509458848\n",
      "train loss:0.01829255086646781\n",
      "train loss:0.08772475639627539\n",
      "train loss:0.021350701315184083\n",
      "train loss:0.05621417472482885\n",
      "train loss:0.049298703330843546\n",
      "train loss:0.06949713790713279\n",
      "train loss:0.07257831471778116\n",
      "train loss:0.015449019613543025\n",
      "train loss:0.06920058340017993\n",
      "train loss:0.03363723305961845\n",
      "train loss:0.03648735279363049\n",
      "train loss:0.037519528681407094\n",
      "train loss:0.0735295877943613\n",
      "train loss:0.0464126647864358\n",
      "train loss:0.06116209538587702\n",
      "train loss:0.01717136010800901\n",
      "train loss:0.03052430157446248\n",
      "train loss:0.010808294725671037\n",
      "train loss:0.023084875353579486\n",
      "train loss:0.020566515924147776\n",
      "train loss:0.02974339446450537\n",
      "train loss:0.06555499723990016\n",
      "train loss:0.15207134195175934\n",
      "train loss:0.04865629757821897\n",
      "train loss:0.027269844792869855\n",
      "train loss:0.032574442953877195\n",
      "train loss:0.05850616772094721\n",
      "train loss:0.037763479854132934\n",
      "train loss:0.06247057082160233\n",
      "train loss:0.0230468684621236\n",
      "train loss:0.04780776306262747\n",
      "train loss:0.02262093073024662\n",
      "train loss:0.032725177756563716\n",
      "train loss:0.016914351321771225\n",
      "train loss:0.02945729721918001\n",
      "train loss:0.0480074621599468\n",
      "train loss:0.04094082463154248\n",
      "train loss:0.039393658446642554\n",
      "train loss:0.019355614122101024\n",
      "train loss:0.05869812198224597\n",
      "train loss:0.06385453366010072\n",
      "train loss:0.016164327881548913\n",
      "train loss:0.0487894267131181\n",
      "train loss:0.016040100666997598\n",
      "train loss:0.063635286099294\n",
      "train loss:0.01976527879497225\n",
      "train loss:0.06470233935806165\n",
      "train loss:0.030106504507184682\n",
      "train loss:0.04975335479559868\n",
      "train loss:0.029475579927174533\n",
      "train loss:0.019466308218487584\n",
      "train loss:0.03907020095988754\n",
      "train loss:0.028171168737290087\n",
      "train loss:0.040656910231614794\n",
      "train loss:0.06932738723631922\n",
      "train loss:0.028831637001534488\n",
      "train loss:0.03661962393975996\n",
      "train loss:0.05488894134667432\n",
      "train loss:0.0442336401744343\n",
      "train loss:0.07970510304169184\n",
      "train loss:0.05701692455528913\n",
      "train loss:0.06654696059541798\n",
      "train loss:0.02845395329949954\n",
      "train loss:0.04254020626022359\n",
      "train loss:0.07151745607226928\n",
      "train loss:0.025894118277457103\n",
      "train loss:0.029637334226738567\n",
      "train loss:0.009875534783901343\n",
      "train loss:0.022718913321050214\n",
      "train loss:0.04211446491726654\n",
      "train loss:0.025583221021624244\n",
      "train loss:0.036682769493652484\n",
      "train loss:0.03431296187401164\n",
      "train loss:0.02167567779223907\n",
      "train loss:0.02352666052684119\n",
      "train loss:0.013242422507061173\n",
      "train loss:0.025554004927703766\n",
      "train loss:0.0335378319022534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.01207397507736755\n",
      "train loss:0.042538407258606824\n",
      "train loss:0.09305830052498858\n",
      "train loss:0.037155384337502255\n",
      "train loss:0.06964656508819508\n",
      "train loss:0.039222415268401895\n",
      "train loss:0.06350674998557357\n",
      "train loss:0.0246230673520489\n",
      "train loss:0.020636329620865465\n",
      "train loss:0.013394117598863841\n",
      "train loss:0.03569312337899211\n",
      "train loss:0.028489466714786013\n",
      "train loss:0.0407621460453905\n",
      "train loss:0.09493174008603322\n",
      "train loss:0.0371621868942483\n",
      "train loss:0.03513185598445757\n",
      "train loss:0.0430924219039961\n",
      "train loss:0.022950497235223064\n",
      "train loss:0.0460340760187728\n",
      "train loss:0.03511277767837479\n",
      "train loss:0.029077750978928858\n",
      "train loss:0.04418926945127061\n",
      "train loss:0.011658722854210603\n",
      "train loss:0.028995001283225092\n",
      "train loss:0.028305319970521613\n",
      "train loss:0.049052238793307355\n",
      "train loss:0.056503595575079696\n",
      "train loss:0.007493463742089217\n",
      "train loss:0.032705846671879535\n",
      "train loss:0.053107758940581624\n",
      "train loss:0.055682798552769155\n",
      "train loss:0.012238921174246712\n",
      "train loss:0.04475731126913527\n",
      "train loss:0.03576883635952619\n",
      "train loss:0.04217098329195679\n",
      "train loss:0.0461632820848239\n",
      "train loss:0.03468772664984515\n",
      "train loss:0.03999543463177944\n",
      "train loss:0.027852351809494545\n",
      "train loss:0.020289130575112075\n",
      "=== epoch:25, train acc:0.982, test acc:0.912 ===\n",
      "train loss:0.03514092682028313\n",
      "train loss:0.051994692088055114\n",
      "train loss:0.01684875525380179\n",
      "train loss:0.012143516106966823\n",
      "train loss:0.061159551944962205\n",
      "train loss:0.036973558096841386\n",
      "train loss:0.037482713960852856\n",
      "train loss:0.05976035805433631\n",
      "train loss:0.05145988151078881\n",
      "train loss:0.012449045723256532\n",
      "train loss:0.031168524920219872\n",
      "train loss:0.04578085551879327\n",
      "train loss:0.07262008737218968\n",
      "train loss:0.04754043008371105\n",
      "train loss:0.030379708958469812\n",
      "train loss:0.029270329863948622\n",
      "train loss:0.03176242054185223\n",
      "train loss:0.039195174778037106\n",
      "train loss:0.025706724915162144\n",
      "train loss:0.050266304162397815\n",
      "train loss:0.018997837017831355\n",
      "train loss:0.02455826529412533\n",
      "train loss:0.06039081905193924\n",
      "train loss:0.12954066086400381\n",
      "train loss:0.05731838551371243\n",
      "train loss:0.040308589358759445\n",
      "train loss:0.05042380868421322\n",
      "train loss:0.04178451976041957\n",
      "train loss:0.05017973854766496\n",
      "train loss:0.038875033271573135\n",
      "train loss:0.044174563527360974\n",
      "train loss:0.10684666004830624\n",
      "train loss:0.063904139837979\n",
      "train loss:0.04079866079688197\n",
      "train loss:0.11454033402096296\n",
      "train loss:0.05934638500064872\n",
      "train loss:0.020448927656374995\n",
      "train loss:0.019045331341377533\n",
      "train loss:0.04083081834673912\n",
      "train loss:0.0729515730679035\n",
      "train loss:0.01899226213930456\n",
      "train loss:0.049692368934270315\n",
      "train loss:0.08012633445831834\n",
      "train loss:0.0672398185942034\n",
      "train loss:0.017118396405310207\n",
      "train loss:0.027524553971080713\n",
      "train loss:0.042489084593795946\n",
      "train loss:0.018737371969728328\n",
      "train loss:0.037901004806330914\n",
      "train loss:0.029314002852167724\n",
      "train loss:0.02665560314998691\n",
      "train loss:0.05061989851356068\n",
      "train loss:0.014762098282331697\n",
      "train loss:0.060537147599954606\n",
      "train loss:0.04581542529800186\n",
      "train loss:0.03128357955906985\n",
      "train loss:0.05360722499290407\n",
      "train loss:0.03922444498869978\n",
      "train loss:0.08365556871749014\n",
      "train loss:0.021389413221403676\n",
      "train loss:0.02075858550034092\n",
      "train loss:0.08681515784714039\n",
      "train loss:0.04300341192839019\n",
      "train loss:0.031175096932099827\n",
      "train loss:0.05144942346381022\n",
      "train loss:0.022302779196007348\n",
      "train loss:0.04774576120876132\n",
      "train loss:0.05286777338092495\n",
      "train loss:0.032936485089881985\n",
      "train loss:0.019203906572523938\n",
      "train loss:0.009765988303685526\n",
      "train loss:0.017325434066122847\n",
      "train loss:0.031418616546436226\n",
      "train loss:0.029941065897613965\n",
      "train loss:0.029770850217146424\n",
      "train loss:0.042102996485671056\n",
      "train loss:0.06072768816013519\n",
      "train loss:0.018565794889528916\n",
      "train loss:0.02324161571431836\n",
      "train loss:0.03793322359931459\n",
      "train loss:0.025019871007193762\n",
      "train loss:0.02409360421076206\n",
      "train loss:0.050663461483407446\n",
      "train loss:0.0437235245258667\n",
      "train loss:0.02635098075874092\n",
      "train loss:0.04313873323770483\n",
      "train loss:0.023508460042280875\n",
      "train loss:0.01851153760431802\n",
      "train loss:0.041652204729285415\n",
      "train loss:0.04929916414572468\n",
      "train loss:0.026585795931244282\n",
      "train loss:0.05158006903434116\n",
      "train loss:0.06111743496924747\n",
      "train loss:0.03569180334035852\n",
      "train loss:0.022898605174980113\n",
      "train loss:0.042402151722914484\n",
      "train loss:0.04983949670158623\n",
      "train loss:0.03433357878646277\n",
      "train loss:0.07912161762863897\n",
      "train loss:0.017568197172840073\n",
      "train loss:0.06680297124999203\n",
      "train loss:0.026058975883044445\n",
      "train loss:0.054272701105796343\n",
      "train loss:0.06610884686362212\n",
      "train loss:0.043490380509119096\n",
      "train loss:0.027518915384121424\n",
      "train loss:0.04220525903363554\n",
      "train loss:0.053618647015053894\n",
      "train loss:0.023221057277378807\n",
      "train loss:0.01635244749473159\n",
      "train loss:0.01488354137353082\n",
      "train loss:0.008284730933566494\n",
      "train loss:0.03498515531506307\n",
      "train loss:0.08283623117095637\n",
      "train loss:0.031234148938477615\n",
      "train loss:0.02051935979246519\n",
      "train loss:0.059451694010891565\n",
      "train loss:0.06329120326524773\n",
      "train loss:0.05894000334504236\n",
      "train loss:0.023705279458800382\n",
      "train loss:0.025896322260672115\n",
      "train loss:0.07565257929453985\n",
      "train loss:0.01704959951352637\n",
      "train loss:0.016115601084399966\n",
      "train loss:0.07758568396881453\n",
      "train loss:0.06666052843415687\n",
      "train loss:0.04909616898268081\n",
      "train loss:0.07043296045525016\n",
      "train loss:0.034652772645091916\n",
      "train loss:0.026870898287719935\n",
      "train loss:0.07648700564012759\n",
      "train loss:0.03839899519238698\n",
      "train loss:0.0707799853049284\n",
      "train loss:0.07867880535823789\n",
      "train loss:0.025695138027301848\n",
      "train loss:0.048110076299078895\n",
      "train loss:0.02865188132743572\n",
      "train loss:0.032482420849543406\n",
      "train loss:0.03377792869883232\n",
      "train loss:0.01803570489318673\n",
      "train loss:0.006054931808754207\n",
      "train loss:0.03050322736124276\n",
      "train loss:0.016302056194299832\n",
      "train loss:0.032337516322896095\n",
      "train loss:0.08373073289852263\n",
      "train loss:0.03527827093115518\n",
      "train loss:0.04936169507366455\n",
      "train loss:0.08136573724847337\n",
      "train loss:0.025891327211992863\n",
      "train loss:0.045471430581515655\n",
      "train loss:0.023820606846983044\n",
      "train loss:0.05057925100621791\n",
      "train loss:0.05525786498740213\n",
      "train loss:0.025916955822251352\n",
      "train loss:0.049028409121919074\n",
      "train loss:0.035891772100492034\n",
      "train loss:0.05765478588626273\n",
      "train loss:0.022799395825371674\n",
      "train loss:0.02161848876785779\n",
      "train loss:0.05043535753842033\n",
      "train loss:0.04814359601154019\n",
      "train loss:0.019022514837972994\n",
      "train loss:0.0538076994816878\n",
      "train loss:0.027320154313190837\n",
      "train loss:0.10932192677436321\n",
      "train loss:0.03114919077261716\n",
      "train loss:0.05420734099894048\n",
      "train loss:0.03449403525593077\n",
      "train loss:0.01936405849336912\n",
      "train loss:0.026279379883137572\n",
      "train loss:0.021058153348508322\n",
      "train loss:0.04196323805478535\n",
      "train loss:0.07446695703823539\n",
      "train loss:0.03336164213736194\n",
      "train loss:0.02953350209801592\n",
      "train loss:0.04564962798627756\n",
      "train loss:0.07233963409289347\n",
      "train loss:0.01894004962842872\n",
      "train loss:0.060528770220549984\n",
      "train loss:0.03847174393519698\n",
      "train loss:0.053595820936215344\n",
      "train loss:0.09863740150194694\n",
      "train loss:0.041573658809268395\n",
      "train loss:0.029134557234588146\n",
      "train loss:0.04189806760701824\n",
      "train loss:0.03120484497258455\n",
      "train loss:0.045670935441016774\n",
      "train loss:0.06327670606293402\n",
      "train loss:0.029690502591880268\n",
      "train loss:0.01697696021219123\n",
      "train loss:0.05769662410651593\n",
      "train loss:0.057837204910295155\n",
      "train loss:0.026033733611210884\n",
      "train loss:0.05672279340255733\n",
      "train loss:0.05745783021513606\n",
      "train loss:0.047117379873184005\n",
      "train loss:0.10659466146538873\n",
      "train loss:0.0241020909362984\n",
      "train loss:0.060842213610673906\n",
      "train loss:0.04481300420920726\n",
      "train loss:0.08771748062624395\n",
      "train loss:0.04587826881587263\n",
      "train loss:0.013913069296728309\n",
      "train loss:0.025091287096184037\n",
      "train loss:0.06938531346886863\n",
      "train loss:0.025814949100907456\n",
      "train loss:0.028580129871940856\n",
      "train loss:0.025628767990673196\n",
      "train loss:0.024851565717340818\n",
      "train loss:0.05406492187218286\n",
      "train loss:0.04388165281478182\n",
      "train loss:0.05010587297236316\n",
      "train loss:0.05515996218483714\n",
      "train loss:0.033853567635669546\n",
      "train loss:0.0649216325826622\n",
      "train loss:0.024165733838038675\n",
      "train loss:0.02895511037975213\n",
      "train loss:0.029224165712607105\n",
      "train loss:0.04525795479731357\n",
      "train loss:0.021038747576771075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.08542993624856952\n",
      "train loss:0.057878826421370544\n",
      "train loss:0.04340540712508772\n",
      "train loss:0.02705126821496587\n",
      "train loss:0.018969555913102093\n",
      "train loss:0.04098128796809615\n",
      "train loss:0.01719697888221232\n",
      "train loss:0.04754692273579129\n",
      "train loss:0.07910742221632044\n",
      "train loss:0.06056278032029162\n",
      "train loss:0.013515073877831822\n",
      "train loss:0.04474965450263797\n",
      "train loss:0.0362640745469558\n",
      "train loss:0.00837460986103942\n",
      "train loss:0.02268371765383903\n",
      "train loss:0.030470676228992067\n",
      "train loss:0.016301846604739188\n",
      "train loss:0.12302718334662821\n",
      "train loss:0.017155660992557144\n",
      "train loss:0.032139114578209185\n",
      "train loss:0.043565994933628366\n",
      "train loss:0.07632530208681308\n",
      "train loss:0.03768895179988692\n",
      "train loss:0.01100514481021867\n",
      "train loss:0.0845169893077384\n",
      "train loss:0.10507746788270701\n",
      "train loss:0.060190045571300504\n",
      "train loss:0.03922398443291467\n",
      "train loss:0.05002100563137689\n",
      "train loss:0.07517596224001005\n",
      "train loss:0.034963248207745046\n",
      "train loss:0.06062415908105435\n",
      "train loss:0.005889145919174561\n",
      "train loss:0.03285963397629668\n",
      "train loss:0.03213479205878493\n",
      "train loss:0.021100431315600073\n",
      "train loss:0.03833034519941036\n",
      "train loss:0.09980085874465466\n",
      "train loss:0.040288390484657724\n",
      "train loss:0.024606666609338742\n",
      "train loss:0.036220274365777114\n",
      "train loss:0.08061079746925155\n",
      "train loss:0.012884897137838434\n",
      "train loss:0.04069278957898555\n",
      "train loss:0.07917921532623268\n",
      "train loss:0.06461467682044708\n",
      "train loss:0.013993457314826475\n",
      "train loss:0.017638997333611427\n",
      "train loss:0.05610762703206202\n",
      "train loss:0.030887144456495\n",
      "train loss:0.04792216241476824\n",
      "train loss:0.031232720788446303\n",
      "train loss:0.017371282477654137\n",
      "train loss:0.06619528166818887\n",
      "train loss:0.013390746798948878\n",
      "train loss:0.04841643405528078\n",
      "train loss:0.07067162303241956\n",
      "train loss:0.026059430104060134\n",
      "train loss:0.0243027943347019\n",
      "train loss:0.058601950185061036\n",
      "train loss:0.0187402035826675\n",
      "train loss:0.03912686134241779\n",
      "train loss:0.061914699586426314\n",
      "train loss:0.02575633784981632\n",
      "train loss:0.041353064313313447\n",
      "train loss:0.026088706728016574\n",
      "train loss:0.037542085380613356\n",
      "train loss:0.08092188504215841\n",
      "train loss:0.03383463610704229\n",
      "train loss:0.04430606687019342\n",
      "train loss:0.036831122630220425\n",
      "train loss:0.014361611049661448\n",
      "train loss:0.011530854311660867\n",
      "train loss:0.09368479010867889\n",
      "train loss:0.03950753730695817\n",
      "train loss:0.026598040260581955\n",
      "train loss:0.0406442249849147\n",
      "train loss:0.032032434024938695\n",
      "train loss:0.015104995232047487\n",
      "train loss:0.029172481815708095\n",
      "train loss:0.04225847458117436\n",
      "train loss:0.029766561328106025\n",
      "train loss:0.03033747241267769\n",
      "train loss:0.014446071736868413\n",
      "train loss:0.0250706764341891\n",
      "train loss:0.02794738720151448\n",
      "train loss:0.05875800522393936\n",
      "train loss:0.04262320745969776\n",
      "train loss:0.06613162581196046\n",
      "train loss:0.05170945212845754\n",
      "train loss:0.08350638717289925\n",
      "train loss:0.05724900388163326\n",
      "train loss:0.014771505136991875\n",
      "train loss:0.029864651080376895\n",
      "train loss:0.02495192462622599\n",
      "train loss:0.042400854820420955\n",
      "train loss:0.03519900656566806\n",
      "train loss:0.058794486244550026\n",
      "train loss:0.02627009749460392\n",
      "train loss:0.0358952283495779\n",
      "train loss:0.022878255777042868\n",
      "train loss:0.02300973545465092\n",
      "train loss:0.07817896752997737\n",
      "train loss:0.041385291900276185\n",
      "train loss:0.029686806220037054\n",
      "train loss:0.05345664052684745\n",
      "train loss:0.01389734974276855\n",
      "train loss:0.03567113494007055\n",
      "train loss:0.023387700645774223\n",
      "train loss:0.02681285256889994\n",
      "train loss:0.013846057364367743\n",
      "train loss:0.08659684340359405\n",
      "train loss:0.058067558196703215\n",
      "train loss:0.010612118717063378\n",
      "train loss:0.04396773898933132\n",
      "train loss:0.019875206979929887\n",
      "train loss:0.024133851762814098\n",
      "train loss:0.040491271278448045\n",
      "train loss:0.0441138615905845\n",
      "train loss:0.011669278852260741\n",
      "train loss:0.04232954002210784\n",
      "train loss:0.08143033592571813\n",
      "train loss:0.021714812737434787\n",
      "train loss:0.008022627846565416\n",
      "train loss:0.09328140070067831\n",
      "train loss:0.023137606541893452\n",
      "train loss:0.0313589658259262\n",
      "train loss:0.017672885017606502\n",
      "train loss:0.07081062846577642\n",
      "train loss:0.03404974193519936\n",
      "train loss:0.04537326172193351\n",
      "train loss:0.018056332390665335\n",
      "train loss:0.05432164005040228\n",
      "train loss:0.039312233636126924\n",
      "train loss:0.009751710355048312\n",
      "train loss:0.029406802446548478\n",
      "train loss:0.011519889815833396\n",
      "train loss:0.02712918904734572\n",
      "train loss:0.04273267104587968\n",
      "train loss:0.051558485444141613\n",
      "train loss:0.024198068307079112\n",
      "train loss:0.042030806351050096\n",
      "train loss:0.018778987193698568\n",
      "train loss:0.03301463089753235\n",
      "train loss:0.0651960504636203\n",
      "train loss:0.04133960710794037\n",
      "train loss:0.035306796504356315\n",
      "train loss:0.01183060324945909\n",
      "train loss:0.028885289102602903\n",
      "train loss:0.08296724875975955\n",
      "train loss:0.038295668937949424\n",
      "train loss:0.03370750575948401\n",
      "train loss:0.06849002534942616\n",
      "train loss:0.03012795586314781\n",
      "train loss:0.036806246730719125\n",
      "train loss:0.01347971740544905\n",
      "train loss:0.033756886396904474\n",
      "train loss:0.025173288891128874\n",
      "train loss:0.03346543435167442\n",
      "train loss:0.10627030034073362\n",
      "train loss:0.033115865987700104\n",
      "train loss:0.08806899602436344\n",
      "train loss:0.04713436730901344\n",
      "train loss:0.06041868386840022\n",
      "train loss:0.01686547875135199\n",
      "train loss:0.03977988012520286\n",
      "train loss:0.039030915443007734\n",
      "train loss:0.030242830470392768\n",
      "train loss:0.026423594079050088\n",
      "train loss:0.027987514917835025\n",
      "train loss:0.06154420758189679\n",
      "train loss:0.06752983036583124\n",
      "train loss:0.08352180961510972\n",
      "train loss:0.05586481914806907\n",
      "train loss:0.07039774644022756\n",
      "train loss:0.0744495970388157\n",
      "train loss:0.06431694254633437\n",
      "train loss:0.014582565164390538\n",
      "train loss:0.050601991486680695\n",
      "train loss:0.017748821335731874\n",
      "train loss:0.04649591524964533\n",
      "train loss:0.03564946046800787\n",
      "train loss:0.02689985322423946\n",
      "train loss:0.05234530537066597\n",
      "train loss:0.03248050487498362\n",
      "train loss:0.009429340848743499\n",
      "train loss:0.018631320072177552\n",
      "train loss:0.04436379241534993\n",
      "train loss:0.021153129766824073\n",
      "train loss:0.05565387456552085\n",
      "train loss:0.04354161544173472\n",
      "train loss:0.008546768159846237\n",
      "train loss:0.08564862745165405\n",
      "train loss:0.02733795023097288\n",
      "train loss:0.012836716667452407\n",
      "train loss:0.06549648443436187\n",
      "train loss:0.04893614332619579\n",
      "train loss:0.03879729654749121\n",
      "train loss:0.04712785394020814\n",
      "train loss:0.02149558786191425\n",
      "train loss:0.05945347829493491\n",
      "train loss:0.02443944315780844\n",
      "train loss:0.012051164535079267\n",
      "train loss:0.09611434823896381\n",
      "train loss:0.048887507331727365\n",
      "train loss:0.020370271197939948\n",
      "train loss:0.0321091482594398\n",
      "train loss:0.03229166242912573\n",
      "train loss:0.05879148883922066\n",
      "train loss:0.0864628840202357\n",
      "train loss:0.02924492941402161\n",
      "train loss:0.009237754368240137\n",
      "train loss:0.04091153361791548\n",
      "train loss:0.03676205940456085\n",
      "train loss:0.045097151665545836\n",
      "train loss:0.038244096632965824\n",
      "train loss:0.020452309506199997\n",
      "train loss:0.015254999941468683\n",
      "train loss:0.03353405673686256\n",
      "train loss:0.08583175200627538\n",
      "train loss:0.017142068775887184\n",
      "train loss:0.032839186895382684\n",
      "train loss:0.01761030606332281\n",
      "train loss:0.05245504078278224\n",
      "train loss:0.02072133572183559\n",
      "train loss:0.015415802779211911\n",
      "train loss:0.041390025614061896\n",
      "train loss:0.03891426602634875\n",
      "train loss:0.036894982712974554\n",
      "train loss:0.02821959356852368\n",
      "train loss:0.015845665419884393\n",
      "train loss:0.03398954105899069\n",
      "train loss:0.030846743335647134\n",
      "train loss:0.03868807543395464\n",
      "train loss:0.016566926837005825\n",
      "train loss:0.09113798772859447\n",
      "train loss:0.046573921955193054\n",
      "train loss:0.030705839357300774\n",
      "train loss:0.047012256826294695\n",
      "train loss:0.07896667467251152\n",
      "train loss:0.06321982859613658\n",
      "train loss:0.03420838765003959\n",
      "train loss:0.0442781604323161\n",
      "train loss:0.05000994444838246\n",
      "train loss:0.01827582570750889\n",
      "train loss:0.02006668553516891\n",
      "train loss:0.018977186649449286\n",
      "train loss:0.0099458820545038\n",
      "train loss:0.0368369631233367\n",
      "train loss:0.024053560821724062\n",
      "train loss:0.04865505044444258\n",
      "train loss:0.021045755472199355\n",
      "train loss:0.02670573368247242\n",
      "train loss:0.03758180890092647\n",
      "train loss:0.017669753527592078\n",
      "train loss:0.047353964612343466\n",
      "train loss:0.008598546311685908\n",
      "train loss:0.02964004096703234\n",
      "train loss:0.01593816311063847\n",
      "train loss:0.029886428038463676\n",
      "train loss:0.009057097278596682\n",
      "train loss:0.05867143245579176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.04464939129200595\n",
      "train loss:0.03226541702685963\n",
      "train loss:0.0477629611244317\n",
      "train loss:0.05053257450058294\n",
      "train loss:0.030835956211735772\n",
      "train loss:0.04422585347658612\n",
      "train loss:0.05036841442327107\n",
      "train loss:0.038975421846277204\n",
      "train loss:0.028007382592015583\n",
      "train loss:0.04845328182511976\n",
      "train loss:0.013483808912290481\n",
      "train loss:0.04459708183316625\n",
      "train loss:0.020884972643118564\n",
      "train loss:0.06365798167486501\n",
      "train loss:0.00811626683859581\n",
      "train loss:0.06738534877333219\n",
      "train loss:0.01904799609079633\n",
      "train loss:0.04021617001050707\n",
      "train loss:0.03292473683274801\n",
      "train loss:0.03560989551253452\n",
      "train loss:0.014257677127374193\n",
      "train loss:0.023176360812390807\n",
      "train loss:0.03555599982252323\n",
      "train loss:0.06507469190806744\n",
      "train loss:0.032494864696066654\n",
      "train loss:0.07103288883648147\n",
      "train loss:0.019050058138226415\n",
      "train loss:0.04513512691286134\n",
      "train loss:0.06748699043610802\n",
      "train loss:0.05506211119415874\n",
      "train loss:0.032537674005570894\n",
      "train loss:0.05293201344223922\n",
      "train loss:0.040877434347432615\n",
      "train loss:0.061375036073790155\n",
      "train loss:0.05998795505190763\n",
      "train loss:0.013793573214162547\n",
      "train loss:0.04957529948059987\n",
      "train loss:0.007061994853695575\n",
      "train loss:0.009179247308931045\n",
      "train loss:0.03838673288878725\n",
      "train loss:0.024426101905529587\n",
      "train loss:0.012217510779715581\n",
      "train loss:0.04731636762836004\n",
      "train loss:0.014979773859903378\n",
      "train loss:0.037580102445817824\n",
      "train loss:0.09294097274852625\n",
      "train loss:0.02978396484476642\n",
      "train loss:0.008274510954176927\n",
      "train loss:0.023444504573002747\n",
      "train loss:0.018154155407767228\n",
      "train loss:0.027782336765870594\n",
      "train loss:0.022124312129395238\n",
      "train loss:0.029947261708376454\n",
      "train loss:0.07261996989628765\n",
      "train loss:0.04966630957022497\n",
      "train loss:0.024519469914668038\n",
      "train loss:0.019282837751319268\n",
      "train loss:0.07705804278981626\n",
      "train loss:0.011191445347810145\n",
      "train loss:0.020316488851078715\n",
      "train loss:0.0255860499843542\n",
      "train loss:0.12019815177298965\n",
      "train loss:0.046147741916691576\n",
      "train loss:0.025875046366941202\n",
      "train loss:0.04374521162548751\n",
      "train loss:0.04455880004609286\n",
      "train loss:0.04458239277991345\n",
      "train loss:0.044268843285714184\n",
      "train loss:0.07087443307976266\n",
      "train loss:0.05724806476776446\n",
      "train loss:0.07418671991460558\n",
      "train loss:0.014184597750207221\n",
      "train loss:0.05596367966069605\n",
      "train loss:0.024765222949465707\n",
      "train loss:0.05876758000870447\n",
      "train loss:0.10026391892159443\n",
      "train loss:0.027257341311699948\n",
      "train loss:0.054474604329462446\n",
      "train loss:0.05992508492682124\n",
      "train loss:0.013661742673204162\n",
      "train loss:0.06603266663616318\n",
      "train loss:0.041514214387167764\n",
      "train loss:0.015806205829752677\n",
      "train loss:0.018358644354423404\n",
      "train loss:0.03753769910669513\n",
      "train loss:0.020438641119364286\n",
      "train loss:0.040649869034788025\n",
      "train loss:0.007274163171090905\n",
      "train loss:0.045948034052804364\n",
      "train loss:0.06856066563291596\n",
      "train loss:0.027081326234129482\n",
      "train loss:0.03738320468603464\n",
      "train loss:0.03199751838019142\n",
      "train loss:0.062406206726900476\n",
      "train loss:0.06198764050564226\n",
      "train loss:0.018944628825818308\n",
      "train loss:0.02408499794699204\n",
      "train loss:0.0844871739529981\n",
      "train loss:0.03193825981458559\n",
      "train loss:0.022860142332227475\n",
      "train loss:0.037231456071703646\n",
      "train loss:0.036508839436582306\n",
      "train loss:0.03559980851000976\n",
      "train loss:0.035548637729031406\n",
      "train loss:0.04179910314257964\n",
      "train loss:0.02779879110335976\n",
      "train loss:0.09760880280340926\n",
      "train loss:0.026003503715214697\n",
      "train loss:0.049698493036797194\n",
      "train loss:0.1186459119578613\n",
      "train loss:0.08156828742901784\n",
      "train loss:0.03478743213116375\n",
      "train loss:0.014238351003904349\n",
      "train loss:0.03857047514865817\n",
      "train loss:0.02768799806922015\n",
      "train loss:0.043216858377409094\n",
      "train loss:0.02141397567113861\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc: 0.914 train acc : 0.9834\n",
      "Saved Network Parameters!\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 25 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "from common.trainer import Trainer\n",
    "\n",
    "# 데이터 읽기\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "# 시간이 오래 걸릴 경우 데이터를 줄인다.\n",
    "#x_train, t_train = x_train[:5000], t_train[:5000]\n",
    "#x_test, t_test = x_test[:1000], t_test[:1000]\n",
    "\n",
    "max_epochs = 25\n",
    "\n",
    "network = SimpleConvNet(input_dim=(1,28,28), \n",
    "                        conv_param = {'filter_num': 30, 'filter_size': 5, 'pad': 0, 'stride': 1},\n",
    "                        hidden_size=100, output_size=10, weight_init_std=0.01)\n",
    "                        \n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=max_epochs, mini_batch_size=100,\n",
    "                  optimizer='Adam', optimizer_param={'lr': 0.001},\n",
    "                  evaluate_sample_num_per_epoch=1000)\n",
    "trainer.train()\n",
    "\n",
    "# 매개변수 보존\n",
    "network.save_params(\"params.pkl\")\n",
    "print(\"Saved Network Parameters!\")\n",
    "\n",
    "\n",
    "\n",
    "# 그래프 그리기\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(max_epochs)\n",
    "plt.plot(x, trainer.train_acc_list, marker='o', label='train', markevery=2)\n",
    "plt.plot(x, trainer.test_acc_list, marker='s', label='test', markevery=2)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "def plot_sample_images(x, y, class_names):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i in range(25):\n",
    "        plt.subplot(5, 5, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(x[i].reshape(28, 28), cmap=plt.cm.binary)\n",
    "        plt.xlabel(class_names[y[i]])\n",
    "    plt.show()\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = load_mnist(normalize=False, flatten=True, one_hot_label=False)\n",
    "\n",
    "class_names = [str(i) for i in range(10)]\n",
    "\n",
    "plot_sample_images(x_train, y_train, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4d789d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
